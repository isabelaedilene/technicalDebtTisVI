file path,line #,comment,satd
keras/keras/optimizers.py,33,if clipnorm == 0 no need to add ops to the graph,not
keras/keras/optimizers.py,36,tf require using a special op to multiply IndexedSliced by scalar,not
keras/keras/optimizers.py,42,saving the shape to avoid converting sparse tensor to dense,not
keras/keras/optimizers.py,160,Legacy support.,not
keras/keras/optimizers.py,199,momentum,not
keras/keras/optimizers.py,205,velocity,not
keras/keras/optimizers.py,213,Apply constraints.,not
keras/keras/optimizers.py,273,update accumulator,not
keras/keras/optimizers.py,278,Apply constraints.,not
keras/keras/optimizers.py,287,Override set_weights for backward compatibility of Keras 2.2.4 optimizer,not
keras/keras/optimizers.py,288,since it does not include iteration at head of the weight list. Set,not
keras/keras/optimizers.py,289,iteration to 0.,not
keras/keras/optimizers.py,348,update accumulator,not
keras/keras/optimizers.py,352,Apply constraints.,not
keras/keras/optimizers.py,361,Override set_weights for backward compatibility of Keras 2.2.4 optimizer,not
keras/keras/optimizers.py,362,since it does not include iteration at head of the weight list. Set,not
keras/keras/optimizers.py,363,iteration to 0.,not
keras/keras/optimizers.py,430,update accumulator,not
keras/keras/optimizers.py,434,use the new accumulator and the *old* delta_accumulator,not
keras/keras/optimizers.py,438,Apply constraints.,not
keras/keras/optimizers.py,444,update delta_accumulator,not
keras/keras/optimizers.py,451,Override set_weights for backward compatibility of Keras 2.2.4 optimizer,not
keras/keras/optimizers.py,452,since it does not include iteration at head of the weight list. Set,not
keras/keras/optimizers.py,453,iteration to 0.,not
keras/keras/optimizers.py,549,Apply constraints.,not
keras/keras/optimizers.py,610,zero init of 1st moment,not
keras/keras/optimizers.py,613,zero init of exponentially weighted infinity norm,not
keras/keras/optimizers.py,628,Apply constraints.,not
keras/keras/optimizers.py,686,"Due to the recommendations in [2], i.e. warming momentum schedule",not
keras/keras/optimizers.py,704,the following equations given in [1],not
keras/keras/optimizers.py,720,Apply constraints.,not
keras/keras/optimizers.py,729,Override set_weights for backward compatibility of Keras 2.2.4 optimizer,not
keras/keras/optimizers.py,730,since it does not include m_schedule at head of the weight list. Set,not
keras/keras/optimizers.py,731,m_schedule to 1.,not
keras/keras/optimizers.py,789,Aliases.,not
keras/keras/optimizers.py,827,Make deserialization case-insensitive for built-in optimizers.,not
keras/keras/optimizers.py,854,Wrap TF optimizer instances,not
keras/keras/initializers.py,27,Initializers saved from `tf.keras`,not
keras/keras/initializers.py,28,may contain an unused `dtype` argument.,not
keras/keras/initializers.py,220,"0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)",not
keras/keras/initializers.py,269,Pick the one with the correct shape.,not
keras/keras/initializers.py,448,Compatibility aliases,not
keras/keras/initializers.py,459,Utility functions,not
keras/keras/initializers.py,482,"Assuming convolution kernels (1D, 2D or 3D).",not
keras/keras/initializers.py,483,"TH kernel shape: (depth, input_depth, ...)",not
keras/keras/initializers.py,484,"TF kernel shape: (..., input_depth, depth)",not
keras/keras/initializers.py,496,No specific assumptions.,not
keras/keras/losses.py,67,If we are wrapping a lambda function strip '<>' from the name as it is not,not
keras/keras/losses.py,68,accepted in scope name.,not
keras/keras/losses.py,740,Convert the binary labels to -1 or 1.,not
keras/keras/losses.py,749,Aliases.,not
keras/keras/constraints.py,146,Aliases.,not
keras/keras/constraints.py,154,Legacy aliases.,not
keras/keras/metrics.py,63,All metric layers are stateful.,not
keras/keras/metrics.py,81,For TF,not
keras/keras/metrics.py,84,We are adding the metric object as metadata on the result tensor.,not
keras/keras/metrics.py,85,This is required when we want to use a metric with `add_metric` API on,not
keras/keras/metrics.py,86,a Model/Layer in graph mode. This metric instance will later be used,not
keras/keras/metrics.py,87,to reset variable state after each epoch of training.,not
keras/keras/metrics.py,88,Example:,not
keras/keras/metrics.py,89,model = Model(),not
keras/keras/metrics.py,90,mean = Mean(),not
keras/keras/metrics.py,91,"model.add_metric(mean(values), name='mean')",not
keras/keras/metrics.py,121,For use by subclasses,not
keras/keras/metrics.py,135,End: For use by subclasses,not
keras/keras/metrics.py,176,Update dimensions of weights to match with values if possible.,not
keras/keras/metrics.py,180,Broadcast weights if possible.,not
keras/keras/metrics.py,188,Exit early if the reduction doesn't have a denominator.,not
keras/keras/metrics.py,192,Update `count` for reductions that require a denominator.,not
keras/keras/metrics.py,1183,"Compute `num_thresholds` thresholds in [0, 1]",not
keras/keras/metrics.py,1256,Calculate specificities at all the thresholds.,not
keras/keras/metrics.py,1262,Find the index of the threshold where the specificity is closest to the,not
keras/keras/metrics.py,1263,given specificity.,not
keras/keras/metrics.py,1268,Compute sensitivity at that index.,not
keras/keras/metrics.py,1329,Calculate sensitivities at all the thresholds.,not
keras/keras/metrics.py,1335,Find the index of the threshold where the sensitivity is closest to the,not
keras/keras/metrics.py,1336,given specificity.,not
keras/keras/metrics.py,1341,Compute specificity at that index.,not
keras/keras/metrics.py,1641,Validate configurations.,not
keras/keras/metrics.py,1654,Update properties.,not
keras/keras/metrics.py,1656,"If specified, use the supplied thresholds.",not
keras/keras/metrics.py,1663,"Otherwise, linearly interpolate (num_thresholds - 2) thresholds in",not
keras/keras/metrics.py,1664,"(0, 1).",not
keras/keras/metrics.py,1669,"Add an endpoint ""threshold"" below zero and above one for either",not
keras/keras/metrics.py,1670,threshold method to account for floating point imprecisions.,not
keras/keras/metrics.py,1684,Create metric variables,not
keras/keras/metrics.py,1766,Logical and,not
keras/keras/metrics.py,1791,This use case is different and is handled separately.,not
keras/keras/metrics.py,1794,Set `x` and `y` values for the curves based on `curve` config.,not
keras/keras/metrics.py,1808,curve == 'PR'.,not
keras/keras/metrics.py,1816,Find the rectangle heights based on `summation_method`.,not
keras/keras/metrics.py,1818,"Note: the case ('PR', 'interpolation') has been handled above.",not
keras/keras/metrics.py,1822,self.summation_method = metrics_utils.AUCSummationMethod.MAJORING:,not
keras/keras/metrics.py,1825,Sum up the areas of all the rectangles.,not
keras/keras/metrics.py,1837,We remove the endpoint thresholds as an inverse of how the thresholds,not
keras/keras/metrics.py,1838,were initialized. This ensures that a metric initialized from this,not
keras/keras/metrics.py,1839,config has the same thresholds.,not
keras/keras/metrics.py,1912,"reshape in case it's in shape (num_samples, 1) instead of (num_samples,)",not
keras/keras/metrics.py,1915,convert dense predictions to labels,not
keras/keras/metrics.py,1926,"If the shape of y_true is (num_samples, 1), flatten to (num_samples,)",not
keras/keras/metrics.py,1953,Aliases,not
keras/keras/models.py,55,Cache for created layers.,not
keras/keras/models.py,56,"Map {reference_tensor: (corresponding_tensor, mask)}",not
keras/keras/models.py,58,Create placeholders to build the model on top of.,not
keras/keras/models.py,67,Cache newly created input layer.,not
keras/keras/models.py,73,Make sure that all input tensors come from a Keras layer.,not
keras/keras/models.py,74,If tensor comes from an input layer: cache the input layer.,not
keras/keras/models.py,83,Cache newly created input layer.,not
keras/keras/models.py,92,"tensor, mask",not
keras/keras/models.py,94,"Iterated over every node in the reference model, in depth order.",not
keras/keras/models.py,100,Recover the corresponding layer.,not
keras/keras/models.py,103,Get or create layer.,not
keras/keras/models.py,105,Clone layer.,not
keras/keras/models.py,110,Reuse previously cloned layer.,not
keras/keras/models.py,112,Don't call InputLayer multiple times.,not
keras/keras/models.py,116,Gather inputs to call the new layer.,not
keras/keras/models.py,120,"If all previous input tensors are available in tensor_map,",not
keras/keras/models.py,121,then call node.inbound_layer on them.,not
keras/keras/models.py,122,"List of tuples (input, mask).",not
keras/keras/models.py,128,Call layer.,not
keras/keras/models.py,162,Update tensor_map.,not
keras/keras/models.py,168,"Check that we did compute the model outputs,",not
keras/keras/models.py,169,then instantiate a new model from inputs and outputs.,not
keras/keras/__init__.py,21,Also importable from root,not
keras/keras/regularizers.py,50,Aliases.,not
keras/keras/legacy/interfaces.py,572,Model methods,not
keras/keras/legacy/interfaces.py,645,"Old interface: (params, constraints, loss)",not
keras/keras/legacy/interfaces.py,646,"New interface: (loss, params)",not
keras/keras/legacy/interfaces.py,651,Assuming old interface.,not
keras/keras/legacy/layers.py,125,"no activation, this layer is only linear.",not
keras/keras/legacy/layers.py,486,"build an all-zero tensor of shape (samples, output_dim)",not
keras/keras/legacy/layers.py,487,"(samples, timesteps, input_dim)",not
keras/keras/legacy/layers.py,488,"(samples,)",not
keras/keras/legacy/layers.py,489,"(samples, 1)",not
keras/keras/legacy/layers.py,490,"(samples, output_dim)",not
keras/keras/legacy/layers.py,500,"If there are multiple inputs, then",not
keras/keras/legacy/layers.py,501,they should be the main input and `initial_state`,not
keras/keras/legacy/layers.py,502,e.g. when loading model from file,not
keras/keras/legacy/layers.py,508,"If `initial_state` is specified,",not
keras/keras/legacy/layers.py,509,"and if it a Keras tensor,",not
keras/keras/legacy/layers.py,510,then add it to the inputs and temporarily,not
keras/keras/legacy/layers.py,511,modify the input spec to include the state.,not
keras/keras/legacy/layers.py,525,"Compute the full input spec, including state",not
keras/keras/legacy/layers.py,532,"Compute the full inputs, including state",not
keras/keras/legacy/layers.py,535,Perform the call,not
keras/keras/legacy/layers.py,538,Restore original input spec,not
keras/keras/legacy/layers.py,546,"input shape: `(samples, time (padded with zeros), input_dim)`",not
keras/keras/legacy/layers.py,547,note that the .build() method of subclasses MUST define,not
keras/keras/legacy/layers.py,548,self.input_spec and self.state_spec with complete input shapes.,not
keras/keras/legacy/layers.py,597,Properly set learning phase,not
keras/keras/legacy/layers.py,628,initialize state if None,not
keras/keras/backend/numpy_backend.py,133,indexing trick,not
keras/keras/backend/numpy_backend.py,205,"expand mask so that `mask[:, t].ndim == x.ndim`",not
keras/keras/backend/numpy_backend.py,220,"tm1 means ""t minus one"" as in ""previous timestep""",not
keras/keras/backend/numpy_backend.py,559,Handle negative axes,not
keras/keras/backend/numpy_backend.py,581,ignore batch dimension,not
keras/keras/backend/load_backend.py,17,"Set Keras base dir path given KERAS_HOME env variable, if applicable.",not
keras/keras/backend/load_backend.py,18,Otherwise either ~/.keras or /tmp.,not
keras/keras/backend/load_backend.py,27,Default backend: TensorFlow.,not
keras/keras/backend/load_backend.py,30,Attempt to read Keras config file.,not
keras/keras/backend/load_backend.py,52,"Save config file, if possible.",not
keras/keras/backend/load_backend.py,57,Except permission denied and potential race conditions,not
keras/keras/backend/load_backend.py,58,in multi-threaded environments.,not
keras/keras/backend/load_backend.py,72,Except permission denied.,not
keras/keras/backend/load_backend.py,75,"Set backend based on KERAS_BACKEND flag, if applicable.",not
keras/keras/backend/load_backend.py,81,Import backend functions.,not
keras/keras/backend/load_backend.py,92,Try and load external backend.,not
keras/keras/backend/load_backend.py,96,Check if valid backend.,not
keras/keras/backend/load_backend.py,97,Module is a valid backend if it has the required entries.,not
keras/keras/backend/load_backend.py,104,"Make sure we don't override any entries from common, such as epsilon.",not
keras/keras/backend/tensorflow_backend.py,32,INTERNAL UTILS,not
keras/keras/backend/tensorflow_backend.py,34,This list holds the available devices.,not
keras/keras/backend/tensorflow_backend.py,35,It is populated when `_get_available_gpus()` is called for the first time.,not
keras/keras/backend/tensorflow_backend.py,36,We assume our devices don't change during our lifetime.,not
keras/keras/backend/tensorflow_backend.py,47,Set initial config,not
keras/keras/backend/tensorflow_backend.py,53,Private TF Keras utils,not
keras/keras/backend/tensorflow_backend.py,55,learning_phase_scope = tf_keras_backend.learning_phase_scope  # TODO,not
keras/keras/backend/tensorflow_backend.py,428,"This step is expensive, so we only run it on variables",not
keras/keras/backend/tensorflow_backend.py,429,not already marked as initialized.,not
keras/keras/backend/tensorflow_backend.py,441,DEVICE MANIPULATION AND PROBING,not
keras/keras/backend/tensorflow_backend.py,447,NOTE(robieta): This differs from tf.keras in that self.device is a,not
keras/keras/backend/tensorflow_backend.py,448,DeviceSpec rather than a string. This is done for compatibility,not
keras/keras/backend/tensorflow_backend.py,449,with a range of TensorFlow versions.,not
keras/keras/backend/tensorflow_backend.py,526,VARIABLE MANIPULATION,not
keras/keras/backend/tensorflow_backend.py,1140,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/tensorflow_backend.py,1178,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/tensorflow_backend.py,1242,UPDATES OPS,not
keras/keras/backend/tensorflow_backend.py,1304,LINEAR ALGEBRA,not
keras/keras/backend/tensorflow_backend.py,1475,"if tuple, convert to list.",not
keras/keras/backend/tensorflow_backend.py,1478,convert negative indices.,not
keras/keras/backend/tensorflow_backend.py,1484,sanity checks,not
keras/keras/backend/tensorflow_backend.py,1501,backup ndims. Need them later.,not
keras/keras/backend/tensorflow_backend.py,1505,"if rank is 2, expand to 3.",not
keras/keras/backend/tensorflow_backend.py,1514,bring x's dimension to be reduced to last axis.,not
keras/keras/backend/tensorflow_backend.py,1522,bring y's dimension to be reduced to axis 1.,not
keras/keras/backend/tensorflow_backend.py,1530,normalize both inputs to rank 3.,not
keras/keras/backend/tensorflow_backend.py,1532,squash middle dimensions of x.,not
keras/keras/backend/tensorflow_backend.py,1543,squash trailing dimensions of y.,not
keras/keras/backend/tensorflow_backend.py,1555,"if inputs were squashed, we have to reshape the matmul output.",not
keras/keras/backend/tensorflow_backend.py,1572,"if the inputs were originally rank 2, we remove the added 1 dim.",not
keras/keras/backend/tensorflow_backend.py,1632,ELEMENT-WISE OPERATIONS,not
keras/keras/backend/tensorflow_backend.py,2349,The CPU implementation of FusedBatchNorm only support NHWC,not
keras/keras/backend/tensorflow_backend.py,2361,The mean / var / beta / gamma may be processed by broadcast,not
keras/keras/backend/tensorflow_backend.py,2362,"so it may have extra axes with 1,",not
keras/keras/backend/tensorflow_backend.py,2363,it is not needed and should be removed,not
keras/keras/backend/tensorflow_backend.py,2402,default,not
keras/keras/backend/tensorflow_backend.py,2406,SHAPE OPERATIONS,not
keras/keras/backend/tensorflow_backend.py,2561,For static axis,not
keras/keras/backend/tensorflow_backend.py,2563,slices along the repeat axis,not
keras/keras/backend/tensorflow_backend.py,2565,repeat each slice the given number of reps,not
keras/keras/backend/tensorflow_backend.py,2569,Here we use tf.tile to mimic behavior of np.repeat so that,not
keras/keras/backend/tensorflow_backend.py,2570,we can handle dynamic shapes (that include None).,not
keras/keras/backend/tensorflow_backend.py,2571,"To do that, we need an auxiliary axis to repeat elements along",not
keras/keras/backend/tensorflow_backend.py,2572,it and then merge them along the desired axis.,not
keras/keras/backend/tensorflow_backend.py,2574,Repeating,not
keras/keras/backend/tensorflow_backend.py,2582,Merging,not
keras/keras/backend/tensorflow_backend.py,2589,Fix shape representation,not
keras/keras/backend/tensorflow_backend.py,2635,Match the behavior of numpy and Theano by returning an empty sequence.,not
keras/keras/backend/tensorflow_backend.py,2641,Handle case where start is a tensor,not
keras/keras/backend/tensorflow_backend.py,2683,Padding the axis,not
keras/keras/backend/tensorflow_backend.py,2912,VALUE MANIPULATION,not
keras/keras/backend/tensorflow_backend.py,3001,GRAPH MANIPULATION,not
keras/keras/backend/tensorflow_backend.py,3046,CONTROL FLOW,not
keras/keras/backend/tensorflow_backend.py,3149,tf.where needs its condition tensor,not
keras/keras/backend/tensorflow_backend.py,3150,to be the same shape as its two,not
keras/keras/backend/tensorflow_backend.py,3151,result tensors,not
keras/keras/backend/tensorflow_backend.py,3213,else: assume learning phase is a placeholder tensor.,not
keras/keras/backend/tensorflow_backend.py,3241,NN OPERATIONS,not
keras/keras/backend/tensorflow_backend.py,3277,computes x for x > threshold else 0,not
keras/keras/backend/tensorflow_backend.py,3280,"if no threshold, then can use nn.relu6 native TF op for performance",not
keras/keras/backend/tensorflow_backend.py,3523,Note that the order of the 2 first positional arguments,not
keras/keras/backend/tensorflow_backend.py,3524,has been inverted in TF 2.,not
keras/keras/backend/tensorflow_backend.py,3530,CONVOLUTIONS,not
keras/keras/backend/tensorflow_backend.py,3543,tensorflow doesn't support float64 for conv layer before 1.8.0,not
keras/keras/backend/tensorflow_backend.py,3547,to pass TF Conv2dNative operations,not
keras/keras/backend/tensorflow_backend.py,3550,NCW -> NWC,not
keras/keras/backend/tensorflow_backend.py,3568,tensorflow doesn't support float64 for conv layer before 1.8.0,not
keras/keras/backend/tensorflow_backend.py,3575,NCHW -> NHWC,not
keras/keras/backend/tensorflow_backend.py,3591,tensorflow doesn't support float64 for conv layer before 1.8.0,not
keras/keras/backend/tensorflow_backend.py,3652,causal (dilated) convolution:,not
keras/keras/backend/tensorflow_backend.py,3659,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,3674,NWC -> NCW,not
keras/keras/backend/tensorflow_backend.py,3705,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,3719,NHWC -> NCHW,not
keras/keras/backend/tensorflow_backend.py,3747,tf.nn.atrous_conv2d_transpose input only supports NHWC format,not
keras/keras/backend/tensorflow_backend.py,3781,NHWC -> NCHW,not
keras/keras/backend/tensorflow_backend.py,3828,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,3844,NWC -> NCW,not
keras/keras/backend/tensorflow_backend.py,3879,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,3892,NHWC -> NCHW,not
keras/keras/backend/tensorflow_backend.py,3925,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,3938,NHWC -> NCHW,not
keras/keras/backend/tensorflow_backend.py,3968,TF 2 arg conversion,not
keras/keras/backend/tensorflow_backend.py,4081,NHWC -> NCHW,not
keras/keras/backend/tensorflow_backend.py,4166,"Shape: `(output_length, batch_size, filters)`.",not
keras/keras/backend/tensorflow_backend.py,4302,RANDOMNESS,not
keras/keras/backend/tensorflow_backend.py,4416,CTC,not
keras/keras/backend/tensorflow_backend.py,4417,"TensorFlow has a native implementation, but it uses sparse tensors",not
keras/keras/backend/tensorflow_backend.py,4418,and therefore requires a wrapper for Keras. The functions below convert,not
keras/keras/backend/tensorflow_backend.py,4419,dense to sparse tensors and also wraps up the beam search code that is,not
keras/keras/backend/tensorflow_backend.py,4420,in TensorFlow's CTC implementation,not
keras/keras/backend/tensorflow_backend.py,4557,HIGH ORDER FUNCTIONS,not
keras/keras/backend/common.py,7,the type of float to use throughout the session.,not
keras/keras/backend/common.py,192,Legacy methods,not
keras/keras/backend/theano_backend.py,28,Legacy functions,not
keras/keras/backend/theano_backend.py,37,INTERNAL UTILS,not
keras/keras/backend/theano_backend.py,39,"0 = test, 1 = train",not
keras/keras/backend/theano_backend.py,45,"False = test, True = train",not
keras/keras/backend/theano_backend.py,84,VARIABLE MANIPULATION,not
keras/keras/backend/theano_backend.py,145,"Support for RandomStreams().normal(), .uniform().",not
keras/keras/backend/theano_backend.py,380,We don't want those compilation to show up in Theano profiler.,not
keras/keras/backend/theano_backend.py,401,UPDATES OPS,not
keras/keras/backend/theano_backend.py,420,LINEAR ALGEBRA,not
keras/keras/backend/theano_backend.py,487,behaves like tf.batch_matmul as default,not
keras/keras/backend/theano_backend.py,518,Expand dims if ndim == 1,not
keras/keras/backend/theano_backend.py,546,ELEMENT-WISE OPERATIONS,not
keras/keras/backend/theano_backend.py,599,bool is available since theano v0.9dev,not
keras/keras/backend/theano_backend.py,698,Theano has a built-in optimization for logsumexp,not
keras/keras/backend/theano_backend.py,699,(see https://github.com/Theano/Theano/pull/4736),not
keras/keras/backend/theano_backend.py,700,so we can just write the expression directly:,not
keras/keras/backend/theano_backend.py,777,TODO remove this if statement when Theano without,SATD
keras/keras/backend/theano_backend.py,778,T.nnet.bn.batch_normalization_train is deprecated,not
keras/keras/backend/theano_backend.py,802,TODO remove this if statement when Theano without,SATD
keras/keras/backend/theano_backend.py,803,T.nnet.bn.batch_normalization_test is deprecated,not
keras/keras/backend/theano_backend.py,813,based on TensorFlow's default: normalize along rightmost dimension,not
keras/keras/backend/theano_backend.py,822,TODO remove this function when Theano without,SATD
keras/keras/backend/theano_backend.py,823,T.nnet.bn.batch_normalization_train is deprecated,not
keras/keras/backend/theano_backend.py,825,pragma: no cover,not
keras/keras/backend/theano_backend.py,873,TODO remove this if statement when Theano without,SATD
keras/keras/backend/theano_backend.py,874,T.nnet.bn.batch_normalization_test is deprecated,not
keras/keras/backend/theano_backend.py,876,pragma: no cover,not
keras/keras/backend/theano_backend.py,885,"in TensorFlow's batch_normalization, if the parameters are vectors",not
keras/keras/backend/theano_backend.py,886,the batch normalization should be applied along the rightmost axis.,not
keras/keras/backend/theano_backend.py,887,Theano expects the parameters to always have x.ndim dimensions.,not
keras/keras/backend/theano_backend.py,923,SHAPE OPERATIONS,not
keras/keras/backend/theano_backend.py,1098,Padding the axis,not
keras/keras/backend/theano_backend.py,1369,VALUE MANIPULATION,not
keras/keras/backend/theano_backend.py,1406,GRAPH MANIPULATION,not
keras/keras/backend/theano_backend.py,1478,CONTROL FLOW,not
keras/keras/backend/theano_backend.py,1550,tf.where needs its condition tensor,not
keras/keras/backend/theano_backend.py,1551,to be the same shape as its two,not
keras/keras/backend/theano_backend.py,1552,result tensors,not
keras/keras/backend/theano_backend.py,1597,"build an all-zero tensor of shape (samples, output_dim)",not
keras/keras/backend/theano_backend.py,1600,Theano gets confused by broadcasting patterns in the scan op,not
keras/keras/backend/theano_backend.py,1610,output previous output if masked.,not
keras/keras/backend/theano_backend.py,1626,deal with Theano API inconsistency,SATD
keras/keras/backend/theano_backend.py,1662,Theano likes to make shape==1 dimensions,not
keras/keras/backend/theano_backend.py,1663,in the initial states (outputs_info) broadcastable,not
keras/keras/backend/theano_backend.py,1674,deal with Theano API inconsistency,SATD
keras/keras/backend/theano_backend.py,1751,else: assume learning phase is a placeholder tensor.,not
keras/keras/backend/theano_backend.py,1768,NN OPERATIONS,not
keras/keras/backend/theano_backend.py,1838,"If the channels are not in the last axis, move them to be there:",not
keras/keras/backend/theano_backend.py,1847,scale preds so that the class probas of each sample sum to 1,not
keras/keras/backend/theano_backend.py,1849,avoid numerical instability with _EPSILON clipping,not
keras/keras/backend/theano_backend.py,1862,"If the channels are not in the last axis, move them to be there:",not
keras/keras/backend/theano_backend.py,1877,avoid numerical instability with _EPSILON clipping,not
keras/keras/backend/theano_backend.py,1946,handle k < 1 and k >= predictions.shape[1] cases to match TF behavior,not
keras/keras/backend/theano_backend.py,1948,dtype='bool' is only available since Theano 0.9.0,not
keras/keras/backend/theano_backend.py,1965,CONVOLUTIONS,not
keras/keras/backend/theano_backend.py,1969,"TF uses the last dimension as channel dimension,",not
keras/keras/backend/theano_backend.py,1970,instead of the 2nd one.,not
keras/keras/backend/theano_backend.py,1971,"TH input shape: (samples, input_depth, rows, cols)",not
keras/keras/backend/theano_backend.py,1972,"TF input shape: (samples, rows, cols, input_depth)",not
keras/keras/backend/theano_backend.py,1979,"TF uses the last dimension as channel dimension,",not
keras/keras/backend/theano_backend.py,1980,instead of the 2nd one.,not
keras/keras/backend/theano_backend.py,1981,"TH input shape: (samples, input_depth, rows, cols, slices)",not
keras/keras/backend/theano_backend.py,1982,"TF input shape: (samples, rows, cols, slices, input_depth)",not
keras/keras/backend/theano_backend.py,1988,"As of Keras 2.0.0, all kernels are normalized",not
keras/keras/backend/theano_backend.py,1989,"on the format `(rows, cols, input_depth, depth)`,",not
keras/keras/backend/theano_backend.py,1990,independently of `data_format`.,not
keras/keras/backend/theano_backend.py,1991,"Theano expects `(depth, input_depth, rows, cols)`.",not
keras/keras/backend/theano_backend.py,1997,"As of Keras 2.0.0, all kernels are normalized",not
keras/keras/backend/theano_backend.py,1998,"on the format `(rows, cols, input_depth, depth)`,",not
keras/keras/backend/theano_backend.py,1999,independently of `data_format`.,not
keras/keras/backend/theano_backend.py,2000,"Theano expects `(input_depth * depth, 1, rows, cols)`",not
keras/keras/backend/theano_backend.py,2001,for depthwise convolution.,not
keras/keras/backend/theano_backend.py,2009,"As of Keras 2.0.0, all kernels are normalized",not
keras/keras/backend/theano_backend.py,2010,"on the format `(space, input_depth, depth)`,",not
keras/keras/backend/theano_backend.py,2011,independently of `data_format`.,not
keras/keras/backend/theano_backend.py,2012,"Theano expects `(depth, input_depth, space)`.",not
keras/keras/backend/theano_backend.py,2030,Theano might not accept long type,not
keras/keras/backend/theano_backend.py,2046,Theano might not accept long type,not
keras/keras/backend/theano_backend.py,2062,Theano might not accept long type,not
keras/keras/backend/theano_backend.py,2077,Theano might not accept long type,not
keras/keras/backend/theano_backend.py,2092,Theano might not accept long type,not
keras/keras/backend/theano_backend.py,2154,causal (dilated) convolution:,not
keras/keras/backend/theano_backend.py,2162,"original shape: (batch, length, input_dim)",not
keras/keras/backend/theano_backend.py,2163,"add dim to x to have (batch, length, 1, input_dim)",not
keras/keras/backend/theano_backend.py,2165,update x._keras_shape,not
keras/keras/backend/theano_backend.py,2169,"original shape: (batch, input_dim, length)",not
keras/keras/backend/theano_backend.py,2170,"add dim to x to have (batch, input_dim, length, 1)",not
keras/keras/backend/theano_backend.py,2172,update x._keras_shape,not
keras/keras/backend/theano_backend.py,2175,"update dilation rate, strides",not
keras/keras/backend/theano_backend.py,2178,add dim to kernel (always same format independently of data_format),not
keras/keras/backend/theano_backend.py,2179,"i.e. (rows, 1, input_depth, depth)",not
keras/keras/backend/theano_backend.py,2184,remove added dim,not
keras/keras/backend/theano_backend.py,2209,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2255,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2320,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2326,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2383,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2389,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2444,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2484,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2530,in case of a shared variable,not
keras/keras/backend/theano_backend.py,2688,RANDOMNESS,not
keras/keras/backend/theano_backend.py,2730,Poor man's truncated normal: we literally clip the tensor,not
keras/keras/backend/theano_backend.py,2734,Theano implementation of CTC,not
keras/keras/backend/theano_backend.py,2735,Used with permission from Shawn Tan,not
keras/keras/backend/theano_backend.py,2736,https://github.com/shawntan/,not
keras/keras/backend/theano_backend.py,2737,Note that TensorFlow's native CTC code is significantly,not
keras/keras/backend/theano_backend.py,2738,faster than this,not
keras/keras/backend/theano_backend.py,2764,copy over,not
keras/keras/backend/theano_backend.py,2766,previous transitions,not
keras/keras/backend/theano_backend.py,2768,skip transitions,not
keras/keras/backend/theano_backend.py,2787,there should be a shortcut to calculating this,not
keras/keras/backend/theano_backend.py,2817,batchifies original CTC code,not
keras/keras/backend/theano_backend.py,2850,HIGH ORDER FUNCTIONS,not
keras/keras/backend/theano_backend.py,2884,We need to change the order of the arguments because theano accepts x as,not
keras/keras/backend/theano_backend.py,2885,first parameter and accumulator as second,not
keras/keras/backend/theano_backend.py,2907,We need to change the order of the arguments because theano accepts x as,not
keras/keras/backend/theano_backend.py,2908,first parameter and accumulator as second,not
keras/keras/backend/theano_backend.py,2927,"Shape: `(output_length, batch_size, filters)`.",not
keras/keras/backend/cntk_backend.py,30,A learning phase is a bool tensor used to run Keras models in,not
keras/keras/backend/cntk_backend.py,31,either train mode (learning_phase == 1) or test mode (learning_phase == 0).,not
keras/keras/backend/cntk_backend.py,32,LEARNING_PHASE_PLACEHOLDER is the placeholder for dynamic learning phase,not
keras/keras/backend/cntk_backend.py,37,"static learning phase flag, if it is not 0 or 1, we will go with dynamic",not
keras/keras/backend/cntk_backend.py,38,learning phase tensor.,not
keras/keras/backend/cntk_backend.py,42,"cntk doesn't support gradient as symbolic op, to hook up with keras model,",not
keras/keras/backend/cntk_backend.py,43,"we will create gradient as a constant placeholder, here use this global",not
keras/keras/backend/cntk_backend.py,44,map to keep the mapping from grad placeholder to parameter,not
keras/keras/backend/cntk_backend.py,64,"If _LEARNING_PHASE is not 0 or 1, return dynamic learning phase tensor",not
keras/keras/backend/cntk_backend.py,97,"CNTK currently don't support cond op, so here we use",not
keras/keras/backend/cntk_backend.py,98,element_select approach as workaround. It may have,SATD
keras/keras/backend/cntk_backend.py,99,"perf issue, will resolve it later with cntk cond op.",not
keras/keras/backend/cntk_backend.py,109,if _LEARNING_PHASE is static,not
keras/keras/backend/cntk_backend.py,130,"cntk only running with float,",not
keras/keras/backend/cntk_backend.py,131,try to cast to float to run the model,not
keras/keras/backend/cntk_backend.py,174,"we don't support init parameter with symbolic op, so eval it first as",not
keras/keras/backend/cntk_backend.py,175,workaround,SATD
keras/keras/backend/cntk_backend.py,183,"TODO: remove the conversion when cntk supports int32, int64",SATD
keras/keras/backend/cntk_backend.py,184,https://www.cntk.ai/pythondocs/cntk.variables.html#cntk.variables.Parameter,not
keras/keras/backend/cntk_backend.py,394,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/cntk_backend.py,419,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/cntk_backend.py,432,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/cntk_backend.py,462,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/cntk_backend.py,492,ensure that randomness is conditioned by the Numpy RNG,not
keras/keras/backend/cntk_backend.py,566,"cntk calculate everything in float, so don't need case from bool / int",not
keras/keras/backend/cntk_backend.py,626,"if tuple, convert to list",not
keras/keras/backend/cntk_backend.py,629,convert negative indices,not
keras/keras/backend/cntk_backend.py,649,Input shapes:,not
keras/keras/backend/cntk_backend.py,650,"x: (b_size, x1, ..., d, ..., xn)",not
keras/keras/backend/cntk_backend.py,651,"y: (b_size, y1, ..., d, ..., yn)",not
keras/keras/backend/cntk_backend.py,652,where d is the dimension to reduce.,not
keras/keras/backend/cntk_backend.py,654,Bring d to the last dimension in x,not
keras/keras/backend/cntk_backend.py,655,"x: (b_size, ..., d)",not
keras/keras/backend/cntk_backend.py,664,Bring d to the second dimension in y,not
keras/keras/backend/cntk_backend.py,665,"y: (b_size, d, ...)",not
keras/keras/backend/cntk_backend.py,673,Expand to rank 3 if needed,not
keras/keras/backend/cntk_backend.py,689,batch size might be lost at this point,not
keras/keras/backend/cntk_backend.py,712,for older versions of CNTK,not
keras/keras/backend/cntk_backend.py,734,There is a bug in cntk gather op which may cause crash.,not
keras/keras/backend/cntk_backend.py,735,We have made a fix but not catched in CNTK 2.1 release.,not
keras/keras/backend/cntk_backend.py,736,Will update with gather op in next release,not
keras/keras/backend/cntk_backend.py,749,"sequence axis is removed by default, so don't need reshape on it",not
keras/keras/backend/cntk_backend.py,866,Padding the axis,not
keras/keras/backend/cntk_backend.py,894,"Current cntk does not support shape like (1, batch). so using the workaround",not
keras/keras/backend/cntk_backend.py,895,here to mapping the correct axis. Will remove this tricky after we add support,not
keras/keras/backend/cntk_backend.py,896,in native cntk op,not
keras/keras/backend/cntk_backend.py,1096,"cntk does not support gradients as symbolic op,",not
keras/keras/backend/cntk_backend.py,1097,to hook up with keras model,not
keras/keras/backend/cntk_backend.py,1098,"we will return a constant as place holder, the cntk learner will apply",not
keras/keras/backend/cntk_backend.py,1099,the gradient during training.,not
keras/keras/backend/cntk_backend.py,1170,need broadcasting,not
keras/keras/backend/cntk_backend.py,1173,skip the batch axis,not
keras/keras/backend/cntk_backend.py,1202,Compute true mean while keeping the dims for proper broadcasting.,not
keras/keras/backend/cntk_backend.py,1226,The mean / var / beta / gamma may be processed by broadcast,not
keras/keras/backend/cntk_backend.py,1227,"so it may have an extra batch axis with 1, it is not needed",not
keras/keras/backend/cntk_backend.py,1228,"in cntk, need to remove those dummy axis.",not
keras/keras/backend/cntk_backend.py,1281,collapse axis with batch axis,not
keras/keras/backend/cntk_backend.py,1291,"no collapse, then first need to padding the shape",not
keras/keras/backend/cntk_backend.py,1375,this is a workaround for recurrent layer,SATD
keras/keras/backend/cntk_backend.py,1376,"if n is inferred dimension,",not
keras/keras/backend/cntk_backend.py,1377,we can't figure out how to repeat it in cntk now,not
keras/keras/backend/cntk_backend.py,1378,return the same x to take cntk broadcast feature,not
keras/keras/backend/cntk_backend.py,1379,to make the recurrent layer work.,not
keras/keras/backend/cntk_backend.py,1380,need to be fixed in GA.,not
keras/keras/backend/cntk_backend.py,1411,"if the second axis is static axis, CNTK will do unroll by default",not
keras/keras/backend/cntk_backend.py,1438,remove dummy dimension,not
keras/keras/backend/cntk_backend.py,1468,remove dummy dimension,not
keras/keras/backend/cntk_backend.py,1496,add the time_step axis back,not
keras/keras/backend/cntk_backend.py,1500,add the time_step axis back,not
keras/keras/backend/cntk_backend.py,1603,create place holder,not
keras/keras/backend/cntk_backend.py,1676,causal (dilated) convolution:,not
keras/keras/backend/cntk_backend.py,1684,"As of Keras 2.0.0, all kernels are normalized",not
keras/keras/backend/cntk_backend.py,1685,"on the format `(steps, input_depth, depth)`,",not
keras/keras/backend/cntk_backend.py,1686,independently of `data_format`.,not
keras/keras/backend/cntk_backend.py,1687,"CNTK expects `(depth, input_depth, steps)`.",not
keras/keras/backend/cntk_backend.py,1876,cntk output_shape does not include batch axis,not
keras/keras/backend/cntk_backend.py,1878,"in keras2, need handle output shape in different format",not
keras/keras/backend/cntk_backend.py,1980,"cntk's batch axis is not in shape,",not
keras/keras/backend/cntk_backend.py,1981,so just flatten all the dim in x.shape,not
keras/keras/backend/cntk_backend.py,2001,"Here, unlike other backends, the tensors lack a batch dimension:",not
keras/keras/backend/cntk_backend.py,2010,"If the channels are not in the last axis, move them to be there:",not
keras/keras/backend/cntk_backend.py,2019,"cntk's result shape is (batch, 1), while keras expect (batch, )",not
keras/keras/backend/cntk_backend.py,2022,scale preds so that the class probas of each sample sum to 1,not
keras/keras/backend/cntk_backend.py,2024,avoid numerical instability with epsilon clipping,not
keras/keras/backend/cntk_backend.py,2030,"Here, unlike other backends, the tensors lack a batch dimension:",not
keras/keras/backend/cntk_backend.py,2055,need group update by gradient place holder,not
keras/keras/backend/cntk_backend.py,2111,"cntk only could handle loss and 1 metric in trainer, for metrics more",not
keras/keras/backend/cntk_backend.py,2112,"than 2, need manual eval",not
keras/keras/backend/cntk_backend.py,2136,"cntk only support calculate on float, do auto cast here",not
keras/keras/backend/cntk_backend.py,2145,in current version cntk can't support input with variable,not
keras/keras/backend/cntk_backend.py,2146,length. Will support it in next release.,not
keras/keras/backend/cntk_backend.py,2185,"Some ops (like dropout) won't be applied during ""eval"" in cntk.",not
keras/keras/backend/cntk_backend.py,2186,"They only evaluated in training phase. To make it work, call",not
keras/keras/backend/cntk_backend.py,2187,"""forward"" method to let cntk know we want to evaluate them.from",not
keras/keras/backend/cntk_backend.py,2188,"But the assign ops won't be executed under this mode, that's why",not
keras/keras/backend/cntk_backend.py,2189,we need this check.,not
keras/keras/backend/cntk_backend.py,2235,pragma: no cover,not
keras/keras/backend/cntk_backend.py,2266,pragma: no cover,not
keras/keras/backend/cntk_backend.py,2400,cntk output_shape does not include batch axis,not
keras/keras/backend/cntk_backend.py,2402,"in keras2, need handle output shape in different format",not
keras/keras/backend/cntk_backend.py,2430,"TF uses the last dimension as channel dimension,",not
keras/keras/backend/cntk_backend.py,2431,instead of the 2nd one.,not
keras/keras/backend/cntk_backend.py,2432,"TH input shape: (samples, input_depth, rows, cols)",not
keras/keras/backend/cntk_backend.py,2433,"TF input shape: (samples, rows, cols, input_depth)",not
keras/keras/backend/cntk_backend.py,2439,"As of Keras 2.0.0, all kernels are normalized",not
keras/keras/backend/cntk_backend.py,2440,"on the format `(rows, cols, input_depth, depth)`,",not
keras/keras/backend/cntk_backend.py,2441,independently of `data_format`.,not
keras/keras/backend/cntk_backend.py,2442,"CNTK expects `(depth, input_depth, rows, cols)`.",not
keras/keras/backend/cntk_backend.py,2465,"TF uses the last dimension as channel dimension,",not
keras/keras/backend/cntk_backend.py,2466,instead of the 2nd one.,not
keras/keras/backend/cntk_backend.py,2467,"TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)",not
keras/keras/backend/cntk_backend.py,2468,"TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3,",not
keras/keras/backend/cntk_backend.py,2469,input_depth),not
keras/keras/backend/cntk_backend.py,2537,"transpose kernel to output_filters first, to apply broadcast",not
keras/keras/backend/cntk_backend.py,2539,"Shape: (batch, filters, output_length, input_length * kernel_size)",not
keras/keras/backend/cntk_backend.py,2541,"Shape: (batch, filters, output_length)",not
keras/keras/backend/cntk_backend.py,2543,"Shape: (batch, output_length, filters)",not
keras/keras/backend/cntk_backend.py,2574,transpose kernel to put filters first,not
keras/keras/backend/cntk_backend.py,2576,"shape: batch, filters, output_length, input_length * kernel_size",not
keras/keras/backend/cntk_backend.py,2578,"shape: batch, filters, output_length",not
keras/keras/backend/cntk_backend.py,2580,"shape: batch, filters, row, col",not
keras/keras/backend/cntk_backend.py,2585,"shape: batch, row, col, filters",not
keras/keras/backend/cntk_backend.py,2610,there is a bug in cntk 2.1's unpack_batch implementation,SATD
keras/keras/backend/cntk_backend.py,2623,"for hot fix, ignore all the . except the first one.",not
keras/keras/datasets/cifar.py,1,-*- coding: utf-8 -*-,not
keras/keras/datasets/cifar.py,28,decode utf8,not
keras/keras/datasets/reuters.py,1,-*- coding: utf-8 -*-,not
keras/keras/datasets/reuters.py,45,Legacy support,not
keras/keras/datasets/reuters.py,76,"by convention, use 2 as OOV word",not
keras/keras/datasets/reuters.py,77,reserve 'index_from' (=3 by default) characters:,not
keras/keras/datasets/reuters.py,78,"0 (padding), 1 (start), 2 (OOV)",not
keras/keras/datasets/imdb.py,47,Legacy support,not
keras/keras/datasets/imdb.py,90,"by convention, use 2 as OOV word",not
keras/keras/datasets/imdb.py,91,reserve 'index_from' (=3 by default) characters:,not
keras/keras/datasets/imdb.py,92,"0 (padding), 1 (start), 2 (OOV)",not
keras/keras/utils/layer_utils.py,52,"We treat subclassed models as a simple sequence of layers,",not
keras/keras/utils/layer_utils.py,53,for logging purposes.,not
keras/keras/utils/layer_utils.py,61,if the model has multiple nodes,not
keras/keras/utils/layer_utils.py,62,or if the nodes have multiple inbound_layers,not
keras/keras/utils/layer_utils.py,63,the model is no longer sequential,not
keras/keras/utils/layer_utils.py,68,search for shared layers,not
keras/keras/utils/layer_utils.py,86,header names for the different log elements,not
keras/keras/utils/layer_utils.py,93,header names for the different log elements,not
keras/keras/utils/layer_utils.py,141,node is not part of the current network,not
keras/keras/utils/layer_utils.py,202,Note: SeparableConvolution not included,not
keras/keras/utils/layer_utils.py,203,since only supported by TF.,not
keras/keras/utils/layer_utils.py,248,last -> first,not
keras/keras/utils/layer_utils.py,253,first -> last,not
keras/keras/utils/layer_utils.py,283,"Reached an Input layer, stop recursion.",not
keras/keras/utils/layer_utils.py,295,Avoid input redundancy.,not
keras/keras/utils/losses_utils.py,101,Broadcast weights if possible.,not
keras/keras/utils/losses_utils.py,109,Raise error if ndim of weights is > values.,not
keras/keras/utils/losses_utils.py,115,"Expand dim of weights to match ndim of values, if required.",not
keras/keras/utils/losses_utils.py,124,Cannot be broadcasted.,not
keras/keras/utils/losses_utils.py,164,Update dimensions of `sample_weight` to match with `losses` if possible.,not
keras/keras/utils/losses_utils.py,168,Broadcast weights if possible.,not
keras/keras/utils/losses_utils.py,171,Apply weights to losses.,not
keras/keras/utils/losses_utils.py,174,Apply reduction function to the individual weighted losses.,not
keras/keras/utils/losses_utils.py,176,Convert the result back to the input type.,not
keras/keras/utils/test_utils.py,61,generate input data,not
keras/keras/utils/test_utils.py,80,instantiation,not
keras/keras/utils/test_utils.py,83,"test get_weights , set_weights at layer level",not
keras/keras/utils/test_utils.py,89,test in functional API,not
keras/keras/utils/test_utils.py,97,check with the functional API,not
keras/keras/utils/test_utils.py,110,"test serialization, weight setting at model level",not
keras/keras/utils/test_utils.py,119,test training mode (e.g. useful when the layer has a,not
keras/keras/utils/test_utils.py,120,different behavior at training and testing time).,not
keras/keras/utils/test_utils.py,125,test instantiation from layer config,not
keras/keras/utils/test_utils.py,130,for further checks in the caller function,not
keras/keras/utils/test_utils.py,183,will mock gcs locally for tests,not
keras/keras/utils/test_utils.py,191,will use real bucket for tests,not
keras/keras/utils/test_utils.py,199,check that bucket exists and is accessible,not
keras/keras/utils/metrics_utils.py,165,Logical and,not
keras/keras/utils/metrics_utils.py,268,Reshape predictions and labels.,not
keras/keras/utils/metrics_utils.py,273,Tile the thresholds for every prediction.,not
keras/keras/utils/metrics_utils.py,282,Tile the predictions for every threshold.,not
keras/keras/utils/metrics_utils.py,285,Compare predictions and threshold.,not
keras/keras/utils/metrics_utils.py,288,Tile labels by number of thresholds,not
keras/keras/utils/io_utils.py,103,Assume list/iterable,not
keras/keras/utils/io_utils.py,198,Flag to check if a dict is user defined data or a sub group:,not
keras/keras/utils/io_utils.py,224,We have to remember to unpickle in __getitem__,not
keras/keras/utils/io_utils.py,235,scalar,not
keras/keras/utils/io_utils.py,240,Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`,not
keras/keras/utils/io_utils.py,241,because in that case even chunking the array would not make the saving,not
keras/keras/utils/io_utils.py,242,possible.,not
keras/keras/utils/io_utils.py,245,Expecting this to never be true.,not
keras/keras/utils/io_utils.py,254,convert to bytes,not
keras/keras/utils/io_utils.py,262,This will never loop forever thanks to the test above.,not
keras/keras/utils/io_utils.py,305,could be chunked,not
keras/keras/utils/io_utils.py,388,Implementation based on suggestion solution here:,not
keras/keras/utils/io_utils.py,389,https://github.com/keras-team/keras/issues/9343#issuecomment-440903847,not
keras/keras/utils/io_utils.py,396,name does not matter,not
keras/keras/utils/io_utils.py,417,note that filename does not matter here.,not
keras/keras/utils/io_utils.py,427,We can't use isinstance here because it would require,not
keras/keras/utils/io_utils.py,428,us to add pathlib2 to the Python 2 dependencies.,not
keras/keras/utils/multi_gpu_utils.py,154,Using all visible GPUs when not specifying `gpus`,not
keras/keras/utils/multi_gpu_utils.py,155,"e.g. CUDA_VISIBLE_DEVICES=0,2 python keras_mgpu.py",not
keras/keras/utils/multi_gpu_utils.py,200,Relocate the model definition under CPU device scope if needed,not
keras/keras/utils/multi_gpu_utils.py,209,"Place a copy of the model on each GPU,",not
keras/keras/utils/multi_gpu_utils.py,210,each getting a slice of the inputs.,not
keras/keras/utils/multi_gpu_utils.py,215,Retrieve a slice of the input.,not
keras/keras/utils/multi_gpu_utils.py,217,In-place input splitting which is not only,not
keras/keras/utils/multi_gpu_utils.py,218,5% ~ 12% faster but also less GPU memory,not
keras/keras/utils/multi_gpu_utils.py,219,duplication.,not
keras/keras/utils/multi_gpu_utils.py,228,Apply model on slice,not
keras/keras/utils/multi_gpu_utils.py,229,(creating a model replica on the target device).,not
keras/keras/utils/multi_gpu_utils.py,233,Save the outputs for merging back together later.,not
keras/keras/utils/multi_gpu_utils.py,237,Deduplicate output names to handle Siamese networks.,not
keras/keras/utils/multi_gpu_utils.py,252,Merge outputs under expected scope.,not
keras/keras/utils/data_utils.py,171,noqa,not
keras/keras/utils/data_utils.py,195,File found; verify integrity if a hash was provided.,not
keras/keras/utils/data_utils.py,210,Maintain progbar for the lifetime of download.,not
keras/keras/utils/data_utils.py,211,This design was chosen for Python 2.7 compatibility.,not
keras/keras/utils/data_utils.py,381,Global variables to be shared across processes,not
keras/keras/utils/data_utils.py,383,We use a Value to provide unique id to different processes.,not
keras/keras/utils/data_utils.py,440,In this case the OS does not allow us to use,not
keras/keras/utils/data_utils.py,441,multiprocessing. We resort to an int,not
keras/keras/utils/data_utils.py,442,for enqueuer indexing.,not
keras/keras/utils/data_utils.py,449,Doing Multiprocessing.Value += x is not process-safe.,not
keras/keras/utils/data_utils.py,474,We do not need the init since it's threads.,not
keras/keras/utils/data_utils.py,485,For new processes that may spawn,not
keras/keras/utils/data_utils.py,567,Share the initial sequence,not
keras/keras/utils/data_utils.py,580,"Done with the current epoch, waiting for the final batches",not
keras/keras/utils/data_utils.py,584,We're done,not
keras/keras/utils/data_utils.py,587,Call the internal on epoch end.,not
keras/keras/utils/data_utils.py,589,communicate on_epoch_end to the main thread,not
keras/keras/utils/data_utils.py,689,Share the initial generator,not
keras/keras/utils/data_utils.py,723,Special case for finite generators,not
keras/keras/utils/data_utils.py,727,Wait for them to complete,not
keras/keras/utils/data_utils.py,729,Keep the good ones,not
keras/keras/utils/conv_utils.py,159,Get the dilated kernel size,not
keras/keras/utils/conv_utils.py,162,"Infer length if output padding is None, else compute the exact length",not
keras/keras/utils/vis_utils.py,10,"`pydot` is an optional dependency,",not
keras/keras/utils/vis_utils.py,11,see `extras_require` in `setup.py`.,not
keras/keras/utils/vis_utils.py,26,Attempt to create an image of a blank graph,not
keras/keras/utils/vis_utils.py,27,to check the pydot/graphviz installation.,not
keras/keras/utils/vis_utils.py,101,Create graph nodes.,not
keras/keras/utils/vis_utils.py,105,"Append a wrapped layer's label to node's label, if it exists.",not
keras/keras/utils/vis_utils.py,115,sub_w : submodel_wrapper,not
keras/keras/utils/vis_utils.py,130,sub_n : submodel_not_wrapper,not
keras/keras/utils/vis_utils.py,136,Create node's label.,not
keras/keras/utils/vis_utils.py,142,Rebuild the label as a table including input/output shapes.,not
keras/keras/utils/vis_utils.py,163,Connect nodes with edges.,not
keras/keras/utils/vis_utils.py,176,if inbound_layer is not Model or wrapped Model,not
keras/keras/utils/vis_utils.py,179,if current layer is not Model or wrapped Model,not
keras/keras/utils/vis_utils.py,186,if current layer is Model,not
keras/keras/utils/vis_utils.py,190,if current layer is wrapped Model,not
keras/keras/utils/vis_utils.py,197,if inbound_layer is Model,not
keras/keras/utils/vis_utils.py,205,if inbound_layer is wrapped Model,not
keras/keras/utils/vis_utils.py,247,"Return the image as a Jupyter Image object, to be displayed in-line.",not
keras/keras/utils/__init__.py,10,Globally-importable utils.,not
keras/keras/utils/generic_utils.py,126,In this case we are dealing with a Keras config dictionary.,not
keras/keras/utils/generic_utils.py,151,Then `cls` may be a function returning a class.,not
keras/keras/utils/generic_utils.py,152,in this case by convention `config` holds,not
keras/keras/utils/generic_utils.py,153,the kwargs of the function.,not
keras/keras/utils/generic_utils.py,205,unpack previous dump,not
keras/keras/utils/generic_utils.py,221,just access it so it gets captured in .__closure__,not
keras/keras/utils/generic_utils.py,235,backwards compatibility for models serialized prior to 2.1.2,not
keras/keras/utils/generic_utils.py,370,Stateful metrics output a numeric value.  This representation,not
keras/keras/utils/generic_utils.py,371,"means ""take an average from a single value"" but keeps the",not
keras/keras/utils/generic_utils.py,372,numeric formatting.,not
keras/keras/utils/generic_utils.py,552,hdf5 datasets only support list objects as indices,not
keras/keras/preprocessing/sequence.py,13,TODO: make it public?,SATD
keras/keras/engine/training_arrays.py,112,it's possible to callback a different model than itself,not
keras/keras/engine/training_arrays.py,113,(used by Sequential models),not
keras/keras/engine/training_arrays.py,134,"To prevent a slowdown,",not
keras/keras/engine/training_arrays.py,135,we find beforehand the arrays that need conversion.,not
keras/keras/engine/training_arrays.py,168,Same labels assumed.,not
keras/keras/engine/training_arrays.py,182,Do not slice the training phase flag.,not
keras/keras/engine/training_arrays.py,205,Last batch.,not
keras/keras/engine/training_arrays.py,212,Same labels assumed.,not
keras/keras/engine/training_arrays.py,252,Check if callbacks have not been already configured,not
keras/keras/engine/training_arrays.py,280,Step-based predictions.,not
keras/keras/engine/training_arrays.py,281,Since we do not know how many samples,not
keras/keras/engine/training_arrays.py,282,"we will see, we cannot pre-allocate",not
keras/keras/engine/training_arrays.py,283,the returned Numpy arrays.,not
keras/keras/engine/training_arrays.py,284,"Instead, we store one array per batch seen",not
keras/keras/engine/training_arrays.py,285,and concatenate them upon returning.,not
keras/keras/engine/training_arrays.py,308,Sample-based predictions.,not
keras/keras/engine/training_arrays.py,315,Do not slice the training phase flag.,not
keras/keras/engine/training_arrays.py,327,Pre-allocate the results arrays.,not
keras/keras/engine/training_arrays.py,374,Check if callbacks have not been already configured,not
keras/keras/engine/training_arrays.py,396,"To prevent a slowdown,",not
keras/keras/engine/training_arrays.py,397,we find beforehand the arrays that need conversion.,not
keras/keras/engine/training_arrays.py,418,Index 0 == `Loss`,not
keras/keras/engine/training_arrays.py,433,Index 0 == `Loss`,not
keras/keras/engine/training_arrays.py,440,Do not slice the training phase flag.,not
keras/keras/engine/training_arrays.py,454,Index 0 == `Loss`,not
keras/keras/engine/training_arrays.py,469,Index 0 == `Loss`,not
keras/keras/engine/training_utils.py,124,Check shapes compatibility.,not
keras/keras/engine/training_utils.py,222,return a set with the variation between,not
keras/keras/engine/training_utils.py,223,"different shapes, with None => 0",not
keras/keras/engine/training_utils.py,345,to reshape we need to be cleanly divisible by batch size,not
keras/keras/engine/training_utils.py,346,we stash extra items and reappend them after shuffling,not
keras/keras/engine/training_utils.py,365,round up,not
keras/keras/engine/training_utils.py,399,score_array has ndim >= 2,not
keras/keras/engine/training_utils.py,402,Cast the mask to floatX to avoid float64 upcasting in Theano,not
keras/keras/engine/training_utils.py,404,mask should have the same shape as score_array,not
keras/keras/engine/training_utils.py,406,the loss per batch should be proportional,not
keras/keras/engine/training_utils.py,407,to the number of unmasked samples.,not
keras/keras/engine/training_utils.py,410,apply sample weighting,not
keras/keras/engine/training_utils.py,412,reduce score_array to same ndim as weight array,not
keras/keras/engine/training_utils.py,508,subtract the sets to pick all missing classes,not
keras/keras/engine/training_utils.py,524,Everything has weight 1 by default.,not
keras/keras/engine/training_utils.py,579,Edge case where ins == [static_learning_phase],not
keras/keras/engine/training_utils.py,605,TODO Dref360: Decide which pattern to follow. First needs a new TF Version.,SATD
keras/keras/engine/training_utils.py,631,`epoch` is 0-indexed internally but 1-indexed in the public API.,not
keras/keras/engine/training_utils.py,677,In case of nested models: recover the first layer,not
keras/keras/engine/training_utils.py,678,of the deepest model to infer input shape and dtype.,not
keras/keras/engine/training_utils.py,679,Subclassed Models may not have been built so can't be checked.,not
keras/keras/engine/training_utils.py,695,"Deserialize loss configuration, if needed.",not
keras/keras/engine/training_utils.py,699,Custom callable class.,not
keras/keras/engine/training_utils.py,703,"Wrap loss function with signature `(y_true, y_pred, **kwargs)`",not
keras/keras/engine/training_utils.py,704,in `LossFunctionWrapper` class.,not
keras/keras/engine/training_utils.py,707,"For losses which are given as strings/functions in the compile API,",not
keras/keras/engine/training_utils.py,708,we always set the loss reduction type to be `SUM_OVER_BATCH_SIZE`..,not
keras/keras/engine/training_utils.py,916,User has provided a list of len = len(outputs).,not
keras/keras/engine/training_utils.py,919,If it is a single list we then apply all metrics to all outputs.,not
keras/keras/engine/training_utils.py,945,"If the metric function is not stateful, we create a stateful version.",not
keras/keras/engine/training_utils.py,965,We keep the string that the user has set in compile as the metric name.,not
keras/keras/engine/training_utils.py,1003,"If the output_shape[-1] is not 1, then we know output is `categorical`.",not
keras/keras/engine/training_utils.py,1004,We assume it is sparse categorical only if loss is explicitly given,not
keras/keras/engine/training_utils.py,1005,as sparse categorical crossentropy loss.,not
keras/keras/engine/training_utils.py,1024,Use mask as sample weight.,not
keras/keras/engine/training_utils.py,1027,Update dimensions of weights to match with mask.,not
keras/keras/engine/training_utils.py,1034,For TF,not
keras/keras/engine/training_utils.py,1037,`Mean` metric only takes a single value.,not
keras/keras/engine/training_utils.py,1039,For TF,not
keras/keras/engine/training.py,102,List of stateful metric functions. Used for resetting metric state during,not
keras/keras/engine/training.py,103,training/eval.,not
keras/keras/engine/training.py,105,List of metric wrappers on output losses.,not
keras/keras/engine/training.py,109,Model is not compilable because,not
keras/keras/engine/training.py,110,it does not know its number of inputs,not
keras/keras/engine/training.py,111,"and outputs, nor their shapes and names.",not
keras/keras/engine/training.py,112,We will compile after the first,not
keras/keras/engine/training.py,113,time the model gets called on training data.,not
keras/keras/engine/training.py,117,"Prepare list of loss functions, same size as model outputs.",not
keras/keras/engine/training.py,126,"if loss function is None, then this output will be skipped during total",not
keras/keras/engine/training.py,127,loss calculation and feed targets preparation.,not
keras/keras/engine/training.py,135,Prepare output masks.,not
keras/keras/engine/training.py,141,"Prepare list loss weights, same size of model outputs.",not
keras/keras/engine/training.py,145,Prepare targets of model.,not
keras/keras/engine/training.py,206,Prepare sample weights.,not
keras/keras/engine/training.py,210,Save all metric attributes per output of the model.,not
keras/keras/engine/training.py,213,Set metric attributes on model.,not
keras/keras/engine/training.py,216,Invoke metric functions (unweighted) for all the outputs.,not
keras/keras/engine/training.py,224,Compute total loss.,not
keras/keras/engine/training.py,225,Used to keep track of the total loss value (stateless).,not
keras/keras/engine/training.py,226,"eg., total_loss = loss_weight_1 * output_1_loss_fn(...) +",not
keras/keras/engine/training.py,227,loss_weight_2 * output_2_loss_fn(...) +,not
keras/keras/engine/training.py,228,layer losses.,not
keras/keras/engine/training.py,231,"Functions for train, test and predict will",not
keras/keras/engine/training.py,232,be compiled lazily when required.,not
keras/keras/engine/training.py,233,This saves time when the user is not using all functions.,not
keras/keras/engine/training.py,240,"Collected trainable weights, sorted in topological order.",not
keras/keras/engine/training.py,259,Add output loss metric names to the metric names list.,not
keras/keras/engine/training.py,267,Add compile metrics/weighted metrics' names to the metric names list.,not
keras/keras/engine/training.py,270,Add metric names from layers.,not
keras/keras/engine/training.py,327,Gets loss and metrics. Updates weights at each call.,not
keras/keras/engine/training.py,354,"Return loss and metrics, no gradient updates.",not
keras/keras/engine/training.py,355,Does update the network states.,not
keras/keras/engine/training.py,371,Gets network outputs. Does not update weights.,not
keras/keras/engine/training.py,372,Does update the network states.,not
keras/keras/engine/training.py,410,Note: we can't test whether the model,not
keras/keras/engine/training.py,411,is `Sequential` via `isinstance`,not
keras/keras/engine/training.py,412,since `Sequential` depends on `Model`.,not
keras/keras/engine/training.py,422,On-the-fly setting of symbolic model inputs,not
keras/keras/engine/training.py,423,"(either by using the tensor provided,",not
keras/keras/engine/training.py,424,or by creating a placeholder if Numpy data was provided).,not
keras/keras/engine/training.py,440,We fix the placeholder shape except the batch size.,not
keras/keras/engine/training.py,441,"This is suboptimal, but it is the best we can do with the info",not
keras/keras/engine/training.py,442,we have. The user should call `model._set_inputs(placeholders)`,not
keras/keras/engine/training.py,443,to specify custom placeholders if the need arises.,not
keras/keras/engine/training.py,451,Assumed tensor - TODO(fchollet) additional type check?,SATD
keras/keras/engine/training.py,459,Obtain symbolic outputs by calling the model.,not
keras/keras/engine/training.py,478,We need to use `x` to set the model inputs.,not
keras/keras/engine/training.py,479,We type-check that `x` and `y` are either single arrays,not
keras/keras/engine/training.py,480,or lists of arrays.,not
keras/keras/engine/training.py,500,Build the model using the retrieved inputs (value or symbolic).,not
keras/keras/engine/training.py,501,"If values, then in symbolic-mode placeholders will be created",not
keras/keras/engine/training.py,502,to match the value shapes.,not
keras/keras/engine/training.py,512,On-the-fly compilation of the model.,not
keras/keras/engine/training.py,513,We need to use `y` to set the model targets.,not
keras/keras/engine/training.py,530,Typecheck that all inputs are *either* value *or* symbolic.,not
keras/keras/engine/training.py,540,Handle target tensors if any passed.,not
keras/keras/engine/training.py,552,"If `x` and `y` were all symbolic,",not
keras/keras/engine/training.py,553,then the model should not be fed any inputs and targets.,not
keras/keras/engine/training.py,554,"Note: in this case, `any` and `all` are equivalent since we disallow",not
keras/keras/engine/training.py,555,mixed symbolic/value inputs.,not
keras/keras/engine/training.py,559,"What follows is input validation and standardization to list format,",not
keras/keras/engine/training.py,560,in the case where all inputs are value arrays.,not
keras/keras/engine/training.py,563,Case: symbolic-mode subclassed network.,not
keras/keras/engine/training.py,564,Do not do shape validation.,not
keras/keras/engine/training.py,568,Case: symbolic-mode graph network.,not
keras/keras/engine/training.py,569,"In this case, we run extensive shape validation checks.",not
keras/keras/engine/training.py,573,Standardize the inputs.,not
keras/keras/engine/training.py,578,Don't enforce the batch size.,not
keras/keras/engine/training.py,585,Sample weighting not supported in this case.,not
keras/keras/engine/training.py,586,TODO: consider supporting it.,SATD
keras/keras/engine/training.py,607,If the given loss is not an instance of the `Loss` class,not
keras/keras/engine/training.py,608,(custom class) or if the loss function that is wrapped is,not
keras/keras/engine/training.py,609,"not in the `losses` module, then it is a user-defined loss",not
keras/keras/engine/training.py,610,and we make no assumptions about it.,not
keras/keras/engine/training.py,615,Standardize the outputs.,not
keras/keras/engine/training.py,620,Don't enforce the batch size.,not
keras/keras/engine/training.py,623,Generate sample-wise weight values given the `sample_weight` and,not
keras/keras/engine/training.py,624,`class_weight` arguments.,not
keras/keras/engine/training.py,635,Check that all arrays have the same length.,not
keras/keras/engine/training.py,639,Additional checks to avoid users mistakenly,not
keras/keras/engine/training.py,640,using improper loss fns.,not
keras/keras/engine/training.py,648,"Check that for stateful networks, number of samples is a multiple",not
keras/keras/engine/training.py,649,of the static batch size.,not
keras/keras/engine/training.py,681,Update weights with mask.,not
keras/keras/engine/training.py,685,Update dimensions of weights to match with mask.,not
keras/keras/engine/training.py,697,For TF,not
keras/keras/engine/training.py,711,Add regularization penalties and other layer-specific losses.,not
keras/keras/engine/training.py,787,Update the name on the metric class to be the unique generated name.,not
keras/keras/engine/training.py,790,Keep track of metric function.,not
keras/keras/engine/training.py,811,Create a metric wrapper for each output loss. This computes mean of an,not
keras/keras/engine/training.py,812,output loss across mini-batches (irrespective of how we reduce within a,not
keras/keras/engine/training.py,813,batch).,not
keras/keras/engine/training.py,862,Invoke all metrics added using `compile`.,not
keras/keras/engine/training.py,915,Avoids the override in Sequential.,not
keras/keras/engine/training.py,921,Check `batch_size` argument is consistent with InputLayer.,not
keras/keras/engine/training.py,928,Set inferred batch size from the InputLayer.,not
keras/keras/engine/training.py,933,Backwards compatibility,not
keras/keras/engine/training.py,1112,Legacy support,not
keras/keras/engine/training.py,1128,"Case 1: generator-like. Input is Python generator,",not
keras/keras/engine/training.py,1129,"or Sequence object, or iterator.",not
keras/keras/engine/training.py,1149,Case 2: Symbolic tensors or Numpy array-like.,not
keras/keras/engine/training.py,1156,Prepare validation data.,not
keras/keras/engine/training.py,1208,Prepare input arrays and training function.,not
keras/keras/engine/training.py,1216,Prepare display labels.,not
keras/keras/engine/training.py,1226,Delegate logic to `fit_loop`.,not
keras/keras/engine/training.py,1328,"Case 1: generator-like. Input is Python generator, or Sequence object.",not
keras/keras/engine/training.py,1340,Case 2: Symbolic tensors or Numpy array-like.,not
keras/keras/engine/training.py,1345,Validate user data.,not
keras/keras/engine/training.py,1350,"Prepare inputs, delegate logic to `test_loop`.",not
keras/keras/engine/training.py,1424,"Case 1: generator-like. Input is Python generator, or Sequence object.",not
keras/keras/engine/training.py,1440,Case 2: Symbolic tensors or Numpy array-like.,not
keras/keras/engine/training.py,1451,"Prepare inputs, delegate logic to `predict_loop`.",not
keras/keras/engine/training.py,1862,We cannot call 'metrics' on the model because we do not want to,not
keras/keras/engine/training.py,1863,include the metrics that were added in compile API of a nested model.,not
keras/keras/engine/base_layer.py,114,These properties will be set upon call of self.build(),not
keras/keras/engine/base_layer.py,123,A list of metric instances corresponding to the metric tensors added using,not
keras/keras/engine/base_layer.py,124,the `add_metric` API.,not
keras/keras/engine/base_layer.py,127,These lists will be filled via successive calls,not
keras/keras/engine/base_layer.py,128,to self._add_inbound_node().,not
keras/keras/engine/base_layer.py,132,These properties should be set by the user via keyword arguments.,not
keras/keras/engine/base_layer.py,133,"note that 'dtype', 'input_shape' and 'batch_input_shape'",not
keras/keras/engine/base_layer.py,134,are only applicable to input layers: do not pass these keywords,not
keras/keras/engine/base_layer.py,135,to non-input layers.,not
keras/keras/engine/base_layer.py,143,legacy,not
keras/keras/engine/base_layer.py,156,In this case we will later create an input layer,not
keras/keras/engine/base_layer.py,157,to insert before the current layer,not
keras/keras/engine/base_layer.py,166,Set dtype.,not
keras/keras/engine/base_layer.py,335,Check ndim.,not
keras/keras/engine/base_layer.py,359,Check dtype.,not
keras/keras/engine/base_layer.py,367,Check specific shape axes.,not
keras/keras/engine/base_layer.py,384,Check shape.,not
keras/keras/engine/base_layer.py,442,"Handle laying building (weight creating, input spec locking).",not
keras/keras/engine/base_layer.py,444,Raise exceptions in case the input is not compatible,not
keras/keras/engine/base_layer.py,445,with the input_spec specified in the layer constructor.,not
keras/keras/engine/base_layer.py,448,Collect input shapes to build layer.,not
keras/keras/engine/base_layer.py,466,Load weights that were specified at layer instantiation.,not
keras/keras/engine/base_layer.py,470,Raise exceptions in case the input is not compatible,not
keras/keras/engine/base_layer.py,471,with the input_spec set at build time.,not
keras/keras/engine/base_layer.py,474,Handle mask propagation.,not
keras/keras/engine/base_layer.py,478,The previous layer generated a mask.,not
keras/keras/engine/base_layer.py,481,"If mask is explicitly passed to __call__,",not
keras/keras/engine/base_layer.py,482,we should override the default mask.,not
keras/keras/engine/base_layer.py,484,Handle automatic shape inference (only useful for Theano).,not
keras/keras/engine/base_layer.py,487,"Actually call the layer,",not
keras/keras/engine/base_layer.py,488,"collecting output(s), mask(s), and shape(s).",not
keras/keras/engine/base_layer.py,492,"If the layer returns tensors from its inputs, unmodified,",not
keras/keras/engine/base_layer.py,493,we copy them to avoid loss of tensor metadata.,not
keras/keras/engine/base_layer.py,503,Inferring the output shape is only relevant for Theano.,not
keras/keras/engine/base_layer.py,515,Augment the mask to match the length of the output.,not
keras/keras/engine/base_layer.py,518,"Add an inbound node to the layer, so that it keeps track",not
keras/keras/engine/base_layer.py,519,of the call and of all new variables created during the call.,not
keras/keras/engine/base_layer.py,520,This also updates the layer history of the output tensor(s).,not
keras/keras/engine/base_layer.py,521,"If the input tensor(s) had not previous Keras history,",not
keras/keras/engine/base_layer.py,522,this does nothing.,not
keras/keras/engine/base_layer.py,531,Apply activity regularizer if any:,not
keras/keras/engine/base_layer.py,565,Collect input tensor(s) coordinates.,not
keras/keras/engine/base_layer.py,580,"Create node, add it to inbound nodes.",not
keras/keras/engine/base_layer.py,595,"Update tensor history, _keras_shape and _uses_learning_phase.",not
keras/keras/engine/base_layer.py,649,masking not explicitly supported: return None as mask,not
keras/keras/engine/base_layer.py,651,"if masking is explicitly supported, by default",not
keras/keras/engine/base_layer.py,652,carry over the input mask,not
keras/keras/engine/base_layer.py,984,We track the instance using the metadata on the result tensor.,not
keras/keras/engine/base_layer.py,985,Use case: model.add_metric(metrics.Mean(name='metric_2')(y)),not
keras/keras/engine/base_layer.py,988,"Use cases: model.add_metric(K.sum(y), name='metric_1')",not
keras/keras/engine/base_layer.py,1009,Update self.losses,not
keras/keras/engine/base_layer.py,1015,Update self._per_input_updates,not
keras/keras/engine/base_layer.py,1021,Updates indexed by None are unconditional,not
keras/keras/engine/base_layer.py,1022,rather than input-dependent,not
keras/keras/engine/base_layer.py,1043,Update self.updates,not
keras/keras/engine/base_layer.py,1049,Update self._per_input_updates,not
keras/keras/engine/base_layer.py,1055,Updates indexed by None are unconditional,not
keras/keras/engine/base_layer.py,1056,rather than input-dependent,not
keras/keras/engine/base_layer.py,1212,Keep track of metric instance created in subclassed model/layer.,not
keras/keras/engine/base_layer.py,1213,We do this so that we can maintain the correct order of metrics by adding,not
keras/keras/engine/base_layer.py,1214,the instance to the `metrics` list as soon as it is created.,not
keras/keras/engine/base_layer.py,1224,Automatically track layers set as attributes.,not
keras/keras/engine/base_layer.py,1231,Automatically track variables set as attributes.,not
keras/keras/engine/base_layer.py,1258,For TF,not
keras/keras/engine/base_layer.py,1360,Layer instance (NOT a list).,not
keras/keras/engine/base_layer.py,1361,this is the layer that takes a list of input tensors,not
keras/keras/engine/base_layer.py,1362,and turns them into a list of output tensors.,not
keras/keras/engine/base_layer.py,1363,the current node will be added to,not
keras/keras/engine/base_layer.py,1364,the inbound_nodes of outbound_layer.,not
keras/keras/engine/base_layer.py,1367,The following 3 properties describe where,not
keras/keras/engine/base_layer.py,1368,"the input tensors come from: which layers,",not
keras/keras/engine/base_layer.py,1369,"and for each layer, which node and which",not
keras/keras/engine/base_layer.py,1370,tensor output of each node.,not
keras/keras/engine/base_layer.py,1372,List of layer instances.,not
keras/keras/engine/base_layer.py,1374,"List of integers, 1:1 mapping with inbound_layers.",not
keras/keras/engine/base_layer.py,1376,"List of integers, 1:1 mapping with inbound_layers.",not
keras/keras/engine/base_layer.py,1379,Following 2 properties:,not
keras/keras/engine/base_layer.py,1380,tensor inputs and outputs of outbound_layer.,not
keras/keras/engine/base_layer.py,1382,List of tensors. 1:1 mapping with inbound_layers.,not
keras/keras/engine/base_layer.py,1384,"List of tensors, created by outbound_layer.call().",not
keras/keras/engine/base_layer.py,1387,Following 2 properties: input and output masks.,not
keras/keras/engine/base_layer.py,1388,"List of tensors, 1:1 mapping with input_tensor.",not
keras/keras/engine/base_layer.py,1390,"List of tensors, created by outbound_layer.compute_mask().",not
keras/keras/engine/base_layer.py,1393,Following 2 properties: input and output shapes.,not
keras/keras/engine/base_layer.py,1395,"List of shape tuples, shapes of input_tensors.",not
keras/keras/engine/base_layer.py,1397,"List of shape tuples, shapes of output_tensors.",not
keras/keras/engine/base_layer.py,1400,Optional keyword arguments to layer's `call`.,not
keras/keras/engine/base_layer.py,1403,Add nodes to all layers involved.,not
keras/keras/engine/base_layer.py,1451,"If the class is private the name starts with ""_"" which is not secure",not
keras/keras/engine/base_layer.py,1452,"for creating scopes. We prefix the name with ""private"" in this case.",not
keras/keras/engine/sequential.py,91,Add to the model any layers passed to the constructor.,not
keras/keras/engine/sequential.py,98,"Historically, `sequential.layers` only returns layers that were added",not
keras/keras/engine/sequential.py,99,"via `add`, and omits the auto-generated `InputLayer`",not
keras/keras/engine/sequential.py,100,that comes at the bottom of the stack.,not
keras/keras/engine/sequential.py,107,"Historically, `Sequential` was once",not
keras/keras/engine/sequential.py,108,implemented as a wrapper for `Model` which maintained,not
keras/keras/engine/sequential.py,109,its underlying `Model` as the `model` property.,not
keras/keras/engine/sequential.py,110,We keep it for compatibility reasons.,not
keras/keras/engine/sequential.py,137,First layer in model: check that it is an input layer.,not
keras/keras/engine/sequential.py,139,Create an input tensor and call `layer` on the input tensor.,not
keras/keras/engine/sequential.py,140,"First, we need to infer the expected input shape and dtype.",not
keras/keras/engine/sequential.py,143,We were passed a model as first layer.,not
keras/keras/engine/sequential.py,144,This requires a specific way to figure out the,not
keras/keras/engine/sequential.py,145,input shape and dtype.,not
keras/keras/engine/sequential.py,149,In case of nested models: recover the first layer,not
keras/keras/engine/sequential.py,150,of the deepest model to infer input shape and dtype.,not
keras/keras/engine/sequential.py,158,Instantiate the input layer.,not
keras/keras/engine/sequential.py,163,This will build the current layer,not
keras/keras/engine/sequential.py,164,and create the node connecting the current layer,not
keras/keras/engine/sequential.py,165,to the input layer we just created.,not
keras/keras/engine/sequential.py,169,Corner case where the user passes an InputLayer via `add`.,not
keras/keras/engine/sequential.py,295,legacy config file,not
keras/keras/engine/saving.py,41,getargspec() is deprecated since Python 3.0,not
keras/keras/engine/saving.py,99,if obj is a serializable Keras class instance,not
keras/keras/engine/saving.py,100,"e.g. optimizer, layer",not
keras/keras/engine/saving.py,105,if obj is any numpy type,not
keras/keras/engine/saving.py,112,misc functions (e.g. loss function),not
keras/keras/engine/saving.py,116,if obj is a python 'type',not
keras/keras/engine/saving.py,194,Default values of symbolic_weights is /variable,not
keras/keras/engine/saving.py,195,for Theano and CNTK,not
keras/keras/engine/saving.py,310,We batch weight value assignments in a single backend call,not
keras/keras/engine/saving.py,311,which provides a speedup in TensorFlow.,not
keras/keras/engine/saving.py,350,Recover loss functions and metrics.,not
keras/keras/engine/saving.py,351,Deserialize loss class.,not
keras/keras/engine/saving.py,356,Earlier versions of keras didn't dump weighted_metrics properly. Use,not
keras/keras/engine/saving.py,357,a get to avoid failing if the key is missing,not
keras/keras/engine/saving.py,363,Compile model.,not
keras/keras/engine/saving.py,371,Set optimizer weights.,not
keras/keras/engine/saving.py,373,Build train function (to get weight updates).,not
keras/keras/engine/saving.py,543,write as binary stream,not
keras/keras/engine/saving.py,678,Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`,not
keras/keras/engine/saving.py,679,because in that case even chunking the array would not make the saving,not
keras/keras/engine/saving.py,680,possible.,not
keras/keras/engine/saving.py,683,Expecting this to never be true.,not
keras/keras/engine/saving.py,695,This will never loop forever thanks to the test above.,not
keras/keras/engine/saving.py,747,Sort model layers by layer name to ensure that group names are strictly,not
keras/keras/engine/saving.py,748,growing to avoid prefix issues.,not
keras/keras/engine/saving.py,765,scalar,not
keras/keras/engine/saving.py,830,trainable weights,not
keras/keras/engine/saving.py,841,non-trainable weights,not
keras/keras/engine/saving.py,855,Convert layers nested in Bidirectional/TimeDistributed/Model/Sequential.,not
keras/keras/engine/saving.py,856,Both transformation should be ran for both Keras 1->2 conversion,not
keras/keras/engine/saving.py,857,and for conversion of CuDNN layers.,not
keras/keras/engine/saving.py,874,Handle Keras 1.1 format,not
keras/keras/engine/saving.py,876,Legacy shape:,not
keras/keras/engine/saving.py,877,"(filters, input_dim, filter_length, 1)",not
keras/keras/engine/saving.py,885,"old: (filters, stack_size, kernel_rows, kernel_cols)",not
keras/keras/engine/saving.py,886,"new: (kernel_rows, kernel_cols, stack_size, filters)",not
keras/keras/engine/saving.py,891,"old: (kernel_rows, kernel_cols, stack_size, filters)",not
keras/keras/engine/saving.py,892,"new: (kernel_rows, kernel_cols, filters, stack_size)",not
keras/keras/engine/saving.py,895,"old: (filters, stack_size, kernel_rows, kernel_cols)",not
keras/keras/engine/saving.py,896,"new: (kernel_rows, kernel_cols, filters, stack_size)",not
keras/keras/engine/saving.py,901,"old: (filters, stack_size, ...)",not
keras/keras/engine/saving.py,902,"new: (..., stack_size, filters)",not
keras/keras/engine/saving.py,920,"old: i, c, f, o",not
keras/keras/engine/saving.py,921,"new: i, f, c, o",not
keras/keras/engine/saving.py,951,"old: (filters, stack_size, kernel_rows, kernel_cols)",not
keras/keras/engine/saving.py,952,"new: (kernel_rows, kernel_cols, stack_size, filters)",not
keras/keras/engine/saving.py,986,convert CuDNN layers,not
keras/keras/engine/saving.py,1058,convert the weights between CuDNNLSTM and LSTM,not
keras/keras/engine/saving.py,1060,determine if we're loading a CuDNNLSTM layer,not
keras/keras/engine/saving.py,1061,from the number of bias weights:,not
keras/keras/engine/saving.py,1062,CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4),not
keras/keras/engine/saving.py,1063,"if there's no bias weight in the file, skip this conversion",not
keras/keras/engine/saving.py,1076,transpose (and reshape) input and recurrent kernels,not
keras/keras/engine/saving.py,1082,merge input and recurrent biases into a single set,not
keras/keras/engine/saving.py,1085,Split single set of biases evenly to two sets. The way of,not
keras/keras/engine/saving.py,1086,splitting doesn't matter as long as the two sets sum is kept.,not
keras/keras/engine/saving.py,1093,convert the weights between CuDNNGRU and GRU(reset_after=True),not
keras/keras/engine/saving.py,1095,We can determine the source of the weights from the shape of the bias.,not
keras/keras/engine/saving.py,1096,If there is no bias we skip the conversion,not
keras/keras/engine/saving.py,1097,since CuDNNGRU always has biases.,not
keras/keras/engine/saving.py,1127,only convert between different types,not
keras/keras/engine/saving.py,1155,backend information not available,not
keras/keras/engine/saving.py,1161,"By default, do not convert the kernels if the original backend is unknown",not
keras/keras/engine/saving.py,1166,Assume unknown backends use correlation,not
keras/keras/engine/saving.py,1213,We batch weight value assignments in a single backend call,not
keras/keras/engine/saving.py,1214,which provides a speedup in TensorFlow.,not
keras/keras/engine/saving.py,1272,New file format.,not
keras/keras/engine/saving.py,1275,Reverse index of layer name to list of layers with name.,not
keras/keras/engine/saving.py,1281,We batch weight value assignments in a single backend call,not
keras/keras/engine/saving.py,1282,which provides a speedup in TensorFlow.,not
keras/keras/engine/saving.py,1312,Set values.,not
keras/keras/engine/network.py,89,Signature detection,not
keras/keras/engine/network.py,93,Graph network,not
keras/keras/engine/network.py,96,Subclassed network,not
keras/keras/engine/network.py,100,The following are implemented as property functions:,not
keras/keras/engine/network.py,101,self.trainable_weights,not
keras/keras/engine/network.py,102,self.non_trainable_weights,not
keras/keras/engine/network.py,103,self.input_spec,not
keras/keras/engine/network.py,104,self.losses,not
keras/keras/engine/network.py,105,self.updates,not
keras/keras/engine/network.py,107,Handle `name` argument.,not
keras/keras/engine/network.py,113,This acts just like the `trainable` attribute of any layer instance.,not
keras/keras/engine/network.py,114,"It does not affect users of the underlying layers, only users of the",not
keras/keras/engine/network.py,115,Network instance.,not
keras/keras/engine/network.py,126,Don't reset optimizer if already set.,not
keras/keras/engine/network.py,129,Private attributes to implement compatibility with Layer.,not
keras/keras/engine/network.py,137,A list of metric instances corresponding to the metric tensors added using,not
keras/keras/engine/network.py,138,the `add_metric` API.,not
keras/keras/engine/network.py,141,All layers in order of horizontal graph traversal.,not
keras/keras/engine/network.py,142,Entries are unique. Includes input and output layers.,not
keras/keras/engine/network.py,145,Used only in conjunction with graph-networks,not
keras/keras/engine/network.py,151,"Normalize and set self.inputs, self.outputs.",not
keras/keras/engine/network.py,155,User-provided argument validation.,not
keras/keras/engine/network.py,156,Check for redundancy in inputs.,not
keras/keras/engine/network.py,163,Check that x has appropriate `_keras_history` metadata.,not
keras/keras/engine/network.py,170,Check that x is an input tensor.,not
keras/keras/engine/network.py,203,"A Network does not create weights of its own,",not
keras/keras/engine/network.py,204,thus it is already built.,not
keras/keras/engine/network.py,213,This is for performance optimization when calling the Network on new,not
keras/keras/engine/network.py,214,"inputs. Every time the Network is called on a set on input tensors,",not
keras/keras/engine/network.py,215,"we compute the output tensors,",not
keras/keras/engine/network.py,216,"output masks and output shapes in one pass,",not
keras/keras/engine/network.py,217,"then cache them here. When any of these outputs is queried later, we",not
keras/keras/engine/network.py,218,retrieve it from there instead of recomputing it.,not
keras/keras/engine/network.py,223,Build self._output_layers:,not
keras/keras/engine/network.py,229,Build self._input_layers:,not
keras/keras/engine/network.py,232,"It's supposed to be an input layer, so only one node",not
keras/keras/engine/network.py,233,and one tensor output.,not
keras/keras/engine/network.py,239,Keep track of the network's nodes and layers.,not
keras/keras/engine/network.py,247,Create the node linking internal inputs to internal outputs.,not
keras/keras/engine/network.py,254,No network-level masking for now.,not
keras/keras/engine/network.py,260,Fill in the output mask cache.,not
keras/keras/engine/network.py,278,Build self.input_names and self.output_names.,not
keras/keras/engine/network.py,285,Check that layer is an InputLayer.,not
keras/keras/engine/network.py,313,Automatically track layers set as Model,not
keras/keras/engine/network.py,314,attributes for subclassed Models.,not
keras/keras/engine/network.py,346,It would be unreliable to build a dictionary,not
keras/keras/engine/network.py,347,"based on layer names, because names can potentially",not
keras/keras/engine/network.py,348,be changed at any point by the user,not
keras/keras/engine/network.py,349,without the network being notified of it.,not
keras/keras/engine/network.py,385,Collect updates that are dependent on inputs,not
keras/keras/engine/network.py,386,that are part of the model.,not
keras/keras/engine/network.py,390,The model owns this layer node.,not
keras/keras/engine/network.py,393,Collect unconditional updates.,not
keras/keras/engine/network.py,415,Collect losses that are dependent on inputs,not
keras/keras/engine/network.py,416,that are part of the model.,not
keras/keras/engine/network.py,420,The model owns this layer node.,not
keras/keras/engine/network.py,423,Collect unconditional losses.,not
keras/keras/engine/network.py,428,Add any potential unconditional model-level loss.,not
keras/keras/engine/network.py,538,TODO: support it in subclassed networks after inputs are set.,SATD
keras/keras/engine/network.py,605,Must be implemented by subclasses.,not
keras/keras/engine/network.py,621,"Bad luck, we have to run the graph manually.",not
keras/keras/engine/network.py,626,"It's an input layer: compute_output_shape is identity,",not
keras/keras/engine/network.py,627,and there is only one node and one tensor output.,not
keras/keras/engine/network.py,633,"Iterate over nodes, by depth level.",not
keras/keras/engine/network.py,638,"This is always a single layer, never a list.",not
keras/keras/engine/network.py,641,We've already covered the input layers,not
keras/keras/engine/network.py,642,a few lines above.,not
keras/keras/engine/network.py,644,"Potentially redundant list,",not
keras/keras/engine/network.py,645,same size of node.input_tensors.,not
keras/keras/engine/network.py,665,Read final output shapes from layers_to_output_shapes.,not
keras/keras/engine/network.py,678,Store in cache.,not
keras/keras/engine/network.py,701,Dictionary mapping reference tensors to tuples,not
keras/keras/engine/network.py,702,"(computed tensor, compute mask)",not
keras/keras/engine/network.py,703,we assume a 1:1 mapping from tensor to mask,not
keras/keras/engine/network.py,704,TODO: raise exception when a `.compute_mask()` call,SATD
keras/keras/engine/network.py,705,does not return a list the same size as `call`,not
keras/keras/engine/network.py,715,"This is always a single layer, never a list.",not
keras/keras/engine/network.py,720,"If all previous input tensors are available in tensor_map,",not
keras/keras/engine/network.py,721,then call node.inbound_layer on them.,not
keras/keras/engine/network.py,722,"List of tuples (input, mask).",not
keras/keras/engine/network.py,728,call layer,not
keras/keras/engine/network.py,749,computed_masks might be used in the future.,not
keras/keras/engine/network.py,765,Apply activity regularizer if any:,not
keras/keras/engine/network.py,781,Update model updates and losses:,not
keras/keras/engine/network.py,782,Keep track of updates that depend on the inputs,not
keras/keras/engine/network.py,783,(e.g. BN updates).,not
keras/keras/engine/network.py,785,Keep track of unconditional updates (e.g. a counter).,not
keras/keras/engine/network.py,787,Keep track of losses that depend on the inputs,not
keras/keras/engine/network.py,788,(e.g. activity regularizers).,not
keras/keras/engine/network.py,790,Keep track of unconditional losses,not
keras/keras/engine/network.py,791,(e.g. weight regularizers).,not
keras/keras/engine/network.py,794,Update _keras_shape.,not
keras/keras/engine/network.py,807,Update tensor_map.,not
keras/keras/engine/network.py,827,Update cache;,not
keras/keras/engine/network.py,828,keys are based on ids on input tensors and inputs masks.,not
keras/keras/engine/network.py,848,Subclassed networks are not serializable,not
keras/keras/engine/network.py,849,(unless serialization is implemented by,not
keras/keras/engine/network.py,850,the author of the subclassed network).,not
keras/keras/engine/network.py,857,Build a map from a layer unique name (self._node_key),not
keras/keras/engine/network.py,858,to the index of the nodes that are saved in the config.,not
keras/keras/engine/network.py,859,Only nodes in network_nodes are saved.,not
keras/keras/engine/network.py,863,Networks start with a pre-existing node,not
keras/keras/engine/network.py,864,linking their input to output.,not
keras/keras/engine/network.py,871,i.e. we mark it to be saved,not
keras/keras/engine/network.py,875,serialize and save the layers in layer_configs,not
keras/keras/engine/network.py,877,From the earliest layers on.,not
keras/keras/engine/network.py,884,The node is relevant to the model:,not
keras/keras/engine/network.py,885,add to filtered_inbound_nodes.,not
keras/keras/engine/network.py,925,Gather info about inputs and outputs.,not
keras/keras/engine/network.py,968,Layer instances created during,not
keras/keras/engine/network.py,969,the graph reconstruction process,not
keras/keras/engine/network.py,972,Dictionary mapping layer instances to,not
keras/keras/engine/network.py,973,node data that specifies a layer call.,not
keras/keras/engine/network.py,974,It acts as a queue that maintains any unprocessed,not
keras/keras/engine/network.py,975,layer call until it becomes possible to process it,not
keras/keras/engine/network.py,976,(i.e. until the input tensors to the call all exist).,not
keras/keras/engine/network.py,1014,Raise an error if the corresponding layer node,not
keras/keras/engine/network.py,1015,has not yet been created,not
keras/keras/engine/network.py,1022,"Call layer on its inputs, thus creating the node",not
keras/keras/engine/network.py,1023,and building the layer if needed.,not
keras/keras/engine/network.py,1038,Instantiate layer.,not
keras/keras/engine/network.py,1045,Gather layer inputs.,not
keras/keras/engine/network.py,1048,We don't process nodes (i.e. make layer calls),not
keras/keras/engine/network.py,1049,"on the fly because the inbound node may not yet exist,",not
keras/keras/engine/network.py,1050,in case of layer shared at different topological depths,not
keras/keras/engine/network.py,1051,(e.g. a model such as A(B(A(B(x))))),not
keras/keras/engine/network.py,1054,"First, we create all layers and enqueue nodes to be processed",not
keras/keras/engine/network.py,1058,Then we process nodes in order of layer depth.,not
keras/keras/engine/network.py,1059,Nodes that cannot yet be processed (if the inbound node,not
keras/keras/engine/network.py,1060,"does not yet exist) are re-enqueued, and the process",not
keras/keras/engine/network.py,1061,is repeated until all nodes are processed.,not
keras/keras/engine/network.py,1066,"Process all nodes in layer, if not yet processed",not
keras/keras/engine/network.py,1070,Process nodes in order,not
keras/keras/engine/network.py,1077,If the node does not have all inbound layers,not
keras/keras/engine/network.py,1078,"available, stop processing and continue later",not
keras/keras/engine/network.py,1084,If not all nodes processed then store unprocessed nodes,not
keras/keras/engine/network.py,1087,If all nodes processed remove the layer,not
keras/keras/engine/network.py,1091,Create lits of input and output tensors and return new class,not
keras/keras/engine/network.py,1178,If file exists and should not be overwritten:,not
keras/keras/engine/network.py,1267,If obj is any numpy type,not
keras/keras/engine/network.py,1274,If obj is a python 'type',not
keras/keras/engine/network.py,1360,Network_nodes: set of nodes included in the graph of layers,not
keras/keras/engine/network.py,1361,(not all nodes included in the layers are relevant to the current graph).,not
keras/keras/engine/network.py,1362,ids of all nodes relevant to the Network,not
keras/keras/engine/network.py,1363,dict {node: depth value},not
keras/keras/engine/network.py,1364,dict {layer: depth value},not
keras/keras/engine/network.py,1365,dict {layer: index in traversal},not
keras/keras/engine/network.py,1395,Prevent cycles.,not
keras/keras/engine/network.py,1400,Don't repeat work for shared subgraphs,not
keras/keras/engine/network.py,1405,Update network_nodes.,not
keras/keras/engine/network.py,1408,Store the traversal order for layer sorting.,not
keras/keras/engine/network.py,1414,Propagate to all previous tensors connected to this node.,not
keras/keras/engine/network.py,1437,"If the depth is not set, the node has no outbound nodes (depth 0).",not
keras/keras/engine/network.py,1440,Update the depth of the corresponding layer,not
keras/keras/engine/network.py,1442,"If we've seen this layer before at a higher depth,",not
keras/keras/engine/network.py,1443,we should use that depth instead of the node depth.,not
keras/keras/engine/network.py,1444,This is necessary for shared layers that have inputs at different,not
keras/keras/engine/network.py,1445,depth levels in the graph.,not
keras/keras/engine/network.py,1450,Update the depth of inbound nodes.,not
keras/keras/engine/network.py,1451,"The ""depth"" of a node is the max of the depths",not
keras/keras/engine/network.py,1452,of all layers it is connected to.,not
keras/keras/engine/network.py,1460,Build a dict {depth: list of nodes with this depth},not
keras/keras/engine/network.py,1467,Build a dict {depth: list of layers with this depth},not
keras/keras/engine/network.py,1474,Get sorted list of layer depths.,not
keras/keras/engine/network.py,1478,Set self.layers and self._layers_by_depth.,not
keras/keras/engine/network.py,1482,Network.layers needs to have a deterministic order:,not
keras/keras/engine/network.py,1483,here we order them by traversal order.,not
keras/keras/engine/network.py,1487,Get sorted list of node depths.,not
keras/keras/engine/network.py,1491,Check that all tensors required are computable.,not
keras/keras/engine/network.py,1492,computable_tensors: all tensors in the graph,not
keras/keras/engine/network.py,1493,that can be computed from the inputs provided.,not
keras/keras/engine/network.py,1498,To provide a better error msg.,SATD
keras/keras/engine/network.py,1516,"Ensure name unicity, which will be crucial for serialization",not
keras/keras/engine/network.py,1517,(since serialized nodes refer to layers by their name).,not
keras/keras/engine/__init__.py,1,"note: `Node` is an internal class,",not
keras/keras/engine/__init__.py,2,it isn't meant to be used by Keras users.,not
keras/keras/engine/training_generator.py,54,if generator is instance of Sequence and steps_per_epoch are not provided -,not
keras/keras/engine/training_generator.py,55,recompute steps_per_epoch after each epoch,not
keras/keras/engine/training_generator.py,68,"python 2 has 'next', 3 has '__next__'",not
keras/keras/engine/training_generator.py,69,avoid any explicit version checks,not
keras/keras/engine/training_generator.py,81,Prepare display labels.,not
keras/keras/engine/training_generator.py,85,prepare callbacks,not
keras/keras/engine/training_generator.py,97,it's possible to callback a different model than self:,not
keras/keras/engine/training_generator.py,116,Create an Enqueuer that can be reused,not
keras/keras/engine/training_generator.py,138,Prepare data for validation,not
keras/keras/engine/training_generator.py,177,Construct epoch logs.,not
keras/keras/engine/training_generator.py,204,Handle data tensors support when no input given,not
keras/keras/engine/training_generator.py,205,step-size = 1 for data tensors,not
keras/keras/engine/training_generator.py,213,build batch logs,not
keras/keras/engine/training_generator.py,231,Epoch finished.,not
keras/keras/engine/training_generator.py,235,Note that `callbacks` here is an instance of,not
keras/keras/engine/training_generator.py,236,`keras.callbacks.CallbackList`,not
keras/keras/engine/training_generator.py,244,No need for try/except because,not
keras/keras/engine/training_generator.py,245,data has already been validated.,not
keras/keras/engine/training_generator.py,253,Same labels assumed.,not
keras/keras/engine/training_generator.py,272,recomute steps per epochs in case if Sequence changes it's length,not
keras/keras/engine/training_generator.py,275,update callbacks to make sure params are valid each epoch,not
keras/keras/engine/training_generator.py,327,Check if callbacks have not been already configured,not
keras/keras/engine/training_generator.py,383,Handle data tensors support when no input given,not
keras/keras/engine/training_generator.py,384,step-size = 1 for data tensors,not
keras/keras/engine/training_generator.py,420,index 0 = 'loss',not
keras/keras/engine/training_generator.py,455,Check if callbacks have not been already configured,not
keras/keras/engine/training_generator.py,493,Compatibility with the generators,not
keras/keras/engine/training_generator.py,494,used for training.,not
keras/keras/engine/training_generator.py,505,Assumes a generator that only,not
keras/keras/engine/training_generator.py,506,yields inputs (not targets and sample weights).,not
keras/keras/engine/training_generator.py,510,Handle data tensors support when no input given,not
keras/keras/engine/training_generator.py,511,step-size = 1 for data tensors,not
keras/keras/engine/input_layer.py,52,"If input_tensor is set, and batch_input_shape is not set:",not
keras/keras/engine/input_layer.py,53,Attempt automatic input shape inference.,not
keras/keras/engine/input_layer.py,91,Create an input node to add to self.outbound_node,not
keras/keras/engine/input_layer.py,92,and set output_tensors' _keras_history.,not
keras/keras/engine/input_layer.py,179,Return tensor including _keras_shape and _keras_history.,not
keras/keras/engine/input_layer.py,180,Note that in this case train_output and test_output are the same pointer.,not
keras/keras/layers/cudnn_recurrent.py,68,"input shape: `(samples, time (padded with zeros), input_dim)`",not
keras/keras/layers/cudnn_recurrent.py,69,note that the .build() method of subclasses MUST define,not
keras/keras/layers/cudnn_recurrent.py,70,self.input_spec and self.state_spec with complete input shapes.,not
keras/keras/layers/cudnn_recurrent.py,88,Reverse time axis.,not
keras/keras/layers/local.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/advanced_activations.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/advanced_activations.py,121,Set input spec,not
keras/keras/layers/convolutional.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/convolutional.py,19,imports for backwards namespace compatibility,not
keras/keras/layers/convolutional.py,150,Set input spec.,not
keras/keras/layers/convolutional.py,804,Set input spec.,not
keras/keras/layers/convolutional.py,824,Infer the dynamic output shape:,not
keras/keras/layers/convolutional.py,1076,Set input spec.,not
keras/keras/layers/convolutional.py,1099,Infer the dynamic output shape:,not
keras/keras/layers/convolutional.py,1357,Set input spec.,not
keras/keras/layers/convolutional.py,1839,Set input spec.,not
keras/keras/layers/convolutional.py,1916,"self.rank is 1 for UpSampling1D, 2 for UpSampling2D.",not
keras/keras/layers/convolutional.py,2096,"self.rank is 1 for ZeroPadding1D, 2 for ZeroPadding2D.",not
keras/keras/layers/convolutional.py,2337,"self.rank is 1 for Cropping1D, 2 for Cropping2D...",not
keras/keras/layers/convolutional.py,2571,Aliases,not
keras/keras/layers/convolutional.py,2582,Legacy aliases,not
keras/keras/layers/noise.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/noise.py,157,Get affine transformation params,not
keras/keras/layers/noise.py,161,Apply mask,not
keras/keras/layers/noise.py,164,Do affine transformation,not
keras/keras/layers/normalization.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/normalization.py,134,Prepare broadcasting shape.,not
keras/keras/layers/normalization.py,141,Determines whether broadcasting is needed.,not
keras/keras/layers/normalization.py,146,In this case we must explicitly broadcast all parameters.,not
keras/keras/layers/normalization.py,178,If the learning phase is *static* and set to inference:,not
keras/keras/layers/normalization.py,182,"If the learning is either dynamic, or set to training:",not
keras/keras/layers/normalization.py,194,sample variance - unbiased estimator of population variance,not
keras/keras/layers/normalization.py,205,Pick the normalized form corresponding to the training phase.,not
keras/keras/layers/pooling.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/pooling.py,52,add dummy last dimension,not
keras/keras/layers/pooling.py,58,remove dummy last dimension,not
keras/keras/layers/pooling.py,779,Aliases,not
keras/keras/layers/merge.py,66,Used purely for shape validation.,not
keras/keras/layers/merge.py,92,"If the inputs have different ranks, we have to reshape them",not
keras/keras/layers/merge.py,93,to make them broadcastable.,not
keras/keras/layers/merge.py,107,"If ranks of all inputs are available,",not
keras/keras/layers/merge.py,108,we simply expand each of them at axis=1,not
keras/keras/layers/merge.py,109,until all of them have the same rank.,not
keras/keras/layers/merge.py,118,Transpose all inputs so that batch size is the last dimension.,not
keras/keras/layers/merge.py,119,"(batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)",not
keras/keras/layers/merge.py,139,We don't transpose inputs if they are,not
keras/keras/layers/merge.py,140,1D vectors or scalars.,not
keras/keras/layers/merge.py,145,"If inputs have been transposed,",not
keras/keras/layers/merge.py,146,we have to transpose the output too.,not
keras/keras/layers/merge.py,347,Used purely for shape validation.,not
keras/keras/layers/merge.py,392,Make a list of masks while making sure,not
keras/keras/layers/merge.py,393,the dimensionality of each mask,not
keras/keras/layers/merge.py,394,is the same as the corresponding input.,not
keras/keras/layers/merge.py,398,"Input is unmasked. Append all 1s to masks,",not
keras/keras/layers/merge.py,401,"Mask is smaller than the input, expand it",not
keras/keras/layers/merge.py,452,Used purely for shape validation.,not
keras/keras/layers/embeddings.py,125,input_length can be tuple if input is 3D or higher,not
keras/keras/layers/wrappers.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/wrappers.py,33,Tracks mapping of Wrapper inputs to inner layer inputs. Useful when,not
keras/keras/layers/wrappers.py,34,the inner layer has update ops that depend on its inputs (as opposed,not
keras/keras/layers/wrappers.py,35,to the inputs to the Wrapper layer).,not
keras/keras/layers/wrappers.py,72,"If the wrapper modifies the inputs, use the modified inputs to",not
keras/keras/layers/wrappers.py,73,get the updates from the inner layer.,not
keras/keras/layers/wrappers.py,184,replace all None in int_shape by K.shape,not
keras/keras/layers/wrappers.py,219,"batch size matters, use rnn-based implementation",not
keras/keras/layers/wrappers.py,234,"No batch size specified, therefore the layer will be able",not
keras/keras/layers/wrappers.py,235,to process batches of any size.,not
keras/keras/layers/wrappers.py,236,We can go with reshape-based implementation for performance.,not
keras/keras/layers/wrappers.py,241,"Shape: (num_samples * timesteps, ...). And track the",not
keras/keras/layers/wrappers.py,242,transformation in self._input_map.,not
keras/keras/layers/wrappers.py,246,"(num_samples * timesteps, ...)",not
keras/keras/layers/wrappers.py,253,"Shape: (num_samples, timesteps, ...)",not
keras/keras/layers/wrappers.py,259,Apply activity regularizer if any:,not
keras/keras/layers/wrappers.py,295,cases need to call the layer.compute_mask when input_mask is None:,not
keras/keras/layers/wrappers.py,296,Masking layer and Embedding layer with mask_zero,not
keras/keras/layers/wrappers.py,299,"batch size matters, we currently do not handle mask explicitly",not
keras/keras/layers/wrappers.py,311,"input_mask is not None, and output_mask is None:",not
keras/keras/layers/wrappers.py,312,we should return a not-None mask,not
keras/keras/layers/wrappers.py,317,output_mask is not None. We need to reshape it,not
keras/keras/layers/wrappers.py,323,"if the output_mask does not have a static shape,",not
keras/keras/layers/wrappers.py,324,its shape must be the same as mask's,not
keras/keras/layers/wrappers.py,385,This is isolated in its own method in order to use,not
keras/keras/layers/wrappers.py,386,the disable_tracking decorator without altering the,not
keras/keras/layers/wrappers.py,387,visible signature of __init__.,not
keras/keras/layers/wrappers.py,439,Applies the same workaround as in `RNN.__call__`,SATD
keras/keras/layers/wrappers.py,443,Check if `initial_state` can be splitted into half,not
keras/keras/layers/wrappers.py,482,"Compute the full input spec, including state",not
keras/keras/layers/wrappers.py,486,Perform the call with temporarily replaced input_spec,not
keras/keras/layers/wrappers.py,560,Properly set learning phase,not
keras/keras/layers/__init__.py,58,Aliases (not in the docs),not
keras/keras/layers/__init__.py,78,Aliases (not in the docs),not
keras/keras/layers/__init__.py,128,Legacy imports,not
keras/keras/layers/__init__.py,162,All layers.,not
keras/keras/layers/recurrent.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/recurrent.py,22,Legacy support.,not
keras/keras/layers/recurrent.py,59,reverse_state_order determines whether the state size will be in a,not
keras/keras/layers/recurrent.py,60,reverse order of the cells' state. User might want to set this to True,not
keras/keras/layers/recurrent.py,61,to keep the existing behavior. This is only useful when use,not
keras/keras/layers/recurrent.py,62,`RNN(return_state=True)` since the state will be returned as the same,not
keras/keras/layers/recurrent.py,63,order of state_size.,not
keras/keras/layers/recurrent.py,75,States are a flat list of the individual cell state size.,not
keras/keras/layers/recurrent.py,76,"e.g. states of a 2-layer LSTM would be `[h1, c1, h2, c2]`.",not
keras/keras/layers/recurrent.py,77,"(assuming one LSTM has states [h, c])",not
keras/keras/layers/recurrent.py,78,"In the case of reverse_state_order=True, the state_size will be",not
keras/keras/layers/recurrent.py,79,"`[h2, c2, h1, c1]`.",not
keras/keras/layers/recurrent.py,98,Recover per-cell states.,not
keras/keras/layers/recurrent.py,110,Call the cells in order and store the returned states.,not
keras/keras/layers/recurrent.py,121,Format the new states as a flat list,not
keras/keras/layers/recurrent.py,122,in reverse cell order.,not
keras/keras/layers/recurrent.py,427,This is isolated in its own method in order to use,not
keras/keras/layers/recurrent.py,428,the disable_tracking decorator without altering the,not
keras/keras/layers/recurrent.py,429,visible signature of __init__.,not
keras/keras/layers/recurrent.py,482,Note input_shape will be list of shapes of initial states and,not
keras/keras/layers/recurrent.py,483,constants if these are passed in __call__.,not
keras/keras/layers/recurrent.py,496,allow cell (if layer) to build before we set or validate state_spec,not
keras/keras/layers/recurrent.py,504,set or validate state_spec,not
keras/keras/layers/recurrent.py,511,"initial_state was passed in call, check compatibility",not
keras/keras/layers/recurrent.py,526,"build an all-zero tensor of shape (samples, output_dim)",not
keras/keras/layers/recurrent.py,527,"(samples, timesteps, input_dim)",not
keras/keras/layers/recurrent.py,528,"(samples,)",not
keras/keras/layers/recurrent.py,529,"(samples, 1)",not
keras/keras/layers/recurrent.py,543,If any of `initial_state` or `constants` are specified and are Keras,not
keras/keras/layers/recurrent.py,544,"tensors, then add them to the inputs and temporarily modify the",not
keras/keras/layers/recurrent.py,545,input_spec to include them.,not
keras/keras/layers/recurrent.py,563,at this point additional_inputs cannot be empty,not
keras/keras/layers/recurrent.py,574,"Compute the full input spec, including state and constants",not
keras/keras/layers/recurrent.py,577,Perform the call with temporarily replaced input_spec,not
keras/keras/layers/recurrent.py,600,"input shape: `(samples, time (padded with zeros), input_dim)`",not
keras/keras/layers/recurrent.py,601,note that the .build() method of subclasses MUST define,not
keras/keras/layers/recurrent.py,602,self.input_spec and self.state_spec with complete input shapes.,not
keras/keras/layers/recurrent.py,607,get initial_state from full input spec,not
keras/keras/layers/recurrent.py,608,as they could be copied to multiple GPU.,not
keras/keras/layers/recurrent.py,694,Properly set learning phase,not
keras/keras/layers/recurrent.py,721,initialize state if None,not
keras/keras/layers/recurrent.py,754,TODO: consider batch calls to `set_value`.,SATD
keras/keras/layers/recurrent.py,947,Properly set learning phase on output tensor.,not
keras/keras/layers/recurrent.py,1327,separate biases for input and recurrent kernels,not
keras/keras/layers/recurrent.py,1328,Note: the shape is intentionally different from CuDNNGRU biases,not
keras/keras/layers/recurrent.py,1329,"`(2 * 3 * self.units,)`, so that we can distinguish the classes",not
keras/keras/layers/recurrent.py,1330,when loading and converting saved weights.,not
keras/keras/layers/recurrent.py,1340,"NOTE: need to flatten, since slicing in CNTK gives 2D array",not
keras/keras/layers/recurrent.py,1346,update gate,not
keras/keras/layers/recurrent.py,1349,reset gate,not
keras/keras/layers/recurrent.py,1354,new gate,not
keras/keras/layers/recurrent.py,1359,bias for inputs,not
keras/keras/layers/recurrent.py,1363,bias for hidden state - just for compatibility with CuDNN,not
keras/keras/layers/recurrent.py,1380,previous memory,not
keras/keras/layers/recurrent.py,1396,dropout matrices for input units,not
keras/keras/layers/recurrent.py,1398,dropout matrices for recurrent units,not
keras/keras/layers/recurrent.py,1437,reset gate applied after/before matrix multiplication,not
keras/keras/layers/recurrent.py,1451,inputs projected by all gate matrices at once,not
keras/keras/layers/recurrent.py,1454,"biases: bias_z_i, bias_r_i, bias_h_i",not
keras/keras/layers/recurrent.py,1464,hidden state projected by all gate matrices at once,not
keras/keras/layers/recurrent.py,1469,hidden state projected separately for update/reset and new,not
keras/keras/layers/recurrent.py,1487,previous and candidate state mixed by update gate,not
keras/keras/layers/recurrent.py,1985,dropout matrices for input units,not
keras/keras/layers/recurrent.py,1987,dropout matrices for recurrent units,not
keras/keras/layers/recurrent.py,1990,previous memory state,not
keras/keras/layers/recurrent.py,1991,previous carry state,not
keras/keras/layers/convolutional_recurrent.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/convolutional_recurrent.py,142,The StackedConvRNN2DCells isn't implemented yet.,not
keras/keras/layers/convolutional_recurrent.py,191,Note input_shape will be list of shapes of initial states and,not
keras/keras/layers/convolutional_recurrent.py,192,constants if these are passed in __call__.,not
keras/keras/layers/convolutional_recurrent.py,204,allow cell (if layer) to build before we set or validate state_spec,not
keras/keras/layers/convolutional_recurrent.py,212,set or validate state_spec,not
keras/keras/layers/convolutional_recurrent.py,219,"initial_state was passed in call, check compatibility",not
keras/keras/layers/convolutional_recurrent.py,243,"(samples, timesteps, rows, cols, filters)",not
keras/keras/layers/convolutional_recurrent.py,245,"(samples, rows, cols, filters)",not
keras/keras/layers/convolutional_recurrent.py,251,We need to force this to be a tensor,not
keras/keras/layers/convolutional_recurrent.py,252,"and not a variable, to avoid variable initialization",not
keras/keras/layers/convolutional_recurrent.py,253,issues.,not
keras/keras/layers/convolutional_recurrent.py,261,Fix for Theano because it needs,not
keras/keras/layers/convolutional_recurrent.py,262,K.int_shape to work in call() with initial_state.,not
keras/keras/layers/convolutional_recurrent.py,290,If any of `initial_state` or `constants` are specified and are Keras,not
keras/keras/layers/convolutional_recurrent.py,291,"tensors, then add them to the inputs and temporarily modify the",not
keras/keras/layers/convolutional_recurrent.py,292,input_spec to include them.,not
keras/keras/layers/convolutional_recurrent.py,303,Fix for Theano,not
keras/keras/layers/convolutional_recurrent.py,316,at this point additional_inputs cannot be empty,not
keras/keras/layers/convolutional_recurrent.py,324,"Compute the full input spec, including state and constants",not
keras/keras/layers/convolutional_recurrent.py,327,Perform the call with temporarily replaced input_spec,not
keras/keras/layers/convolutional_recurrent.py,342,note that the .build() method of subclasses MUST define,not
keras/keras/layers/convolutional_recurrent.py,343,self.input_spec and self.state_spec with complete input shapes.,not
keras/keras/layers/convolutional_recurrent.py,398,Properly set learning phase,not
keras/keras/layers/convolutional_recurrent.py,431,helper function,not
keras/keras/layers/convolutional_recurrent.py,442,initialize state if None,not
keras/keras/layers/convolutional_recurrent.py,475,TODO: consider batch calls to `set_value`.,SATD
keras/keras/layers/convolutional_recurrent.py,687,dropout matrices for input units,not
keras/keras/layers/convolutional_recurrent.py,689,dropout matrices for recurrent units,not
keras/keras/layers/convolutional_recurrent.py,692,previous memory state,not
keras/keras/layers/convolutional_recurrent.py,693,previous carry state,not
keras/keras/layers/core.py,1,-*- coding: utf-8 -*-,not
keras/keras/layers/core.py,393,input shape (partially) unknown? replace -1's with None's,not
keras/keras/layers/core.py,397,input shape known? then we can compute the output shape,not
keras/keras/layers/core.py,509,Ensure works for any dim,not
keras/keras/layers/core.py,669,"With TensorFlow or CNTK, we can infer the output shape directly:",not
keras/keras/layers/core.py,682,"Otherwise, we default to the input shape.",not
keras/keras/layers/core.py,757,Simple lookup in custom objects,not
keras/keras/layers/core.py,763,Unsafe deserialization from bytecode,not
keras/keras/layers/core.py,770,Simple lookup in custom objects,not
keras/keras/layers/core.py,776,Unsafe deserialization from bytecode,not
keras/keras/layers/core.py,781,"If arguments were numpy array, they have been saved as",not
keras/keras/layers/core.py,782,list. We need to recover the ndarray,not
keras/keras/layers/core.py,788,Overwrite the argument with its numpy translation,not
keras/keras/callbacks/tensorboard_v1.py,131,It is the same as writing as frequently as possible.,not
keras/keras/callbacks/tensorboard_v1.py,161,dense layer kernel case,not
keras/keras/callbacks/tensorboard_v1.py,169,convnet case,not
keras/keras/callbacks/tensorboard_v1.py,171,switch to channels_first to display,not
keras/keras/callbacks/tensorboard_v1.py,172,every kernel as a separate image,not
keras/keras/callbacks/tensorboard_v1.py,179,bias case,not
keras/keras/callbacks/tensorboard_v1.py,185,not possible to handle 3D convnets etc.,not
keras/keras/callbacks/tensorboard_v1.py,282,do not slice the learning phase,not
keras/keras/callbacks/tensorboard_v1.py,296,We need a second forward-pass here because we're passing,not
keras/keras/callbacks/tensorboard_v1.py,297,the `embeddings_data` explicitly. This design allows to pass,not
keras/keras/callbacks/tensorboard_v1.py,298,arbitrary data as `embeddings_data` and results from the fact,not
keras/keras/callbacks/tensorboard_v1.py,299,that we need to know the size of the `tf.Variable`s which,not
keras/keras/callbacks/tensorboard_v1.py,300,"hold the embeddings in `set_model`. At this point, however,",not
keras/keras/callbacks/tensorboard_v1.py,301,the `validation_data` is not yet set.,not
keras/keras/callbacks/tensorboard_v1.py,303,More details in this discussion:,not
keras/keras/callbacks/tensorboard_v1.py,304,https://github.com/keras-team/keras/pull/7766#issuecomment-329195622,not
keras/keras/callbacks/callbacks.py,78,"Batch is ending, calculate batch time",not
keras/keras/callbacks/callbacks.py,353,For backwards compatibility,not
keras/keras/callbacks/callbacks.py,365,For backwards compatibility,not
keras/keras/callbacks/callbacks.py,517,Make value available to next callbacks.,not
keras/keras/callbacks/callbacks.py,600,Skip progbar update for the last batch;,not
keras/keras/callbacks/callbacks.py,601,will be handled by on_epoch_end.,not
keras/keras/callbacks/callbacks.py,807,Allow instances to be re-used,not
keras/keras/callbacks/callbacks.py,929,new API,not
keras/keras/callbacks/callbacks.py,931,old API for backward compatibility,not
keras/keras/callbacks/callbacks.py,1006,Cooldown counter.,not
keras/keras/callbacks/callbacks.py,1134,We set NA so that csv parsers do not fail for this last epoch.,not
keras/keras/wrappers/scikit_learn.py,257,check if binary classification,not
keras/keras/wrappers/scikit_learn.py,259,first column is probability of class 0 and second is of class 1,not
keras/tests/test_loss_masking.py,43,Normally the trailing 1 is added by standardize_weights,not
keras/tests/test_model_saving.py,62,cleanup,not
keras/tests/test_model_saving.py,72,test that new updates are the same with both models,not
keras/tests/test_model_saving.py,79,"test with custom optimizer, loss",not
keras/tests/test_model_saving.py,104,cleanup,not
keras/tests/test_model_saving.py,140,cleanup,not
keras/tests/test_model_saving.py,158,test non-default options in h5,not
keras/tests/test_model_saving.py,190,save directly to binary file,not
keras/tests/test_model_saving.py,193,"Load the data the usual way, and make sure the model is intact.",not
keras/tests/test_model_saving.py,205,save the model the usual way,not
keras/tests/test_model_saving.py,208,"Load the data binary, and make sure the model is intact.",not
keras/tests/test_model_saving.py,242,assure that model is working,not
keras/tests/test_model_saving.py,300,"test with custom optimizer, loss",not
keras/tests/test_model_saving.py,304,sequential model,not
keras/tests/test_model_saving.py,321,delete and recreate model,not
keras/tests/test_model_saving.py,328,load weights from first model,not
keras/tests/test_model_saving.py,341,"only compare layers that have weights, skipping Flatten()",not
keras/tests/test_model_saving.py,345,delete and recreate model with `use_bias=False`,not
keras/tests/test_model_saving.py,361,delete and recreate model with `filters=10`,not
keras/tests/test_model_saving.py,382,"test with custom optimizer, loss",not
keras/tests/test_model_saving.py,386,sequential model,not
keras/tests/test_model_saving.py,402,delete and recreate model using Functional API,not
keras/tests/test_model_saving.py,406,add 2 layers (but maintain shapes),not
keras/tests/test_model_saving.py,413,load weights from first model,not
keras/tests/test_model_saving.py,429,biases init to 0,not
keras/tests/test_model_saving.py,430,biases init to 0,not
keras/tests/test_model_saving.py,439,"test with custom optimizer, loss",not
keras/tests/test_model_saving.py,443,sequential model,not
keras/tests/test_model_saving.py,459,delete and recreate model,not
keras/tests/test_model_saving.py,463,different shape w.r.t. previous model,not
keras/tests/test_model_saving.py,466,load weights from first model,not
keras/tests/test_model_saving.py,467,expect UserWarning for skipping weights,not
keras/tests/test_model_saving.py,471,assert layers 'rick' are equal,not
keras/tests/test_model_saving.py,475,"assert layers 'morty' are not equal, since we skipped loading this layer",not
keras/tests/test_model_saving.py,480,a function to be called from the Lambda layer,not
keras/tests/test_model_saving.py,552,This layer name will make the `layers_name` HDF5 attribute blow,not
keras/tests/test_model_saving.py,553,out of proportion. Note that it fits into the internal HDF5,not
keras/tests/test_model_saving.py,554,attribute memory limit on its own but because h5py converts,not
keras/tests/test_model_saving.py,555,"the list of layer names into numpy array, which uses the same",not
keras/tests/test_model_saving.py,556,"amout of memory for every item, it increases the memory",not
keras/tests/test_model_saving.py,557,requirements substantially.,not
keras/tests/test_model_saving.py,578,Check that the HDF5 files contains chunked array,not
keras/tests/test_model_saving.py,579,of layer names.,not
keras/tests/test_model_saving.py,586,The chunking of layer names array should have happened.,not
keras/tests/test_model_saving.py,599,This layer name will make the `weights_name`,not
keras/tests/test_model_saving.py,600,HDF5 attribute blow out of proportion.,not
keras/tests/test_model_saving.py,623,Check that the HDF5 files contains chunked array,not
keras/tests/test_model_saving.py,624,of weight names.,not
keras/tests/test_model_saving.py,632,The chunking of layer names array should have happened.,not
keras/tests/test_model_saving.py,734,we should not use same filename in several tests to allow for parallel,not
keras/tests/test_model_saving.py,735,execution,not
keras/tests/test_model_saving.py,744,cleanup,not
keras/tests/test_model_saving.py,784,we should not use same filename in several tests to allow for parallel,not
keras/tests/test_model_saving.py,785,execution,not
keras/tests/test_model_saving.py,804,cleanup,not
keras/tests/test_model_saving.py,832,ensure biases are non-zero and properly converted,not
keras/tests/test_model_saving.py,865,"example: make_nested_seq_model((1,), Dense(10), level=2).summary()",not
keras/tests/test_model_saving.py,873,"example: make_nested_func_model((1,), Dense(10), level=2).summary()",not
keras/tests/test_model_saving.py,912,ensure biases are non-zero and properly converted,not
keras/tests/test_model_saving.py,950,A model is needed to initialize weights.,not
keras/tests/test_model_saving.py,979,for theano backend,not
keras/tests/test_model_saving.py,983,for theano backend,not
keras/tests/test_model_pickling.py,40,test that new updates are the same with both models,not
keras/tests/test_model_pickling.py,51,"test with custom optimizer, loss",not
keras/tests/test_model_pickling.py,116,assure that model is working,not
keras/tests/test_loss_weighting.py,42,convert class vectors to binary class matrices,not
keras/tests/test_multiprocessing.py,120,Build a NN,not
keras/tests/test_multiprocessing.py,125,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,126,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,127,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,128,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,129,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,150,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,151,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,161,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,162,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,163,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,164,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,165,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,188,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,189,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,200,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,201,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,202,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,203,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,204,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,223,"- Produce data on 1 worker thread AT A TIME, consume on main thread:",not
keras/tests/test_multiprocessing.py,224,- Worker threads for training and validation run generator SEQUENTIALLY,not
keras/tests/test_multiprocessing.py,233,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,234,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,250,Test invalid use cases,not
keras/tests/test_multiprocessing.py,256,not specified `validation_steps`,not
keras/tests/test_multiprocessing.py,266,validation data is neither a tuple nor a triple.,not
keras/tests/test_multiprocessing.py,279,validation generator is neither a tuple nor a triple.,not
keras/tests/test_multiprocessing.py,289,- For Sequence,not
keras/tests/test_multiprocessing.py,327,Build a NN,not
keras/tests/test_multiprocessing.py,332,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,333,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,334,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,335,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,336,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,357,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,358,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,359,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,360,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,361,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,382,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,383,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,385,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,386,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,418,Build a NN,not
keras/tests/test_multiprocessing.py,423,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,424,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,434,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,435,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,445,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,446,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,475,Build a NN,not
keras/tests/test_multiprocessing.py,480,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,481,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,482,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,483,process boundaries -> make sure `predict_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,484,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,499,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,500,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,501,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,502,process boundaries -> make sure `predict_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,503,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,518,- Main thread runs the generator without a queue,not
keras/tests/test_multiprocessing.py,519,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,542,Build a NN,not
keras/tests/test_multiprocessing.py,547,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,548,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,555,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,556,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,563,- Main thread runs the generator without a queue,not
keras/tests/test_multiprocessing.py,564,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,590,Build a NN,not
keras/tests/test_multiprocessing.py,595,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,596,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,597,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,598,process boundaries,not
keras/tests/test_multiprocessing.py,599,-> make sure `evaluate_generator()` raises raises ValueError,not
keras/tests/test_multiprocessing.py,600,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,615,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,616,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,617,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,618,process boundaries -> make sure `evaluate_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,619,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,634,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,635,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,660,Build a NN,not
keras/tests/test_multiprocessing.py,665,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,666,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,673,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,674,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,681,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,682,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,716,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,717,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,718,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,719,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,720,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,721,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,739,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,740,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,741,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,742,process boundaries -> make sure `fit_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,743,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,744,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,762,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,763,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,798,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,799,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,800,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,809,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,810,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,811,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,820,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,821,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,822,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,856,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,857,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,858,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,859,process boundaries -> make sure `evaluate_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,860,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,861,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,877,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,878,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,879,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,880,process boundaries -> make sure `evaluate_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,881,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,882,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,898,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,899,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,900,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,932,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,933,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,934,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,942,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,943,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,944,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,952,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,953,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,954,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,986,"- Produce data on 4 worker processes, consume on main process:",not
keras/tests/test_multiprocessing.py,987,- Each worker process runs OWN copy of generator,not
keras/tests/test_multiprocessing.py,988,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,989,process boundaries -> make sure `predict_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,990,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,991,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,1007,"- Produce data on 1 worker process, consume on main process:",not
keras/tests/test_multiprocessing.py,1008,- Worker process runs generator,not
keras/tests/test_multiprocessing.py,1009,"- BUT on Windows, `multiprocessing` won't marshall generators across",not
keras/tests/test_multiprocessing.py,1010,process boundaries -> make sure `predict_generator()` raises ValueError,not
keras/tests/test_multiprocessing.py,1011,exception and does not attempt to run the generator.,not
keras/tests/test_multiprocessing.py,1012,"- On other platforms, make sure `RuntimeError` exception bubbles up",not
keras/tests/test_multiprocessing.py,1028,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,1029,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,1030,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,1061,"- Produce data on 4 worker threads, consume on main thread:",not
keras/tests/test_multiprocessing.py,1062,- All worker threads share the SAME generator,not
keras/tests/test_multiprocessing.py,1063,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,1070,"- Produce data on 1 worker thread, consume on main thread:",not
keras/tests/test_multiprocessing.py,1071,- Worker thread is the only thread running the generator,not
keras/tests/test_multiprocessing.py,1072,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_multiprocessing.py,1080,- Produce and consume data without a queue on main thread,not
keras/tests/test_multiprocessing.py,1081,- Make sure the value of `use_multiprocessing` is ignored,not
keras/tests/test_multiprocessing.py,1082,- Make sure `RuntimeError` exception bubbles up,not
keras/tests/test_dynamic_trainability.py,10,"with constructor argument, in Sequential",not
keras/tests/test_dynamic_trainability.py,15,"by setting the `trainable` argument, in Sequential",not
keras/tests/test_dynamic_trainability.py,23,"with constructor argument, in Model",not
keras/tests/test_dynamic_trainability.py,29,"by setting the `trainable` argument, in Model",not
keras/tests/test_dynamic_trainability.py,40,a non-trainable model has no trainable weights,not
keras/tests/test_dynamic_trainability.py,47,same for Sequential,not
keras/tests/test_dynamic_trainability.py,55,a Sequential inside a Model,not
keras/tests/test_dynamic_trainability.py,69,a Sequential inside a Sequential,not
keras/tests/test_dynamic_trainability.py,81,a Model inside a Model,not
keras/tests/test_dynamic_trainability.py,95,a Model inside a Sequential,not
keras/tests/keras/optimizers_test.py,49,Test constraints.,not
keras/tests/keras/optimizers_test.py,67,Test saving.,not
keras/tests/keras/activations_test.py,36,1. Default returns linear,not
keras/tests/keras/activations_test.py,40,2. Passing in a layer raises a warning,not
keras/tests/keras/activations_test.py,45,3. Callables return themselves for some reason,not
keras/tests/keras/activations_test.py,49,4. Anything else is not a valid argument,not
keras/tests/keras/activations_test.py,77,One dimensional arrays are supposed to raise a value error,not
keras/tests/keras/activations_test.py,183,Test max_value,not
keras/tests/keras/activations_test.py,189,Test max_value == 6.,not
keras/tests/keras/metrics_functional_test.py,52,use one_hot embedding to convert sparse labels to equivalent dense labels,not
keras/tests/keras/metrics_functional_test.py,102,"Test correctness if the shape of y_true is (num_samples, 1)",not
keras/tests/keras/metrics_functional_test.py,104,"Test correctness if the shape of y_true is (num_samples,)",not
keras/tests/keras/metrics_confusion_matrix_test.py,10,Need TensorFlow to use metric.__call__,not
keras/tests/keras/metrics_confusion_matrix_test.py,24,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,85,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,143,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,200,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,259,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,325,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,389,"threshold values are [0 - 1e-7, 0.5, 1 + 1e-7]",not
keras/tests/keras/metrics_confusion_matrix_test.py,390,"y_pred when threshold = 0 - 1e-7  : [1, 1, 1, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,391,"y_pred when threshold = 0.5       : [0, 0, 0, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,392,"y_pred when threshold = 1 + 1e-7  : [0, 0, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,394,without sample_weight:,not
keras/tests/keras/metrics_confusion_matrix_test.py,395,"tp = np.sum([[0, 0, 1, 1], [0, 0, 0, 1], [0, 0, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,396,"fp = np.sum([[1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,397,"fn = np.sum([[0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 1]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,398,"tn = np.sum([[0, 0, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,400,"tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]",not
keras/tests/keras/metrics_confusion_matrix_test.py,402,with sample_weight:,not
keras/tests/keras/metrics_confusion_matrix_test.py,403,"tp = np.sum([[0, 0, 3, 4], [0, 0, 0, 4], [0, 0, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,404,"fp = np.sum([[1, 2, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,405,"fn = np.sum([[0, 0, 0, 0], [0, 0, 3, 0], [0, 0, 3, 4]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,406,"tn = np.sum([[0, 0, 0, 0], [1, 2, 0, 0], [1, 2, 0, 0]], axis=1)",not
keras/tests/keras/metrics_confusion_matrix_test.py,408,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,422,Check save and restore config.,not
keras/tests/keras/metrics_confusion_matrix_test.py,444,Check save and restore config.,not
keras/tests/keras/metrics_confusion_matrix_test.py,463,"tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]",not
keras/tests/keras/metrics_confusion_matrix_test.py,464,"recall = [2/2, 1/(1+1), 0] = [1, 0.5, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,465,"fp_rate = [2/2, 0, 0] = [1, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,466,"heights = [(1 + 0.5)/2, (0.5 + 0)/2] = [0.75, 0.25]",not
keras/tests/keras/metrics_confusion_matrix_test.py,467,"widths = [(1 - 0), (0 - 0)] = [1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,473,"Verify that when specified, thresholds are used instead of num_thresholds.",not
keras/tests/keras/metrics_confusion_matrix_test.py,479,"tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2]",not
keras/tests/keras/metrics_confusion_matrix_test.py,480,"recall = [2/2, 1/(1+1), 0] = [1, 0.5, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,481,"fp_rate = [2/2, 0, 0] = [1, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,482,"heights = [(1 + 0.5)/2, (0.5 + 0)/2] = [0.75, 0.25]",not
keras/tests/keras/metrics_confusion_matrix_test.py,483,"widths = [(1 - 0), (0 - 0)] = [1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,492,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,493,"recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,494,"fp_rate = [3/3, 0, 0] = [1, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,495,"heights = [(1 + 0.571)/2, (0.571 + 0)/2] = [0.7855, 0.2855]",not
keras/tests/keras/metrics_confusion_matrix_test.py,496,"widths = [(1 - 0), (0 - 0)] = [1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,506,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,507,"recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,508,"fp_rate = [3/3, 0, 0] = [1, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,509,"heights = [max(1, 0.571), max(0.571, 0)] = [1, 0.571]",not
keras/tests/keras/metrics_confusion_matrix_test.py,510,"widths = [(1 - 0), (0 - 0)] = [1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,520,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,521,"recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,522,"fp_rate = [3/3, 0, 0] = [1, 0, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,523,"heights = [min(1, 0.571), min(0.571, 0)] = [0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,524,"widths = [(1 - 0), (0 - 0)] = [1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,536,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,537,"precision = [7/(7+3), 4/4, 0] = [0.7, 1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,538,"recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,539,"heights = [max(0.7, 1), max(1, 0)] = [1, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,540,"widths = [(1 - 0.571), (0.571 - 0)] = [0.429, 0.571]",not
keras/tests/keras/metrics_confusion_matrix_test.py,552,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,553,"precision = [7/(7+3), 4/4, 0] = [0.7, 1, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,554,"recall = [7/7, 4/(4+3), 0] = [1, 0.571, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,555,"heights = [min(0.7, 1), min(1, 0)] = [0.7, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,556,"widths = [(1 - 0.571), (0.571 - 0)] = [0.429, 0.571]",not
keras/tests/keras/metrics_confusion_matrix_test.py,565,auc = (slope / Total Pos) * [dTP - intercept * log(Pb/Pa)],not
keras/tests/keras/metrics_confusion_matrix_test.py,567,"tp = [7, 4, 0], fp = [3, 0, 0], fn = [0, 3, 7], tn = [0, 3, 3]",not
keras/tests/keras/metrics_confusion_matrix_test.py,568,"P = tp + fp = [10, 4, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,569,"dTP = [7-4, 4-0] = [3, 4]",not
keras/tests/keras/metrics_confusion_matrix_test.py,570,"dP = [10-4, 4-0] = [6, 4]",not
keras/tests/keras/metrics_confusion_matrix_test.py,571,"slope = dTP/dP = [0.5, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,572,"intercept = (TPa+(slope*Pa) = [(4 - 0.5*4), (0 - 1*0)] = [2, 0]",not
keras/tests/keras/metrics_confusion_matrix_test.py,573,"(Pb/Pa) = (Pb/Pa) if Pb > 0 AND Pa > 0 else 1 = [10/4, 4/0] = [2.5, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,574,"auc * TotalPos = [(0.5 * (3 + 2 * log(2.5))), (1 * (4 + 0))]",not
keras/tests/keras/metrics_confusion_matrix_test.py,575,"= [2.416, 4]",not
keras/tests/keras/metrics_confusion_matrix_test.py,576,"auc = [2.416, 4]/(tp[1:]+fn[1:])",not
keras/tests/keras/metrics_confusion_matrix_test.py,577,expected_result = (2.416 / 7 + 4 / 7),not
keras/tests/keras/metrics_confusion_matrix_test.py,610,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,759,Check save and restore config,not
keras/tests/keras/metrics_confusion_matrix_test.py,915,"cm = [[1, 1],",not
keras/tests/keras/metrics_confusion_matrix_test.py,916,"[1, 1]]",not
keras/tests/keras/metrics_confusion_matrix_test.py,917,"sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,918,iou = true_positives / (sum_row + sum_col - true_positives)),not
keras/tests/keras/metrics_confusion_matrix_test.py,930,"cm = [[0.2, 0.3],",not
keras/tests/keras/metrics_confusion_matrix_test.py,931,"[0.4, 0.1]]",not
keras/tests/keras/metrics_confusion_matrix_test.py,932,"sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,933,iou = true_positives / (sum_row + sum_col - true_positives)),not
keras/tests/keras/metrics_confusion_matrix_test.py,945,"cm = [[0.2, 0.3],",not
keras/tests/keras/metrics_confusion_matrix_test.py,946,"[0.4, 0.1]]",not
keras/tests/keras/metrics_confusion_matrix_test.py,947,"sum_row = [0.6, 0.4], sum_col = [0.5, 0.5], true_positives = [0.2, 0.1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,948,iou = true_positives / (sum_row + sum_col - true_positives)),not
keras/tests/keras/metrics_confusion_matrix_test.py,963,"cm = [[0, 0],",not
keras/tests/keras/metrics_confusion_matrix_test.py,964,"[0, 1]]",not
keras/tests/keras/metrics_confusion_matrix_test.py,965,"sum_row = [0, 1], sum_col = [0, 1], true_positives = [0, 1]",not
keras/tests/keras/metrics_confusion_matrix_test.py,966,iou = true_positives / (sum_row + sum_col - true_positives)),not
keras/tests/keras/metrics_test.py,11,Need TensorFlow to use metric.__call__,not
keras/tests/keras/metrics_test.py,20,check config,not
keras/tests/keras/metrics_test.py,26,check initial state,not
keras/tests/keras/metrics_test.py,29,check __call__,not
keras/tests/keras/metrics_test.py,33,check update_state() and result() + state accumulation + tensor input,not
keras/tests/keras/metrics_test.py,36,100 + 1 + 5,not
keras/tests/keras/metrics_test.py,38,check reset_states(),not
keras/tests/keras/metrics_test.py,46,check scalar weight,not
keras/tests/keras/metrics_test.py,51,check weights not scalar and weights rank matches values rank,not
keras/tests/keras/metrics_test.py,54,50 + 1 + 5 * 0.2,not
keras/tests/keras/metrics_test.py,57,check weights broadcast,not
keras/tests/keras/metrics_test.py,59,52 + 0.5 + 1,not
keras/tests/keras/metrics_test.py,62,check weights squeeze,not
keras/tests/keras/metrics_test.py,64,53.5 + 1 + 1,not
keras/tests/keras/metrics_test.py,67,check weights expand,not
keras/tests/keras/metrics_test.py,69,55.5 + 1 + 1,not
keras/tests/keras/metrics_test.py,72,check values reduced to the dimensions of weight,not
keras/tests/keras/metrics_test.py,75,result = (prev: 57.5) + 0.5 + 1 + 1.5 + 1 + 0.25 + 2,not
keras/tests/keras/metrics_test.py,85,check config,not
keras/tests/keras/metrics_test.py,91,check initial state,not
keras/tests/keras/metrics_test.py,95,check __call__(),not
keras/tests/keras/metrics_test.py,100,check update_state() and result(),not
keras/tests/keras/metrics_test.py,103,100 + 1 + 5,not
keras/tests/keras/metrics_test.py,106,check reset_states(),not
keras/tests/keras/metrics_test.py,111,Check save and restore config,not
keras/tests/keras/metrics_test.py,122,check scalar weight,not
keras/tests/keras/metrics_test.py,128,check weights not scalar and weights rank matches values rank,not
keras/tests/keras/metrics_test.py,132,50 + 1 + 5 * 0.2,not
keras/tests/keras/metrics_test.py,133,0.5 + 1.2,not
keras/tests/keras/metrics_test.py,135,check weights broadcast,not
keras/tests/keras/metrics_test.py,138,52 + 0.5 + 1,not
keras/tests/keras/metrics_test.py,139,1.7 + 0.5 + 0.5,not
keras/tests/keras/metrics_test.py,141,check weights squeeze,not
keras/tests/keras/metrics_test.py,144,53.5 + 1 + 1,not
keras/tests/keras/metrics_test.py,145,2.7 + 1.2,not
keras/tests/keras/metrics_test.py,147,check weights expand,not
keras/tests/keras/metrics_test.py,150,55.5 + 1 + 1,not
keras/tests/keras/metrics_test.py,151,3.9 + 1.2,not
keras/tests/keras/metrics_test.py,160,check initial state,not
keras/tests/keras/metrics_test.py,166,check __call__(),not
keras/tests/keras/metrics_test.py,186,check config,not
keras/tests/keras/metrics_test.py,192,verify that correct value is returned,not
keras/tests/keras/metrics_test.py,194,2/2,not
keras/tests/keras/metrics_test.py,196,Check save and restore config,not
keras/tests/keras/metrics_test.py,203,check with sample_weight,not
keras/tests/keras/metrics_test.py,211,check config,not
keras/tests/keras/metrics_test.py,217,verify that correct value is returned,not
keras/tests/keras/metrics_test.py,220,2/2,not
keras/tests/keras/metrics_test.py,222,check y_pred squeeze,not
keras/tests/keras/metrics_test.py,227,check y_true squeeze,not
keras/tests/keras/metrics_test.py,232,check with sample_weight,not
keras/tests/keras/metrics_test.py,246,check config,not
keras/tests/keras/metrics_test.py,252,verify that correct value is returned,not
keras/tests/keras/metrics_test.py,256,2/2,not
keras/tests/keras/metrics_test.py,258,check with sample_weight,not
keras/tests/keras/metrics_test.py,263,2.5/2.7,not
keras/tests/keras/metrics_test.py,268,check config,not
keras/tests/keras/metrics_test.py,274,verify that correct value is returned,not
keras/tests/keras/metrics_test.py,279,2/2,not
keras/tests/keras/metrics_test.py,281,check with sample_weight,not
keras/tests/keras/metrics_test.py,291,check config,not
keras/tests/keras/metrics_test.py,297,verify that correct value is returned,not
keras/tests/keras/metrics_test.py,300,2/2,not
keras/tests/keras/metrics_test.py,302,check with sample_weight,not
keras/tests/keras/metrics_test.py,316,Check save and restore config,not
keras/tests/keras/metrics_test.py,349,Check save and restore config,not
keras/tests/keras/metrics_test.py,381,Check save and restore config,not
keras/tests/keras/metrics_test.py,415,Check save and restore config,not
keras/tests/keras/metrics_test.py,459,both the samples match,not
keras/tests/keras/metrics_test.py,461,With `k` < 5.,not
keras/tests/keras/metrics_test.py,464,only sample #2 matches,not
keras/tests/keras/metrics_test.py,466,With `k` > 5.,not
keras/tests/keras/metrics_test.py,472,only 1 sample matches.,not
keras/tests/keras/metrics_test.py,502,both the samples match,not
keras/tests/keras/metrics_test.py,504,With `k` < 5.,not
keras/tests/keras/metrics_test.py,507,only sample #2 matches,not
keras/tests/keras/metrics_test.py,509,With `k` > 5.,not
keras/tests/keras/metrics_test.py,514,only 1 sample matches.,not
keras/tests/keras/metrics_test.py,660,Check save and restore config,not
keras/tests/keras/metrics_test.py,699,Check save and restore config,not
keras/tests/keras/metrics_test.py,733,Check save and restore config,not
keras/tests/keras/metrics_test.py,767,Check save and restore config,not
keras/tests/keras/metrics_test.py,801,Check save and restore config,not
keras/tests/keras/metrics_test.py,847,"error = [-1, -1, -4], square(error) = [1, 1, 16], mean = 18/3 = 6",not
keras/tests/keras/constraints_test.py,16,0 could possibly cause trouble,not
keras/tests/keras/constraints_test.py,39,a more explicit example,not
keras/tests/keras/constraints_test.py,61,"In the unit norm constraint, it should be equal to 1.",not
keras/tests/keras/test_sequential_model.py,110,TODO: factor out,SATD
keras/tests/keras/test_sequential_model.py,169,Test serialization,not
keras/tests/keras/test_sequential_model.py,173,Model should be built.,not
keras/tests/keras/test_sequential_model.py,236,Test serialization,not
keras/tests/keras/test_sequential_model.py,318,Everything should work in a new session.,not
keras/tests/keras/test_sequential_model.py,321,With placeholder creation,not
keras/tests/keras/test_sequential_model.py,326,On top of new tensors,not
keras/tests/keras/test_sequential_model.py,334,"On top of new, non-Keras tensors",not
keras/tests/keras/test_sequential_model.py,346,Layer with single input and multiple outputs,not
keras/tests/keras/test_sequential_model.py,358,Layer with multiple inputs and outputs,not
keras/tests/keras/test_sequential_model.py,381,Everything should work in a new session.,not
keras/tests/keras/test_sequential_model.py,384,With placeholder creation,not
keras/tests/keras/test_sequential_model.py,389,On top of new tensor,not
keras/tests/keras/test_sequential_model.py,396,"On top of new, non-Keras tensor",not
keras/tests/keras/test_sequential_model.py,448,Test serialization,not
keras/tests/keras/initializers_test.py,7,2D tensor test fixture,not
keras/tests/keras/initializers_test.py,10,4D convolution in th order. This shape has the same effective shape as FC_SHAPE,not
keras/tests/keras/initializers_test.py,157,Test that calling a same seeded random initializer,not
keras/tests/keras/initializers_test.py,158,in succession results in different values.,not
keras/tests/keras/losses_test.py,32,"losses.SparseCategoricalCrossentropy,",not
keras/tests/keras/losses_test.py,155,"mse = [((4 - 1)^2 + (8 - 9)^2) / 2, ((12 - 2)^2 + (3 - 5)^2) / 2]",not
keras/tests/keras/losses_test.py,156,"mse = [5, 52]",not
keras/tests/keras/losses_test.py,157,"weighted_mse = [5 * 1.2, 52 * 0.5] = [6, 26]",not
keras/tests/keras/losses_test.py,158,reduced_weighted_mse = (6 + 26) / 2 =,not
keras/tests/keras/losses_test.py,465,Test with logits.,not
keras/tests/keras/losses_test.py,479,"EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999",not
keras/tests/keras/losses_test.py,480,"y` = clip(output, EPSILON, 1. - EPSILON)",not
keras/tests/keras/losses_test.py,481,"y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]",not
keras/tests/keras/losses_test.py,483,Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON)),not
keras/tests/keras/losses_test.py,484,"= [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),",not
keras/tests/keras/losses_test.py,485,"-log(Y_MAX + EPSILON), -log(1)]",not
keras/tests/keras/losses_test.py,486,"= [0, 15.33, 0, 0]",not
keras/tests/keras/losses_test.py,487,Reduced loss = 15.33 / 4,not
keras/tests/keras/losses_test.py,491,Test with logits.,not
keras/tests/keras/losses_test.py,497,"Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))",not
keras/tests/keras/losses_test.py,498,(where x = logits and z = y_true),not
keras/tests/keras/losses_test.py,499,= [((100 - 100 * 1 + log(1 + exp(-100))) +,not
keras/tests/keras/losses_test.py,500,(0 + 100 * 0 + log(1 + exp(-100))) +,not
keras/tests/keras/losses_test.py,501,"(100 - 100 * 1 + log(1 + exp(-100))),",not
keras/tests/keras/losses_test.py,502,((100 - 100 * 0 + log(1 + exp(-100))) +,not
keras/tests/keras/losses_test.py,503,(100 - 100 * 1 + log(1 + exp(-100))) +,not
keras/tests/keras/losses_test.py,504,(0 + 100 * 1 + log(1 + exp(-100))))],not
keras/tests/keras/losses_test.py,505,"= [(0 + 0 + 0) / 3, 200 / 3]",not
keras/tests/keras/losses_test.py,506,Reduced loss = (0 + 66.666) / 2,not
keras/tests/keras/losses_test.py,516,"EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999",not
keras/tests/keras/losses_test.py,517,"y` = clip(output, EPSILON, 1. - EPSILON)",not
keras/tests/keras/losses_test.py,518,"y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]",not
keras/tests/keras/losses_test.py,520,Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON)),not
keras/tests/keras/losses_test.py,521,"= [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),",not
keras/tests/keras/losses_test.py,522,"-log(Y_MAX + EPSILON), -log(1)]",not
keras/tests/keras/losses_test.py,523,"= [0, 15.33, 0, 0]",not
keras/tests/keras/losses_test.py,524,"Weighted loss = [0, 15.33 * 2.3, 0, 0]",not
keras/tests/keras/losses_test.py,525,Reduced loss = 15.33 * 2.3 / 4,not
keras/tests/keras/losses_test.py,529,Test with logits.,not
keras/tests/keras/losses_test.py,535,"Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))",not
keras/tests/keras/losses_test.py,536,(where x = logits and z = y_true),not
keras/tests/keras/losses_test.py,537,"Loss = [(0 + 0 + 0) / 3, 200 / 3]",not
keras/tests/keras/losses_test.py,538,"Weighted loss = [0 * 2.3, 66.666 * 2.3]",not
keras/tests/keras/losses_test.py,539,Reduced loss = (0 + 66.666 * 2.3) / 2,not
keras/tests/keras/losses_test.py,550,"EPSILON = 1e-7, y = y_true, y` = y_pred, Y_MAX = 0.9999999",not
keras/tests/keras/losses_test.py,551,"y` = clip(output, EPSILON, 1. - EPSILON)",not
keras/tests/keras/losses_test.py,552,"y` = [Y_MAX, Y_MAX, Y_MAX, EPSILON]",not
keras/tests/keras/losses_test.py,554,Loss = -(y log(y` + EPSILON) + (1 - y) log(1 - y` + EPSILON)),not
keras/tests/keras/losses_test.py,555,"= [-log(Y_MAX + EPSILON), -log(1 - Y_MAX + EPSILON),",not
keras/tests/keras/losses_test.py,556,"-log(Y_MAX + EPSILON), -log(1)]",not
keras/tests/keras/losses_test.py,557,"= [0, 15.33, 0, 0]",not
keras/tests/keras/losses_test.py,558,Reduced loss = 15.33 * 1.2 / 4,not
keras/tests/keras/losses_test.py,562,Test with logits.,not
keras/tests/keras/losses_test.py,569,"Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))",not
keras/tests/keras/losses_test.py,570,(where x = logits and z = y_true),not
keras/tests/keras/losses_test.py,571,"Loss = [(0 + 0 + 0)/3, 200 / 3]",not
keras/tests/keras/losses_test.py,572,"Weighted loss = [0 * 4, 66.666 * 3]",not
keras/tests/keras/losses_test.py,573,Reduced loss = (0 + 66.666 * 3) / 2,not
keras/tests/keras/losses_test.py,584,"Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))",not
keras/tests/keras/losses_test.py,585,(where x = logits and z = y_true),not
keras/tests/keras/losses_test.py,586,"Loss = [(0 + 0 + 0)/3, (200)/3]",not
keras/tests/keras/losses_test.py,594,"Loss: max(x, 0) - x * z + log(1 + exp(-abs(x)))",not
keras/tests/keras/losses_test.py,595,(where x = logits and z = y_true),not
keras/tests/keras/losses_test.py,596,Label smoothing: z' = z * (1 - L) + 0.5L,not
keras/tests/keras/losses_test.py,597,1  = 1 - 0.5L,not
keras/tests/keras/losses_test.py,598,0  = 0.5L,not
keras/tests/keras/losses_test.py,599,Applying the above two fns to the given input:,not
keras/tests/keras/losses_test.py,600,(100 - 100 * (1 - 0.5 L)  + 0 +,not
keras/tests/keras/losses_test.py,601,0   + 100 * (0.5 L)      + 0 +,not
keras/tests/keras/losses_test.py,602,0   + 100 * (1 - 0.5 L)  + 0) * (1/3),not
keras/tests/keras/losses_test.py,603,= (100 + 50L) * 1/3,not
keras/tests/keras/losses_test.py,627,Test with logits.,not
keras/tests/keras/losses_test.py,641,Test with logits.,not
keras/tests/keras/losses_test.py,655,Test with logits.,not
keras/tests/keras/losses_test.py,670,Test with logits.,not
keras/tests/keras/losses_test.py,688,Softmax Cross Entropy Loss: -\sum_i p_i \log q_i,not
keras/tests/keras/losses_test.py,689,where for a softmax activation,not
keras/tests/keras/losses_test.py,690,\log q_i = x_i - \log \sum_j \exp x_j,not
keras/tests/keras/losses_test.py,691,= x_i - x_max - \log \sum_j \exp (x_j - x_max),not
keras/tests/keras/losses_test.py,692,"For our activations, [100, -100, -100]",not
keras/tests/keras/losses_test.py,693,\log ( exp(0) + exp(-200) + exp(-200) ) = 0,not
keras/tests/keras/losses_test.py,694,"so our log softmaxes become: [0, -200, -200]",not
keras/tests/keras/losses_test.py,695,Label smoothing: z' = z * (1 - L) + L/n,not
keras/tests/keras/losses_test.py,696,1  = 1 - L + L/n,not
keras/tests/keras/losses_test.py,697,0  = L/n,not
keras/tests/keras/losses_test.py,698,Applying the above two fns to the given input:,not
keras/tests/keras/losses_test.py,699,-0 * (1 - L + L/n) + 200 * L/n + 200 * L/n = 400 L/n,not
keras/tests/keras/losses_test.py,723,Test with logits.,not
keras/tests/keras/losses_test.py,737,Test with logits.,not
keras/tests/keras/losses_test.py,751,Test with logits.,not
keras/tests/keras/losses_test.py,766,Test with logits.,not
keras/tests/keras/metrics_correctness_test.py,73,"y_true_1 = [[2.], [4.], [6.], [8.]], y_pred = [[3.], [6.], [9.], [12.]]",not
keras/tests/keras/metrics_correctness_test.py,74,"y_true_2 = [[1.], [2.], [3.], [4.]], y_pred = [[3.], [6.], [9.], [12.]]",not
keras/tests/keras/metrics_correctness_test.py,76,Weighted metric `output_1`:,not
keras/tests/keras/metrics_correctness_test.py,77,Total = ((3 - 2)^2 * 2  + (6 - 4)^2 * 3) +,not
keras/tests/keras/metrics_correctness_test.py,78,((9 - 6)^2 * 4 + (12 - 8)^2 * 5),not
keras/tests/keras/metrics_correctness_test.py,79,= 130,not
keras/tests/keras/metrics_correctness_test.py,80,Count = (2 + 3) + (4 + 5),not
keras/tests/keras/metrics_correctness_test.py,81,Result = 9.2857141,not
keras/tests/keras/metrics_correctness_test.py,83,Weighted metric `output_2`:,not
keras/tests/keras/metrics_correctness_test.py,84,Total = ((3 - 1)^2 * 3.5 + (6 - 2)^2 * 2.5) +,not
keras/tests/keras/metrics_correctness_test.py,85,((9 - 3)^2 * 1.5 + (12 - 4)^2 * 0.5),not
keras/tests/keras/metrics_correctness_test.py,86,= 140,not
keras/tests/keras/metrics_correctness_test.py,87,Count = (3.5 + 2.5) + (1.5 + 0.5),not
keras/tests/keras/metrics_correctness_test.py,88,Result = 17.5,not
keras/tests/keras/metrics_correctness_test.py,90,Loss `output_1` with weights:,not
keras/tests/keras/metrics_correctness_test.py,91,Total = ((3 - 2)^2 * 2  + (6 - 4)^2 * 3) +,not
keras/tests/keras/metrics_correctness_test.py,92,((9 - 6)^2 * 4 + (12 - 8)^2 * 5),not
keras/tests/keras/metrics_correctness_test.py,93,= 130,not
keras/tests/keras/metrics_correctness_test.py,94,Count = 2 + 2,not
keras/tests/keras/metrics_correctness_test.py,95,Result = 32.5,not
keras/tests/keras/metrics_correctness_test.py,97,Loss `output_1` without weights/Metric `output_1`:,not
keras/tests/keras/metrics_correctness_test.py,98,Total = ((3 - 2)^2 + (6 - 4)^2) + ((9 - 6)^2 + (12 - 8)^2) = 30,not
keras/tests/keras/metrics_correctness_test.py,99,Count = 2 + 2,not
keras/tests/keras/metrics_correctness_test.py,100,Result = 7.5,not
keras/tests/keras/metrics_correctness_test.py,102,Loss `output_2` with weights:,not
keras/tests/keras/metrics_correctness_test.py,103,Total = ((3 - 1)^2 * 3.5 + (6 - 2)^2 * 2.5) +,not
keras/tests/keras/metrics_correctness_test.py,104,((9 - 3)^2 * 1.5 + (12 - 4)^2 * 0.5),not
keras/tests/keras/metrics_correctness_test.py,105,= 140,not
keras/tests/keras/metrics_correctness_test.py,106,Count = 2 + 2,not
keras/tests/keras/metrics_correctness_test.py,107,Result = 35,not
keras/tests/keras/metrics_correctness_test.py,109,Loss `output_2` without weights/Metric `output_2`:,not
keras/tests/keras/metrics_correctness_test.py,110,Total = ((3 - 1)^2 + (6 - 2)^2) + ((9 - 3)^2 + (12 - 4)^2) = 120,not
keras/tests/keras/metrics_correctness_test.py,111,Count = 2 + 2,not
keras/tests/keras/metrics_correctness_test.py,112,Result = 30,not
keras/tests/keras/metrics_correctness_test.py,114,Total loss with weights = 32.5 + 35 = 67.5,not
keras/tests/keras/metrics_correctness_test.py,115,Total loss without weights = 7.5 + 30 = 37.5,not
keras/tests/keras/metrics_correctness_test.py,147,"In the order: 'loss', 'output_1_loss', 'output_2_loss',",not
keras/tests/keras/metrics_correctness_test.py,148,"'output_1_mean_squared_error', 'output_1_mean_squared_error_2',",not
keras/tests/keras/metrics_correctness_test.py,149,"'output_2_mean_squared_error', 'output_2_mean_squared_error_2'",not
keras/tests/keras/metrics_correctness_test.py,181,Set weights for one output (use batch size).,not
keras/tests/keras/metrics_correctness_test.py,204,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,232,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,241,Verify that metric value is same with arbitrary weights and batch size.,not
keras/tests/keras/metrics_correctness_test.py,265,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,280,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,302,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,328,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,350,Set weights for one output.,not
keras/tests/keras/metrics_correctness_test.py,374,Set weights for one output.,not
keras/tests/keras/backend/backend_test.py,42,Must wait for tf.keras to support sparse ops.,not
keras/tests/keras/backend/backend_test.py,214,note that numpy reference implementation is independent of `unroll` argument,not
keras/tests/keras/backend/backend_test.py,254,not supported learning_phase,not
keras/tests/keras/backend/backend_test.py,312,Note : batch_dot implementation is different for,not
keras/tests/keras/backend/backend_test.py,313,placeholders and variables in CNTK backend,not
keras/tests/keras/backend/backend_test.py,336,test with placeholders,not
keras/tests/keras/backend/backend_test.py,349,test with placeholders (no shape info),not
keras/tests/keras/backend/backend_test.py,364,test with variables,not
keras/tests/keras/backend/backend_test.py,396,Test shape inference when input,not
keras/tests/keras/backend/backend_test.py,397,shape has `None` entries,not
keras/tests/keras/backend/backend_test.py,433,test theano shape inference when,not
keras/tests/keras/backend/backend_test.py,434,input shape has None entries,not
keras/tests/keras/backend/backend_test.py,456,test theano shape inference when,not
keras/tests/keras/backend/backend_test.py,457,input shape has None entries,not
keras/tests/keras/backend/backend_test.py,481,TODO: somehow this capture mechanism doesn't work for TF,SATD
keras/tests/keras/backend/backend_test.py,482,even though the TF op does print to stdout.,not
keras/tests/keras/backend/backend_test.py,489,"Theano inserts ""__str__ = "" for no good reason",SATD
keras/tests/keras/backend/backend_test.py,547,two-tensor ops,not
keras/tests/keras/backend/backend_test.py,557,assumes first uid will always be the same,not
keras/tests/keras/backend/backend_test.py,640,This test checks the consistency of the stop_gradient backend API.,not
keras/tests/keras/backend/backend_test.py,641,It doesn't check the functionality (which is checked at the,not
keras/tests/keras/backend/backend_test.py,642,test_gradient test).,not
keras/tests/keras/backend/backend_test.py,664,Need to use `identity` to make this symbolic,not
keras/tests/keras/backend/backend_test.py,665,(TODO: fix in tf.keras),SATD
keras/tests/keras/backend/backend_test.py,679,Additional operations can be passed to tf.Session().run() via its,not
keras/tests/keras/backend/backend_test.py,680,`fetches` arguments. In contrast to `updates` argument of,not
keras/tests/keras/backend/backend_test.py,681,"KTF.function() these do not have control dependency on `outputs`, so",not
keras/tests/keras/backend/backend_test.py,682,they can run in parallel. Also they should not contribute to output of,not
keras/tests/keras/backend/backend_test.py,683,KTF.function().,not
keras/tests/keras/backend/backend_test.py,701,Additional substitutions can be passed to `tf.Session().run()` via its,not
keras/tests/keras/backend/backend_test.py,702,`feed_dict` arguments. Note that the feed_dict is passed once in the,not
keras/tests/keras/backend/backend_test.py,703,constructor but we can modify the values in the dictionary. Through,not
keras/tests/keras/backend/backend_test.py,704,this feed_dict we can provide additional substitutions besides Keras,not
keras/tests/keras/backend/backend_test.py,705,inputs.,not
keras/tests/keras/backend/backend_test.py,723,updated value in feed_dict will be modified within the K.function(),not
keras/tests/keras/backend/backend_test.py,738,enable run_options.,not
keras/tests/keras/backend/backend_test.py,746,disable run_options.,not
keras/tests/keras/backend/backend_test.py,757,Test functions with string inputs.,not
keras/tests/keras/backend/backend_test.py,767,implement a simple RNN,not
keras/tests/keras/backend/backend_test.py,843,implement a simple RNN with an additional state,not
keras/tests/keras/backend/backend_test.py,844,whose shape is different from that of the output,not
keras/tests/keras/backend/backend_test.py,885,implement a simple RNN without states,not
keras/tests/keras/backend/backend_test.py,919,implement a simple RNN,not
keras/tests/keras/backend/backend_test.py,938,constants are appended to states in K.rnn,not
keras/tests/keras/backend/backend_test.py,964,for second sample only,not
keras/tests/keras/backend/backend_test.py,966,"a step function that just outputs inputs,",not
keras/tests/keras/backend/backend_test.py,967,but increments states +1 per timestep,not
keras/tests/keras/backend/backend_test.py,974,masking of two last timesteps for second sample only,not
keras/tests/keras/backend/backend_test.py,978,outputs expected to be same as inputs for the first sample,not
keras/tests/keras/backend/backend_test.py,980,but for the second sample all outputs in masked region should be the same,not
keras/tests/keras/backend/backend_test.py,981,as last output before masked region,not
keras/tests/keras/backend/backend_test.py,986,first state should be incremented for every timestep (no masking),not
keras/tests/keras/backend/backend_test.py,988,second state should not be incremented for last two timesteps,not
keras/tests/keras/backend/backend_test.py,991,verify same expected output for `unroll=true/false`,not
keras/tests/keras/backend/backend_test.py,1020,final timestep masked for last sample,not
keras/tests/keras/backend/backend_test.py,1023,"for the last sample, the final timestep (in masked region) should be the",not
keras/tests/keras/backend/backend_test.py,1024,same as the second to final output (before masked region),not
keras/tests/keras/backend/backend_test.py,1052,final two timesteps masked for first sample,not
keras/tests/keras/backend/backend_test.py,1070,not updated last timestep:,not
keras/tests/keras/backend/backend_test.py,1100,scalar,not
keras/tests/keras/backend/backend_test.py,1108,non scalar,not
keras/tests/keras/backend/backend_test.py,1125,"dropout patterns are different, only check mean",not
keras/tests/keras/backend/backend_test.py,1133,"dropout patterns are different, only check mean",not
keras/tests/keras/backend/backend_test.py,1137,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1142,standard relu,not
keras/tests/keras/backend/backend_test.py,1143,set alpha only,not
keras/tests/keras/backend/backend_test.py,1144,set max_value only,not
keras/tests/keras/backend/backend_test.py,1145,set threshold only,not
keras/tests/keras/backend/backend_test.py,1146,set alpha and max_value,not
keras/tests/keras/backend/backend_test.py,1147,set alpha and threshold,not
keras/tests/keras/backend/backend_test.py,1148,set max_value and threshold,not
keras/tests/keras/backend/backend_test.py,1149,set all,not
keras/tests/keras/backend/backend_test.py,1150,max_value is zero,not
keras/tests/keras/backend/backend_test.py,1151,threshold is negative,not
keras/tests/keras/backend/backend_test.py,1152,max_value > 6,not
keras/tests/keras/backend/backend_test.py,1175,"toy label matrix (4 samples, 2 classes)",not
keras/tests/keras/backend/backend_test.py,1192,"toy label matrix (2 samples, 3 classes)",not
keras/tests/keras/backend/backend_test.py,1206,Random prediction test case,not
keras/tests/keras/backend/backend_test.py,1210,(k == 0 or k > num_classes) does not raise an error,not
keras/tests/keras/backend/backend_test.py,1211,but just return an unmeaningful tensor.,not
keras/tests/keras/backend/backend_test.py,1218,Identical prediction test case:,not
keras/tests/keras/backend/backend_test.py,1219,randomly set half of the predictions to an identical value,not
keras/tests/keras/backend/backend_test.py,1411,TODO: make this a parameterized test,SATD
keras/tests/keras/backend/backend_test.py,1450,assumption in initializers.VarianceScaling,not
keras/tests/keras/backend/backend_test.py,1525,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1562,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1584,Check handling of dynamic shapes.,not
keras/tests/keras/backend/backend_test.py,1590,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1606,Check handling of dynamic shapes.,not
keras/tests/keras/backend/backend_test.py,1612,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1638,Test invalid use cases,not
keras/tests/keras/backend/backend_test.py,1704,the Theano and TensorFlow CTC code use different methods to ensure,not
keras/tests/keras/backend/backend_test.py,1705,numerical stability.  The Theano code subtracts out the max,not
keras/tests/keras/backend/backend_test.py,1706,"before the final log, so the results are different but scale",not
keras/tests/keras/backend/backend_test.py,1707,identically and still train properly,not
keras/tests/keras/backend/backend_test.py,1714,simplified version of TensorFlow's test,not
keras/tests/keras/backend/backend_test.py,1717,number of timesteps,not
keras/tests/keras/backend/backend_test.py,1719,dimensions are batch x time x categories,not
keras/tests/keras/backend/backend_test.py,1745,"test when batch_size = 1, that is, one sample only",not
keras/tests/keras/backend/backend_test.py,1746,get only first sample from above test case,not
keras/tests/keras/backend/backend_test.py,1783,t=0,not
keras/tests/keras/backend/backend_test.py,1784,t=1,not
keras/tests/keras/backend/backend_test.py,1785,t=2,not
keras/tests/keras/backend/backend_test.py,1786,t=3,not
keras/tests/keras/backend/backend_test.py,1787,t=4 (ignored),not
keras/tests/keras/backend/backend_test.py,1788,t=5 (ignored),not
keras/tests/keras/backend/backend_test.py,1792,dimensions are time x depth,not
keras/tests/keras/backend/backend_test.py,1795,t=0,not
keras/tests/keras/backend/backend_test.py,1796,t=1,not
keras/tests/keras/backend/backend_test.py,1797,t=2,not
keras/tests/keras/backend/backend_test.py,1798,t=3,not
keras/tests/keras/backend/backend_test.py,1799,t=4,not
keras/tests/keras/backend/backend_test.py,1800,t=5 (ignored),not
keras/tests/keras/backend/backend_test.py,1803,len max_time_steps array of batch_size x depth matrices,not
keras/tests/keras/backend/backend_test.py,1808,change tensorflow order to keras backend order,not
keras/tests/keras/backend/backend_test.py,1811,batch_size length vector of sequence_lengths,not
keras/tests/keras/backend/backend_test.py,1858,Random entry added in at time=5,not
keras/tests/keras/backend/backend_test.py,1862,Add arbitrary offset - this is fine,not
keras/tests/keras/backend/backend_test.py,1865,len max_time_steps array of batch_size x depth matrices,not
keras/tests/keras/backend/backend_test.py,1867,Pad to max_time_steps = 8,not
keras/tests/keras/backend/backend_test.py,1870,Take exponential as we directly apply ctc_decode_beam_search,not
keras/tests/keras/backend/backend_test.py,1873,change tensorflow order to keras backend order,not
keras/tests/keras/backend/backend_test.py,1876,batch_size length vector of sequence_lengths,not
keras/tests/keras/backend/backend_test.py,1878,batch_size length vector of log probabilities,not
keras/tests/keras/backend/backend_test.py,1881,output beam 0,not
keras/tests/keras/backend/backend_test.py,1882,output beam 1,not
keras/tests/keras/backend/backend_test.py,1910,"A simple CTC probability map with some repeating characters,",not
keras/tests/keras/backend/backend_test.py,1911,"shape(batch, input_width, char_count)",not
keras/tests/keras/backend/backend_test.py,1912,"Without merging should be decoded as: ""AABB"", with merging as: ""AB"".",not
keras/tests/keras/backend/backend_test.py,1914,"blank, A ,B",not
keras/tests/keras/backend/backend_test.py,1915,blank,not
keras/tests/keras/backend/backend_test.py,1916,A,not
keras/tests/keras/backend/backend_test.py,1917,blank,not
keras/tests/keras/backend/backend_test.py,1918,A,not
keras/tests/keras/backend/backend_test.py,1919,B,not
keras/tests/keras/backend/backend_test.py,1920,blank,not
keras/tests/keras/backend/backend_test.py,1921,B,not
keras/tests/keras/backend/backend_test.py,1938,merged: A B,not
keras/tests/keras/backend/backend_test.py,1940,not merged: A A B B,not
keras/tests/keras/backend/backend_test.py,2007,"In stack, each array must have the same shape.",not
keras/tests/keras/backend/backend_test.py,2020,make sure we can also walk the indexes in tensorflow which we,not
keras/tests/keras/backend/backend_test.py,2021,can't without specifying dtype,not
keras/tests/keras/backend/backend_test.py,2041,This test aims to make sure that we walk the array from right to left,not
keras/tests/keras/backend/backend_test.py,2042,and checks it in the following way: multiplying left to right 1e-40,not
keras/tests/keras/backend/backend_test.py,2043,cannot be held into a float32 so it causes an underflow while from,not
keras/tests/keras/backend/backend_test.py,2044,right to left we have no such problem and the result is larger,not
keras/tests/keras/backend/backend_test.py,2107,Keep track of the old value,not
keras/tests/keras/backend/backend_test.py,2115,Keep track of the old value,not
keras/tests/keras/backend/backend_test.py,2117,Check correct values,not
keras/tests/keras/backend/backend_test.py,2120,Make sure that changes to the global floatx are effectively,not
keras/tests/keras/backend/backend_test.py,2121,taken into account by the backend.,not
keras/tests/keras/backend/backend_test.py,2123,Restore old value,not
keras/tests/keras/backend/backend_test.py,2139,GitHub issue: 11435,not
keras/tests/keras/utils/multi_gpu_test.py,156,Baseline,not
keras/tests/keras/utils/multi_gpu_test.py,163,Training,not
keras/tests/keras/utils/multi_gpu_test.py,169,Inference,not
keras/tests/keras/utils/multi_gpu_test.py,190,Inference,not
keras/tests/keras/utils/multi_gpu_test.py,213,Baseline,not
keras/tests/keras/utils/multi_gpu_test.py,228,Change this,not
keras/tests/keras/utils/multi_gpu_test.py,235,Training,not
keras/tests/keras/utils/data_utils_test.py,288,TODO: resolve flakyness issue. Tracked with #11587,SATD
keras/tests/keras/utils/data_utils_test.py,412,One epoch is completed so enqueuer will switch the Sequence,not
keras/tests/keras/utils/data_utils_test.py,418,One epoch has been completed so enqueuer2 will switch,not
keras/tests/keras/utils/data_utils_test.py,420,Be sure that both Sequence were updated,not
keras/tests/keras/utils/data_utils_test.py,426,Tear down everything,not
keras/tests/keras/utils/data_utils_test.py,489,TODO: resolve flakyness issue. Tracked with #11586,SATD
keras/tests/keras/utils/generic_utils_test.py,52,Keyword-only arguments (Python 3 only),not
keras/tests/keras/utils/generic_utils_test.py,57,lambda,not
keras/tests/keras/utils/generic_utils_test.py,71,Sometimes exec adds builtins to the context,not
keras/tests/keras/utils/generic_utils_test.py,124,this test ensures that models serialized prior to version 2.1.2 can still be,not
keras/tests/keras/utils/generic_utils_test.py,125,deserialized,not
keras/tests/keras/utils/generic_utils_test.py,127,see:,not
keras/tests/keras/utils/generic_utils_test.py,128,https://github.com/evhub/keras/blob/2.1.1/keras/utils/generic_utils.py#L166,not
keras/tests/keras/utils/io_utils_test.py,45,Creating dataset to store features,not
keras/tests/keras/utils/io_utils_test.py,48,Creating dataset to store labels,not
keras/tests/keras/utils/io_utils_test.py,60,"Instantiating HDF5Matrix for the training set,",not
keras/tests/keras/utils/io_utils_test.py,61,which is a slice of the first 150 elements,not
keras/tests/keras/utils/io_utils_test.py,65,Likewise for the test set,not
keras/tests/keras/utils/io_utils_test.py,69,HDF5Matrix behave more or less like Numpy matrices with regards to indexing,not
keras/tests/keras/utils/io_utils_test.py,71,"But they do not support negative indices, so don't try print(X_train[-1])",not
keras/tests/keras/utils/io_utils_test.py,84,Note: you have to use shuffle='batch' or False with HDF5Matrix,not
keras/tests/keras/utils/io_utils_test.py,86,test that evalutation and prediction don't crash and,not
keras/tests/keras/utils/io_utils_test.py,87,return reasonable results,not
keras/tests/keras/utils/io_utils_test.py,95,test slicing for shortened array,not
keras/tests/keras/utils/io_utils_test.py,98,test __getitem__,not
keras/tests/keras/utils/io_utils_test.py,115,test normalizer,not
keras/tests/keras/utils/io_utils_test.py,121,test resizing normalizer,not
keras/tests/keras/utils/io_utils_test.py,127,test dtype changing normalizer,not
keras/tests/keras/utils/io_utils_test.py,148,test both HDF5 and dict implementations,not
keras/tests/keras/utils/io_utils_test.py,154,str,not
keras/tests/keras/utils/io_utils_test.py,158,list<bytes>,not
keras/tests/keras/utils/io_utils_test.py,162,ndarray,not
keras/tests/keras/utils/io_utils_test.py,184,test both HDF5 and dict implementations,not
keras/tests/keras/utils/layer_utils_test.py,45,Test equivalence of convert_all_kernels_in_model,not
keras/tests/keras/utils/layer_utils_test.py,52,Test equivalence of convert_dense_weights_data_format,not
keras/tests/keras/utils/np_utils_test.py,22,Check shape,not
keras/tests/keras/utils/np_utils_test.py,24,Make sure there are only 0s and 1s,not
keras/tests/keras/utils/np_utils_test.py,26,Make sure there is exactly one 1 in a row,not
keras/tests/keras/utils/np_utils_test.py,28,Get original labels back from one hots,not
keras/tests/keras/engine/test_training.py,32,It will work for use_multiprocessing=False,not
keras/tests/keras/engine/test_training.py,144,weighted_masked_objective,not
keras/tests/keras/engine/test_training.py,171,test starting from non-zero initial epoch,not
keras/tests/keras/engine/test_training.py,181,define tracer callback,not
keras/tests/keras/engine/test_training.py,189,TODO: resolve flakyness issue. Tracked with #11560,SATD
keras/tests/keras/engine/test_training.py,204,training/testing doesn't work before compiling.,not
keras/tests/keras/engine/test_training.py,212,test train_on_batch,not
keras/tests/keras/engine/test_training.py,220,test fit,not
keras/tests/keras/engine/test_training.py,229,test validation_split,not
keras/tests/keras/engine/test_training.py,237,test validation data,not
keras/tests/keras/engine/test_training.py,256,test_on_batch,not
keras/tests/keras/engine/test_training.py,264,predict_on_batch,not
keras/tests/keras/engine/test_training.py,269,"predict, evaluate",not
keras/tests/keras/engine/test_training.py,281,with sample_weight,not
keras/tests/keras/engine/test_training.py,297,test accuracy metric,not
keras/tests/keras/engine/test_training.py,308,this should also work,not
keras/tests/keras/engine/test_training.py,319,and this as well,not
keras/tests/keras/engine/test_training.py,337,test starting from non-zero initial epoch for generator too,not
keras/tests/keras/engine/test_training.py,352,test with a custom metric function,not
keras/tests/keras/engine/test_training.py,361,total loss + 2 outputs * (loss + metric),not
keras/tests/keras/engine/test_training.py,381,enable verbose for evaluate_generator,not
keras/tests/keras/engine/test_training.py,383,pass generator directly so `is_generator_or_sequence`,not
keras/tests/keras/engine/test_training.py,384,doesn't get confused.,not
keras/tests/keras/engine/test_training.py,387,empty batch,not
keras/tests/keras/engine/test_training.py,403,x is not a list of numpy arrays.,not
keras/tests/keras/engine/test_training.py,407,x does not match _feed_input_names.,not
keras/tests/keras/engine/test_training.py,413,all input/output/weight arrays should have the same number of samples.,not
keras/tests/keras/engine/test_training.py,428,`sample_weight` is neither a dict nor a list.,not
keras/tests/keras/engine/test_training.py,434,`validation_data` is neither a tuple nor a triple.,not
keras/tests/keras/engine/test_training.py,441,`loss` does not match outputs.,not
keras/tests/keras/engine/test_training.py,445,`loss_weights` does not match output_names.,not
keras/tests/keras/engine/test_training.py,449,`loss_weights` does not match outputs.,not
keras/tests/keras/engine/test_training.py,453,`loss_weights` is invalid type.,not
keras/tests/keras/engine/test_training.py,457,`sample_weight_mode` does not match output_names.,not
keras/tests/keras/engine/test_training.py,462,`sample_weight_mode` does not match output_names.,not
keras/tests/keras/engine/test_training.py,466,`sample_weight_mode` matches output_names partially.,not
keras/tests/keras/engine/test_training.py,471,`loss` does not exist.,not
keras/tests/keras/engine/test_training.py,480,the rank of weight arrays should be 1.,not
keras/tests/keras/engine/test_training.py,491,the rank of output arrays should be at least 3D.,not
keras/tests/keras/engine/test_training.py,498,TODO: resolve flakyness issue. Tracked with #11560,SATD
keras/tests/keras/engine/test_training.py,536,steps_per_epoch will be equal to len of sequence if it's unspecified,not
keras/tests/keras/engine/test_training.py,547,the queue may be full.,not
keras/tests/keras/engine/test_training.py,559,the queue may be full.,not
keras/tests/keras/engine/test_training.py,561,test for workers = 0,not
keras/tests/keras/engine/test_training.py,587,fit_generator will throw an exception,not
keras/tests/keras/engine/test_training.py,588,if steps is unspecified for regular generator,not
keras/tests/keras/engine/test_training.py,599,Check if generator is only accessed an expected number of times,not
keras/tests/keras/engine/test_training.py,615,Need range check here as filling,not
keras/tests/keras/engine/test_training.py,616,of the queue depends on sleep in the enqueuers,not
keras/tests/keras/engine/test_training.py,620,12 = (epoch * workers * validation steps * max_queue_size),not
keras/tests/keras/engine/test_training.py,630,12 = (epoch * workers * validation steps * max_queue_size),not
keras/tests/keras/engine/test_training.py,631,Need range check here as filling,not
keras/tests/keras/engine/test_training.py,632,of the queue depends on sleep in the enqueuers,not
keras/tests/keras/engine/test_training.py,656,1st epoch -> ceil(20 / 3) = 7 batches,not
keras/tests/keras/engine/test_training.py,657,2nd epoch -> ceil(20 / 5) = 4 batches,not
keras/tests/keras/engine/test_training.py,658,3d  epoch -> ceil(20 / 7) = 3 batches,not
keras/tests/keras/engine/test_training.py,659,4th epoch -> ceil(20 / 9) = 3 batches,not
keras/tests/keras/engine/test_training.py,660,5th epoch -> ceil(20 /11) = 2 batches,not
keras/tests/keras/engine/test_training.py,676,1st epoch -> ceil(30 / 3) = 10 batches,not
keras/tests/keras/engine/test_training.py,677,2nd epoch -> ceil(30 / 5) =  6 batches,not
keras/tests/keras/engine/test_training.py,678,3d  epoch -> ceil(30 / 7) =  5 batches,not
keras/tests/keras/engine/test_training.py,679,4th epoch -> ceil(30 / 9) =  4 batches,not
keras/tests/keras/engine/test_training.py,680,5th epoch -> ceil(30 /11) =  3 batches,not
keras/tests/keras/engine/test_training.py,695,number of trained batches should match sum of steps per each epoch,not
keras/tests/keras/engine/test_training.py,720,1st epoch -> ceil(20 / 3) = 7 batches,not
keras/tests/keras/engine/test_training.py,721,2nd epoch -> ceil(20 / 5) = 4 batches,not
keras/tests/keras/engine/test_training.py,722,3d  epoch -> ceil(20 / 7) = 3 batches,not
keras/tests/keras/engine/test_training.py,723,4th epoch -> ceil(20 / 9) = 3 batches,not
keras/tests/keras/engine/test_training.py,724,5th epoch -> ceil(20 /11) = 2 batches,not
keras/tests/keras/engine/test_training.py,740,1st epoch -> ceil(30 / 3) = 10 batches,not
keras/tests/keras/engine/test_training.py,741,2nd epoch -> ceil(30 / 5) =  6 batches,not
keras/tests/keras/engine/test_training.py,742,3d  epoch -> ceil(30 / 7) =  5 batches,not
keras/tests/keras/engine/test_training.py,743,4th epoch -> ceil(30 / 9) =  4 batches,not
keras/tests/keras/engine/test_training.py,744,5th epoch -> ceil(30 /11) =  3 batches,not
keras/tests/keras/engine/test_training.py,759,number of trained batches should match sum of steps per each epoch,not
keras/tests/keras/engine/test_training.py,765,predict_generator output shape behavior should be consistent,not
keras/tests/keras/engine/test_training.py,773,Multiple outputs and one step.,not
keras/tests/keras/engine/test_training.py,785,Multiple outputs and multiple steps.,not
keras/tests/keras/engine/test_training.py,797,Create a model with a single output.,not
keras/tests/keras/engine/test_training.py,802,Single output and one step.,not
keras/tests/keras/engine/test_training.py,814,Single output and multiple steps.,not
keras/tests/keras/engine/test_training.py,946,test with nesting,not
keras/tests/keras/engine/test_training.py,1024,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1033,test fit,not
keras/tests/keras/engine/test_training.py,1039,test evaluate,not
keras/tests/keras/engine/test_training.py,1045,test predict,not
keras/tests/keras/engine/test_training.py,1050,Now test a model with a single input,not
keras/tests/keras/engine/test_training.py,1051,i.e. we don't pass any data to fit the model.,not
keras/tests/keras/engine/test_training.py,1062,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1075,test fit,not
keras/tests/keras/engine/test_training.py,1081,test evaluate,not
keras/tests/keras/engine/test_training.py,1087,test predict,not
keras/tests/keras/engine/test_training.py,1092,"Same, without learning phase",not
keras/tests/keras/engine/test_training.py,1093,i.e. we don't pass any data to fit the model.,not
keras/tests/keras/engine/test_training.py,1103,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1116,test fit,not
keras/tests/keras/engine/test_training.py,1122,test evaluate,not
keras/tests/keras/engine/test_training.py,1128,test predict,not
keras/tests/keras/engine/test_training.py,1148,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1151,fit,not
keras/tests/keras/engine/test_training.py,1153,evaluate,not
keras/tests/keras/engine/test_training.py,1156,Same without dropout.,not
keras/tests/keras/engine/test_training.py,1166,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1169,fit,not
keras/tests/keras/engine/test_training.py,1171,evaluate,not
keras/tests/keras/engine/test_training.py,1178,"None loss, only regularization loss.",not
keras/tests/keras/engine/test_training.py,1194,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1197,fit,not
keras/tests/keras/engine/test_training.py,1199,evaluate,not
keras/tests/keras/engine/test_training.py,1202,"No dropout, external loss.",not
keras/tests/keras/engine/test_training.py,1214,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1217,fit,not
keras/tests/keras/engine/test_training.py,1219,evaluate,not
keras/tests/keras/engine/test_training.py,1222,Test fit with no external data at all.,not
keras/tests/keras/engine/test_training.py,1236,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1241,test fit,not
keras/tests/keras/engine/test_training.py,1246,define a generator to produce x=None and y=None,not
keras/tests/keras/engine/test_training.py,1254,test fit_generator for framework-native data tensors,not
keras/tests/keras/engine/test_training.py,1258,test evaluate_generator for framework-native data tensors,not
keras/tests/keras/engine/test_training.py,1262,test fit with validation data,not
keras/tests/keras/engine/test_training.py,1273,test evaluate,not
keras/tests/keras/engine/test_training.py,1278,test predict,not
keras/tests/keras/engine/test_training.py,1284,Test multi-output model without external data.,not
keras/tests/keras/engine/test_training.py,1294,test train_on_batch,not
keras/tests/keras/engine/test_training.py,1299,test fit,not
keras/tests/keras/engine/test_training.py,1304,test fit with validation data,not
keras/tests/keras/engine/test_training.py,1315,test evaluate,not
keras/tests/keras/engine/test_training.py,1320,test predict,not
keras/tests/keras/engine/test_training.py,1330,"single-output, as list",not
keras/tests/keras/engine/test_training.py,1339,"single-output, as dict",not
keras/tests/keras/engine/test_training.py,1344,"single-output, as tensor",not
keras/tests/keras/engine/test_training.py,1349,test invalid arguments,not
keras/tests/keras/engine/test_training.py,1364,"multi-output, as list",not
keras/tests/keras/engine/test_training.py,1379,"multi-output, as dict",not
keras/tests/keras/engine/test_training.py,1385,"multi-output, not enough target tensors when `target_tensors` is not a dict",not
keras/tests/keras/engine/test_training.py,1399,test with sample weights,not
keras/tests/keras/engine/test_training.py,1426,test list of target tensors,not
keras/tests/keras/engine/test_training.py,1442,test dictionary of target_tensors,not
keras/tests/keras/engine/test_training.py,1449,test dictionary of target_tensors,not
keras/tests/keras/engine/test_training.py,1460,test with custom placeholder as target,not
keras/tests/keras/engine/test_training.py,1490,Should warn on .summary(),not
keras/tests/keras/engine/test_training.py,1497,And on .fit(),not
keras/tests/keras/engine/test_training.py,1504,And shouldn't warn if we recompile,not
keras/tests/keras/engine/test_training.py,1654,Test with dictionary inputs,not
keras/tests/keras/engine/test_training.py,1682,Test with validation data,not
keras/tests/keras/engine/test_training.py,1691,Test with validation split,not
keras/tests/keras/engine/test_training.py,1702,Test evaluation / prediction methods,not
keras/tests/keras/engine/test_training.py,1747,"Labels for testing 4-class sparse_categorical_crossentropy, 4-class",not
keras/tests/keras/engine/test_training.py,1748,"categorical_crossentropy, and 2-class binary_crossentropy:",not
keras/tests/keras/engine/test_training.py,1756,Compute one loss for each loss function in the list `losses_to_test`:,not
keras/tests/keras/engine/test_training.py,1762,"Evaluate a simple network with channels last, with all three loss",not
keras/tests/keras/engine/test_training.py,1763,functions:,not
keras/tests/keras/engine/test_training.py,1773,"Evaluate the same network with channels first, with all three loss",not
keras/tests/keras/engine/test_training.py,1774,functions:,not
keras/tests/keras/engine/test_training.py,1833,Only `sample_weights`.,not
keras/tests/keras/engine/test_training.py,1837,Only `class_weights`.,not
keras/tests/keras/engine/test_training.py,1841,Both 'sample_weights` and 'class_weights`.,not
keras/tests/keras/engine/test_training.py,1866,Test in training_arrays.py,not
keras/tests/keras/engine/test_training.py,1878,Test in training_generator.py,not
keras/tests/keras/engine/test_training.py,1947,Verify that the metrics added using `compile` and `add_metric` API are,not
keras/tests/keras/engine/test_training.py,1948,included,not
keras/tests/keras/engine/test_training.py,1979,Verify that the metrics added using `compile` and `add_metric` API are,not
keras/tests/keras/engine/test_training.py,1980,included,not
keras/tests/keras/engine/test_training.py,2055,Provide same name as in the instance created in __init__,not
keras/tests/keras/engine/test_training.py,2056,for eager mode,not
keras/tests/keras/engine/test_topology.py,61,sequential model,not
keras/tests/keras/engine/test_topology.py,124,test merge,not
keras/tests/keras/engine/test_topology.py,128,Test recursion,not
keras/tests/keras/engine/test_topology.py,140,try actually running graph,not
keras/tests/keras/engine/test_topology.py,146,output a: nothing changes,not
keras/tests/keras/engine/test_topology.py,148,output b: dropout applied,not
keras/tests/keras/engine/test_topology.py,153,Test the ability to pass and serialize arguments to `call`.,not
keras/tests/keras/engine/test_topology.py,160,Test that argument is kept when applying the model,not
keras/tests/keras/engine/test_topology.py,165,Test that argument is kept after loading a model,not
keras/tests/keras/engine/test_topology.py,172,,not
keras/tests/keras/engine/test_topology.py,173,test basics,not
keras/tests/keras/engine/test_topology.py,219,test layer properties,not
keras/tests/keras/engine/test_topology.py,254,,not
keras/tests/keras/engine/test_topology.py,255,test multi-input layer,not
keras/tests/keras/engine/test_topology.py,286,we don't check names of first 2 layers (inputs) because,not
keras/tests/keras/engine/test_topology.py,287,ordering of same-level layers is not fixed,not
keras/tests/keras/engine/test_topology.py,293,actually run model,not
keras/tests/keras/engine/test_topology.py,300,test get_source_inputs,not
keras/tests/keras/engine/test_topology.py,305,serialization / deserialization,not
keras/tests/keras/engine/test_topology.py,322,,not
keras/tests/keras/engine/test_topology.py,323,test recursion,not
keras/tests/keras/engine/test_topology.py,341,"g2, h2 = model([e, f])",not
keras/tests/keras/engine/test_topology.py,346,test separate manipulation of different layer outputs,not
keras/tests/keras/engine/test_topology.py,354,we don't check names of first 2 layers (inputs) because,not
keras/tests/keras/engine/test_topology.py,355,ordering of same-level layers is not fixed,not
keras/tests/keras/engine/test_topology.py,361,run recursive model,not
keras/tests/keras/engine/test_topology.py,368,test serialization,not
keras/tests/keras/engine/test_topology.py,379,,not
keras/tests/keras/engine/test_topology.py,380,test multi-input multi-output,not
keras/tests/keras/engine/test_topology.py,395,test with single output as 1-elem list,not
keras/tests/keras/engine/test_topology.py,403,test with single output as tensor,not
keras/tests/keras/engine/test_topology.py,409,note that the output of the K.function will still be a 1-elem list,not
keras/tests/keras/engine/test_topology.py,412,test serialization,not
keras/tests/keras/engine/test_topology.py,419,note that the output of the K.function will still be a 1-elem list,not
keras/tests/keras/engine/test_topology.py,432,,not
keras/tests/keras/engine/test_topology.py,433,test invalid graphs,not
keras/tests/keras/engine/test_topology.py,435,input is not an Input tensor,not
keras/tests/keras/engine/test_topology.py,444,disconnected graph,not
keras/tests/keras/engine/test_topology.py,451,redundant outputs,not
keras/tests/keras/engine/test_topology.py,455,this should work with a warning,not
keras/tests/keras/engine/test_topology.py,458,redundant inputs,not
keras/tests/keras/engine/test_topology.py,465,i have not idea what I'm doing: garbage as inputs/outputs,not
keras/tests/keras/engine/test_topology.py,472,,not
keras/tests/keras/engine/test_topology.py,473,test calling layers/models on placeholders,not
keras/tests/keras/engine/test_topology.py,485,test merge,not
keras/tests/keras/engine/test_topology.py,489,test tensor input,not
keras/tests/keras/engine/test_topology.py,512,TimeDistributed Conv2D layer,not
keras/tests/keras/engine/test_topology.py,513,use 'channels_first' data format to check that,not
keras/tests/keras/engine/test_topology.py,514,the function is being called correctly for Conv2D,not
keras/tests/keras/engine/test_topology.py,515,"old: (filters, stack_size, kernel_rows, kernel_cols)",not
keras/tests/keras/engine/test_topology.py,516,"new: (kernel_rows, kernel_cols, stack_size, filters)",not
keras/tests/keras/engine/test_topology.py,530,Bidirectional ConvLSTM2D layer,not
keras/tests/keras/engine/test_topology.py,531,"old ConvLSTM2D took a list of 12 weight tensors,",not
keras/tests/keras/engine/test_topology.py,532,returns a list of 3 concatenated larger tensors.,not
keras/tests/keras/engine/test_topology.py,534,bidirectional,not
keras/tests/keras/engine/test_topology.py,536,kernel,not
keras/tests/keras/engine/test_topology.py,537,recurrent kernel,not
keras/tests/keras/engine/test_topology.py,538,bias,not
keras/tests/keras/engine/test_topology.py,584,A model is needed to initialize weights.,not
keras/tests/keras/engine/test_topology.py,619,layer can be instantiated only for supported backends,not
keras/tests/keras/engine/test_topology.py,621,A model is needed to initialize weights.,not
keras/tests/keras/engine/test_topology.py,687,"Basic outline here: we have a shared embedding layer, and two inputs that",not
keras/tests/keras/engine/test_topology.py,688,go through different depths of computation in the graph before,not
keras/tests/keras/engine/test_topology.py,689,the final output.  We need the computed depth of the input layers to be,not
keras/tests/keras/engine/test_topology.py,690,"the same, because they both pass through the embedding layer before anything",not
keras/tests/keras/engine/test_topology.py,691,else happens.  That's what we're testing.,not
keras/tests/keras/engine/test_topology.py,763,This tests for the bug in this issue,SATD
keras/tests/keras/engine/test_topology.py,764,https://github.com/keras-team/keras/issues/11159,not
keras/tests/keras/engine/test_topology.py,765,It occurs with layer sharing at heterogeneous depth when,not
keras/tests/keras/engine/test_topology.py,766,the layers need to be applied in an order that differs from,not
keras/tests/keras/engine/test_topology.py,767,the order that occurs in the config.,not
keras/tests/keras/engine/test_topology.py,779,Note: if the order of the layers in the concat is,not
keras/tests/keras/engine/test_topology.py,780,"changed to ([Aout1, Aout2]) the bug doesn't trigger",not
keras/tests/keras/engine/layer_subclassing_tests.py,9,basic case,not
keras/tests/keras/engine/layer_subclassing_tests.py,28,recursive case,not
keras/tests/keras/engine/layer_subclassing_tests.py,47,subnetwork case,not
keras/tests/keras/engine/layer_subclassing_tests.py,105,basic case,not
keras/tests/keras/engine/layer_subclassing_tests.py,120,includes input layer,not
keras/tests/keras/layers/cudnn_recurrent_test.py,306,train once so that the states change,not
keras/tests/keras/layers/cudnn_recurrent_test.py,311,"if the state is not reset, output should be different",not
keras/tests/keras/layers/cudnn_recurrent_test.py,314,check that output changes after states are reset,not
keras/tests/keras/layers/cudnn_recurrent_test.py,315,(even though the model itself didn't change),not
keras/tests/keras/layers/cudnn_recurrent_test.py,320,check that container-level reset_states() works,not
keras/tests/keras/layers/cudnn_recurrent_test.py,325,check that the call to `predict` updated the states,not
keras/tests/keras/layers/cudnn_recurrent_test.py,343,test with Sequential model,not
keras/tests/keras/layers/cudnn_recurrent_test.py,351,test config,not
keras/tests/keras/layers/cudnn_recurrent_test.py,356,test stacked bidirectional layers,not
keras/tests/keras/layers/cudnn_recurrent_test.py,366,test with functional API,not
keras/tests/keras/layers/cudnn_recurrent_test.py,374,Bidirectional and stateful,not
keras/tests/keras/layers/advanced_activations_test.py,51,max_value of ReLU layer cannot be negative value,not
keras/tests/keras/layers/advanced_activations_test.py,56,negative_slope of ReLU layer cannot be negative value,not
keras/tests/keras/layers/advanced_activations_test.py,66,Test that `relu` op gets used.,not
keras/tests/keras/layers/advanced_activations_test.py,69,Test that `leakyrelu` op gets used.,not
keras/tests/keras/layers/advanced_activations_test.py,72,Test that `relu6` op gets used.,not
keras/tests/keras/layers/wrappers_test.py,15,"first, test with Dense layer",not
keras/tests/keras/layers/wrappers_test.py,24,test config,not
keras/tests/keras/layers/wrappers_test.py,27,test when specifying a batch_input_shape,not
keras/tests/keras/layers/wrappers_test.py,42,test with Embedding,not
keras/tests/keras/layers/wrappers_test.py,51,compare to not using batch_input_shape,not
keras/tests/keras/layers/wrappers_test.py,65,test with Conv2D,not
keras/tests/keras/layers/wrappers_test.py,78,test stacked layers,not
keras/tests/keras/layers/wrappers_test.py,88,test wrapping Sequential model,not
keras/tests/keras/layers/wrappers_test.py,97,test with functional API,not
keras/tests/keras/layers/wrappers_test.py,105,test with BatchNormalization,not
keras/tests/keras/layers/wrappers_test.py,111,Assert that mean and variance are 0 and 1.,not
keras/tests/keras/layers/wrappers_test.py,115,Train,not
keras/tests/keras/layers/wrappers_test.py,118,Assert that mean and variance changed.,not
keras/tests/keras/layers/wrappers_test.py,121,Verify input_map has one mapping from inputs to reshaped inputs.,not
keras/tests/keras/layers/wrappers_test.py,131,test layers that need learning_phase to be set,not
keras/tests/keras/layers/wrappers_test.py,141,test layers that need learning_phase to be set,not
keras/tests/keras/layers/wrappers_test.py,158,test with unspecified shape and Embeddings with mask_zero,not
keras/tests/keras/layers/wrappers_test.py,162,"the shape so far: (N, t_1, t_2, 6)",not
keras/tests/keras/layers/wrappers_test.py,177,embedding layer,not
keras/tests/keras/layers/wrappers_test.py,178,first RNN layer,not
keras/tests/keras/layers/wrappers_test.py,179,second RNN layer,not
keras/tests/keras/layers/wrappers_test.py,183,final layer,not
keras/tests/keras/layers/wrappers_test.py,187,test with Masking layer,not
keras/tests/keras/layers/wrappers_test.py,239,test with Sequential model,not
keras/tests/keras/layers/wrappers_test.py,248,test config,not
keras/tests/keras/layers/wrappers_test.py,253,test stacked bidirectional layers,not
keras/tests/keras/layers/wrappers_test.py,263,Bidirectional and stateful,not
keras/tests/keras/layers/wrappers_test.py,275,test with functional API with dynamic length,not
keras/tests/keras/layers/wrappers_test.py,316,basic case,not
keras/tests/keras/layers/wrappers_test.py,331,test return_state,not
keras/tests/keras/layers/wrappers_test.py,348,test if the state of a BiRNN is the concatenation of the underlying RNNs,not
keras/tests/keras/layers/wrappers_test.py,398,test passing invalid initial_state: passing a tensor,not
keras/tests/keras/layers/wrappers_test.py,403,test valid usage: passing a list,not
keras/tests/keras/layers/wrappers_test.py,424,will (and should) raise if more than one constant passed,not
keras/tests/keras/layers/wrappers_test.py,454,Test basic case.,not
keras/tests/keras/layers/wrappers_test.py,469,Test basic case serialization.,not
keras/tests/keras/layers/wrappers_test.py,483,test flat list inputs,not
keras/tests/keras/layers/wrappers_test.py,504,will (and should) raise if more than one constant passed,not
keras/tests/keras/layers/wrappers_test.py,534,Test basic case.,not
keras/tests/keras/layers/wrappers_test.py,552,Test basic case serialization.,not
keras/tests/keras/layers/wrappers_test.py,568,verify that state is used,not
keras/tests/keras/layers/wrappers_test.py,573,test flat list inputs,not
keras/tests/keras/layers/wrappers_test.py,584,test layers that need learning_phase to be set,not
keras/tests/keras/layers/convolutional_recurrent_test.py,40,test for return state:,not
keras/tests/keras/layers/convolutional_recurrent_test.py,61,test for output shape:,not
keras/tests/keras/layers/convolutional_recurrent_test.py,78,Tests for statefulness,not
keras/tests/keras/layers/convolutional_recurrent_test.py,93,train once so that the states change,not
keras/tests/keras/layers/convolutional_recurrent_test.py,98,"if the state is not reset, output should be different",not
keras/tests/keras/layers/convolutional_recurrent_test.py,101,check that output changes after states are reset,not
keras/tests/keras/layers/convolutional_recurrent_test.py,102,(even though the model itself didn't change),not
keras/tests/keras/layers/convolutional_recurrent_test.py,107,check that container-level reset_states() works,not
keras/tests/keras/layers/convolutional_recurrent_test.py,112,check that the call to `predict` updated the states,not
keras/tests/keras/layers/convolutional_recurrent_test.py,116,cntk doesn't support eval convolution with static,not
keras/tests/keras/layers/convolutional_recurrent_test.py,117,"variable, will enable it later",not
keras/tests/keras/layers/convolutional_recurrent_test.py,119,check regularizers,not
keras/tests/keras/layers/convolutional_recurrent_test.py,143,check dropout,not
keras/tests/keras/layers/convolutional_recurrent_test.py,154,check state initialization,not
keras/tests/keras/layers/merge_test.py,34,Test invalid use case,not
keras/tests/keras/layers/merge_test.py,66,Test invalid use case,not
keras/tests/keras/layers/merge_test.py,192,Test invalid use case,not
keras/tests/keras/layers/merge_test.py,223,Test with negative tuple of axes.,not
keras/tests/keras/layers/merge_test.py,233,shapes provided,not
keras/tests/keras/layers/merge_test.py,247,shapes not provided,not
keras/tests/keras/layers/merge_test.py,261,ndim not provided,not
keras/tests/keras/layers/convolutional_test.py,12,TensorFlow does not support full convolution.,not
keras/tests/keras/layers/convolutional_test.py,24,Causal,not
keras/tests/keras/layers/convolutional_test.py,28,Non-causal,not
keras/tests/keras/layers/convolutional_test.py,32,Causal dilated with larger kernel size,not
keras/tests/keras/layers/convolutional_test.py,228,Check dilated conv transpose returns expected output,not
keras/tests/keras/layers/convolutional_test.py,286,Test invalid output padding for given stride. Output padding equal to stride,not
keras/tests/keras/layers/convolutional_test.py,296,Output padding greater than stride,not
keras/tests/keras/layers/convolutional_test.py,614,Test invalid use case,not
keras/tests/keras/layers/convolutional_test.py,622,Test invalid output padding for given stride. Output padding equal,not
keras/tests/keras/layers/convolutional_test.py,623,to stride,not
keras/tests/keras/layers/convolutional_test.py,633,Output padding greater than stride,not
keras/tests/keras/layers/convolutional_test.py,651,basic test,not
keras/tests/keras/layers/convolutional_test.py,659,correctness test,not
keras/tests/keras/layers/convolutional_test.py,845,tf,not
keras/tests/keras/layers/convolutional_test.py,849,basic test,not
keras/tests/keras/layers/convolutional_test.py,865,tf,not
keras/tests/keras/layers/convolutional_test.py,869,compare with numpy,not
keras/tests/keras/layers/convolutional_test.py,873,tf,not
keras/tests/keras/layers/convolutional_test.py,893,tf,not
keras/tests/keras/layers/convolutional_test.py,897,basic test,not
keras/tests/keras/layers/convolutional_test.py,915,tf,not
keras/tests/keras/layers/convolutional_test.py,935,tf,not
keras/tests/keras/layers/convolutional_test.py,940,basic test,not
keras/tests/keras/layers/convolutional_test.py,958,tf,not
keras/tests/keras/layers/convolutional_test.py,963,compare with numpy,not
keras/tests/keras/layers/convolutional_test.py,968,tf,not
keras/tests/keras/layers/convolutional_test.py,1004,basic test,not
keras/tests/keras/layers/convolutional_test.py,1009,correctness test,not
keras/tests/keras/layers/convolutional_test.py,1015,compare with numpy,not
keras/tests/keras/layers/convolutional_test.py,1036,another correctness test (no cropping),not
keras/tests/keras/layers/convolutional_test.py,1043,compare with input,not
keras/tests/keras/layers/convolutional_test.py,1046,Test invalid use cases,not
keras/tests/keras/layers/convolutional_test.py,1069,basic test,not
keras/tests/keras/layers/convolutional_test.py,1074,correctness test,not
keras/tests/keras/layers/convolutional_test.py,1080,compare with numpy,not
keras/tests/keras/layers/convolutional_test.py,1103,another correctness test (no cropping),not
keras/tests/keras/layers/convolutional_test.py,1110,compare with input,not
keras/tests/keras/layers/convolutional_test.py,1113,Test invalid use cases,not
keras/tests/keras/layers/normalization_test.py,54,"centered on 5.0, variance 10.0",not
keras/tests/keras/layers/normalization_test.py,73,"centered on 5.0, variance 10.0",not
keras/tests/keras/layers/normalization_test.py,109,This is a regression test for issue #4881 with the old,not
keras/tests/keras/layers/normalization_test.py,110,batch normalization functions in the Theano backend.,not
keras/tests/keras/layers/normalization_test.py,129,"centered on 5.0, variance 10.0",not
keras/tests/keras/layers/normalization_test.py,150,"centered on 5.0, variance 10.0",not
keras/tests/keras/layers/normalization_test.py,163,Test single layer reuse,not
keras/tests/keras/layers/normalization_test.py,177,Test model-level reuse,not
keras/tests/keras/layers/normalization_test.py,235,Simulates training-mode with trainable layer. Should use mini-batch statistics.,not
keras/tests/keras/layers/recurrent_test.py,81,Test that dropout is applied during training,not
keras/tests/keras/layers/recurrent_test.py,91,Test that dropout is not applied during testing,not
keras/tests/keras/layers/recurrent_test.py,118,train once so that the states change,not
keras/tests/keras/layers/recurrent_test.py,123,"if the state is not reset, output should be different",not
keras/tests/keras/layers/recurrent_test.py,126,check that output changes after states are reset,not
keras/tests/keras/layers/recurrent_test.py,127,(even though the model itself didn't change),not
keras/tests/keras/layers/recurrent_test.py,132,check that container-level reset_states() works,not
keras/tests/keras/layers/recurrent_test.py,137,check that the call to `predict` updated the states,not
keras/tests/keras/layers/recurrent_test.py,144,Check masking: output with left padding and right padding,not
keras/tests/keras/layers/recurrent_test.py,145,should be the same.,not
keras/tests/keras/layers/recurrent_test.py,187,also equal to `output_size`,not
keras/tests/keras/layers/recurrent_test.py,189,random inputs and state values,not
keras/tests/keras/layers/recurrent_test.py,191,last timestep masked for first sample (all zero inputs masked by Masking layer),not
keras/tests/keras/layers/recurrent_test.py,195,final outputs equal to last inputs,not
keras/tests/keras/layers/recurrent_test.py,197,"except for first sample, where it is equal to second to last value due to mask",not
keras/tests/keras/layers/recurrent_test.py,201,states are incremented `num_timesteps - 1` times for first sample,not
keras/tests/keras/layers/recurrent_test.py,203,and `num_timesteps - 1` times for remaining samples,not
keras/tests/keras/layers/recurrent_test.py,246,random inputs and state values,not
keras/tests/keras/layers/recurrent_test.py,248,last timestep masked for first sample (all zero inputs masked by Masking layer),not
keras/tests/keras/layers/recurrent_test.py,252,final outputs equal to last inputs concatenated,not
keras/tests/keras/layers/recurrent_test.py,254,"except for first sample, where it is equal to second to last value due to mask",not
keras/tests/keras/layers/recurrent_test.py,258,states are incremented `num_timesteps - 1` times for first sample,not
keras/tests/keras/layers/recurrent_test.py,260,and `num_timesteps - 1` times for remaining samples,not
keras/tests/keras/layers/recurrent_test.py,285,Without dropout,not
keras/tests/keras/layers/recurrent_test.py,290,With dropout,not
keras/tests/keras/layers/recurrent_test.py,297,Without bias,not
keras/tests/keras/layers/recurrent_test.py,377,Test with Keras tensor,not
keras/tests/keras/layers/recurrent_test.py,402,Test with non-Keras tensor,not
keras/tests/keras/layers/recurrent_test.py,438,Test fit with invalid data,not
keras/tests/keras/layers/recurrent_test.py,447,Test with Keras tensor,not
keras/tests/keras/layers/recurrent_test.py,550,Basic test case.,not
keras/tests/keras/layers/recurrent_test.py,559,Test stacking.,not
keras/tests/keras/layers/recurrent_test.py,588,Basic test case.,not
keras/tests/keras/layers/recurrent_test.py,597,Test stacking.,not
keras/tests/keras/layers/recurrent_test.py,619,no time axis in the input shape passed to RNN cells,not
keras/tests/keras/layers/recurrent_test.py,642,Test basic case.,not
keras/tests/keras/layers/recurrent_test.py,651,Test basic case serialization.,not
keras/tests/keras/layers/recurrent_test.py,664,Test stacking.,not
keras/tests/keras/layers/recurrent_test.py,674,Test stacked RNN serialization.,not
keras/tests/keras/layers/recurrent_test.py,690,Test basic case.,not
keras/tests/keras/layers/recurrent_test.py,699,Test basic case serialization.,not
keras/tests/keras/layers/recurrent_test.py,711,Test stacking.,not
keras/tests/keras/layers/recurrent_test.py,721,Test stacked RNN serialization.,not
keras/tests/keras/layers/recurrent_test.py,756,Test regularization losses,not
keras/tests/keras/layers/recurrent_test.py,759,Test weights,not
keras/tests/keras/layers/recurrent_test.py,765,Test `get_losses_for`,not
keras/tests/keras/layers/recurrent_test.py,784,Test reverse_state_order = True for stacked cell.,not
keras/tests/keras/layers/recurrent_test.py,823,will (and should) raise if more than one constant passed,not
keras/tests/keras/layers/recurrent_test.py,853,Test basic case.,not
keras/tests/keras/layers/recurrent_test.py,866,Test basic case serialization.,not
keras/tests/keras/layers/recurrent_test.py,881,test flat list inputs,not
keras/tests/keras/layers/recurrent_test.py,890,Test stacking.,not
keras/tests/keras/layers/recurrent_test.py,903,Test stacked RNN serialization.,not
keras/tests/keras/layers/recurrent_test.py,931,will (and should) raise if more than one constant passed,not
keras/tests/keras/layers/recurrent_test.py,961,Test basic case.,not
keras/tests/keras/layers/recurrent_test.py,975,Test basic case serialization.,not
keras/tests/keras/layers/recurrent_test.py,991,verify that state is used,not
keras/tests/keras/layers/recurrent_test.py,996,test flat list inputs,not
keras/tests/keras/layers/recurrent_test.py,1048,theano does not support static shape inference.,not
keras/tests/keras/layers/embeddings_test.py,37,len(input_length) should be equal to len(input_shape) - 1,not
keras/tests/keras/layers/pooling_test.py,114,Test GlobalAveragePooling1D supports masking,not
keras/tests/keras/layers/core_test.py,53,Test invalid use cases,not
keras/tests/keras/layers/core_test.py,62,with string argument,not
keras/tests/keras/layers/core_test.py,67,with function argument,not
keras/tests/keras/layers/core_test.py,175,only valid for 2D tensors,not
keras/tests/keras/layers/core_test.py,184,test layer with multiple outputs,not
keras/tests/keras/layers/core_test.py,215,test layer with multiple outputs and no,not
keras/tests/keras/layers/core_test.py,216,explicit mask,not
keras/tests/keras/layers/core_test.py,257,test serialization with function,not
keras/tests/keras/layers/core_test.py,265,test with lambda,not
keras/tests/keras/layers/core_test.py,272,test serialization with output_shape function,not
keras/tests/keras/layers/core_test.py,329,test in functional API,not
keras/tests/keras/layers/core_test.py,338,test serialization,not
keras/tests/keras/callbacks/tensorboard_test.py,44,Changing the default arguments of get_test_data.,not
keras/tests/keras/callbacks/tensorboard_test.py,89,"we must generate new callbacks for each test, as they aren't stateless",not
keras/tests/keras/callbacks/tensorboard_test.py,109,fit without validation data,not
keras/tests/keras/callbacks/tensorboard_test.py,114,fit with validation data and accuracy,not
keras/tests/keras/callbacks/tensorboard_test.py,120,fit generator without validation data,not
keras/tests/keras/callbacks/tensorboard_test.py,125,fit generator with validation data and accuracy,not
keras/tests/keras/callbacks/tensorboard_test.py,150,test a layer with a list of output tensors,not
keras/tests/keras/callbacks/tensorboard_test.py,162,"we must generate new callbacks for each test, as they aren't stateless",not
keras/tests/keras/callbacks/tensorboard_test.py,181,fit without validation data,not
keras/tests/keras/callbacks/tensorboard_test.py,186,fit with validation data and accuracy,not
keras/tests/keras/callbacks/tensorboard_test.py,194,fit generator without validation data,not
keras/tests/keras/callbacks/tensorboard_test.py,198,fit generator with validation data and accuracy,not
keras/tests/keras/callbacks/callbacks_test.py,57,Changing the default arguments of get_test_data.,not
keras/tests/keras/callbacks/callbacks_test.py,365,case 1 fit,not
keras/tests/keras/callbacks/callbacks_test.py,439,case 1,not
keras/tests/keras/callbacks/callbacks_test.py,458,case 2,not
keras/tests/keras/callbacks/callbacks_test.py,467,case 3,not
keras/tests/keras/callbacks/callbacks_test.py,479,case 4,not
keras/tests/keras/callbacks/callbacks_test.py,490,case 5,not
keras/tests/keras/callbacks/callbacks_test.py,564,This should allow training to go for at least `patience` epochs,not
keras/tests/keras/callbacks/callbacks_test.py,586,"Should stop after epoch 3,",not
keras/tests/keras/callbacks/callbacks_test.py,587,as the loss has not improved after patience=2 epochs.,not
keras/tests/keras/callbacks/callbacks_test.py,630,All epochs should run because baseline was met in second epoch,not
keras/tests/keras/callbacks/callbacks_test.py,632,Baseline was not met by second epoch and should stop,not
keras/tests/keras/callbacks/callbacks_test.py,667,"The best configuration is in the epoch 2 (loss = 0.1000),",not
keras/tests/keras/callbacks/callbacks_test.py,668,so with patience=2 we need to end up at epoch 4,not
keras/tests/keras/callbacks/callbacks_test.py,693,The best configuration is in the epoch 2 (loss = 0.1000).,not
keras/tests/keras/callbacks/callbacks_test.py,706,"The best configuration is in epoch 2 (loss = 0.1000),",not
keras/tests/keras/callbacks/callbacks_test.py,707,"and while patience = 2, we're restoring the best weights,",not
keras/tests/keras/callbacks/callbacks_test.py,708,"so we end up at the epoch with the best weights, i.e. epoch 2",SATD
keras/tests/keras/callbacks/callbacks_test.py,749,This should reduce the LR after the first epoch (due to high epsilon).,not
keras/tests/keras/callbacks/callbacks_test.py,797,The learning rates should be 1.0 except the last one,not
keras/tests/keras/callbacks/callbacks_test.py,805,Check if warnings are disabled,not
keras/tests/keras/callbacks/callbacks_test.py,832,"case 1, create new file with defined separator",not
keras/tests/keras/callbacks/callbacks_test.py,845,"case 2, append data to existing file, skip header",not
keras/tests/keras/callbacks/callbacks_test.py,851,"case 3, reuse of CSVLogger object",not
keras/tests/keras/callbacks/callbacks_test.py,890,"callback validation data should always have x, y, and sample weights",not
keras/tests/keras/callbacks/callbacks_test.py,909,Start an arbitrary process that should run during model training and,not
keras/tests/keras/callbacks/callbacks_test.py,910,be terminated after training has completed.,not
keras/tests/keras/wrappers/scikit_learn_test.py,191,Usage of sklearn's grid_search,not
keras/tests/keras/wrappers/scikit_learn_test.py,192,from sklearn import grid_search,not
keras/tests/keras/wrappers/scikit_learn_test.py,193,"parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],",not
keras/tests/keras/wrappers/scikit_learn_test.py,194,"epochs=[2], verbose=[0])",not
keras/tests/keras/wrappers/scikit_learn_test.py,195,classifier = Inherit_class_build_fn_clf(),not
keras/tests/keras/wrappers/scikit_learn_test.py,196,"clf = grid_search.GridSearchCV(classifier, parameters)",not
keras/tests/keras/wrappers/scikit_learn_test.py,197,"clf.fit(X_train, y_train)",not
keras/tests/keras/wrappers/scikit_learn_test.py,198,"parameters = dict(hidden_dims = [20, 30], batch_size=[64, 128],",not
keras/tests/keras/wrappers/scikit_learn_test.py,199,"epochs=[2], verbose=[0])",not
keras/tests/keras/wrappers/scikit_learn_test.py,200,regressor = Inherit_class_build_fn_reg(),not
keras/tests/keras/wrappers/scikit_learn_test.py,201,"reg = grid_search.GridSearchCV(regressor, parameters,",not
keras/tests/keras/wrappers/scikit_learn_test.py,202,"scoring='mean_squared_error',",not
keras/tests/keras/wrappers/scikit_learn_test.py,203,"n_jobs=1, cv=2, verbose=2)",not
keras/tests/keras/wrappers/scikit_learn_test.py,204,"reg.fit(X_train_reg, y_train_reg)",not
keras/tests/integration_tests/test_temporal_data_tasks.py,124,generate alphabet:,not
keras/tests/integration_tests/test_temporal_data_tasks.py,125,http://stackoverflow.com/questions/16060899/alphabet-range-python,not
keras/tests/integration_tests/test_temporal_data_tasks.py,129,generate char sequences of length 'sequence_length' out of alphabet and,not
keras/tests/integration_tests/test_temporal_data_tasks.py,130,store the next char as label (e.g. 'ab'->'c'),not
keras/tests/integration_tests/test_temporal_data_tasks.py,137,Transform sequences and labels into 'one-hot' encoding,not
keras/tests/integration_tests/test_temporal_data_tasks.py,145,learn the alphabet with stacked LSTM,not
keras/tests/integration_tests/test_temporal_data_tasks.py,155,prime the model with 'ab' sequence and let it generate the learned alphabet,not
keras/tests/integration_tests/test_temporal_data_tasks.py,167,check that it did generate the alphabet correctly,not
keras/tests/integration_tests/test_vector_data_tasks.py,26,Test with Sequential API,not
keras/tests/integration_tests/test_vector_data_tasks.py,51,Test with functional API,not
keras/tests/integration_tests/test_tensorflow_integration.py,46,Test saving.,not
keras/tests/integration_tests/test_image_data_tasks.py,47,Dummy ImageDataGenerator,not
keras/tests/integration_tests/imagenet_utils_test.py,11,Test image batch with float and int image input,not
keras/tests/integration_tests/imagenet_utils_test.py,26,Test single image,not
keras/tests/integration_tests/imagenet_utils_test.py,41,Test that writing over the input data works predictably,not
keras/tests/integration_tests/imagenet_utils_test.py,49,Caffe mode works differently from the others,not
keras/tests/integration_tests/imagenet_utils_test.py,59,Test image batch,not
keras/tests/integration_tests/imagenet_utils_test.py,78,Test single image,not
keras/tests/integration_tests/imagenet_utils_test.py,99,Disabled due to SSL issues on Travis.,not
keras/tests/integration_tests/imagenet_utils_test.py,107,the numbers of columns and ImageNet classes are not identical.,not
keras/tests/integration_tests/applications_test.py,26,Note that NASNetLarge is too heavy to test on Travis.,not
keras/tests/integration_tests/applications_test.py,33,Create model in a subprocess so that,not
keras/tests/integration_tests/applications_test.py,34,the memory consumed by InceptionResNetV2 will be,not
keras/tests/integration_tests/applications_test.py,35,released back to the system after this test,not
keras/tests/integration_tests/applications_test.py,36,(to deal with OOM error on CNTK backend).,not
keras/tests/integration_tests/applications_test.py,37,TODO: remove the use of multiprocessing from these tests,SATD
keras/tests/integration_tests/applications_test.py,38,once a memory clearing mechanism,not
keras/tests/integration_tests/applications_test.py,39,is implemented in the CNTK backend.,not
keras/tests/integration_tests/applications_test.py,47,The error in a subprocess won't propagate,not
keras/tests/integration_tests/applications_test.py,48,"to the main process, so we check if the model",not
keras/tests/integration_tests/applications_test.py,49,is successfully created by checking if the output shape,not
keras/tests/integration_tests/applications_test.py,50,has been put into the queue,not
keras/tests/integration_tests/test_datasets.py,15,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,16,to speed up frequent testing,not
keras/tests/integration_tests/test_datasets.py,31,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,32,to speed up frequent testing,not
keras/tests/integration_tests/test_datasets.py,47,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,48,to speed up frequent testing,not
keras/tests/integration_tests/test_datasets.py,57,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,58,to speed up frequent testing,not
keras/tests/integration_tests/test_datasets.py,70,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,71,to speed up frequent testing,not
keras/tests/integration_tests/test_datasets.py,80,only run data download tests 20% of the time,not
keras/tests/integration_tests/test_datasets.py,81,to speed up frequent testing,not
keras/tests/integration_tests/preprocessing/sequence_test.py,18,test padding,not
keras/tests/integration_tests/preprocessing/sequence_test.py,24,test truncating,not
keras/tests/integration_tests/preprocessing/sequence_test.py,30,test value,not
keras/tests/integration_tests/preprocessing/sequence_test.py,40,test padding,not
keras/tests/integration_tests/preprocessing/sequence_test.py,50,test truncating,not
keras/tests/integration_tests/preprocessing/sequence_test.py,61,test value,not
keras/tests/integration_tests/preprocessing/sequence_test.py,75,test with no window size and binary labels,not
keras/tests/integration_tests/preprocessing/sequence_test.py,80,test window size and categorical labels,not
keras/tests/integration_tests/preprocessing/sequence_test.py,195,"All elements in range(length, 10) should be used as current step",not
keras/tests/integration_tests/preprocessing/sequence_test.py,222,all batches have the same size when shuffle is True.,not
keras/tests/integration_tests/preprocessing/sequence_test.py,226,last batch will be different if `(samples - length) / stride`,not
keras/tests/integration_tests/preprocessing/sequence_test.py,227,is not a multiple of `batch_size`.,not
keras/tests/integration_tests/preprocessing/text_test.py,1,-*- coding: utf-8 -*-,not
keras/tests/integration_tests/preprocessing/text_test.py,110,"2 OOVs: some, unknown",not
keras/tests/integration_tests/preprocessing/text_test.py,112,"Default, without OOV flag",not
keras/tests/integration_tests/preprocessing/text_test.py,116,discards 2 OOVs,not
keras/tests/integration_tests/preprocessing/text_test.py,118,With OOV feature,not
keras/tests/integration_tests/preprocessing/text_test.py,122,OOVs marked in place,not
keras/tests/integration_tests/preprocessing/image_test.py,66,Test with sample weights,not
keras/tests/integration_tests/preprocessing/image_test.py,77,Test with `shuffle=True`,not
keras/tests/integration_tests/preprocessing/image_test.py,82,Check that the sequence is shuffled.,not
keras/tests/integration_tests/preprocessing/image_test.py,86,Test without y,not
keras/tests/integration_tests/preprocessing/image_test.py,92,Check that the sequence is shuffled.,not
keras/tests/integration_tests/preprocessing/image_test.py,95,Test with a single miscellaneous input data array,not
keras/tests/integration_tests/preprocessing/image_test.py,107,Test with two miscellaneous inputs,not
keras/tests/integration_tests/preprocessing/image_test.py,119,Test cases with `y = None`,not
keras/tests/integration_tests/preprocessing/image_test.py,135,Test some failure cases:,not
keras/tests/integration_tests/preprocessing/image_test.py,148,Test `flow` behavior as Sequence,not
keras/tests/integration_tests/preprocessing/image_test.py,157,Test with `shuffle=True`,not
keras/tests/integration_tests/preprocessing/image_test.py,162,Check that the sequence is shuffled.,not
keras/tests/integration_tests/preprocessing/image_test.py,165,`on_epoch_end` should reshuffle the sequence.,not
keras/tests/integration_tests/preprocessing/image_test.py,182,Test fit with invalid data,not
keras/tests/integration_tests/preprocessing/image_test.py,187,Test flow with invalid data,not
keras/tests/integration_tests/preprocessing/image_test.py,201,Test grayscale,not
keras/tests/integration_tests/preprocessing/image_test.py,204,Test RBG,not
keras/tests/integration_tests/preprocessing/image_test.py,207,Test more samples than dims,not
keras/tests/integration_tests/preprocessing/image_test.py,217,Test grayscale,not
keras/tests/integration_tests/preprocessing/image_test.py,220,Test RBG,not
keras/tests/integration_tests/preprocessing/image_test.py,223,Test more samples than dims,not
keras/tests/integration_tests/preprocessing/image_test.py,230,create folders and subfolders,not
keras/tests/integration_tests/preprocessing/image_test.py,244,save the images in the paths,not
keras/tests/integration_tests/preprocessing/image_test.py,249,rotate image class,not
keras/tests/integration_tests/preprocessing/image_test.py,251,rotate subfolders,not
keras/tests/integration_tests/preprocessing/image_test.py,259,create iterator,not
keras/tests/integration_tests/preprocessing/image_test.py,263,check number of classes and images,not
keras/tests/integration_tests/preprocessing/image_test.py,268,Test invalid use cases,not
keras/tests/integration_tests/preprocessing/image_test.py,284,Test usage as Sequence,not
keras/tests/integration_tests/preprocessing/image_test.py,305,save the images in the paths,not
keras/tests/integration_tests/preprocessing/image_test.py,313,create iterator,not
keras/tests/integration_tests/preprocessing/image_test.py,319,check if input and output have the same shape,not
keras/tests/integration_tests/preprocessing/image_test.py,321,check if the input and output images are not the same numpy array,not
keras/tests/integration_tests/preprocessing/image_test.py,337,create folders and subfolders,not
keras/tests/integration_tests/preprocessing/image_test.py,351,save the images in the paths,not
keras/tests/integration_tests/preprocessing/image_test.py,356,rotate image class,not
keras/tests/integration_tests/preprocessing/image_test.py,358,rotate subfolders,not
keras/tests/integration_tests/preprocessing/image_test.py,366,create iterator,not
keras/tests/integration_tests/preprocessing/image_test.py,380,check number of classes and images,not
keras/tests/integration_tests/preprocessing/image_test.py,390,Test th data format,not
keras/tests/integration_tests/preprocessing/image_test.py,396,Test 2D,not
keras/tests/integration_tests/preprocessing/image_test.py,403,Test tf data format,not
keras/tests/integration_tests/preprocessing/image_test.py,409,Test 2D,not
keras/tests/integration_tests/preprocessing/image_test.py,416,Test invalid use case,not
keras/tests/integration_tests/preprocessing/image_test.py,418,not 3D,not
keras/tests/integration_tests/preprocessing/image_test.py,420,unknown data_format,not
keras/tests/integration_tests/preprocessing/image_test.py,423,neither RGB nor gray-scale,not
keras/tests/integration_tests/preprocessing/image_test.py,426,unknown data_format,not
keras/tests/integration_tests/preprocessing/image_test.py,429,neither RGB nor gray-scale,not
keras/tests/integration_tests/preprocessing/image_test.py,441,Test get_random_transform with predefined seed,not
keras/tests/integration_tests/preprocessing/image_test.py,473,Test get_random_transform without any randomness,not
keras/tests/integration_tests/preprocessing/image_test.py,511,ImageDataGenerator.standardize should work on batches,not
keras/tests/integration_tests/preprocessing/image_test.py,550,Test that loaded image is exactly equal to original.,not
keras/tests/integration_tests/preprocessing/image_test.py,562,Test that nothing is changed when target size is equal to original.,not
keras/tests/integration_tests/preprocessing/image_test.py,575,Test down-sampling with bilinear interpolation.,not
keras/tests/integration_tests/preprocessing/image_test.py,586,Test down-sampling with nearest neighbor interpolation.,not
keras/tests/integration_tests/preprocessing/image_test.py,594,Check that exception is raised if interpolation not supported.,not
keras/tests/docs/test_documentation.py,21,Functions or classes with less than 'MIN_CODE_SIZE' lines can be ignored,not
keras/tests/docs/test_documentation.py,52,We don't need to check this one.,not
keras/tests/docs/test_documentation.py,138,Check arguments styling,not
keras/tests/docs/test_documentation.py,147,Check arguments order,not
keras/tests/docs/test_documentation.py,168,Only test keras' modules,not
keras/examples/babi_memnn.py,58,Only select the related substory,not
keras/examples/babi_memnn.py,62,Provide all the substories,not
keras/examples/babi_memnn.py,110,"QA1 with 10,000 samples",not
keras/examples/babi_memnn.py,113,"QA2 with 10,000 samples",not
keras/examples/babi_memnn.py,130,Reserve 0 for masking via pad_sequences,not
keras/examples/babi_memnn.py,166,placeholders,not
keras/examples/babi_memnn.py,170,encoders,not
keras/examples/babi_memnn.py,171,embed the input sequence into a sequence of vectors,not
keras/examples/babi_memnn.py,176,"output: (samples, story_maxlen, embedding_dim)",not
keras/examples/babi_memnn.py,178,embed the input into a sequence of vectors of size query_maxlen,not
keras/examples/babi_memnn.py,183,"output: (samples, story_maxlen, query_maxlen)",not
keras/examples/babi_memnn.py,185,embed the question into a sequence of vectors,not
keras/examples/babi_memnn.py,191,"output: (samples, query_maxlen, embedding_dim)",not
keras/examples/babi_memnn.py,193,encode input sequence and questions (which are indices),not
keras/examples/babi_memnn.py,194,to sequences of dense vectors,not
keras/examples/babi_memnn.py,199,compute a 'match' between the first input vector sequence,not
keras/examples/babi_memnn.py,200,and the question vector sequence,not
keras/examples/babi_memnn.py,201,"shape: `(samples, story_maxlen, query_maxlen)`",not
keras/examples/babi_memnn.py,205,add the match matrix with the second input vector sequence,not
keras/examples/babi_memnn.py,206,"(samples, story_maxlen, query_maxlen)",not
keras/examples/babi_memnn.py,207,"(samples, query_maxlen, story_maxlen)",not
keras/examples/babi_memnn.py,209,concatenate the match matrix with the question vector sequence,not
keras/examples/babi_memnn.py,212,the original paper uses a matrix multiplication for this reduction step.,not
keras/examples/babi_memnn.py,213,we choose to use a RNN instead.,not
keras/examples/babi_memnn.py,214,"(samples, 32)",not
keras/examples/babi_memnn.py,216,one regularization layer -- more would probably be needed.,SATD
keras/examples/babi_memnn.py,218,"(samples, vocab_size)",not
keras/examples/babi_memnn.py,219,we output a probability distribution over the vocabulary,not
keras/examples/babi_memnn.py,222,build the final model,not
keras/examples/babi_memnn.py,227,train,not
keras/examples/mnist_hierarchical_rnn.py,43,Training parameters.,not
keras/examples/mnist_hierarchical_rnn.py,48,Embedding dimensions.,not
keras/examples/mnist_hierarchical_rnn.py,52,"The data, split between train and test sets.",not
keras/examples/mnist_hierarchical_rnn.py,55,Reshapes data to 4D for Hierarchical RNN.,not
keras/examples/mnist_hierarchical_rnn.py,66,Converts class vectors to binary class matrices.,not
keras/examples/mnist_hierarchical_rnn.py,72,4D input.,not
keras/examples/mnist_hierarchical_rnn.py,75,Encodes a row of pixels using TimeDistributed Wrapper.,not
keras/examples/mnist_hierarchical_rnn.py,78,Encodes columns of encoded rows.,not
keras/examples/mnist_hierarchical_rnn.py,81,Final predictions and model.,not
keras/examples/mnist_hierarchical_rnn.py,88,Training.,not
keras/examples/mnist_hierarchical_rnn.py,95,Evaluation.,not
keras/examples/variational_autoencoder.py,33,reparameterization trick,not
keras/examples/variational_autoencoder.py,34,"instead of sampling from Q(z|X), sample epsilon = N(0,I)",not
keras/examples/variational_autoencoder.py,35,z = z_mean + sqrt(var) * epsilon,not
keras/examples/variational_autoencoder.py,49,"by default, random_normal has mean = 0 and std = 1.0",not
keras/examples/variational_autoencoder.py,72,display a 2D plot of the digit classes in the latent space,not
keras/examples/variational_autoencoder.py,84,display a 30x30 2D manifold of digits,not
keras/examples/variational_autoencoder.py,88,linearly spaced coordinates corresponding to the 2D plot,not
keras/examples/variational_autoencoder.py,89,of digit classes in the latent space,not
keras/examples/variational_autoencoder.py,116,MNIST dataset,not
keras/examples/variational_autoencoder.py,126,network parameters,not
keras/examples/variational_autoencoder.py,133,VAE model = encoder + decoder,not
keras/examples/variational_autoencoder.py,134,build encoder model,not
keras/examples/variational_autoencoder.py,140,use reparameterization trick to push the sampling out as input,not
keras/examples/variational_autoencoder.py,141,"note that ""output_shape"" isn't necessary with the TensorFlow backend",not
keras/examples/variational_autoencoder.py,144,instantiate encoder model,not
keras/examples/variational_autoencoder.py,149,build decoder model,not
keras/examples/variational_autoencoder.py,154,instantiate decoder model,not
keras/examples/variational_autoencoder.py,159,instantiate VAE model,not
keras/examples/variational_autoencoder.py,175,VAE loss = mse_loss or xent_loss + kl_loss,not
keras/examples/variational_autoencoder.py,197,train the autoencoder,not
keras/examples/antirectifier.py,52,only valid for 2D tensors,not
keras/examples/antirectifier.py,63,global parameters,not
keras/examples/antirectifier.py,68,"the data, split between train and test sets",not
keras/examples/antirectifier.py,80,convert class vectors to binary class matrices,not
keras/examples/antirectifier.py,84,build the model,not
keras/examples/antirectifier.py,95,compile the model,not
keras/examples/antirectifier.py,100,train the model,not
keras/examples/antirectifier.py,107,"next, compare with an equivalent network",not
keras/examples/antirectifier.py,108,with2x bigger Dense layers and ReLU,not
keras/examples/imdb_cnn_lstm.py,16,Embedding,not
keras/examples/imdb_cnn_lstm.py,21,Convolution,not
keras/examples/imdb_cnn_lstm.py,26,LSTM,not
keras/examples/imdb_cnn_lstm.py,29,Training,not
keras/examples/lstm_seq2seq.py,58,Batch size for training.,not
keras/examples/lstm_seq2seq.py,59,Number of epochs to train for.,not
keras/examples/lstm_seq2seq.py,60,Latent dimensionality of the encoding space.,not
keras/examples/lstm_seq2seq.py,61,Number of samples to train on.,not
keras/examples/lstm_seq2seq.py,62,Path to the data txt file on disk.,not
keras/examples/lstm_seq2seq.py,65,Vectorize the data.,not
keras/examples/lstm_seq2seq.py,74,"We use ""tab"" as the ""start sequence"" character",not
keras/examples/lstm_seq2seq.py,75,"for the targets, and ""\n"" as ""end sequence"" character.",not
keras/examples/lstm_seq2seq.py,119,decoder_target_data is ahead of decoder_input_data by one timestep,not
keras/examples/lstm_seq2seq.py,122,decoder_target_data will be ahead by one timestep,not
keras/examples/lstm_seq2seq.py,123,and will not include the start character.,not
keras/examples/lstm_seq2seq.py,127,Define an input sequence and process it.,not
keras/examples/lstm_seq2seq.py,131,We discard `encoder_outputs` and only keep the states.,not
keras/examples/lstm_seq2seq.py,134,"Set up the decoder, using `encoder_states` as initial state.",not
keras/examples/lstm_seq2seq.py,136,"We set up our decoder to return full output sequences,",not
keras/examples/lstm_seq2seq.py,137,and to return internal states as well. We don't use the,not
keras/examples/lstm_seq2seq.py,138,"return states in the training model, but we will use them in inference.",not
keras/examples/lstm_seq2seq.py,145,Define the model that will turn,not
keras/examples/lstm_seq2seq.py,146,`encoder_input_data` & `decoder_input_data` into `decoder_target_data`,not
keras/examples/lstm_seq2seq.py,149,Run training,not
keras/examples/lstm_seq2seq.py,156,Save model,not
keras/examples/lstm_seq2seq.py,159,Next: inference mode (sampling).,not
keras/examples/lstm_seq2seq.py,160,Here's the drill:,not
keras/examples/lstm_seq2seq.py,161,1) encode input and retrieve initial decoder state,not
keras/examples/lstm_seq2seq.py,162,2) run one step of decoder with this initial state,not
keras/examples/lstm_seq2seq.py,163,"and a ""start of sequence"" token as target.",not
keras/examples/lstm_seq2seq.py,164,Output will be the next target token,not
keras/examples/lstm_seq2seq.py,165,3) Repeat with the current target token and current states,not
keras/examples/lstm_seq2seq.py,167,Define sampling models,not
keras/examples/lstm_seq2seq.py,181,Reverse-lookup token index to decode sequences back to,not
keras/examples/lstm_seq2seq.py,182,something readable.,not
keras/examples/lstm_seq2seq.py,190,Encode the input as state vectors.,not
keras/examples/lstm_seq2seq.py,193,Generate empty target sequence of length 1.,not
keras/examples/lstm_seq2seq.py,195,Populate the first character of target sequence with the start character.,not
keras/examples/lstm_seq2seq.py,198,Sampling loop for a batch of sequences,not
keras/examples/lstm_seq2seq.py,199,"(to simplify, here we assume a batch of size 1).",not
keras/examples/lstm_seq2seq.py,206,Sample a token,not
keras/examples/lstm_seq2seq.py,211,Exit condition: either hit max length,not
keras/examples/lstm_seq2seq.py,212,or find stop character.,not
keras/examples/lstm_seq2seq.py,217,Update the target sequence (of length 1).,not
keras/examples/lstm_seq2seq.py,221,Update states,not
keras/examples/lstm_seq2seq.py,228,Take one sequence (part of the training set),not
keras/examples/lstm_seq2seq.py,229,for trying out decoding.,not
keras/examples/mnist_siamese.py,96,"the data, split between train and test sets",not
keras/examples/mnist_siamese.py,104,create training+test positive and negative pairs,not
keras/examples/mnist_siamese.py,111,network definition,not
keras/examples/mnist_siamese.py,117,"because we re-use the same instance `base_network`,",not
keras/examples/mnist_siamese.py,118,the weights of the network,not
keras/examples/mnist_siamese.py,119,will be shared across the two branches,not
keras/examples/mnist_siamese.py,128,train,not
keras/examples/mnist_siamese.py,136,compute final accuracy on training and test sets,not
keras/examples/imdb_cnn.py,17,set parameters:,not
keras/examples/imdb_cnn.py,41,we start off with an efficient embedding layer which maps,not
keras/examples/imdb_cnn.py,42,our vocab indices into embedding_dims dimensions,not
keras/examples/imdb_cnn.py,48,"we add a Convolution1D, which will learn filters",not
keras/examples/imdb_cnn.py,49,word group filters of size filter_length:,not
keras/examples/imdb_cnn.py,55,we use max pooling:,not
keras/examples/imdb_cnn.py,58,We add a vanilla hidden layer:,not
keras/examples/imdb_cnn.py,63,"We project onto a single unit output layer, and squash it with a sigmoid:",not
keras/examples/mnist_sklearn_wrapper.py,20,input image dimensions,not
keras/examples/mnist_sklearn_wrapper.py,23,load training data and do basic data normalization,not
keras/examples/mnist_sklearn_wrapper.py,40,convert class vectors to binary class matrices,not
keras/examples/mnist_sklearn_wrapper.py,83,epochs is avail for tuning even when not,not
keras/examples/mnist_sklearn_wrapper.py,84,an argument to model building function,not
keras/examples/mnist_sklearn_wrapper.py,96,validator.best_estimator_ returns sklearn-wrapped version of best model.,not
keras/examples/mnist_sklearn_wrapper.py,97,validator.best_estimator_.model returns the (unwrapped) keras model,not
keras/examples/mnist_mlp.py,20,"the data, split between train and test sets",not
keras/examples/mnist_mlp.py,32,convert class vectors to binary class matrices,not
keras/examples/mnist_cnn.py,20,input image dimensions,not
keras/examples/mnist_cnn.py,23,"the data, split between train and test sets",not
keras/examples/mnist_cnn.py,43,convert class vectors to binary class matrices,not
keras/examples/mnist_acgan.py,1,-*- coding: utf-8 -*-,not
keras/examples/mnist_acgan.py,50,"we will map a pair of (z, L), where z is a latent vector and L is a",not
keras/examples/mnist_acgan.py,51,"label drawn from P_c, to image space (..., 28, 28, 1)",not
keras/examples/mnist_acgan.py,57,"upsample to (7, 7, ...)",not
keras/examples/mnist_acgan.py,63,"upsample to (14, 14, ...)",not
keras/examples/mnist_acgan.py,69,"upsample to (28, 28, ...)",not
keras/examples/mnist_acgan.py,74,this is the z space commonly referred to in GAN papers,not
keras/examples/mnist_acgan.py,77,this will be our label,not
keras/examples/mnist_acgan.py,83,hadamard product between z-space and a class conditional embedding,not
keras/examples/mnist_acgan.py,92,"build a relatively standard conv net, with LeakyReLUs as suggested in",not
keras/examples/mnist_acgan.py,93,the reference paper,not
keras/examples/mnist_acgan.py,119,first output (name=generation) is whether or not the discriminator,not
keras/examples/mnist_acgan.py,120,"thinks the image that is being shown is fake, and the second output",not
keras/examples/mnist_acgan.py,121,(name=auxiliary) is the class that the discriminator thinks the image,not
keras/examples/mnist_acgan.py,122,belongs to.,not
keras/examples/mnist_acgan.py,130,batch and latent size taken from the paper,not
keras/examples/mnist_acgan.py,135,Adam parameters suggested in https://arxiv.org/abs/1511.06434,not
keras/examples/mnist_acgan.py,139,build the discriminator,not
keras/examples/mnist_acgan.py,148,build the generator,not
keras/examples/mnist_acgan.py,154,get a fake image,not
keras/examples/mnist_acgan.py,157,we only want to be able to train generation for the combined model,not
keras/examples/mnist_acgan.py,169,"get our mnist data, and force it to be of shape (..., 28, 28, 1) with",not
keras/examples/mnist_acgan.py,170,"range [-1, 1]",not
keras/examples/mnist_acgan.py,193,get a batch of real images,not
keras/examples/mnist_acgan.py,197,generate a new batch of noise,not
keras/examples/mnist_acgan.py,200,sample some labels from p_c,not
keras/examples/mnist_acgan.py,203,"generate a batch of fake images, using the generated labels as a",not
keras/examples/mnist_acgan.py,204,conditioner. We reshape the sampled labels to be,not
keras/examples/mnist_acgan.py,205,"(len(image_batch), 1) so that we can feed them into the embedding",not
keras/examples/mnist_acgan.py,206,layer as a length one sequence,not
keras/examples/mnist_acgan.py,212,use one-sided soft real/fake labels,not
keras/examples/mnist_acgan.py,213,"Salimans et al., 2016",not
keras/examples/mnist_acgan.py,214,https://arxiv.org/pdf/1606.03498.pdf (Section 3.4),not
keras/examples/mnist_acgan.py,220,we don't want the discriminator to also maximize the classification,not
keras/examples/mnist_acgan.py,221,"accuracy of the auxiliary classifier on generated images, so we",not
keras/examples/mnist_acgan.py,222,don't train discriminator to produce class labels for generated,not
keras/examples/mnist_acgan.py,223,images (see https://openreview.net/forum?id=rJXTf9Bxg).,not
keras/examples/mnist_acgan.py,224,"To preserve sum of sample weights for the auxiliary classifier,",not
keras/examples/mnist_acgan.py,225,we assign sample weight of 2 to the real images.,not
keras/examples/mnist_acgan.py,230,see if the discriminator can figure itself out...,not
keras/examples/mnist_acgan.py,234,make new noise. we generate 2 * batch size here such that we have,not
keras/examples/mnist_acgan.py,235,the generator optimize over an identical number of images as the,not
keras/examples/mnist_acgan.py,236,discriminator,not
keras/examples/mnist_acgan.py,240,we want to train the generator to trick the discriminator,not
keras/examples/mnist_acgan.py,241,"For the generator, we want all the {fake, not-fake} labels to say",not
keras/examples/mnist_acgan.py,242,not-fake,not
keras/examples/mnist_acgan.py,253,evaluate the testing loss here,not
keras/examples/mnist_acgan.py,255,generate a new batch of noise,not
keras/examples/mnist_acgan.py,258,sample some labels from p_c and generate images from them,not
keras/examples/mnist_acgan.py,267,see if the discriminator can figure itself out...,not
keras/examples/mnist_acgan.py,273,make new noise,not
keras/examples/mnist_acgan.py,285,generate an epoch report on performance,not
keras/examples/mnist_acgan.py,306,save weights every epoch,not
keras/examples/mnist_acgan.py,312,generate some digits to display,not
keras/examples/mnist_acgan.py,321,get a batch to display,not
keras/examples/mnist_acgan.py,325,prepare real images sorted by class label,not
keras/examples/mnist_acgan.py,332,"display generated images, white separator, real images",not
keras/examples/mnist_acgan.py,338,arrange them into a grid,not
keras/examples/cnn_seq2seq.py,54,Batch size for training.,not
keras/examples/cnn_seq2seq.py,55,Number of epochs to train for.,not
keras/examples/cnn_seq2seq.py,56,Number of samples to train on.,not
keras/examples/cnn_seq2seq.py,57,Path to the data txt file on disk.,not
keras/examples/cnn_seq2seq.py,60,Vectorize the data.,not
keras/examples/cnn_seq2seq.py,69,"We use ""tab"" as the ""start sequence"" character",not
keras/examples/cnn_seq2seq.py,70,"for the targets, and ""\n"" as ""end sequence"" character.",not
keras/examples/cnn_seq2seq.py,113,decoder_target_data is ahead of decoder_input_data by one timestep,not
keras/examples/cnn_seq2seq.py,116,decoder_target_data will be ahead by one timestep,not
keras/examples/cnn_seq2seq.py,117,and will not include the start character.,not
keras/examples/cnn_seq2seq.py,120,Define an input sequence and process it.,not
keras/examples/cnn_seq2seq.py,122,Encoder,not
keras/examples/cnn_seq2seq.py,131,Decoder,not
keras/examples/cnn_seq2seq.py,138,Attention,not
keras/examples/cnn_seq2seq.py,149,Output,not
keras/examples/cnn_seq2seq.py,153,Define the model that will turn,not
keras/examples/cnn_seq2seq.py,154,`encoder_input_data` & `decoder_input_data` into `decoder_target_data`,not
keras/examples/cnn_seq2seq.py,158,Run training,not
keras/examples/cnn_seq2seq.py,164,Save model,not
keras/examples/cnn_seq2seq.py,167,Next: inference mode (sampling).,not
keras/examples/cnn_seq2seq.py,169,Define sampling models,not
keras/examples/cnn_seq2seq.py,195,Take one sequence (part of the training set),not
keras/examples/cnn_seq2seq.py,196,for trying out decoding.,not
keras/examples/cifar10_resnet.py,51,Training parameters,not
keras/examples/cifar10_resnet.py,52,orig paper trained all networks with batch_size=128,not
keras/examples/cifar10_resnet.py,57,Subtracting pixel mean improves accuracy,not
keras/examples/cifar10_resnet.py,60,Model parameter,not
keras/examples/cifar10_resnet.py,61,----------------------------------------------------------------------------,not
keras/examples/cifar10_resnet.py,62,|      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch,not
keras/examples/cifar10_resnet.py,63,Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti,not
keras/examples/cifar10_resnet.py,64,|v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2),not
keras/examples/cifar10_resnet.py,65,----------------------------------------------------------------------------,not
keras/examples/cifar10_resnet.py,66,ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---),not
keras/examples/cifar10_resnet.py,67,ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA),not
keras/examples/cifar10_resnet.py,68,ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA),not
keras/examples/cifar10_resnet.py,69,ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100),not
keras/examples/cifar10_resnet.py,70,ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180),not
keras/examples/cifar10_resnet.py,71,ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---),not
keras/examples/cifar10_resnet.py,72,ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---),not
keras/examples/cifar10_resnet.py,73,---------------------------------------------------------------------------,not
keras/examples/cifar10_resnet.py,76,Model version,not
keras/examples/cifar10_resnet.py,77,"Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)",not
keras/examples/cifar10_resnet.py,80,Computed depth from supplied model parameter n,not
keras/examples/cifar10_resnet.py,86,"Model name, depth and version",not
keras/examples/cifar10_resnet.py,89,Load the CIFAR10 data.,not
keras/examples/cifar10_resnet.py,92,Input image dimensions.,not
keras/examples/cifar10_resnet.py,95,Normalize data.,not
keras/examples/cifar10_resnet.py,99,If subtract pixel mean is enabled,not
keras/examples/cifar10_resnet.py,110,Convert class vectors to binary class matrices.,not
keras/examples/cifar10_resnet.py,215,Start model definition.,not
keras/examples/cifar10_resnet.py,221,Instantiate the stack of residual units,not
keras/examples/cifar10_resnet.py,225,first layer but not first stack,not
keras/examples/cifar10_resnet.py,226,downsample,not
keras/examples/cifar10_resnet.py,233,first layer but not first stack,not
keras/examples/cifar10_resnet.py,234,linear projection residual shortcut connection to match,not
keras/examples/cifar10_resnet.py,235,changed dims,not
keras/examples/cifar10_resnet.py,246,Add classifier on top.,not
keras/examples/cifar10_resnet.py,247,v1 does not use BN after last shortcut connection-ReLU,not
keras/examples/cifar10_resnet.py,254,Instantiate model.,not
keras/examples/cifar10_resnet.py,286,Start model definition.,not
keras/examples/cifar10_resnet.py,291,v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths,not
keras/examples/cifar10_resnet.py,296,Instantiate the stack of residual units,not
keras/examples/cifar10_resnet.py,304,first layer and first stage,not
keras/examples/cifar10_resnet.py,309,first layer but not first stage,not
keras/examples/cifar10_resnet.py,310,downsample,not
keras/examples/cifar10_resnet.py,312,bottleneck residual unit,not
keras/examples/cifar10_resnet.py,328,linear projection residual shortcut connection to match,not
keras/examples/cifar10_resnet.py,329,changed dims,not
keras/examples/cifar10_resnet.py,340,Add classifier on top.,not
keras/examples/cifar10_resnet.py,341,v2 has BN-ReLU before Pooling,not
keras/examples/cifar10_resnet.py,350,Instantiate model.,not
keras/examples/cifar10_resnet.py,366,Prepare model model saving directory.,not
keras/examples/cifar10_resnet.py,373,Prepare callbacks for model saving and for learning rate adjustment.,not
keras/examples/cifar10_resnet.py,388,"Run training, with or without data augmentation.",not
keras/examples/cifar10_resnet.py,399,This will do preprocessing and realtime data augmentation:,not
keras/examples/cifar10_resnet.py,401,set input mean to 0 over the dataset,not
keras/examples/cifar10_resnet.py,403,set each sample mean to 0,not
keras/examples/cifar10_resnet.py,405,divide inputs by std of dataset,not
keras/examples/cifar10_resnet.py,407,divide each input by its std,not
keras/examples/cifar10_resnet.py,409,apply ZCA whitening,not
keras/examples/cifar10_resnet.py,411,epsilon for ZCA whitening,not
keras/examples/cifar10_resnet.py,413,randomly rotate images in the range (deg 0 to 180),not
keras/examples/cifar10_resnet.py,415,randomly shift images horizontally,not
keras/examples/cifar10_resnet.py,417,randomly shift images vertically,not
keras/examples/cifar10_resnet.py,419,set range for random shear,not
keras/examples/cifar10_resnet.py,421,set range for random zoom,not
keras/examples/cifar10_resnet.py,423,set range for random channel shifts,not
keras/examples/cifar10_resnet.py,425,set mode for filling points outside the input boundaries,not
keras/examples/cifar10_resnet.py,427,"value used for fill_mode = ""constant""",not
keras/examples/cifar10_resnet.py,429,randomly flip images,not
keras/examples/cifar10_resnet.py,431,randomly flip images,not
keras/examples/cifar10_resnet.py,433,set rescaling factor (applied before any other transformation),not
keras/examples/cifar10_resnet.py,435,set function that will be applied on each input,not
keras/examples/cifar10_resnet.py,437,"image data format, either ""channels_first"" or ""channels_last""",not
keras/examples/cifar10_resnet.py,439,fraction of images reserved for validation (strictly between 0 and 1),not
keras/examples/cifar10_resnet.py,442,Compute quantities required for featurewise normalization,not
keras/examples/cifar10_resnet.py,443,"(std, mean, and principal components if ZCA whitening is applied).",not
keras/examples/cifar10_resnet.py,446,Fit the model on the batches generated by datagen.flow().,not
keras/examples/cifar10_resnet.py,452,Score trained model.,not
keras/examples/variational_autoencoder_deconv.py,35,reparameterization trick,not
keras/examples/variational_autoencoder_deconv.py,36,"instead of sampling from Q(z|X), sample eps = N(0,I)",not
keras/examples/variational_autoencoder_deconv.py,37,then z = z_mean + sqrt(var)*eps,not
keras/examples/variational_autoencoder_deconv.py,51,"by default, random_normal has mean=0 and std=1.0",not
keras/examples/variational_autoencoder_deconv.py,74,display a 2D plot of the digit classes in the latent space,not
keras/examples/variational_autoencoder_deconv.py,86,display a 30x30 2D manifold of digits,not
keras/examples/variational_autoencoder_deconv.py,90,linearly spaced coordinates corresponding to the 2D plot,not
keras/examples/variational_autoencoder_deconv.py,91,of digit classes in the latent space,not
keras/examples/variational_autoencoder_deconv.py,118,MNIST dataset,not
keras/examples/variational_autoencoder_deconv.py,127,network parameters,not
keras/examples/variational_autoencoder_deconv.py,135,VAE model = encoder + decoder,not
keras/examples/variational_autoencoder_deconv.py,136,build encoder model,not
keras/examples/variational_autoencoder_deconv.py,147,shape info needed to build decoder model,not
keras/examples/variational_autoencoder_deconv.py,150,generate latent vector Q(z|X),not
keras/examples/variational_autoencoder_deconv.py,156,use reparameterization trick to push the sampling out as input,not
keras/examples/variational_autoencoder_deconv.py,157,"note that ""output_shape"" isn't necessary with the TensorFlow backend",not
keras/examples/variational_autoencoder_deconv.py,160,instantiate encoder model,not
keras/examples/variational_autoencoder_deconv.py,165,build decoder model,not
keras/examples/variational_autoencoder_deconv.py,184,instantiate decoder model,not
keras/examples/variational_autoencoder_deconv.py,189,instantiate VAE model,not
keras/examples/variational_autoencoder_deconv.py,203,VAE loss = mse_loss or xent_loss + kl_loss,not
keras/examples/variational_autoencoder_deconv.py,223,train the autoencoder,not
keras/examples/cifar10_cnn.py,25,"The data, split between train and test sets:",not
keras/examples/cifar10_cnn.py,31,Convert class vectors to binary class matrices.,not
keras/examples/cifar10_cnn.py,58,initiate RMSprop optimizer,not
keras/examples/cifar10_cnn.py,61,Let's train the model using RMSprop,not
keras/examples/cifar10_cnn.py,80,This will do preprocessing and realtime data augmentation:,not
keras/examples/cifar10_cnn.py,82,set input mean to 0 over the dataset,not
keras/examples/cifar10_cnn.py,83,set each sample mean to 0,not
keras/examples/cifar10_cnn.py,84,divide inputs by std of the dataset,not
keras/examples/cifar10_cnn.py,85,divide each input by its std,not
keras/examples/cifar10_cnn.py,86,apply ZCA whitening,not
keras/examples/cifar10_cnn.py,87,epsilon for ZCA whitening,not
keras/examples/cifar10_cnn.py,88,"randomly rotate images in the range (degrees, 0 to 180)",not
keras/examples/cifar10_cnn.py,89,randomly shift images horizontally (fraction of total width),not
keras/examples/cifar10_cnn.py,91,randomly shift images vertically (fraction of total height),not
keras/examples/cifar10_cnn.py,93,set range for random shear,not
keras/examples/cifar10_cnn.py,94,set range for random zoom,not
keras/examples/cifar10_cnn.py,95,set range for random channel shifts,not
keras/examples/cifar10_cnn.py,96,set mode for filling points outside the input boundaries,not
keras/examples/cifar10_cnn.py,98,"value used for fill_mode = ""constant""",not
keras/examples/cifar10_cnn.py,99,randomly flip images,not
keras/examples/cifar10_cnn.py,100,randomly flip images,not
keras/examples/cifar10_cnn.py,101,set rescaling factor (applied before any other transformation),not
keras/examples/cifar10_cnn.py,103,set function that will be applied on each input,not
keras/examples/cifar10_cnn.py,105,"image data format, either ""channels_first"" or ""channels_last""",not
keras/examples/cifar10_cnn.py,107,fraction of images reserved for validation (strictly between 0 and 1),not
keras/examples/cifar10_cnn.py,110,Compute quantities required for feature-wise normalization,not
keras/examples/cifar10_cnn.py,111,"(std, mean, and principal components if ZCA whitening is applied).",not
keras/examples/cifar10_cnn.py,114,Fit the model on the batches generated by datagen.flow().,not
keras/examples/cifar10_cnn.py,121,Save model and weights,not
keras/examples/cifar10_cnn.py,128,Score trained model.,not
keras/examples/imdb_fasttext.py,70,Set parameters:,not
keras/examples/imdb_fasttext.py,71,ngram_range = 2 will add bi-grams features,not
keras/examples/imdb_fasttext.py,90,Create set of unique n-gram from the training set.,not
keras/examples/imdb_fasttext.py,97,Dictionary mapping n-gram token to a unique integer.,not
keras/examples/imdb_fasttext.py,98,Integer values are greater than max_features in order,not
keras/examples/imdb_fasttext.py,99,to avoid collision with existing features.,not
keras/examples/imdb_fasttext.py,104,max_features is the highest integer that could be found in the dataset.,not
keras/examples/imdb_fasttext.py,107,Augmenting x_train and x_test with n-grams features,not
keras/examples/imdb_fasttext.py,124,we start off with an efficient embedding layer which maps,not
keras/examples/imdb_fasttext.py,125,our vocab indices into embedding_dims dimensions,not
keras/examples/imdb_fasttext.py,130,"we add a GlobalAveragePooling1D, which will average the embeddings",not
keras/examples/imdb_fasttext.py,131,of all words in the document,not
keras/examples/imdb_fasttext.py,134,"We project onto a single unit output layer, and squash it with a sigmoid:",not
keras/examples/lstm_seq2seq_restore.py,18,Batch size for training.,not
keras/examples/lstm_seq2seq_restore.py,19,Number of epochs to train for.,not
keras/examples/lstm_seq2seq_restore.py,20,Latent dimensionality of the encoding space.,not
keras/examples/lstm_seq2seq_restore.py,21,Number of samples to train on.,not
keras/examples/lstm_seq2seq_restore.py,22,Path to the data txt file on disk.,not
keras/examples/lstm_seq2seq_restore.py,25,Vectorize the data.  We use the same approach as the training script.,not
keras/examples/lstm_seq2seq_restore.py,26,"NOTE: the data must be identical, in order for the character -> integer",not
keras/examples/lstm_seq2seq_restore.py,27,mappings to be consistent.,not
keras/examples/lstm_seq2seq_restore.py,28,We omit encoding target_texts since they are not needed.,not
keras/examples/lstm_seq2seq_restore.py,37,"We use ""tab"" as the ""start sequence"" character",not
keras/examples/lstm_seq2seq_restore.py,38,"for the targets, and ""\n"" as ""end sequence"" character.",not
keras/examples/lstm_seq2seq_restore.py,75,Restore the model and construct the encoder and decoder.,not
keras/examples/lstm_seq2seq_restore.py,78,input_1,not
keras/examples/lstm_seq2seq_restore.py,79,lstm_1,not
keras/examples/lstm_seq2seq_restore.py,83,input_2,not
keras/examples/lstm_seq2seq_restore.py,97,Reverse-lookup token index to decode sequences back to,not
keras/examples/lstm_seq2seq_restore.py,98,something readable.,not
keras/examples/lstm_seq2seq_restore.py,105,Decodes an input sequence.  Future work should support beam search.,not
keras/examples/lstm_seq2seq_restore.py,107,Encode the input as state vectors.,not
keras/examples/lstm_seq2seq_restore.py,110,Generate empty target sequence of length 1.,not
keras/examples/lstm_seq2seq_restore.py,112,Populate the first character of target sequence with the start character.,not
keras/examples/lstm_seq2seq_restore.py,115,Sampling loop for a batch of sequences,not
keras/examples/lstm_seq2seq_restore.py,116,"(to simplify, here we assume a batch of size 1).",not
keras/examples/lstm_seq2seq_restore.py,123,Sample a token,not
keras/examples/lstm_seq2seq_restore.py,128,Exit condition: either hit max length,not
keras/examples/lstm_seq2seq_restore.py,129,or find stop character.,not
keras/examples/lstm_seq2seq_restore.py,134,Update the target sequence (of length 1).,not
keras/examples/lstm_seq2seq_restore.py,138,Update states,not
keras/examples/lstm_seq2seq_restore.py,145,Take one sequence (part of the training set),not
keras/examples/lstm_seq2seq_restore.py,146,for trying out decoding.,not
keras/examples/neural_style_transfer.py,87,these are the weights of the different loss components,not
keras/examples/neural_style_transfer.py,92,dimensions of the generated picture.,not
keras/examples/neural_style_transfer.py,97,"util function to open, resize and format pictures into appropriate tensors",not
keras/examples/neural_style_transfer.py,107,util function to convert a tensor into a valid image,not
keras/examples/neural_style_transfer.py,116,Remove zero-center by mean pixel,not
keras/examples/neural_style_transfer.py,120,'BGR'->'RGB',not
keras/examples/neural_style_transfer.py,125,get tensor representations of our images,not
keras/examples/neural_style_transfer.py,129,this will contain our generated image,not
keras/examples/neural_style_transfer.py,135,combine the 3 images into a single Keras tensor,not
keras/examples/neural_style_transfer.py,140,build the VGG19 network with our 3 images as input,not
keras/examples/neural_style_transfer.py,141,the model will be loaded with pre-trained ImageNet weights,not
keras/examples/neural_style_transfer.py,146,"get the symbolic outputs of each ""key"" layer (we gave them unique names).",not
keras/examples/neural_style_transfer.py,149,compute the neural style loss,not
keras/examples/neural_style_transfer.py,150,first we need to define 4 util functions,not
keras/examples/neural_style_transfer.py,152,the gram matrix of an image tensor (feature-wise outer product),not
keras/examples/neural_style_transfer.py,164,"the ""style loss"" is designed to maintain",not
keras/examples/neural_style_transfer.py,165,the style of the reference image in the generated image.,not
keras/examples/neural_style_transfer.py,166,It is based on the gram matrices (which capture style) of,not
keras/examples/neural_style_transfer.py,167,feature maps from the style reference image,not
keras/examples/neural_style_transfer.py,168,and from the generated image,not
keras/examples/neural_style_transfer.py,180,an auxiliary loss function,not
keras/examples/neural_style_transfer.py,181,"designed to maintain the ""content"" of the",not
keras/examples/neural_style_transfer.py,182,base image in the generated image,not
keras/examples/neural_style_transfer.py,188,"the 3rd loss function, total variation loss,",not
keras/examples/neural_style_transfer.py,189,designed to keep the generated image locally coherent,not
keras/examples/neural_style_transfer.py,207,combine these loss functions into a single scalar,not
keras/examples/neural_style_transfer.py,226,get the gradients of the generated image wrt the loss,not
keras/examples/neural_style_transfer.py,251,this Evaluator class makes it possible,not
keras/examples/neural_style_transfer.py,252,to compute loss and gradients in one pass,not
keras/examples/neural_style_transfer.py,253,"while retrieving them via two separate functions,",not
keras/examples/neural_style_transfer.py,254,"""loss"" and ""grads"". This is done because scipy.optimize",not
keras/examples/neural_style_transfer.py,255,"requires separate functions for loss and gradients,",not
keras/examples/neural_style_transfer.py,256,but computing them separately would be inefficient.,not
keras/examples/neural_style_transfer.py,282,run scipy-based optimization (L-BFGS) over the pixels of the generated image,not
keras/examples/neural_style_transfer.py,283,so as to minimize the neural style loss,not
keras/examples/neural_style_transfer.py,292,save current generated image,not
keras/examples/lstm_stateful.py,46,----------------------------------------------------------,not
keras/examples/lstm_stateful.py,47,EDITABLE PARAMETERS,not
keras/examples/lstm_stateful.py,48,Read the documentation in the script head for more details,not
keras/examples/lstm_stateful.py,49,----------------------------------------------------------,not
keras/examples/lstm_stateful.py,51,length of input,not
keras/examples/lstm_stateful.py,54,The window length of the moving average used to generate,not
keras/examples/lstm_stateful.py,55,the output from the input in the input/output pair used,not
keras/examples/lstm_stateful.py,56,to train the LSTM,not
keras/examples/lstm_stateful.py,57,"e.g. if tsteps=2 and input=[1, 2, 3, 4, 5],",not
keras/examples/lstm_stateful.py,58,"then output=[1.5, 2.5, 3.5, 4.5]",not
keras/examples/lstm_stateful.py,61,The input sequence length that the LSTM is trained on for each output point,not
keras/examples/lstm_stateful.py,64,"training parameters passed to ""model.fit(...)""",not
keras/examples/lstm_stateful.py,68,------------,not
keras/examples/lstm_stateful.py,69,MAIN PROGRAM,not
keras/examples/lstm_stateful.py,70,------------,not
keras/examples/lstm_stateful.py,97,"Since the output is a moving average of the input,",not
keras/examples/lstm_stateful.py,98,the first few points of output will be NaN,not
keras/examples/lstm_stateful.py,99,and will be dropped from the generated data,not
keras/examples/lstm_stateful.py,100,before training the LSTM.,not
keras/examples/lstm_stateful.py,101,"Also, when lahead > 1,",not
keras/examples/lstm_stateful.py,102,"the preprocessing step later of ""rolling window view""",not
keras/examples/lstm_stateful.py,103,will also cause some points to be lost.,not
keras/examples/lstm_stateful.py,104,"For aesthetic reasons,",not
keras/examples/lstm_stateful.py,105,"in order to maintain generated data length = input_len after pre-processing,",not
keras/examples/lstm_stateful.py,106,add a few points to account for the values that will be lost.,not
keras/examples/lstm_stateful.py,110,set the target to be a N-point average of the input,not
keras/examples/lstm_stateful.py,113,"when lahead > 1, need to convert the input to ""rolling window view""",not
keras/examples/lstm_stateful.py,114,https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html,not
keras/examples/lstm_stateful.py,121,drop the nan,not
keras/examples/lstm_stateful.py,158,split train/test data,not
keras/examples/lstm_stateful.py,161,tweak to match with batch_size,not
keras/examples/lstm_stateful.py,169,tweak to match with batch_size,not
keras/examples/lstm_stateful.py,175,some reshaping,not
keras/examples/lstm_stateful.py,196,Note that the last state for sample i in a batch will,not
keras/examples/lstm_stateful.py,197,be used as initial state for sample i in the next batch.,not
keras/examples/lstm_stateful.py,198,Thus we are simultaneously training on batch_size series with,not
keras/examples/lstm_stateful.py,199,lower resolution than the original series contained in data_input.,not
keras/examples/lstm_stateful.py,200,Each of these series are offset by one step and can be,not
keras/examples/lstm_stateful.py,201,extracted with data_input[i::batch_size].,not
keras/examples/lstm_stateful.py,229,----------------------------,not
keras/examples/lstm_stateful.py,236,"drop the first ""tsteps-1"" because it is not possible to predict them",not
keras/examples/lstm_stateful.py,237,"since the ""previous"" timesteps to use do not exist",not
keras/examples/babi_rnn.py,103,Only select the related substory,not
keras/examples/babi_rnn.py,107,Provide all the substories,not
keras/examples/babi_rnn.py,138,let's not forget that index 0 is reserved,not
keras/examples/babi_rnn.py,169,Default QA1 with 1000 samples,not
keras/examples/babi_rnn.py,170,challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt',not
keras/examples/babi_rnn.py,171,"QA1 with 10,000 samples",not
keras/examples/babi_rnn.py,172,challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',not
keras/examples/babi_rnn.py,173,QA2 with 1000 samples,not
keras/examples/babi_rnn.py,175,"QA2 with 10,000 samples",not
keras/examples/babi_rnn.py,176,challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',not
keras/examples/babi_rnn.py,186,Reserve 0 for masking via pad_sequences,not
keras/examples/conv_filter_visualization.py,40,"normalize tensor: center on 0., ensure std is 0.25",not
keras/examples/conv_filter_visualization.py,45,"clip to [0, 1]",not
keras/examples/conv_filter_visualization.py,49,convert to RGB array,not
keras/examples/conv_filter_visualization.py,118,we build a loss function that maximizes the activation,not
keras/examples/conv_filter_visualization.py,119,of the nth filter of the layer considered,not
keras/examples/conv_filter_visualization.py,125,we compute the gradient of the input picture wrt this loss,not
keras/examples/conv_filter_visualization.py,128,normalization trick: we normalize the gradient,not
keras/examples/conv_filter_visualization.py,131,this function returns the loss and grads given the input picture,not
keras/examples/conv_filter_visualization.py,134,we start from a gray image with some random noise,not
keras/examples/conv_filter_visualization.py,145,Slowly upscaling towards the original size prevents,not
keras/examples/conv_filter_visualization.py,146,a dominating high-frequency of the to visualized structure,not
keras/examples/conv_filter_visualization.py,147,as it would occur if we directly compute the 412d-image.,not
keras/examples/conv_filter_visualization.py,148,Behaves as a better starting point for each following dimension,SATD
keras/examples/conv_filter_visualization.py,149,and therefore avoids poor local minima,not
keras/examples/conv_filter_visualization.py,151,we run gradient ascent for e.g. 20 steps,not
keras/examples/conv_filter_visualization.py,156,"some filters get stuck to 0, we can skip them",not
keras/examples/conv_filter_visualization.py,160,Calculate upscaled dimension,not
keras/examples/conv_filter_visualization.py,163,Upscale,not
keras/examples/conv_filter_visualization.py,170,decode the resulting input image,not
keras/examples/conv_filter_visualization.py,190,the filters that have the highest loss are assumed to be better-looking.,not
keras/examples/conv_filter_visualization.py,191,we will only keep the top n*n filters.,not
keras/examples/conv_filter_visualization.py,195,build a black picture with enough space for,not
keras/examples/conv_filter_visualization.py,196,"e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between",not
keras/examples/conv_filter_visualization.py,202,fill the picture with our saved filters,not
keras/examples/conv_filter_visualization.py,212,save the result to disk,not
keras/examples/conv_filter_visualization.py,215,this is the placeholder for the input images,not
keras/examples/conv_filter_visualization.py,219,"get the symbolic outputs of each ""key"" layer (we gave them unique names).",not
keras/examples/conv_filter_visualization.py,225,Compute to be processed filter range,not
keras/examples/conv_filter_visualization.py,235,iterate through each filter and generate its corresponding image,not
keras/examples/conv_filter_visualization.py,244,Finally draw and store the best filters to disk,not
keras/examples/conv_filter_visualization.py,249,the name of the layer we want to visualize,not
keras/examples/conv_filter_visualization.py,250,(see model definition at keras/applications/vgg16.py),not
keras/examples/conv_filter_visualization.py,253,build the VGG16 network with ImageNet weights,not
keras/examples/conv_filter_visualization.py,258,example function call,not
keras/examples/conv_lstm.py,14,We create a layer which take as input movies of shape,not
keras/examples/conv_lstm.py,15,"(n_frames, width, height, channels) and returns a movie",not
keras/examples/conv_lstm.py,16,of identical shape.,not
keras/examples/conv_lstm.py,42,Artificial data generation:,not
keras/examples/conv_lstm.py,43,Generate movies with 3 to 7 moving squares inside.,not
keras/examples/conv_lstm.py,44,"The squares are of shape 1x1 or 2x2 pixels,",not
keras/examples/conv_lstm.py,45,which move linearly over time.,not
keras/examples/conv_lstm.py,46,For convenience we first create movies with bigger width and height (80x80),not
keras/examples/conv_lstm.py,47,and at the end we select a 40x40 window.,not
keras/examples/conv_lstm.py,57,Add 3 to 7 moving squares,not
keras/examples/conv_lstm.py,61,Initial position,not
keras/examples/conv_lstm.py,64,Direction of motion,not
keras/examples/conv_lstm.py,68,Size of the square,not
keras/examples/conv_lstm.py,77,Make it more robust by adding noise.,not
keras/examples/conv_lstm.py,78,"The idea is that if during inference,",not
keras/examples/conv_lstm.py,79,"the value of the pixel is not exactly one,",not
keras/examples/conv_lstm.py,80,we need to train the network to be robust and still,not
keras/examples/conv_lstm.py,81,consider it as a pixel belonging to a square.,not
keras/examples/conv_lstm.py,89,Shift the ground truth by 1,not
keras/examples/conv_lstm.py,95,Cut to a 40x40 window,not
keras/examples/conv_lstm.py,102,Train the network,not
keras/examples/conv_lstm.py,107,Testing the network on one movie,not
keras/examples/conv_lstm.py,108,feed it with the first 7 positions and then,not
keras/examples/conv_lstm.py,109,predict the new positions,not
keras/examples/conv_lstm.py,119,And then compare the predictions,not
keras/examples/conv_lstm.py,120,to the ground truth,not
keras/examples/mnist_swwae.py,97,This example assume 'channels_first' data format.,not
keras/examples/mnist_swwae.py,100,input image dimensions,not
keras/examples/mnist_swwae.py,103,"the data, split between train and test sets",not
keras/examples/mnist_swwae.py,116,The size of the kernel used for the MaxPooling2D,not
keras/examples/mnist_swwae.py,118,The total number of feature maps at each layer,not
keras/examples/mnist_swwae.py,120,The sizes of the pooling kernel at each layer,not
keras/examples/mnist_swwae.py,122,The convolution kernel size,not
keras/examples/mnist_swwae.py,124,Number of epochs to train for,not
keras/examples/mnist_swwae.py,126,Batch size during training,not
keras/examples/mnist_swwae.py,130,if using a 5 layer net of pool_size = 2,not
keras/examples/mnist_swwae.py,136,if using a 3 layer net of pool_size = 3,not
keras/examples/mnist_swwae.py,144,Shape of input to train on (note that model is fully convolutional however),not
keras/examples/mnist_swwae.py,146,"The final list of the size of axis=1 for all layers, including input",not
keras/examples/mnist_swwae.py,149,"First build the encoder, all the while keeping track of the 'where' masks",not
keras/examples/mnist_swwae.py,152,We push the 'where' masks to the following list,not
keras/examples/mnist_swwae.py,161,"Now build the decoder, and use the stored 'where' masks to place the features",not
keras/examples/mnist_swwae.py,168,Use hard_simgoid to clip range of reconstruction,not
keras/examples/mnist_swwae.py,171,"Define the model and it's mean square error loss, and compile it with Adam",not
keras/examples/mnist_swwae.py,175,Fit the model,not
keras/examples/mnist_swwae.py,181,Plot,not
keras/examples/class_activation_maps.py,1,-*- coding: utf-8 -*-,not
keras/examples/class_activation_maps.py,13,Set an appropriate image file,not
keras/examples/class_activation_maps.py,21,,not
keras/examples/class_activation_maps.py,22,The following parameters can be changed to other models,not
keras/examples/class_activation_maps.py,23,that use global average pooling.,not
keras/examples/class_activation_maps.py,24,e.g.) InceptionResnetV2 / NASNetLarge,not
keras/examples/class_activation_maps.py,30,,not
keras/examples/class_activation_maps.py,32,number of imagenet classes,not
keras/examples/class_activation_maps.py,74,1. load image,not
keras/examples/class_activation_maps.py,79,2. prediction,not
keras/examples/class_activation_maps.py,86,4. post processing,not
keras/examples/class_activation_maps.py,89,5. plot image+cam to original size,not
keras/examples/addition_rnn.py,1,-*- coding: utf-8 -*-,not
keras/examples/addition_rnn.py,28,noqa,not
keras/examples/addition_rnn.py,85,Parameters for the model and dataset.,not
keras/examples/addition_rnn.py,90,"Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of",not
keras/examples/addition_rnn.py,91,int is DIGITS.,not
keras/examples/addition_rnn.py,94,"All the numbers, plus sign and space for padding.",not
keras/examples/addition_rnn.py,106,Skip any addition questions we've already seen,not
keras/examples/addition_rnn.py,107,Also skip any such that x+Y == Y+x (hence the sorting).,not
keras/examples/addition_rnn.py,112,Pad the data with spaces such that it is always MAXLEN.,not
keras/examples/addition_rnn.py,116,Answers can be of maximum size DIGITS + 1.,not
keras/examples/addition_rnn.py,119,"Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the",not
keras/examples/addition_rnn.py,120,space used for padding.),not
keras/examples/addition_rnn.py,134,"Shuffle (x, y) in unison as the later parts of x will almost all be larger",not
keras/examples/addition_rnn.py,135,digits.,not
keras/examples/addition_rnn.py,141,Explicitly set apart 10% for validation data that we never train over.,not
keras/examples/addition_rnn.py,154,"Try replacing GRU, or SimpleRNN.",not
keras/examples/addition_rnn.py,162,"""Encode"" the input sequence using an RNN, producing an output of HIDDEN_SIZE.",not
keras/examples/addition_rnn.py,163,"Note: In a situation where your input sequences have a variable length,",not
keras/examples/addition_rnn.py,164,"use input_shape=(None, num_feature).",not
keras/examples/addition_rnn.py,166,"As the decoder RNN's input, repeatedly provide with the last output of",not
keras/examples/addition_rnn.py,167,RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum,not
keras/examples/addition_rnn.py,168,"length of output, e.g., when DIGITS=3, max output is 999+999=1998.",not
keras/examples/addition_rnn.py,170,The decoder RNN could be multiple layers stacked or a single layer.,not
keras/examples/addition_rnn.py,172,"By setting return_sequences to True, return not only the last output but",not
keras/examples/addition_rnn.py,173,"all the outputs so far in the form of (num_samples, timesteps,",not
keras/examples/addition_rnn.py,174,output_dim). This is necessary as TimeDistributed in the below expects,not
keras/examples/addition_rnn.py,175,the first dimension to be the timesteps.,not
keras/examples/addition_rnn.py,178,Apply a dense layer to the every temporal slice of an input. For each of step,not
keras/examples/addition_rnn.py,179,"of the output sequence, decide which character should be chosen.",not
keras/examples/addition_rnn.py,186,Train the model each generation and show predictions against the validation,not
keras/examples/addition_rnn.py,187,dataset.,not
keras/examples/addition_rnn.py,196,Select 10 samples from the validation set at random so we can visualize,not
keras/examples/addition_rnn.py,197,errors.,not
keras/examples/imdb_lstm.py,26,cut texts after this number of words (among top max_features most common words),not
keras/examples/imdb_lstm.py,47,try using different optimizers and different optimizer configs,not
keras/examples/imdb_bidirectional_lstm.py,18,cut texts after this number of words,not
keras/examples/imdb_bidirectional_lstm.py,19,(among top max_features most common words),not
keras/examples/imdb_bidirectional_lstm.py,42,try using different optimizers and different optimizer configs,not
keras/examples/mnist_denoising_autoencoder.py,35,MNIST dataset,not
keras/examples/mnist_denoising_autoencoder.py,44,Generate corrupted MNIST images by adding noise with normal dist,not
keras/examples/mnist_denoising_autoencoder.py,45,centered at 0.5 and std=0.5,not
keras/examples/mnist_denoising_autoencoder.py,54,Network parameters,not
keras/examples/mnist_denoising_autoencoder.py,59,Encoder/Decoder number of CNN layers and filters per layer,not
keras/examples/mnist_denoising_autoencoder.py,62,Build the Autoencoder Model,not
keras/examples/mnist_denoising_autoencoder.py,63,First build the Encoder Model,not
keras/examples/mnist_denoising_autoencoder.py,66,Stack of Conv2D blocks,not
keras/examples/mnist_denoising_autoencoder.py,67,Notes:,not
keras/examples/mnist_denoising_autoencoder.py,68,1) Use Batch Normalization before ReLU on deep networks,not
keras/examples/mnist_denoising_autoencoder.py,69,2) Use MaxPooling2D as alternative to strides>1,not
keras/examples/mnist_denoising_autoencoder.py,70,- faster but not as good as strides>1,not
keras/examples/mnist_denoising_autoencoder.py,78,Shape info needed to build Decoder Model,not
keras/examples/mnist_denoising_autoencoder.py,81,Generate the latent vector,not
keras/examples/mnist_denoising_autoencoder.py,85,Instantiate Encoder Model,not
keras/examples/mnist_denoising_autoencoder.py,89,Build the Decoder Model,not
keras/examples/mnist_denoising_autoencoder.py,94,Stack of Transposed Conv2D blocks,not
keras/examples/mnist_denoising_autoencoder.py,95,Notes:,not
keras/examples/mnist_denoising_autoencoder.py,96,1) Use Batch Normalization before ReLU on deep networks,not
keras/examples/mnist_denoising_autoencoder.py,97,2) Use UpSampling2D as alternative to strides>1,not
keras/examples/mnist_denoising_autoencoder.py,98,- faster but not as good as strides>1,not
keras/examples/mnist_denoising_autoencoder.py,112,Instantiate Decoder Model,not
keras/examples/mnist_denoising_autoencoder.py,116,Autoencoder = Encoder + Decoder,not
keras/examples/mnist_denoising_autoencoder.py,117,Instantiate Autoencoder Model,not
keras/examples/mnist_denoising_autoencoder.py,123,Train the autoencoder,not
keras/examples/mnist_denoising_autoencoder.py,130,Predict the Autoencoder output from corrupted test images,not
keras/examples/mnist_denoising_autoencoder.py,133,Display the 1st 8 corrupted and denoised images,not
keras/examples/pretrained_word_embeddings.py,36,"first, build index mapping words in the embeddings set",not
keras/examples/pretrained_word_embeddings.py,37,to their embedding vector,not
keras/examples/pretrained_word_embeddings.py,50,"second, prepare text samples and their labels",not
keras/examples/pretrained_word_embeddings.py,53,list of text samples,not
keras/examples/pretrained_word_embeddings.py,54,dictionary mapping label name to numeric id,not
keras/examples/pretrained_word_embeddings.py,55,list of label ids,not
keras/examples/pretrained_word_embeddings.py,67,skip header,not
keras/examples/pretrained_word_embeddings.py,75,"finally, vectorize the text samples into a 2D integer tensor",not
keras/examples/pretrained_word_embeddings.py,89,split the data into a training set and a validation set,not
keras/examples/pretrained_word_embeddings.py,103,prepare embedding matrix,not
keras/examples/pretrained_word_embeddings.py,111,words not found in embedding index will be all-zeros.,not
keras/examples/pretrained_word_embeddings.py,114,load pre-trained word embeddings into an Embedding layer,not
keras/examples/pretrained_word_embeddings.py,115,note that we set trainable = False so as to keep the embeddings fixed,not
keras/examples/pretrained_word_embeddings.py,124,train a 1D convnet with global maxpooling,not
keras/examples/mnist_transfer_cnn.py,28,input image dimensions,not
keras/examples/mnist_transfer_cnn.py,30,number of convolutional filters to use,not
keras/examples/mnist_transfer_cnn.py,32,size of pooling area for max pooling,not
keras/examples/mnist_transfer_cnn.py,34,convolution kernel size,not
keras/examples/mnist_transfer_cnn.py,54,convert class vectors to binary class matrices,not
keras/examples/mnist_transfer_cnn.py,74,"the data, split between train and test sets",not
keras/examples/mnist_transfer_cnn.py,77,create two datasets one with digits below 5 and one with 5 and above,not
keras/examples/mnist_transfer_cnn.py,88,define two groups of layers: feature (convolutions) and classification (dense),not
keras/examples/mnist_transfer_cnn.py,109,create complete model,not
keras/examples/mnist_transfer_cnn.py,112,train model for 5-digit classification [0..4],not
keras/examples/mnist_transfer_cnn.py,117,freeze feature layers and rebuild model,not
keras/examples/mnist_transfer_cnn.py,121,transfer: train dense layers for new classification task [5..9],not
keras/examples/mnist_net2net.py,76,image shape,not
keras/examples/mnist_net2net.py,78,image shape,not
keras/examples/mnist_net2net.py,79,number of classes,not
keras/examples/mnist_net2net.py,83,load and pre-process data,not
keras/examples/mnist_net2net.py,99,knowledge transfer algorithms,not
keras/examples/mnist_net2net.py,142,"add small noise to break symmetry, so that student model will have",not
keras/examples/mnist_net2net.py,143,full capacity later,not
keras/examples/mnist_net2net.py,192,"add small noise to break symmetry, so that student model will have",not
keras/examples/mnist_net2net.py,193,full capacity later,not
keras/examples/mnist_net2net.py,226,methods to construct teacher_model and student_models,not
keras/examples/mnist_net2net.py,263,a wider conv1 compared to teacher_model,not
keras/examples/mnist_net2net.py,270,a wider fc1 compared to teacher model,not
keras/examples/mnist_net2net.py,274,The weights for other layers need to be copied from teacher_model,not
keras/examples/mnist_net2net.py,275,"to student_model, except for widened layers",not
keras/examples/mnist_net2net.py,276,"and their immediate downstreams, which will be initialized separately.",not
keras/examples/mnist_net2net.py,277,For this example there are no other layers that need to be copied.,not
keras/examples/mnist_net2net.py,314,add another conv2d layer to make original conv2 deeper,not
keras/examples/mnist_net2net.py,327,add another fc layer to make original fc1 deeper,not
keras/examples/mnist_net2net.py,329,"net2deeper for fc layer with relu, is just an identity initializer",not
keras/examples/mnist_net2net.py,338,copy weights for other layers,not
keras/examples/mnist_net2net.py,351,experiments setup,not
keras/examples/mnist_net2net.py,399,run the experiments,not
keras/examples/deep_dream.py,33,These are the names of the layers,not
keras/examples/deep_dream.py,34,"for which we try to maximize activation,",not
keras/examples/deep_dream.py,35,as well as their weight in the final loss,not
keras/examples/deep_dream.py,36,we try to maximize.,not
keras/examples/deep_dream.py,37,You can tweak these setting to obtain new visual effects.,not
keras/examples/deep_dream.py,49,"Util function to open, resize and format pictures",not
keras/examples/deep_dream.py,50,into appropriate tensors.,not
keras/examples/deep_dream.py,59,Util function to convert a tensor into a valid image.,not
keras/examples/deep_dream.py,73,Build the InceptionV3 network with our placeholder.,not
keras/examples/deep_dream.py,74,The model will be loaded with pre-trained ImageNet weights.,not
keras/examples/deep_dream.py,80,"Get the symbolic outputs of each ""key"" layer (we gave them unique names).",not
keras/examples/deep_dream.py,83,Define the loss.,not
keras/examples/deep_dream.py,86,Add the L2 norm of the features of a layer to the loss.,not
keras/examples/deep_dream.py,91,We avoid border artifacts by only involving non-border pixels in the loss.,not
keras/examples/deep_dream.py,98,Compute the gradients of the dream wrt the loss.,not
keras/examples/deep_dream.py,100,Normalize gradients.,not
keras/examples/deep_dream.py,103,Set up function to retrieve the value,not
keras/examples/deep_dream.py,104,of the loss and gradients given an input image.,not
keras/examples/deep_dream.py,158,Playing with these hyperparameters will also allow you to achieve new effects,not
keras/examples/deep_dream.py,159,Gradient ascent step size,not
keras/examples/deep_dream.py,160,Number of scales at which to run gradient ascent,not
keras/examples/deep_dream.py,161,Size ratio between scales,not
keras/examples/deep_dream.py,162,Number of ascent steps per scale,not
keras/examples/image_ocr.py,1,-*- coding: utf-8 -*-,not
keras/examples/image_ocr.py,70,character classes and matching regex filter,not
keras/examples/image_ocr.py,77,"this creates larger ""blotches"" of noise which look",not
keras/examples/image_ocr.py,78,more realistic than just adding gaussian noise,not
keras/examples/image_ocr.py,79,assumes greyscale with pixels ranging from 0 to 1,not
keras/examples/image_ocr.py,90,paints the string in a random location the bounding box,not
keras/examples/image_ocr.py,91,"also uses a random font, a slight random rotation,",not
keras/examples/image_ocr.py,92,and a random amount of speckle noise,not
keras/examples/image_ocr.py,97,White,not
keras/examples/image_ocr.py,99,this font list works in CentOS 7,not
keras/examples/image_ocr.py,119,teach the RNN translational invariance by,not
keras/examples/image_ocr.py,120,"fitting text box randomly on canvas, with some room to rotate",not
keras/examples/image_ocr.py,135,grab single channel,not
keras/examples/image_ocr.py,167,Translation of characters to unique integer values,not
keras/examples/image_ocr.py,175,Reverse translation of numerical classes back to characters,not
keras/examples/image_ocr.py,179,CTC Blank,not
keras/examples/image_ocr.py,186,only a-z and space..probably not to difficult,not
keras/examples/image_ocr.py,187,to expand to uppercase and symbols,not
keras/examples/image_ocr.py,194,Uses generator functions to supply train/test with,not
keras/examples/image_ocr.py,195,data. Image renderings and text are created on the fly,not
keras/examples/image_ocr.py,196,each time with random perturbations,not
keras/examples/image_ocr.py,217,num_words can be independent of the epoch size due to the use of generators,not
keras/examples/image_ocr.py,218,"as max_string_len grows, num_words can grow",not
keras/examples/image_ocr.py,236,monogram file is sorted by frequency in english speech,not
keras/examples/image_ocr.py,245,bigram file contains common word pairings in english speech,not
keras/examples/image_ocr.py,258,interlace to mix up the easy and hard words,not
keras/examples/image_ocr.py,271,"each time an image is requested from train/val/test, a new random",not
keras/examples/image_ocr.py,272,painting of the text is performed,not
keras/examples/image_ocr.py,274,width and height are backwards from typical Keras convention,not
keras/examples/image_ocr.py,275,because width is the time dimension when it gets fed into the RNN,not
keras/examples/image_ocr.py,286,Mix in some blank inputs.  This seems to be important for,not
keras/examples/image_ocr.py,287,achieving translational invariance,not
keras/examples/image_ocr.py,312,used for visualization only,not
keras/examples/image_ocr.py,314,dummy data for dummy loss function,not
keras/examples/image_ocr.py,344,rebind the paint function to implement curriculum learning,not
keras/examples/image_ocr.py,361,the actual loss calc occurs here despite it not being,not
keras/examples/image_ocr.py,362,an internal Keras loss function,not
keras/examples/image_ocr.py,366,the 2 is critical here since the first couple outputs of the RNN,not
keras/examples/image_ocr.py,367,tend to be garbage:,not
keras/examples/image_ocr.py,372,"For a real OCR application, this should be beam search with a dictionary",not
keras/examples/image_ocr.py,373,"and language model.  For this example, best path is sufficient.",not
keras/examples/image_ocr.py,446,Input Parameters,not
keras/examples/image_ocr.py,452,Network parameters,not
keras/examples/image_ocr.py,493,cuts down input size going into RNN:,not
keras/examples/image_ocr.py,496,Two layers of bidirectional GRUs,not
keras/examples/image_ocr.py,497,"GRU seems to work as well, if not better than LSTM:",SATD
keras/examples/image_ocr.py,509,transforms RNN output to character activations:,not
keras/examples/image_ocr.py,519,Keras doesn't currently support loss funcs with extra parameters,not
keras/examples/image_ocr.py,520,so CTC loss is implemented in a lambda layer,not
keras/examples/image_ocr.py,525,clipnorm seems to speeds up convergence,not
keras/examples/image_ocr.py,534,"the loss calc occurs elsewhere, so use a dummy lambda func for the loss",not
keras/examples/image_ocr.py,541,captures output of softmax so we can decode the output during visualization,not
keras/examples/image_ocr.py,559,increase to wider images and start at epoch 20.,not
keras/examples/image_ocr.py,560,The learned weights are reloaded,not
keras/examples/mnist_irnn.py,34,"the data, split between train and test sets",not
keras/examples/mnist_irnn.py,47,convert class vectors to binary class matrices,not
keras/examples/lstm_text_generation.py,38,cut the text in semi-redundant sequences of maxlen characters,not
keras/examples/lstm_text_generation.py,57,build the model: a single LSTM,not
keras/examples/lstm_text_generation.py,68,helper function to sample an index from a probability array,not
keras/examples/lstm_text_generation.py,78,Function invoked at end of each epoch. Prints generated text.,not
keras/examples/neural_doodle.py,62,Command line arguments,not
keras/examples/neural_doodle.py,88,RGB,not
keras/examples/neural_doodle.py,89,determine image sizes based on target_mask,not
keras/examples/neural_doodle.py,100,"To get better generation qualities, use more conv layers for style features",SATD
keras/examples/neural_doodle.py,105,helper functions for reading/processing images,not
keras/examples/neural_doodle.py,120,Remove zero-center by mean pixel,not
keras/examples/neural_doodle.py,124,'BGR'->'RGB',not
keras/examples/neural_doodle.py,176,Create tensor variables for images,not
keras/examples/neural_doodle.py,191,Create tensor variables for masks,not
keras/examples/neural_doodle.py,197,index constants for images and tasks variables,not
keras/examples/neural_doodle.py,200,"Build image model, mask model and use layer outputs as features",not
keras/examples/neural_doodle.py,201,image model as VGG19,not
keras/examples/neural_doodle.py,204,mask model as a series of pooling,not
keras/examples/neural_doodle.py,216,Collect features from image_model and task_model,not
keras/examples/neural_doodle.py,228,Define loss functions,not
keras/examples/neural_doodle.py,298,"Overall loss is the weighted sum of content_loss, style_loss and tv_loss",not
keras/examples/neural_doodle.py,299,Each individual loss uses features from image/mask models.,not
keras/examples/neural_doodle.py,317,Evaluator class for computing efficiency,not
keras/examples/neural_doodle.py,364,Generate images by iterative optimization,not
keras/examples/neural_doodle.py,376,save current generated image,not
keras/docs/structure.py,1,-*- coding: utf-8 -*-,not
keras/docs/structure.py,96,"For each class to document, it is possible to:",not
keras/docs/structure.py,97,"1) Document only the class: [classA, classB, ...]",not
keras/docs/structure.py,98,"2) Document all its methods: [classA, (classB, ""*"")]",not
keras/docs/structure.py,99,3) Choose which methods to document (methods listed as strings):,not
keras/docs/structure.py,100,"[classA, (classB, [""method1"", ""method2"", ...]), ...]",not
keras/docs/structure.py,101,4) Choose which methods to document (methods listed as qualified names):,not
keras/docs/structure.py,102,"[classA, (classB, [module.classB.method1, module.classB.method2, ...]), ...]",not
keras/docs/autogen.py,1,-*- coding: utf-8 -*-,not
keras/docs/autogen.py,69,in case the class inherits from object and does not,not
keras/docs/autogen.py,70,define __init__,not
keras/docs/autogen.py,131,Place marker for later reinjection.,not
keras/docs/autogen.py,138,Remove the computed number of leading white spaces from each line.,not
keras/docs/autogen.py,140,Usually lines have at least 4 additional leading spaces.,not
keras/docs/autogen.py,141,"These have to be removed, but first the list roots have to be detected.",not
keras/docs/autogen.py,146,All the other lines get simply the 4 leading space (if present) removed,not
keras/docs/autogen.py,148,Fix text lines after lists,not
keras/docs/autogen.py,155,If it is a list element,not
keras/docs/autogen.py,173,"First, extract code blocks and process them.",not
keras/docs/autogen.py,181,Place marker in docstring for later reinjection.,not
keras/docs/autogen.py,185,Remove leading spaces.,not
keras/docs/autogen.py,190,Most code snippets have 3 or 4 more leading spaces,not
keras/docs/autogen.py,191,"on inner lines, but not all. Remove them.",not
keras/docs/autogen.py,211,Format docstring lists.,not
keras/docs/autogen.py,232,"`docstring` has changed, so we can't use `next_section_idx` anymore",not
keras/docs/autogen.py,233,we have to recompute it,not
keras/docs/autogen.py,236,Format docstring section titles.,not
keras/docs/autogen.py,241,Strip all remaining leading spaces.,not
keras/docs/autogen.py,245,Reinject list blocks.,not
keras/docs/autogen.py,249,Reinject code blocks.,not
keras/docs/autogen.py,262,"if there is something on the line, add 8 spaces.",not
keras/docs/autogen.py,358,skip docstring,not
keras/docs/autogen.py,363,next line might be empty.,not
keras/docs/autogen.py,368,copy the rest of the file.,not
keras/docs/autogen.py,445,Save module page.,not
keras/docs/autogen.py,446,"Either insert content into existing page,",not
keras/docs/autogen.py,447,or create page otherwise.,not
