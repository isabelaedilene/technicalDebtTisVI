file path,line #,comment,satd
gym/setup.py,4,"Don't import gym module here, since deps may not be installed",not
gym/setup.py,8,Environment-specific dependencies.,not
gym/setup.py,17,Meta dependency groups.,not
gym/bin/render.py,1,!/usr/bin/env python3,not
gym/gym/logger.py,36,DEPRECATED:,not
gym/gym/error.py,6,Local errors,not
gym/gym/error.py,65,API errors,not
gym/gym/error.py,94,Python 2,not
gym/gym/error.py,96,Python 3,not
gym/gym/error.py,120,Video errors,not
gym/gym/error.py,128,Wrapper errors,not
gym/gym/error.py,141,Vectorized environments errors,not
gym/gym/core.py,31,Set this in SOME subclasses,not
gym/gym/core.py,36,Set these in ALL subclasses,not
gym/gym/core.py,152,propagate exception,not
gym/gym/core.py,166,Enforce that each GoalEnv uses a Goal-compatible observation space.,not
gym/gym/utils/closer.py,63,Explicitly fetch all monitors first so that they can't disappear while,not
gym/gym/utils/closer.py,64,we iterate. cf. http://stackoverflow.com/a/12429620,not
gym/gym/utils/seeding.py,53,Adapted from https://svn.python.org/projects/python/tags/r32/Lib/random.py,not
gym/gym/utils/seeding.py,67,TODO: don't hardcode sizeof_int here,SATD
gym/gym/utils/seeding.py,80,Special case 0,not
gym/gym/utils/atomic_write.py,1,Based on http://stackoverflow.com/questions/2333872/atomic-writing-to-file-with-python,not
gym/gym/utils/atomic_write.py,6,We would ideally atomically replace any existing file with the new,not
gym/gym/utils/atomic_write.py,7,"version. However, on Windows there's no Python-only solution prior",not
gym/gym/utils/atomic_write.py,8,to Python 3.3. (This library includes a C extension to do so:,not
gym/gym/utils/atomic_write.py,9,https://pypi.python.org/pypi/pyosreplace/0.1.),not
gym/gym/utils/atomic_write.py,10,,not
gym/gym/utils/atomic_write.py,11,"Correspondingly, we make a best effort, but on Python < 3.3 use a",not
gym/gym/utils/atomic_write.py,12,replace method which could result in the file temporarily,not
gym/gym/utils/atomic_write.py,13,disappearing.,not
gym/gym/utils/atomic_write.py,16,Python 3.3 and up have a native `replace` method,not
gym/gym/utils/atomic_write.py,20,"TODO: on Windows, this will raise if the file is in use,",SATD
gym/gym/utils/atomic_write.py,21,which is possible. We'll need to make this more robust over,not
gym/gym/utils/atomic_write.py,22,time.,not
gym/gym/utils/atomic_write.py,29,POSIX rename() is always atomic,not
gym/gym/utils/play.py,118,process pygame events,not
gym/gym/utils/play.py,120,"test events, set key states",not
gym/gym/utils/__init__.py,5,These submodules should not have any import-time dependencies.,not
gym/gym/utils/__init__.py,6,We want this since we use `utils` during our import-time sanity checks,not
gym/gym/utils/__init__.py,7,that verify that our dependencies are actually present.,not
gym/gym/vector/vector_env.py,40,The observation and action spaces of a single environment are,not
gym/gym/vector/vector_env.py,41,kept in separate properties,not
gym/gym/vector/tests/test_sync_vector_env.py,66,"CubeCrash-v0 - observation_space: Box(40, 32, 3)",not
gym/gym/vector/tests/test_sync_vector_env.py,68,"MemorizeDigits-v0 - observation_space: Box(24, 32, 3)",not
gym/gym/vector/tests/test_numpy_utils.py,16,"Special case: if rhs is a list of scalars, lhs must be an np.ndarray",not
gym/gym/vector/tests/test_async_vector_env.py,190,"CubeCrash-v0 - observation_space: Box(40, 32, 3)",not
gym/gym/vector/tests/test_async_vector_env.py,192,"MemorizeDigits-v0 - observation_space: Box(24, 32, 3)",not
gym/gym/vector/tests/test_shared_memory.py,54,Assert the length of the array,not
gym/gym/vector/tests/test_shared_memory.py,56,Assert the data type,not
gym/gym/tests/test_core.py,11,"This looks like a pretty trivial, but given our usage of",not
gym/gym/tests/test_core.py,12,"__new__, it's worth having.",not
gym/gym/wrappers/test_pixel_observation.py,56,Make sure we are testing the right environment for the test.,not
gym/gym/wrappers/test_pixel_observation.py,62,The wrapper should only add one observation.,not
gym/gym/wrappers/test_pixel_observation.py,82,Check that the added space item is consistent with the added observation.,not
gym/gym/wrappers/atari_preprocessing.py,62,buffer of most recent two observations for max pooling,not
gym/gym/wrappers/atari_preprocessing.py,108,NoopReset,not
gym/gym/wrappers/atari_preprocessing.py,125,more efficient in-place pooling,not
gym/gym/wrappers/test_clip_action.py,8,mountaincar: action-based rewards,not
gym/gym/wrappers/test_filter_observation.py,55,Make sure we are testing the right environment for the test.,not
gym/gym/wrappers/test_filter_observation.py,70,Check that the added space item is consistent with the added observation.,not
gym/gym/wrappers/record_episode_statistics.py,10,TODO: use perf_counter when gym removes Python 2 support,SATD
gym/gym/wrappers/test_gray_scale_observation.py,34,"ALE gray scale is slightly different, but no more than by one shade",not
gym/gym/wrappers/pixel_observation.py,70,Make sure that now keys in the `pixel_keys` overlap with,not
gym/gym/wrappers/pixel_observation.py,71,`observation_keys`,not
gym/gym/wrappers/pixel_observation.py,85,Extend observation space with pixels.,not
gym/gym/wrappers/test_transform_reward.py,11,use case #1: scale,not
gym/gym/wrappers/test_transform_reward.py,29,use case #2: clip,not
gym/gym/wrappers/test_transform_reward.py,48,use case #3: sign,not
gym/gym/wrappers/monitor.py,79,Check on whether we need to clear anything,not
gym/gym/wrappers/monitor.py,93,We use the 'openai-gym' prefix to determine if a file is,not
gym/gym/wrappers/monitor.py,94,ours,not
gym/gym/wrappers/monitor.py,113,"Give it a very distiguished name, since we need to pick it",not
gym/gym/wrappers/monitor.py,114,up from the filesystem later.,not
gym/gym/wrappers/monitor.py,118,We need to write relative paths here since people may,not
gym/gym/wrappers/monitor.py,119,move the training_dir around. It would be cleaner to,SATD
gym/gym/wrappers/monitor.py,120,already have the basenames rather than basename'ing,not
gym/gym/wrappers/monitor.py,121,"manually, but this works for now.",not
gym/gym/wrappers/monitor.py,140,Stop tracking this for autoclose,not
gym/gym/wrappers/monitor.py,163,"For envs with BlockingReset wrapping VNCEnv, this observation will be the first one of the new episode",not
gym/gym/wrappers/monitor.py,168,Record stats,not
gym/gym/wrappers/monitor.py,170,Record video,not
gym/gym/wrappers/monitor.py,182,Reset the stat count,not
gym/gym/wrappers/monitor.py,187,Bump *after* all reset activity has finished,not
gym/gym/wrappers/monitor.py,193,Close any existing video recorder,not
gym/gym/wrappers/monitor.py,197,Start recording the next video.,not
gym/gym/wrappers/monitor.py,198,,not
gym/gym/wrappers/monitor.py,199,TODO: calculate a more correct 'episode_id' upon merge,SATD
gym/gym/wrappers/monitor.py,225,Make sure we've closed up shop when garbage collecting,not
gym/gym/wrappers/monitor.py,265,This method gets used for a sanity check in scoreboard/api.py. It's,not
gym/gym/wrappers/monitor.py,266,not intended for use outside of the gym codebase.,not
gym/gym/wrappers/monitor.py,292,Load up stats + video files,not
gym/gym/wrappers/monitor.py,300,Make these paths absolute again,not
gym/gym/wrappers/monitor.py,333,"so empty file doesn't mess up results, due to null initial_reset_timestamp",not
gym/gym/wrappers/monitor.py,338,Recent addition,not
gym/gym/wrappers/monitor.py,340,Keep track of where each episode came from.,not
gym/gym/wrappers/monitor.py,361,"TODO training_dir isn't used except for error messages, clean up the layering",SATD
gym/gym/wrappers/test_atari_preprocessing.py,30,"the edges of the numbers do not render quite the same in the grayscale, so we ignore them",not
gym/gym/wrappers/test_atari_preprocessing.py,32,the paddle also do not render quite the same,not
gym/gym/wrappers/test_atari_preprocessing.py,41,arbitrarily chosen number for stepping into env. and ensuring all observations are in the required range,not
gym/gym/wrappers/monitoring/video_recorder.py,36,Don't bother setting anything else if not enabled,not
gym/gym/wrappers/monitoring/video_recorder.py,46,"Whoops, turns out we shouldn't be enabled after all",not
gym/gym/wrappers/monitoring/video_recorder.py,59,"Base path given, append ext",not
gym/gym/wrappers/monitoring/video_recorder.py,62,"Otherwise, just generate a unique filename",not
gym/gym/wrappers/monitoring/video_recorder.py,72,"Touch the file in any case, so we know it's present. (This",not
gym/gym/wrappers/monitoring/video_recorder.py,73,corrects for platform platform differences. Using ffmpeg on,not
gym/gym/wrappers/monitoring/video_recorder.py,74,"OS X, the file is precreated, but not on Linux.",not
gym/gym/wrappers/monitoring/video_recorder.py,79,lazily start the process,not
gym/gym/wrappers/monitoring/video_recorder.py,82,Dump metadata,not
gym/gym/wrappers/monitoring/video_recorder.py,107,Indicates a bug in the environment: don't want to raise,not
gym/gym/wrappers/monitoring/video_recorder.py,108,an error here.,not
gym/gym/wrappers/monitoring/video_recorder.py,128,"No frames captured. Set metadata, and remove the empty output file.",not
gym/gym/wrappers/monitoring/video_recorder.py,135,"If broken, get rid of the output file, otherwise we'd leak it.",not
gym/gym/wrappers/monitoring/video_recorder.py,139,"Might have crashed before even starting the output file, don't try to remove in that case.",not
gym/gym/wrappers/monitoring/video_recorder.py,203,frame_duration = float(1) / self.frames_per_sec,not
gym/gym/wrappers/monitoring/video_recorder.py,206,Turn frames into events: clear screen beforehand,not
gym/gym/wrappers/monitoring/video_recorder.py,207,https://rosettacode.org/wiki/Terminal_control/Clear_the_screen#Python,not
gym/gym/wrappers/monitoring/video_recorder.py,208,https://rosettacode.org/wiki/Terminal_control/Cursor_positioning#Python,not
gym/gym/wrappers/monitoring/video_recorder.py,210,Decode the bytes as UTF-8 since JSON may only contain UTF-8,not
gym/gym/wrappers/monitoring/video_recorder.py,213,Calculate frame size from the largest frames.,not
gym/gym/wrappers/monitoring/video_recorder.py,214,Add some padding since we'll get cut off otherwise.,not
gym/gym/wrappers/monitoring/video_recorder.py,225,could add some env metadata here,not
gym/gym/wrappers/monitoring/video_recorder.py,240,"Frame shape should be lines-first, so w and h are swapped",not
gym/gym/wrappers/monitoring/video_recorder.py,271,suppress warnings,not
gym/gym/wrappers/monitoring/video_recorder.py,274,input,not
gym/gym/wrappers/monitoring/video_recorder.py,279,"this used to be /dev/stdin, which is not Windows-friendly",not
gym/gym/wrappers/monitoring/video_recorder.py,281,output,not
gym/gym/wrappers/monitoring/video_recorder.py,290,setsid not present on Windows,not
gym/gym/wrappers/monitoring/stats_recorder.py,19,experimental addition,not
gym/gym/wrappers/monitoring/stats_recorder.py,77,We write the type at the beginning of the episode. If a user,not
gym/gym/wrappers/monitoring/stats_recorder.py,78,"changes the type, it's more natural for it to apply next",not
gym/gym/wrappers/monitoring/stats_recorder.py,79,time the user calls reset().,not
gym/gym/spaces/multi_discrete.py,40,Promote list to array for contains check,not
gym/gym/spaces/multi_discrete.py,41,"if nvec is uint32 and space dtype is uint32, then 0 <= x < self.nvec guarantees that x",not
gym/gym/spaces/multi_discrete.py,42,is within correct bounds for space dtype (even though x does not have to be unsigned),not
gym/gym/spaces/space.py,10,"takes about 300-400ms to import, so we load lazily",not
gym/gym/spaces/space.py,38,"By default, assume identity is JSONable",not
gym/gym/spaces/space.py,43,"By default, assume identity is JSONable",not
gym/gym/spaces/box.py,28,determine shape if it isn't provided directly,not
gym/gym/spaces/box.py,65,Boolean arrays which indicate the interval type for each coordinate,not
gym/gym/spaces/box.py,99,Masking arrays which classify the coordinates according to interval,not
gym/gym/spaces/box.py,100,type,not
gym/gym/spaces/box.py,107,Vectorized sampling by interval type,not
gym/gym/spaces/box.py,127,Promote list to array for contains check,not
gym/gym/spaces/dict.py,45,"None for shape and dtype, since it'll require special handling",not
gym/gym/spaces/dict.py,70,serialize as dict-repr of vectors,not
gym/gym/spaces/tuple.py,26,Promote list to tuple for contains check,not
gym/gym/spaces/tuple.py,34,serialize as list-repr of tuple of vectors,not
gym/gym/spaces/multi_binary.py,30,Promote list to array for contains check,not
gym/gym/spaces/tests/test_spaces.py,1,note: ujson fails this test due to float equality,not
gym/gym/envs/registration.py,8,"This format is true today, but it's *not* an official spec.",not
gym/gym/envs/registration.py,9,"[username/](env-name)-v(version)    env-name is group 1, version is group 2",not
gym/gym/envs/registration.py,10,,not
gym/gym/envs/registration.py,11,2016-10-31: We're experimentally expanding the environment ID format,not
gym/gym/envs/registration.py,12,to include an optional username.,not
gym/gym/envs/registration.py,62,Make the environment aware of which spec it came from.,not
gym/gym/envs/registration.py,91,We used to have people override _reset/_step rather than,not
gym/gym/envs/registration.py,92,reset/step. Set _gym_disable_underscore_compat = True on,not
gym/gym/envs/registration.py,93,your environment if you use these methods and don't want,not
gym/gym/envs/registration.py,94,compatibility code to be invoked.,not
gym/gym/envs/registration.py,110,catch ImportError for python2.7 compatibility,not
gym/gym/envs/registration.py,123,Parse the env name and check to see if it matches the non-version,not
gym/gym/envs/registration.py,124,part of a valid env (could also check the exact number here),not
gym/gym/envs/registration.py,138,Have a global registry,not
gym/gym/envs/__init__.py,3,Algorithmic,not
gym/gym/envs/__init__.py,4,----------------------------------------,not
gym/gym/envs/__init__.py,50,Classic,not
gym/gym/envs/__init__.py,51,----------------------------------------,not
gym/gym/envs/__init__.py,94,Box2d,not
gym/gym/envs/__init__.py,95,----------------------------------------,not
gym/gym/envs/__init__.py,132,Toy Text,not
gym/gym/envs/__init__.py,133,----------------------------------------,not
gym/gym/envs/__init__.py,155,optimum = .8196,not
gym/gym/envs/__init__.py,163,optimum = 1,not
gym/gym/envs/__init__.py,186,optimum = 8.46,not
gym/gym/envs/__init__.py,202,Mujoco,not
gym/gym/envs/__init__.py,203,----------------------------------------,not
gym/gym/envs/__init__.py,205,2D,not
gym/gym/envs/__init__.py,335,Robotics,not
gym/gym/envs/__init__.py,336,----------------------------------------,not
gym/gym/envs/__init__.py,348,Fetch,not
gym/gym/envs/__init__.py,377,Hand,not
gym/gym/envs/__init__.py,455,"Alias for ""Full""",not
gym/gym/envs/__init__.py,505,"Alias for ""Full""",not
gym/gym/envs/__init__.py,555,"Alias for ""Full""",not
gym/gym/envs/__init__.py,577,Atari,not
gym/gym/envs/__init__.py,578,----------------------------------------,not
gym/gym/envs/__init__.py,580,"# print ', '.join([""'{}'"".format(name.split('.')[0]) for name in atari_py.list_games()])",not
gym/gym/envs/__init__.py,591,space_invaders should yield SpaceInvaders-v0 and SpaceInvaders-ram-v0,not
gym/gym/envs/__init__.py,598,ElevatorAction-ram-v0 seems to yield slightly,not
gym/gym/envs/__init__.py,599,non-deterministic observations about 10% of the time. We,not
gym/gym/envs/__init__.py,600,"should track this down eventually, but for now we just",not
gym/gym/envs/__init__.py,601,mark it as nondeterministic.,not
gym/gym/envs/__init__.py,620,Standard Deterministic (as in the original DeepMind paper),not
gym/gym/envs/__init__.py,626,Use a deterministic frame skip.,not
gym/gym/envs/__init__.py,646,A frameskip of 1 means we get every frame,not
gym/gym/envs/__init__.py,651,"No frameskip. (Atari has no entropy source, so these are",not
gym/gym/envs/__init__.py,652,deterministic environments.),not
gym/gym/envs/__init__.py,656,A frameskip of 1 means we get every frame,not
gym/gym/envs/__init__.py,662,Unit test,not
gym/gym/envs/__init__.py,663,---------,not
gym/gym/envs/unittest/cube_crash.py,6,Unit test environment for CNNs and CNN+RNN algorithms.,not
gym/gym/envs/unittest/cube_crash.py,7,Looks like this (RGB observations):,not
gym/gym/envs/unittest/cube_crash.py,8,,not
gym/gym/envs/unittest/cube_crash.py,9,---------------------------,not
gym/gym/envs/unittest/cube_crash.py,10,|                           |,not
gym/gym/envs/unittest/cube_crash.py,11,|                           |,not
gym/gym/envs/unittest/cube_crash.py,12,|                           |,not
gym/gym/envs/unittest/cube_crash.py,13,|          **               |,not
gym/gym/envs/unittest/cube_crash.py,14,|          **               |,not
gym/gym/envs/unittest/cube_crash.py,15,|                           |,not
gym/gym/envs/unittest/cube_crash.py,16,|                           |,not
gym/gym/envs/unittest/cube_crash.py,17,|                           |,not
gym/gym/envs/unittest/cube_crash.py,18,|                           |,not
gym/gym/envs/unittest/cube_crash.py,19,|                           |,not
gym/gym/envs/unittest/cube_crash.py,20,========     ==============,not
gym/gym/envs/unittest/cube_crash.py,21,,not
gym/gym/envs/unittest/cube_crash.py,22,Goal is to go through the hole at the bottom. Agent controls square using Left-Nop-Right actions.,not
gym/gym/envs/unittest/cube_crash.py,23,"It falls down automatically, episode length is a bit less than FIELD_H",not
gym/gym/envs/unittest/cube_crash.py,24,,not
gym/gym/envs/unittest/cube_crash.py,25,CubeCrash-v0                    # shaped reward,not
gym/gym/envs/unittest/cube_crash.py,26,CubeCrashSparse-v0              # reward 0 or 1 at the end,not
gym/gym/envs/unittest/cube_crash.py,27,CubeCrashScreenBecomesBlack-v0  # for RNNs,not
gym/gym/envs/unittest/cube_crash.py,28,,not
gym/gym/envs/unittest/cube_crash.py,29,"To see how it works, run:",not
gym/gym/envs/unittest/cube_crash.py,30,,not
gym/gym/envs/unittest/cube_crash.py,31,python examples/agents/keyboard_agent.py CubeCrashScreen-v0,not
gym/gym/envs/unittest/cube_crash.py,51,Makes env too hard,not
gym/gym/envs/unittest/memorize_digits.py,6,Unit test environment for CNNs.,not
gym/gym/envs/unittest/memorize_digits.py,7,Looks like this (RGB observations):,not
gym/gym/envs/unittest/memorize_digits.py,8,,not
gym/gym/envs/unittest/memorize_digits.py,9,---------------------------,not
gym/gym/envs/unittest/memorize_digits.py,10,|                           |,not
gym/gym/envs/unittest/memorize_digits.py,11,|         ******            |,not
gym/gym/envs/unittest/memorize_digits.py,12,|         ******            |,not
gym/gym/envs/unittest/memorize_digits.py,13,|       **      **          |,not
gym/gym/envs/unittest/memorize_digits.py,14,|       **      **          |,not
gym/gym/envs/unittest/memorize_digits.py,15,|               **          |,not
gym/gym/envs/unittest/memorize_digits.py,16,|               **          |,not
gym/gym/envs/unittest/memorize_digits.py,17,|           ****            |,not
gym/gym/envs/unittest/memorize_digits.py,18,|           ****            |,not
gym/gym/envs/unittest/memorize_digits.py,19,|       ****                |,not
gym/gym/envs/unittest/memorize_digits.py,20,|       ****                |,not
gym/gym/envs/unittest/memorize_digits.py,21,|       **********          |,not
gym/gym/envs/unittest/memorize_digits.py,22,|       **********          |,not
gym/gym/envs/unittest/memorize_digits.py,23,|                           |,not
gym/gym/envs/unittest/memorize_digits.py,24,---------------------------,not
gym/gym/envs/unittest/memorize_digits.py,25,,not
gym/gym/envs/unittest/memorize_digits.py,26,Agent should hit action 2 to gain reward. Catches off-by-one errors in your agent.,not
gym/gym/envs/unittest/memorize_digits.py,27,,not
gym/gym/envs/unittest/memorize_digits.py,28,"To see how it works, run:",not
gym/gym/envs/unittest/memorize_digits.py,29,,not
gym/gym/envs/unittest/memorize_digits.py,30,python examples/agents/keyboard_agent.py MemorizeDigits-v0,not
gym/gym/envs/box2d/car_racing.py,45,less than Atari 160x192,not
gym/gym/envs/box2d/car_racing.py,52,Track scale,not
gym/gym/envs/box2d/car_racing.py,53,Track is heavily morphed circle with this radius,not
gym/gym/envs/box2d/car_racing.py,54,Game over boundary,not
gym/gym/envs/box2d/car_racing.py,55,Frames per second,not
gym/gym/envs/box2d/car_racing.py,56,Camera zoom,not
gym/gym/envs/box2d/car_racing.py,57,Set to False for fixed view (don't use zoom),not
gym/gym/envs/box2d/car_racing.py,132,"steer, gas, brake",not
gym/gym/envs/box2d/car_racing.py,151,Create checkpoints,not
gym/gym/envs/box2d/car_racing.py,166,Go from one checkpoint to another to create track,not
gym/gym/envs/box2d/car_racing.py,181,Find destination from checkpoints,not
gym/gym/envs/box2d/car_racing.py,199,vector towards destination,not
gym/gym/envs/box2d/car_racing.py,201,destination vector projected on rad,not
gym/gym/envs/box2d/car_racing.py,221,"Find closed loop range i1..i2, first loop should be ignored, second is OK",not
gym/gym/envs/box2d/car_racing.py,227,Failed,not
gym/gym/envs/box2d/car_racing.py,244,Length of perpendicular jump to put together head and tail,not
gym/gym/envs/box2d/car_racing.py,251,Red-white border on hard turns,not
gym/gym/envs/box2d/car_racing.py,267,Create tiles,not
gym/gym/envs/box2d/car_racing.py,330,"First step without action, called from reset()",not
gym/gym/envs/box2d/car_racing.py,332,"We actually don't want to count fuel spent, we want car to be faster.",not
gym/gym/envs/box2d/car_racing.py,333,self.reward -=  10 * self.car.fuel_spent / ENGINE_POWER,not
gym/gym/envs/box2d/car_racing.py,356,reset() not called yet,not
gym/gym/envs/box2d/car_racing.py,358,Animate zoom first second,not
gym/gym/envs/box2d/car_racing.py,389,pylint: disable=protected-access,not
gym/gym/envs/box2d/car_racing.py,464,ABS sensors,not
gym/gym/envs/box2d/car_racing.py,485,set 1.0 for wheels to block to zero rotation,not
gym/gym/envs/box2d/lunar_lander.py,40,"affects how fast-paced the game is, forces should be adjusted as well",not
gym/gym/envs/box2d/lunar_lander.py,45,Set 1500 to make game harder,not
gym/gym/envs/box2d/lunar_lander.py,101,"useful range is -1 .. +1, but spikes can be higher",not
gym/gym/envs/box2d/lunar_lander.py,105,"Action is two floats [main engine, left-right engines].",not
gym/gym/envs/box2d/lunar_lander.py,106,"Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.",not
gym/gym/envs/box2d/lunar_lander.py,107,"Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off",not
gym/gym/envs/box2d/lunar_lander.py,110,"Nop, fire left engine, main engine, right engine",not
gym/gym/envs/box2d/lunar_lander.py,140,terrain,not
gym/gym/envs/box2d/lunar_lander.py,177,collide only with ground,not
gym/gym/envs/box2d/lunar_lander.py,178,0.99 bouncy,not
gym/gym/envs/box2d/lunar_lander.py,210,low enough not to jump back into the sky,not
gym/gym/envs/box2d/lunar_lander.py,213,"The most esoteric numbers here, angled legs have freedom to travel within",not
gym/gym/envs/box2d/lunar_lander.py,234,collide only with ground,not
gym/gym/envs/box2d/lunar_lander.py,252,Engines,not
gym/gym/envs/box2d/lunar_lander.py,259,Main engine,not
gym/gym/envs/box2d/lunar_lander.py,261,0.5..1.0,not
gym/gym/envs/box2d/lunar_lander.py,266,"4 is move a bit downwards, +-2 for randomness",SATD
gym/gym/envs/box2d/lunar_lander.py,269,3.5 is here to make particle speed adequate,not
gym/gym/envs/box2d/lunar_lander.py,272,particles are just a decoration,not
gym/gym/envs/box2d/lunar_lander.py,282,Orientation engines,not
gym/gym/envs/box2d/lunar_lander.py,322,"And ten points for legs contact, the idea is if you",not
gym/gym/envs/box2d/lunar_lander.py,323,"lose contact again after landing, you get negative reward",not
gym/gym/envs/box2d/lunar_lander.py,328,"less fuel spent is better, about -30 for heuristic landing",SATD
gym/gym/envs/box2d/lunar_lander.py,408,angle should point towards center,not
gym/gym/envs/box2d/lunar_lander.py,409,more than 0.4 radians (22 degrees) is bad,not
gym/gym/envs/box2d/lunar_lander.py,411,target y should be proportional to horizontal offset,not
gym/gym/envs/box2d/lunar_lander.py,416,legs have contact,not
gym/gym/envs/box2d/lunar_lander.py,418,"override to reduce fall speed, that's all we need after contact",not
gym/gym/envs/box2d/bipedal_walker.py,12,This is simple 4-joints walker robot environment.,not
gym/gym/envs/box2d/bipedal_walker.py,13,,not
gym/gym/envs/box2d/bipedal_walker.py,14,There are two versions:,not
gym/gym/envs/box2d/bipedal_walker.py,15,,not
gym/gym/envs/box2d/bipedal_walker.py,16,"- Normal, with slightly uneven terrain.",not
gym/gym/envs/box2d/bipedal_walker.py,17,,not
gym/gym/envs/box2d/bipedal_walker.py,18,"- Hardcore with ladders, stumps, pitfalls.",not
gym/gym/envs/box2d/bipedal_walker.py,19,,not
gym/gym/envs/box2d/bipedal_walker.py,20,"Reward is given for moving forward, total 300+ points up to the far end. If the robot falls,",not
gym/gym/envs/box2d/bipedal_walker.py,21,"it gets -100. Applying motor torque costs a small amount of points, more optimal agent",not
gym/gym/envs/box2d/bipedal_walker.py,22,will get better score.,SATD
gym/gym/envs/box2d/bipedal_walker.py,23,,not
gym/gym/envs/box2d/bipedal_walker.py,24,"Heuristic is provided for testing, it's also useful to get demonstrations to",not
gym/gym/envs/box2d/bipedal_walker.py,25,learn from. To run heuristic:,not
gym/gym/envs/box2d/bipedal_walker.py,26,,not
gym/gym/envs/box2d/bipedal_walker.py,27,python gym/envs/box2d/bipedal_walker.py,not
gym/gym/envs/box2d/bipedal_walker.py,28,,not
gym/gym/envs/box2d/bipedal_walker.py,29,"State consists of hull angle speed, angular velocity, horizontal speed, vertical speed,",not
gym/gym/envs/box2d/bipedal_walker.py,30,"position of joints and joints angular speed, legs contact with ground, and 10 lidar",not
gym/gym/envs/box2d/bipedal_walker.py,31,rangefinder measurements to help to deal with the hardcore version. There's no coordinates,not
gym/gym/envs/box2d/bipedal_walker.py,32,"in the state vector. Lidar is less useful in normal version, but it works.",not
gym/gym/envs/box2d/bipedal_walker.py,33,,not
gym/gym/envs/box2d/bipedal_walker.py,34,To solve the game you need to get 300 points in 1600 time steps.,not
gym/gym/envs/box2d/bipedal_walker.py,35,,not
gym/gym/envs/box2d/bipedal_walker.py,36,To solve hardcore version you need 300 points in 2000 time steps.,not
gym/gym/envs/box2d/bipedal_walker.py,37,,not
gym/gym/envs/box2d/bipedal_walker.py,38,Created by Oleg Klimov. Licensed on the same terms as the rest of OpenAI Gym.,not
gym/gym/envs/box2d/bipedal_walker.py,41,"affects how fast-paced the game is, forces should be adjusted as well",not
gym/gym/envs/box2d/bipedal_walker.py,61,in steps,not
gym/gym/envs/box2d/bipedal_walker.py,63,"low long are grass spots, in steps",not
gym/gym/envs/box2d/bipedal_walker.py,64,in steps,not
gym/gym/envs/box2d/bipedal_walker.py,72,collide only with ground,not
gym/gym/envs/box2d/bipedal_walker.py,73,0.99 bouncy,not
gym/gym/envs/box2d/bipedal_walker.py,178,1,not
gym/gym/envs/box2d/bipedal_walker.py,277,"Sorry for the clouds, couldn't resist",not
gym/gym/envs/box2d/bipedal_walker.py,377,"self.hull.ApplyForceToCenter((0, 20), True) -- Uncomment this to receive a bit of stability help",not
gym/gym/envs/box2d/bipedal_walker.py,378,Should be easier as well,not
gym/gym/envs/box2d/bipedal_walker.py,408,"Normal angles up to 0.5 here, but sure more is possible.",not
gym/gym/envs/box2d/bipedal_walker.py,410,Normalized to get -1..1 range,not
gym/gym/envs/box2d/bipedal_walker.py,412,"This will give 1.1 on high up, but it's still OK (and there should be spikes on hiting the ground, that's normal too)",not
gym/gym/envs/box2d/bipedal_walker.py,428,moving forward is a way to receive reward (normalized to get 300 on completion),not
gym/gym/envs/box2d/bipedal_walker.py,429,"keep head straight, other than that and falling, any behavior is unpunished",not
gym/gym/envs/box2d/bipedal_walker.py,438,"normalized to about -50.0 using heuristic, more optimal agent should spend less",not
gym/gym/envs/box2d/bipedal_walker.py,507,"Heurisic: suboptimal, have no notion of balance.",not
gym/gym/envs/box2d/bipedal_walker.py,514,Will fall forward on higher speed,not
gym/gym/envs/box2d/bipedal_walker.py,536,-0.8 .. +1.1,not
gym/gym/envs/box2d/bipedal_walker.py,537,-0.6 .. +0.9,not
gym/gym/envs/box2d/bipedal_walker.py,548,supporting leg is behind,not
gym/gym/envs/box2d/bipedal_walker.py,570,PID to keep head strait,not
gym/gym/envs/box2d/bipedal_walker.py,572,"vertical speed, to damp oscillations",not
gym/gym/envs/box2d/car_dynamics.py,18,friction ~= mass ~= size^2 (calculated implicitly using density),not
gym/gym/envs/box2d/car_dynamics.py,89,wheel angle,not
gym/gym/envs/box2d/car_dynamics.py,90,angular velocity,not
gym/gym/envs/box2d/car_dynamics.py,121,"gradually increase, but stop immediately",not
gym/gym/envs/box2d/car_dynamics.py,142,Steer each wheel,not
gym/gym/envs/box2d/car_dynamics.py,147,Position => friction_limit,not
gym/gym/envs/box2d/car_dynamics.py,149,Grass friction if no tile,not
gym/gym/envs/box2d/car_dynamics.py,154,Force,not
gym/gym/envs/box2d/car_dynamics.py,158,forward speed,not
gym/gym/envs/box2d/car_dynamics.py,159,side speed,not
gym/gym/envs/box2d/car_dynamics.py,161,WHEEL_MOMENT_OF_INERTIA*np.square(w.omega)/2 = E -- energy,not
gym/gym/envs/box2d/car_dynamics.py,162,WHEEL_MOMENT_OF_INERTIA*w.omega * domega/dt = dE/dt = W -- power,not
gym/gym/envs/box2d/car_dynamics.py,163,domega = dt*W/WHEEL_MOMENT_OF_INERTIA/w.omega,not
gym/gym/envs/box2d/car_dynamics.py,165,add small coef not to divide by zero,not
gym/gym/envs/box2d/car_dynamics.py,172,radians per second,not
gym/gym/envs/box2d/car_dynamics.py,175,low speed => same as = 0,not
gym/gym/envs/box2d/car_dynamics.py,179,rotating wheel speed,not
gym/gym/envs/box2d/car_dynamics.py,180,force direction is direction of speed difference,not
gym/gym/envs/box2d/car_dynamics.py,183,Physically correct is to always apply friction_limit until speed is equal.,not
gym/gym/envs/box2d/car_dynamics.py,184,"But dt is finite, that will lead to oscillations if difference is already near zero.",not
gym/gym/envs/box2d/car_dynamics.py,186,Random coefficient to cut oscillations in few steps (have no effect on friction_limit),not
gym/gym/envs/box2d/car_dynamics.py,191,Skid trace,not
gym/gym/envs/box2d/car_dynamics.py,207,Correct physics here,not
gym/gym/envs/box2d/car_dynamics.py,228,radians,not
gym/gym/envs/classic_control/rendering.py,10,(JDS 2016/04/15): avoid bug on Anaconda 2.3.0 / Yosemite,not
gym/gym/envs/classic_control/rendering.py,47,"returns already available pyglet_display,",not
gym/gym/envs/classic_control/rendering.py,48,if there is no pyglet display available then it creates one,not
gym/gym/envs/classic_control/rendering.py,58,available screens,not
gym/gym/envs/classic_control/rendering.py,59,selecting the first screen,not
gym/gym/envs/classic_control/rendering.py,60,create GL context,not
gym/gym/envs/classic_control/rendering.py,116,"In https://github.com/openai/gym-http-api/issues/2, we",not
gym/gym/envs/classic_control/rendering.py,117,discovered that someone using Xmonad on Arch was having,not
gym/gym/envs/classic_control/rendering.py,118,"a window of size 598 x 398, though a 600 x 400 window",not
gym/gym/envs/classic_control/rendering.py,119,was requested. (Guess Xmonad was preserving a pixel for,not
gym/gym/envs/classic_control/rendering.py,120,the boundary.) So we use the buffer height/width rather,not
gym/gym/envs/classic_control/rendering.py,121,than the requested one.,not
gym/gym/envs/classic_control/rendering.py,128,Convenience,not
gym/gym/envs/classic_control/rendering.py,200,translate to GL loc ppint,not
gym/gym/envs/classic_control/rendering.py,237,draw point,not
gym/gym/envs/classic_control/rendering.py,250,draw each vertex,not
gym/gym/envs/classic_control/rendering.py,299,draw each vertex,not
gym/gym/envs/classic_control/rendering.py,329,================================================================,not
gym/gym/envs/classic_control/rendering.py,370,draw,not
gym/gym/envs/classic_control/rendering.py,374,"^^^ check sys.meta_path to avoid 'ImportError: sys.meta_path is None, Python is likely shutting down'",not
gym/gym/envs/classic_control/continuous_mountain_car.py,1,-*- coding: utf-8 -*-,not
gym/gym/envs/classic_control/continuous_mountain_car.py,38,"was 0.5 in gym, 0.45 in Arnaud de Broissia's version",not
gym/gym/envs/classic_control/continuous_mountain_car.py,84,Convert a possible numpy bool to a Python bool.,not
gym/gym/envs/classic_control/pendulum.py,42,th := theta,not
gym/gym/envs/classic_control/pendulum.py,50,for rendering,not
gym/gym/envs/classic_control/acrobot.py,14,SOURCE:,not
gym/gym/envs/classic_control/acrobot.py,15,https://github.com/rlpy/rlpy/blob/master/rlpy/Domains/Acrobot.py,not
gym/gym/envs/classic_control/acrobot.py,65,[m],not
gym/gym/envs/classic_control/acrobot.py,66,[m],not
gym/gym/envs/classic_control/acrobot.py,67,: [kg] mass of link 1,not
gym/gym/envs/classic_control/acrobot.py,68,: [kg] mass of link 2,not
gym/gym/envs/classic_control/acrobot.py,69,: [m] position of the center of mass of link 1,not
gym/gym/envs/classic_control/acrobot.py,70,: [m] position of the center of mass of link 2,not
gym/gym/envs/classic_control/acrobot.py,71,: moments of inertia for both links,not
gym/gym/envs/classic_control/acrobot.py,80,: use dynamics equations from the nips paper or the book,not
gym/gym/envs/classic_control/acrobot.py,107,Add noise to the force action,not
gym/gym/envs/classic_control/acrobot.py,111,"Now, augment the state with our force action so it can be passed to",not
gym/gym/envs/classic_control/acrobot.py,112,_dsdt,not
gym/gym/envs/classic_control/acrobot.py,116,only care about final timestep of integration returned by integrator,not
gym/gym/envs/classic_control/acrobot.py,118,omit action,not
gym/gym/envs/classic_control/acrobot.py,119,ODEINT IS TOO SLOW!,not
gym/gym/envs/classic_control/acrobot.py,120,"ns_continuous = integrate.odeint(self._dsdt, self.s_continuous, [0, self.dt])",not
gym/gym/envs/classic_control/acrobot.py,121,self.s_continuous = ns_continuous[-1] # We only care about the state,not
gym/gym/envs/classic_control/acrobot.py,122,"at the ''final timestep'', self.dt",not
gym/gym/envs/classic_control/acrobot.py,164,the following line is consistent with the description in the,not
gym/gym/envs/classic_control/acrobot.py,165,paper,not
gym/gym/envs/classic_control/acrobot.py,169,the following line is consistent with the java implementation and the,not
gym/gym/envs/classic_control/acrobot.py,170,book,not
gym/gym/envs/classic_control/acrobot.py,183,2.2 for default,not
gym/gym/envs/classic_control/acrobot.py,249,bound x between min (m) and Max (M),not
gym/gym/envs/classic_control/mountain_car.py,122,control with left and right arrow keys,not
gym/gym/envs/classic_control/cartpole.py,71,actually half the pole's length,not
gym/gym/envs/classic_control/cartpole.py,74,seconds between state updates,not
gym/gym/envs/classic_control/cartpole.py,77,Angle at which to fail the episode,not
gym/gym/envs/classic_control/cartpole.py,81,Angle limit set to 2 * theta_threshold_radians so failing observation,not
gym/gym/envs/classic_control/cartpole.py,82,is still within bounds.,not
gym/gym/envs/classic_control/cartpole.py,111,For the interested reader:,not
gym/gym/envs/classic_control/cartpole.py,112,https://coneural.org/florian/papers/05_cart_pole.pdf,not
gym/gym/envs/classic_control/cartpole.py,122,semi-implicit euler,not
gym/gym/envs/classic_control/cartpole.py,140,Pole just fell!,not
gym/gym/envs/classic_control/cartpole.py,167,TOP OF CART,not
gym/gym/envs/classic_control/cartpole.py,203,Edit the pole polygon vertex,not
gym/gym/envs/classic_control/cartpole.py,209,MIDDLE OF CART,not
gym/gym/envs/algorithmic/algorithmic_env.py,45,Only 'promote' the length of generated input strings if the worst of the,not
gym/gym/envs/algorithmic/algorithmic_env.py,46,last n episodes was no more than this far from the maximum reward,not
gym/gym/envs/algorithmic/algorithmic_env.py,58,Keep track of this many past episodes,not
gym/gym/envs/algorithmic/algorithmic_env.py,60,Cumulative reward earned this episode,not
gym/gym/envs/algorithmic/algorithmic_env.py,62,Running tally of reward shortfalls. e.g. if there were 10 points to,not
gym/gym/envs/algorithmic/algorithmic_env.py,63,"earn and we got 8, we'd append -2",not
gym/gym/envs/algorithmic/algorithmic_env.py,70,TODO: Not clear why this is a class variable rather than instance.,SATD
gym/gym/envs/algorithmic/algorithmic_env.py,71,Could lead to some spooky action at a distance if someone is working,not
gym/gym/envs/algorithmic/algorithmic_env.py,72,with multiple algorithmic envs at once. Also makes testing tricky.,not
gym/gym/envs/algorithmic/algorithmic_env.py,74,Three sub-actions:,not
gym/gym/envs/algorithmic/algorithmic_env.py,75,1. Move read head left or right (or up/down),SATD
gym/gym/envs/algorithmic/algorithmic_env.py,76,2. Write or not,not
gym/gym/envs/algorithmic/algorithmic_env.py,77,3. Which character to write. (Ignored if should_write=0),not
gym/gym/envs/algorithmic/algorithmic_env.py,81,"Can see just what is on the input tape (one of n characters, or",not
gym/gym/envs/algorithmic/algorithmic_env.py,82,nothing),not
gym/gym/envs/algorithmic/algorithmic_env.py,183,Bail as soon as a wrong character is written to the tape,not
gym/gym/envs/algorithmic/algorithmic_env.py,202,(Seemingly arbitrary),not
gym/gym/envs/algorithmic/algorithmic_env.py,209,This is before the first episode/call to reset(). Nothing to do,not
gym/gym/envs/algorithmic/reversed_addition.py,22,Quirk preserved for the sake of consistency: add the length of the input,not
gym/gym/envs/algorithmic/reversed_addition.py,23,rather than the length of the desired output (which may differ if there's,not
gym/gym/envs/algorithmic/reversed_addition.py,24,an extra carried digit).,not
gym/gym/envs/algorithmic/reversed_addition.py,25,TODO: It seems like this time limit is so strict as to make Addition3-v0,SATD
gym/gym/envs/algorithmic/reversed_addition.py,26,"unsolvable, since agents aren't even given enough time steps to look at",not
gym/gym/envs/algorithmic/reversed_addition.py,27,all the digits. (The solutions on the scoreboard seem to only work by,not
gym/gym/envs/algorithmic/reversed_addition.py,28,save-scumming.),not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,4,All concrete subclasses of AlgorithmicEnv,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,52,Kind of a hack,SATD
gym/gym/envs/algorithmic/tests/test_algorithmic.py,64,Should have leveled up on the last iteration,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,70,Walk off the end,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,75,Walk further off track,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,79,Return to the first input character,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,89,Corresponds to a grid that looks like...,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,90,0 1 2,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,91,3 4 5,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,136,Test numerical alphabet rendering,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,200,"DuplicatedInput needs to generate inputs with even length,",not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,201,so it may be short one,not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,209,"Should get ""size"" sublists, each of length self.rows (not the",not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,210,"opposite, as you might expect)",not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,223,"If requested input size isn't a multiple of duplication, go lower",not
gym/gym/envs/algorithmic/tests/test_algorithmic.py,227,"If requested input size is *less than* duplication, go up",not
gym/gym/envs/robotics/robot_env.py,52,Env methods,not
gym/gym/envs/robotics/robot_env.py,53,----------------------------,not
gym/gym/envs/robotics/robot_env.py,74,"Attempt to reset the simulator. Since we randomize initial conditions, it",not
gym/gym/envs/robotics/robot_env.py,75,is possible to get into a state with numerical issues (e.g. due to penetration or,not
gym/gym/envs/robotics/robot_env.py,76,Gimbel lock) or we may not achieve an initial condition (e.g. an object is within the hand).,not
gym/gym/envs/robotics/robot_env.py,77,"In this case, we just keep randomizing until we eventually achieve a valid initial",not
gym/gym/envs/robotics/robot_env.py,78,configuration.,not
gym/gym/envs/robotics/robot_env.py,89,self.viewer.finish(),not
gym/gym/envs/robotics/robot_env.py,97,window size used for old mujoco-py:,not
gym/gym/envs/robotics/robot_env.py,99,"original image is upside-down, so flip it",not
gym/gym/envs/robotics/robot_env.py,115,Extension methods,not
gym/gym/envs/robotics/robot_env.py,116,----------------------------,not
gym/gym/envs/robotics/utils.py,87,"obj1 is the mocap, obj2 is the welded body",not
gym/gym/envs/robotics/utils.py,90,"obj2 is the mocap, obj1 is the welded body",not
gym/gym/envs/robotics/fetch_env.py,50,GoalEnv methods,not
gym/gym/envs/robotics/fetch_env.py,51,----------------------------,not
gym/gym/envs/robotics/fetch_env.py,54,Compute distance between goal and the achieved goal.,not
gym/gym/envs/robotics/fetch_env.py,61,RobotEnv methods,not
gym/gym/envs/robotics/fetch_env.py,62,----------------------------,not
gym/gym/envs/robotics/fetch_env.py,72,ensure that we don't change the action outside of this scope,not
gym/gym/envs/robotics/fetch_env.py,75,limit maximum change in position,not
gym/gym/envs/robotics/fetch_env.py,76,"fixed rotation of the end effector, expressed as a quaternion",not
gym/gym/envs/robotics/fetch_env.py,83,Apply action to simulation.,not
gym/gym/envs/robotics/fetch_env.py,88,positions,not
gym/gym/envs/robotics/fetch_env.py,95,rotations,not
gym/gym/envs/robotics/fetch_env.py,97,velocities,not
gym/gym/envs/robotics/fetch_env.py,100,gripper state,not
gym/gym/envs/robotics/fetch_env.py,106,change to a scalar if the gripper is made symmetric,not
gym/gym/envs/robotics/fetch_env.py,133,Visualize target.,not
gym/gym/envs/robotics/fetch_env.py,142,Randomize start position of object.,not
gym/gym/envs/robotics/fetch_env.py,176,Move end effector into position.,not
gym/gym/envs/robotics/fetch_env.py,184,Extract information for sampling goals.,not
gym/gym/envs/robotics/rotations.py,1,"Copyright (c) 2009-2017, Matthew Brett and Christoph Gohlke",not
gym/gym/envs/robotics/rotations.py,2,All rights reserved.,not
gym/gym/envs/robotics/rotations.py,3,,not
gym/gym/envs/robotics/rotations.py,4,"Redistribution and use in source and binary forms, with or without",not
gym/gym/envs/robotics/rotations.py,5,"modification, are permitted provided that the following conditions are",not
gym/gym/envs/robotics/rotations.py,6,met:,not
gym/gym/envs/robotics/rotations.py,7,,not
gym/gym/envs/robotics/rotations.py,8,"1. Redistributions of source code must retain the above copyright notice,",not
gym/gym/envs/robotics/rotations.py,9,this list of conditions and the following disclaimer.,not
gym/gym/envs/robotics/rotations.py,10,,not
gym/gym/envs/robotics/rotations.py,11,2. Redistributions in binary form must reproduce the above copyright,not
gym/gym/envs/robotics/rotations.py,12,"notice, this list of conditions and the following disclaimer in the",not
gym/gym/envs/robotics/rotations.py,13,documentation and/or other materials provided with the distribution.,not
gym/gym/envs/robotics/rotations.py,14,,not
gym/gym/envs/robotics/rotations.py,15,"THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS",not
gym/gym/envs/robotics/rotations.py,16,"IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,",not
gym/gym/envs/robotics/rotations.py,17,THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR,not
gym/gym/envs/robotics/rotations.py,18,PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR,not
gym/gym/envs/robotics/rotations.py,19,"CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,",not
gym/gym/envs/robotics/rotations.py,20,"EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,",not
gym/gym/envs/robotics/rotations.py,21,"PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR",not
gym/gym/envs/robotics/rotations.py,22,PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF,not
gym/gym/envs/robotics/rotations.py,23,"LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING",not
gym/gym/envs/robotics/rotations.py,24,NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS,not
gym/gym/envs/robotics/rotations.py,25,"SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",not
gym/gym/envs/robotics/rotations.py,27,Many methods borrow heavily or entirely from transforms3d:,not
gym/gym/envs/robotics/rotations.py,28,https://github.com/matthew-brett/transforms3d,not
gym/gym/envs/robotics/rotations.py,29,They have mostly been modified to support batched operations.,not
gym/gym/envs/robotics/rotations.py,106,For testing whether a number is close to zero,not
gym/gym/envs/robotics/rotations.py,182,Fill only lower half of symmetric matrix,not
gym/gym/envs/robotics/rotations.py,195,TODO: vectorize this -- probably could be made faster,SATD
gym/gym/envs/robotics/rotations.py,199,"Use Hermitian eigenvectors, values for speed",not
gym/gym/envs/robotics/rotations.py,201,"Select largest eigenvector, reorder to w,x,y,z quaternion",not
gym/gym/envs/robotics/rotations.py,203,Prefer quaternion with positive w,not
gym/gym/envs/robotics/rotations.py,204,(q * -1 corresponds to same rotation as q),not
gym/gym/envs/robotics/rotations.py,320,"Should be in qw, qx, qy, qz",not
gym/gym/envs/robotics/hand_env.py,19,RobotEnv methods,not
gym/gym/envs/robotics/hand_env.py,20,----------------------------,not
gym/gym/envs/robotics/fetch/reach.py,6,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/fetch/push.py,6,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/fetch/slide.py,8,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/fetch/pick_and_place.py,6,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/hand/reach.py,46,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/hand/reach.py,72,GoalEnv methods,not
gym/gym/envs/robotics/hand/reach.py,73,----------------------------,not
gym/gym/envs/robotics/hand/reach.py,82,RobotEnv methods,not
gym/gym/envs/robotics/hand/reach.py,83,----------------------------,not
gym/gym/envs/robotics/hand/reach.py,112,Pick a meeting point above the hand.,not
gym/gym/envs/robotics/hand/reach.py,116,Slightly move meeting goal towards the respective finger to avoid that they,SATD
gym/gym/envs/robotics/hand/reach.py,117,overlap.,not
gym/gym/envs/robotics/hand/reach.py,125,"With some probability, ask all fingers to move back to the origin.",not
gym/gym/envs/robotics/hand/reach.py,126,This avoids that the thumb constantly stays near the goal position already.,not
gym/gym/envs/robotics/hand/reach.py,135,Visualize targets.,not
gym/gym/envs/robotics/hand/reach.py,143,Visualize finger positions.,not
gym/gym/envs/robotics/hand/manipulate_touch_sensors.py,7,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/hand/manipulate_touch_sensors.py,50,get touch sensor site names and their ids,not
gym/gym/envs/robotics/hand/manipulate_touch_sensors.py,55,set touch sensors rgba values,not
gym/gym/envs/robotics/hand/manipulate_touch_sensors.py,80,this contains the object position + rotation,not
gym/gym/envs/robotics/hand/manipulate_touch_sensors.py,81,"get touch sensor readings. if there is one, set value to 1",not
gym/gym/envs/robotics/hand/manipulate.py,22,Ensure we get the path separator correct on windows,not
gym/gym/envs/robotics/hand/manipulate.py,82,Object position and rotation.,not
gym/gym/envs/robotics/hand/manipulate.py,101,Special case: We want to ignore the Z component of the rotation.,not
gym/gym/envs/robotics/hand/manipulate.py,102,This code here assumes Euler angles with xyz convention. We first transform,not
gym/gym/envs/robotics/hand/manipulate.py,103,"to euler, then set the Z component to be equal between the two, and finally",not
gym/gym/envs/robotics/hand/manipulate.py,104,transform back into quaternions.,not
gym/gym/envs/robotics/hand/manipulate.py,110,Subtract quaternions and extract angle between them.,not
gym/gym/envs/robotics/hand/manipulate.py,117,GoalEnv methods,not
gym/gym/envs/robotics/hand/manipulate.py,118,----------------------------,not
gym/gym/envs/robotics/hand/manipulate.py,126,We weigh the difference in position to avoid that `d_pos` (in meters) is completely,not
gym/gym/envs/robotics/hand/manipulate.py,127,dominated by `d_rot` (in radians).,not
gym/gym/envs/robotics/hand/manipulate.py,130,RobotEnv methods,not
gym/gym/envs/robotics/hand/manipulate.py,131,----------------------------,not
gym/gym/envs/robotics/hand/manipulate.py,156,Randomization initial rotation.,not
gym/gym/envs/robotics/hand/manipulate.py,180,Randomize initial position.,not
gym/gym/envs/robotics/hand/manipulate.py,196,Run the simulation for a bunch of timesteps to let everything settle in.,not
gym/gym/envs/robotics/hand/manipulate.py,206,Select a goal for the object position.,not
gym/gym/envs/robotics/hand/manipulate.py,220,Select a goal for the object rotation.,not
gym/gym/envs/robotics/hand/manipulate.py,243,normalized quaternion,not
gym/gym/envs/robotics/hand/manipulate.py,248,Assign current state to target object but offset a bit so that the actual object,not
gym/gym/envs/robotics/hand/manipulate.py,249,is not obscured.,not
gym/gym/envs/robotics/hand/manipulate.py,253,Move the object to the side since we do not care about it's position.,not
gym/gym/envs/robotics/hand/manipulate.py,266,this contains the object position + rotation,not
gym/gym/envs/tests/test_envs_semantics.py,27,"This is really bad, str could be same while values change",not
gym/gym/envs/tests/test_frozenlake_dfs.py,6,Test that FrozenLake map generation creates valid maps of various sizes.,not
gym/gym/envs/tests/test_envs.py,7,This runs a smoketest on each official registered env. We may want,not
gym/gym/envs/tests/test_envs.py,8,to try also running environments which are not officially registered,not
gym/gym/envs/tests/test_envs.py,9,envs.,not
gym/gym/envs/tests/test_envs.py,12,Capture warnings,not
gym/gym/envs/tests/test_envs.py,16,Check that dtype is explicitly declared for gym.Box spaces,not
gym/gym/envs/tests/test_envs.py,33,Make sure we can render the environment after close.,not
gym/gym/envs/tests/test_envs.py,39,Run a longer rollout on some environments,not
gym/gym/envs/tests/test_kellycoinflip.py,7,https://github.com/openai/gym/issues/1266,not
gym/gym/envs/tests/test_kellycoinflip.py,14,bet 20% of the wealth,not
gym/gym/envs/tests/test_mujoco_v2_to_v3_conversion.py,71,Raises KeyError because the new envs have extra info,not
gym/gym/envs/tests/test_mujoco_v2_to_v3_conversion.py,75,Raises KeyError because the new envs have extra info,not
gym/gym/envs/tests/test_mujoco_v2_to_v3_conversion.py,79,Raises KeyError because the new envs have extra info,not
gym/gym/envs/tests/test_determinism.py,8,Note that this precludes running this test in multiple,not
gym/gym/envs/tests/test_determinism.py,9,"threads. However, we probably already can't do multithreading",not
gym/gym/envs/tests/test_determinism.py,10,due to some environments.,not
gym/gym/envs/tests/test_determinism.py,38,Don't check rollout equality if it's a a nondeterministic,not
gym/gym/envs/tests/test_determinism.py,39,environment.,not
gym/gym/envs/tests/test_determinism.py,50,"Go returns a Pachi game board in info, which doesn't",not
gym/gym/envs/tests/test_determinism.py,51,"properly check equality. For now, we hack around this by",SATD
gym/gym/envs/tests/test_determinism.py,52,just skipping Go.,not
gym/gym/envs/tests/spec_list.py,18,We skip tests for envs that require dependencies or are otherwise,not
gym/gym/envs/tests/spec_list.py,19,troublesome to run frequently,not
gym/gym/envs/tests/spec_list.py,21,Skip mujoco tests for pull request CI,not
gym/gym/envs/tests/test_registration.py,1,-*- coding: utf-8 -*-,not
gym/gym/envs/tests/test_registration.py,59,must match an env name but not the version above,not
gym/gym/envs/toy_text/cliffwalking.py,40,Cliff Location,not
gym/gym/envs/toy_text/cliffwalking.py,44,Calculate transition probabilities and rewards,not
gym/gym/envs/toy_text/cliffwalking.py,54,Calculate initial state distribution,not
gym/gym/envs/toy_text/cliffwalking.py,55,"We always start in state (3, 0)",not
gym/gym/envs/toy_text/cliffwalking.py,97,Print terminal state,not
gym/gym/envs/toy_text/hotter_colder.py,26,+/- value the randomly select number can be between,not
gym/gym/envs/toy_text/hotter_colder.py,27,Action space bounds,not
gym/gym/envs/toy_text/kellycoinflip.py,43,betting in penny,not
gym/gym/envs/toy_text/kellycoinflip.py,44,increments,not
gym/gym/envs/toy_text/kellycoinflip.py,46,"(w,b)",not
gym/gym/envs/toy_text/kellycoinflip.py,64,action = desired bet in pennies,not
gym/gym/envs/toy_text/kellycoinflip.py,114,store the hyper-parameters for passing back into __init__() during resets so,not
gym/gym/envs/toy_text/kellycoinflip.py,115,"the same hyper-parameters govern the next game's parameters, as the user",not
gym/gym/envs/toy_text/kellycoinflip.py,116,expects:,not
gym/gym/envs/toy_text/kellycoinflip.py,117,"TODO: this is boilerplate, is there any more elegant way to do this?",SATD
gym/gym/envs/toy_text/kellycoinflip.py,129,draw this game's set of parameters:,not
gym/gym/envs/toy_text/kellycoinflip.py,135,add an additional global variable which is the sufficient statistic for the,not
gym/gym/envs/toy_text/kellycoinflip.py,136,"Pareto distribution on wealth cap; alpha doesn't update, but x_m does, and",not
gym/gym/envs/toy_text/kellycoinflip.py,137,simply is the highest wealth count we've seen to date:,not
gym/gym/envs/toy_text/kellycoinflip.py,139,"for the coinflip edge, it is total wins/losses:",not
gym/gym/envs/toy_text/kellycoinflip.py,142,"for the number of rounds, we need to remember how many rounds we've played:",not
gym/gym/envs/toy_text/kellycoinflip.py,145,the rest proceeds as before:,not
gym/gym/envs/toy_text/kellycoinflip.py,148,current wealth,not
gym/gym/envs/toy_text/kellycoinflip.py,149,rounds elapsed,not
gym/gym/envs/toy_text/kellycoinflip.py,150,wins,not
gym/gym/envs/toy_text/kellycoinflip.py,151,losses,not
gym/gym/envs/toy_text/kellycoinflip.py,152,maximum observed wealth,not
gym/gym/envs/toy_text/kellycoinflip.py,189,"re-init everything to draw new parameters etc, but preserve the RNG for",not
gym/gym/envs/toy_text/kellycoinflip.py,190,reproducibility and pass in the same hyper-parameters as originally specified:,not
gym/gym/envs/toy_text/blackjack.py,8,"1 = Ace, 2-10 = Number cards, Jack/Queen/King = 10",not
gym/gym/envs/toy_text/blackjack.py,20,Does this hand have a usable ace?,not
gym/gym/envs/toy_text/blackjack.py,24,Return current hand total,not
gym/gym/envs/toy_text/blackjack.py,30,Is this hand a bust?,not
gym/gym/envs/toy_text/blackjack.py,34,What is the score of this hand (0 if bust),not
gym/gym/envs/toy_text/blackjack.py,38,Is this hand a natural blackjack?,not
gym/gym/envs/toy_text/blackjack.py,81,"Flag to payout 1.5 on a ""natural"" blackjack win, like casino rules",not
gym/gym/envs/toy_text/blackjack.py,82,Ref: http://www.bicyclecards.com/how-to-play/blackjack/,not
gym/gym/envs/toy_text/blackjack.py,84,Start the first game,not
gym/gym/envs/toy_text/blackjack.py,93,hit: add a card to players hand and return,not
gym/gym/envs/toy_text/blackjack.py,101,"stick: play out the dealers hand, and score",not
gym/gym/envs/toy_text/discrete.py,34,for rendering,not
gym/gym/envs/toy_text/roulette.py,30,"observation, reward, done, info",not
gym/gym/envs/toy_text/roulette.py,33,"N.B. np.random.randint draws from [A, B) while random.randint draws from [A,B]",not
gym/gym/envs/toy_text/taxi.py,86,+1 for being inside taxi,not
gym/gym/envs/toy_text/taxi.py,92,defaults,not
gym/gym/envs/toy_text/taxi.py,94,default reward when there is no pickup/dropoff,not
gym/gym/envs/toy_text/taxi.py,106,pickup,not
gym/gym/envs/toy_text/taxi.py,109,passenger not at location,not
gym/gym/envs/toy_text/taxi.py,111,dropoff,not
gym/gym/envs/toy_text/taxi.py,118,dropoff at wrong location,not
gym/gym/envs/toy_text/taxi.py,129,"(5) 5, 5, 4",not
gym/gym/envs/toy_text/taxi.py,164,passenger in taxi,not
gym/gym/envs/toy_text/taxi.py,175,No need to return anything for human,not
gym/gym/envs/toy_text/guessing_game.py,41,Randomly selected number is within +/- this value,not
gym/gym/envs/toy_text/frozen_lake.py,42,DFS to check that it's a valid path.,not
gym/gym/envs/toy_text/nchain.py,26,probability of 'slipping' an action,not
gym/gym/envs/toy_text/nchain.py,27,payout for 'backwards' action,not
gym/gym/envs/toy_text/nchain.py,28,payout at end of chain for 'forwards' action,not
gym/gym/envs/toy_text/nchain.py,29,Start at beginning of the chain,not
gym/gym/envs/toy_text/nchain.py,41,"agent slipped, reverse action taken",not
gym/gym/envs/toy_text/nchain.py,42,"'backwards': go back to the beginning, get small reward",not
gym/gym/envs/toy_text/nchain.py,45,'forwards': go up along the chain,not
gym/gym/envs/toy_text/nchain.py,48,"'forwards': stay at the end of the chain, collect large reward",not
gym/gym/envs/mujoco/mujoco_env.py,85,methods to override:,not
gym/gym/envs/mujoco/mujoco_env.py,86,----------------------------,not
gym/gym/envs/mujoco/mujoco_env.py,103,-----------------------------,not
gym/gym/envs/mujoco/mujoco_env.py,146,window size used for old mujoco-py:,not
gym/gym/envs/mujoco/mujoco_env.py,148,"original image is upside-down, so flip it",not
gym/gym/envs/mujoco/mujoco_env.py,152,window size used for old mujoco-py:,not
gym/gym/envs/mujoco/mujoco_env.py,153,Extract depth part of the read_pixels() tuple,not
gym/gym/envs/mujoco/mujoco_env.py,155,"original image is upside-down, so flip it",not
gym/gym/envs/mujoco/mujoco_env.py,162,self.viewer.finish(),not
gym/gym/envs/mujoco/__init__.py,2,^^^^^ so that user gets the correct error,not
gym/gym/envs/mujoco/__init__.py,3,message if mujoco is not installed correctly,not
gym/gym/envs/mujoco/inverted_double_pendulum.py,25,cart x pos,not
gym/gym/envs/mujoco/inverted_double_pendulum.py,26,link angles,not
gym/gym/envs/mujoco/inverted_double_pendulum.py,43,v.model.stat.center[2],not
gym/gym/envs/atari/atari_env.py,61,Tune (or disable) ALE's action repeat:,not
gym/gym/envs/atari/atari_env.py,62,https://github.com/openai/gym/issues/349,not
gym/gym/envs/atari/atari_env.py,85,"Derive a random seed. This gets passed as a uint, but gets",not
gym/gym/envs/atari/atari_env.py,86,"checked as an int elsewhere, so we need to keep it below",not
gym/gym/envs/atari/atari_env.py,87,2**31.,not
gym/gym/envs/atari/atari_env.py,89,"Empirically, we need to seed before loading the ROM.",not
gym/gym/envs/atari/atari_env.py,142,"return: (states, observations)",not
gym/tests/gym/wrappers/flatten_test.py,88,make sure that unflatten(flatten(original)) == original,not
gym/tests/gym/wrappers/flatten_test.py,94,make sure that the values were flattened in the order they appeared in the,not
gym/tests/gym/wrappers/flatten_test.py,95,OrderedDict,not
gym/tests/gym/wrappers/nested_dict_test.py,82,Make sure we are testing the right environment for the test.,not
gym/scripts/generate_json.py,28,Skip platform-dependent,not
gym/scripts/generate_json.py,33,Skip environments that are nondeterministic,not
gym/scripts/generate_json.py,43,"If running the env generates an exception, don't write to the rollout file",not
gym/examples/agents/_policies.py,1,Support code for cem.py,not
gym/examples/agents/keyboard_agent.py,1,!/usr/bin/env python,not
gym/examples/agents/keyboard_agent.py,4,,not
gym/examples/agents/keyboard_agent.py,5,"Test yourself as a learning agent! Pass environment name as a command-line argument, for example:",not
gym/examples/agents/keyboard_agent.py,6,,not
gym/examples/agents/keyboard_agent.py,7,python keyboard_agent.py SpaceInvadersNoFrameskip-v4,not
gym/examples/agents/keyboard_agent.py,8,,not
gym/examples/agents/keyboard_agent.py,15,"Use previous control decision SKIP_CONTROL times, that's how you",not
gym/examples/agents/keyboard_agent.py,16,can test what skip is still usable.,not
gym/examples/agents/keyboard_agent.py,50,"print(""taking action {}"".format(human_agent_action))",not
gym/examples/agents/cem.py,7,Different file so it can be unpickled,not
gym/examples/agents/cem.py,66,You provide the directory to write to (can be an existing,not
gym/examples/agents/cem.py,67,"directory, but can't contain previous monitor results. You can",not
gym/examples/agents/cem.py,68,also dump to a tempdir if you'd like: tempfile.mkdtemp().,not
gym/examples/agents/cem.py,72,Prepare snapshotting,not
gym/examples/agents/cem.py,73,----------------------------------------,not
gym/examples/agents/cem.py,80,------------------------------------------,not
gym/examples/agents/cem.py,87,"Train the agent, and snapshot each stage",not
gym/examples/agents/cem.py,95,Write out the env at the end so we store the parameters of this,not
gym/examples/agents/cem.py,96,environment.,not
gym/examples/agents/random_agent.py,20,You can set the level to logger.DEBUG or logger.WARN if you,not
gym/examples/agents/random_agent.py,21,want to change the amount of output.,not
gym/examples/agents/random_agent.py,26,You provide the directory to write to (can be an existing,not
gym/examples/agents/random_agent.py,27,"directory, including one with existing data -- all monitor files",not
gym/examples/agents/random_agent.py,28,will be namespaced). You can also dump to a tempdir if you'd,not
gym/examples/agents/random_agent.py,29,like: tempfile.mkdtemp().,not
gym/examples/agents/random_agent.py,46,Note there's no env.render() here. But the environment still can open window and,not
gym/examples/agents/random_agent.py,47,render if asked by env.monitor: it calls env.render('rgb_array') to record video.,not
gym/examples/agents/random_agent.py,48,"Video is not recorded every episode, see capped_cubic_video_schedule for details.",not
gym/examples/agents/random_agent.py,50,Close the env and write monitor result info to disk,not
