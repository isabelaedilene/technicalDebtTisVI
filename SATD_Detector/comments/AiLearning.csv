file path,line #,comment,satd
AiLearning/tool/DecisionTree_getInfoGain.py,1,!/usr/bin/python,not
AiLearning/tool/DecisionTree_getInfoGain.py,2,coding: utf8,not
AiLearning/tool/DecisionTree_getInfoGain.py,17,求list的长度，表示计算参与训练的数据量,not
AiLearning/tool/DecisionTree_getInfoGain.py,19,"print(type(dataSet), 'numEntries: ', numEntries)",not
AiLearning/tool/DecisionTree_getInfoGain.py,21,计算分类标签label出现的次数,not
AiLearning/tool/DecisionTree_getInfoGain.py,23,the the number of unique elements and their occurance,not
AiLearning/tool/DecisionTree_getInfoGain.py,29,"print('-----', featVec, labelCounts)",not
AiLearning/tool/DecisionTree_getInfoGain.py,31,对于label标签的占比，求出label标签的香农熵,not
AiLearning/tool/DecisionTree_getInfoGain.py,35,log base 2,not
AiLearning/tool/DecisionTree_getInfoGain.py,37,"print('---', prob, prob * log(prob, 2), shannonEnt)",not
AiLearning/tool/DecisionTree_getInfoGain.py,55,axis列为value的数据集【该数据集需要排除axis列】,not
AiLearning/tool/DecisionTree_getInfoGain.py,57,chop out axis used for splitting,not
AiLearning/tool/DecisionTree_getInfoGain.py,63,收集结果值 axis列为value的行【该行需要排除axis列】,not
AiLearning/tool/DecisionTree_getInfoGain.py,78,求第一行有多少列的 Feature,not
AiLearning/tool/DecisionTree_getInfoGain.py,80,label的信息熵,not
AiLearning/tool/DecisionTree_getInfoGain.py,82,"最优的信息增益值, 和最优的Featurn编号",not
AiLearning/tool/DecisionTree_getInfoGain.py,84,iterate over all the features,not
AiLearning/tool/DecisionTree_getInfoGain.py,86,create a list of all the examples of this feature,not
AiLearning/tool/DecisionTree_getInfoGain.py,87,获取每一个feature的list集合,not
AiLearning/tool/DecisionTree_getInfoGain.py,89,get a set of unique values,not
AiLearning/tool/DecisionTree_getInfoGain.py,90,获取剔重后的集合,not
AiLearning/tool/DecisionTree_getInfoGain.py,92,创建一个临时的信息熵,not
AiLearning/tool/DecisionTree_getInfoGain.py,94,遍历某一列的value集合，计算该列的信息熵,not
AiLearning/tool/DecisionTree_getInfoGain.py,99,gain[信息增益] 值越大，意味着该分类提供的信息量越大，该特征对分类的不确定程度越小,not
AiLearning/tool/DecisionTree_getInfoGain.py,100,"gain[信息增益]=0, 表示与类别相同，无需其他的分类",not
AiLearning/tool/DecisionTree_getInfoGain.py,101,"gain[信息增益]=baseEntropy, 表示分类和没分类没有区别",not
AiLearning/tool/DecisionTree_getInfoGain.py,103,print(infoGain),not
AiLearning/tool/python2libsvm.py,1,!/usr/bin/python,not
AiLearning/tool/python2libsvm.py,2,coding:utf8,not
AiLearning/tool/python2libsvm.py,24,print len(features),not
AiLearning/tool/python2libsvm.py,29,print svm_format,not
AiLearning/tool/python2libsvm.py,31,print svm_format,not
AiLearning/tool/python2libsvm.py,48,获取数据集,not
AiLearning/tool/python2libsvm.py,52,导出数据为 libsvm,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,1,*-* coding:utf-8 *-*,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,16,该目录下的 config.py文件， 数据文件是: poetry.txt,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,21,读取文本内容，合并到一个大字符中，用 ] 隔开,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,25,"每行的末尾加上""]""符号代表一首诗结束",not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,29,按照字存到字典中，字+频率,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,38,去掉低频的字,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,39,"[('。', 567), ('，', 565), ('风', 47), ('花', 42), ('云', 40)]",not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,41,print(wordPairs),not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,44,word到id的映射,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,58,文件预处理,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,61,如果模型文件存在则直接加载模型，否则开始训练,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,79,设置优化器,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,91,如果给的text不到四个字，则随机补全,not
AiLearning/src/py3.x/tensorflow2.x/text_PoetryModel.py,122,如果越界了，就从0再开始,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,24,save initial config data,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,34,"in windows the new line is '\r\n\r\n' the space is '\r\n' . so if you use windows system,",not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,35,you have to use recorsponding instructions,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,54,set to <unk> (index 1) if not in vocab,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,58,left padding,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,73,left padding,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,84,Random embedding,not
AiLearning/src/py3.x/tensorflow2.x/text_NER.py,99,train model,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,1,-*- coding: utf-8 -*-,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,17,Commented out IPython magic to ensure Python compatibility.,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,21,Colab only,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,22,%tensorflow_version 2.x,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,65,一个映射单词到整数索引的词典,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,68,保留第一个索引,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,72,unknown,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,125,"输入形状是用于电影评论的词汇数目（10,000 词）",not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,217,"“bo”代表 ""蓝点""",not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,219,b代表“蓝色实线”,not
AiLearning/src/py3.x/tensorflow2.x/text_classification.py,228,清除数字,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,1,%%,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,2,-*- coding: utf-8 -*-,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,6,%%,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,7,载入并准备好 MNIST 数据集,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,8,存放地址: /home/xxx/.keras/datasets/mnist.npz,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,13,%%,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,14,将模型的各层堆叠起来，以搭建 tf.keras.Sequential 模型。为训练选择优化器和损失函数：,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,22,%%,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,27,%%,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,28,训练模型,not
AiLearning/src/py3.x/tensorflow2.x/quickstart.py,30,验证模型,not
AiLearning/src/py3.x/tensorflow2.x/config.py,1,*-* coding:utf-8 *-*,not
AiLearning/src/py3.x/tensorflow2.x/config.py,15,根据前六个字预测第七个字,not
AiLearning/src/py3.x/tensorflow2.x/config.py,20,每个文本或者句子的截断长度，只保留1000个单词,not
AiLearning/src/py3.x/tensorflow2.x/config.py,21,词向量维度,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,1,*-* coding:utf-8 *-*,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,2,词向量:,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,3,https://www.cnblogs.com/Darwin2000/p/5786984.html,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,4,数据集:,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,5,https://blog.csdn.net/alip39/article/details/95891321,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,6,参考代码:,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,7,https://blog.csdn.net/u012052268/article/details/90238282,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,8,Attention:,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,9,https://github.com/philipperemy/keras-attention-mechanism,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,31,存储模型: 持久化,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,43,训练自己的词向量，并保存。,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,45,读取分词后的 文本,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,46,训练模型,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,51,导入 预训练的词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,57,训练词向量(用空格隔开的文本),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,60,"trainWord2Vec(infile, outfile)",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,61,加载词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,67,2 构造包含所有词语的 list，以及初始化 “词语-序号”字典 和 “词向量”矩阵,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,68,存储 所有的 词语,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,70,初始化 `[word : token]` ，后期 tokenize 语料库就是用该词典。,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,71,初始化`[word : vector]`字典,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,73,初始化存储所有向量的大矩阵，留意其中多一位（首行），词向量全为 0，用于 padding补零。,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,74,行数 为 所有单词数+1 比如 10000+1 ； 列数为 词向量“维度”比如60。,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,77,3 填充 上述 的字典 和 大矩阵,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,79,print(i),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,80,每个词语,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,81,词语：序号,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,82,词语：词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,83,词向量矩阵,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,96,"“bo”代表 ""蓝点""",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,98,b代表“蓝色实线”,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,105,plt.show(),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,107,清除数字,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,116,plt.show(),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,130,如果模型文件存在则直接加载模型，否则开始训练,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,138,4 在 keras的Embedding层中使用 预训练词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,140,字典长度,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,141,词向量 长度（60）,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,142,重点：预训练的词向量系数,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,143,每句话的 最大长度（必须padding）,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,144,是否在 训练的过程中 更新词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,146,如果不加载外界的，可以自己训练,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,147,可以看出在使用 Keras的中Embedding层时候，不指定参数 weights=[embeddings_matrix] 即可自动生成词向量。,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,148,embedding_layer = Embedding(,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,149,"input_dim = len(word_index) + 1, # 由于 没有预训练，设置+1",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,150,"output_dim = EMBEDDING_DIM, # 设置词向量的维度",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,151,input_length=MAX_SEQUENCE_LENGTH,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,152,) #设置句子的最大长度,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,154,返回一个张量，长度为1000，也就是模型的输入为batch_size*1000,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,155,返回batch_size*1000*100,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,156,添加 注意力(本质上是通过加入  一个随机向量 作为 权重 来优化 输入的值 - 与全链接不同的是，这个还会作为输入项 和 输入做点乘 ),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,162,x = BatchNormalization()(x),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,165,设置优化器,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,194,"将文本 ['1, 2, 3', '1, 2, .., n'] 分解为: [[1, 2, 3], [1, 2, .., n]]",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,203,"按照大小和顺序，生成 label(0,1,2...自然数类型)",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,230,画相关的 loss 和 accuracy=(预测正确-正or负/总预测的),not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,234,"self.model.fit(x_train, y_train, batch_size=60, epochs=40)",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,240,测试加载外界word2vec词向量,not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,241,"vocab_list, word_index, embeddings_matrix = load_embeding()",not
AiLearning/src/py3.x/tensorflow2.x/text_Emotion.py,248,首次启动加载jieba词库,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,1,-*- coding: utf-8 -*-,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,16,使用 seaborn 绘制矩阵图 (pairplot),not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,19,Commented out IPython magic to ensure Python compatibility.,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,29,%tensorflow_version only exists in Colab.,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,30,%tensorflow_version 2.x,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,175,通过为每个完成的时期打印一个点来显示训练进度,not
AiLearning/src/py3.x/tensorflow2.x/text_regression.py,230,patience 值用来检查改进 epochs 的数量,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,2,coding: utf-8,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,3,# 探索过拟合和欠拟合,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,5,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,6,与往常一样，此示例中的代码将使用 `tf.keras` API，您可以在TensorFlow [Keras 指南](https://www.tensorflow.org/guide/keras)中了解更多信息。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,7,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,8,在前面的两个示例（对电影评论进行分类和预测燃油效率）中，我们看到了在验证数据上的模型的准确性在经过多个时期的训练后将达到峰值，然后开始下降。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,9,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,10,换句话说，我们的模型将 *过拟合* 训练数据。学习如何应对过拟合很重要。尽管通常可以在*训练集*上达到高精度，但我们真正想要的是开发能够很好地推广到*测试集*（或之前未见的数据）的模型。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,11,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,12,过拟合的反面是*欠拟合*。当测试数据仍有改进空间时，就会发生欠拟合。发生这种情况的原因有很多：如果模型不够强大，模型过于规范化，或者仅仅是没有经过足够长时间的训练。这意味着网络尚未学习训练数据中的相关模式。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,13,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,14,但是，如果训练时间过长，则模型将开始过拟合并从训练数据中学习无法推广到测试数据的模式。我们需要保持平衡。如下所述，了解如何训练适当的时期是一项有用的技能。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,15,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,16,为了防止过拟合，最好的解决方案是使用更多的训练数据。经过更多数据训练的模型自然会更好地推广。当这不再可能时，下一个最佳解决方案是使用正则化之类的技术。这些因素限制了模型可以存储的信息的数量和类型。如果一个网络只能存储少量模式，那么优化过程将迫使它专注于最突出的模式，这些模式有更好的概括机会。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,17,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,18,在本笔记本中，我们将探讨两种常见的正则化技术（权重正则化和 dropout），并使用它们来改进我们的IMDB电影评论分类笔记本。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,21,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,27,%tensorflow_version only exists in Colab.,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,40,## 下载IMDB数据集,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,41,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,42,而不是像以前的笔记本中那样使用embedding，这里我们将对句子进行 multi-hot 编码。 该模型将很快适合训练集。 它将用于演示何时发生过拟合以及如何应对。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,43,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,44,"对列表进行 multi-hot 编码意味着将它们变成0和1的向量。 具体来说，这意味着例如将序列 `[3, 5]` 变成10,000维向量，该向量除了索引3和5将是1，其他将是全为零。",not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,46,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,54,"Create an all-zero matrix of shape (len(sequences), dimension)",not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,57,set specific indices of results[i] to 1s,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,65,让我们看一下产生的 multi-hot 向量之一。 单词索引按频率排序，因此可以预期在索引零附近有更多的1值，如我们在该图中所看到的：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,66,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,67,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,68,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,69,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,71,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,77,## 证明过拟合,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,78,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,79,防止过拟合的最简单方法是减小模型的大小，即减小模型中可学习的参数的数量（由层数和每层单元数确定）。在深度学习中，模型中可学习参数的数量通常称为模型的“容量”。直观地讲，具有更多参数的模型将具有更多的“记忆能力”，因此将能够轻松学习训练样本与其目标之间的完美的字典式映射，这种映射没有任何泛化能力，但是在进行预测时这将是无用的根据以前看不见的数据。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,80,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,81,始终牢记这一点：深度学习模型往往擅长拟合训练数据，但真正的挑战是泛化而不是拟合。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,82,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,83,另一方面，如果网络的存储资源有限，则将无法轻松地学习映射。为了最大程度地减少损失，它必须学习具有更强预测能力的压缩表示形式。同时，如果您使模型过小，将难以拟合训练数据。 “容量过多”和“容量不足”之间存在平衡。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,84,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,85,不幸的是，没有神奇的公式来确定模型的正确大小或体系结构（根据层数或每层的正确大小）。您将不得不尝试使用一系列不同的体系结构。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,86,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,87,为了找到合适的模型大小，最好从相对较少的图层和参数开始，然后开始增加图层的大小或添加新的图层，直到看到验证损失的收益递减为止。让我们在电影评论分类网络上尝试一下。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,88,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,89,我们将仅使用 `Dense` 层作为基准来创建一个简单的模型，然后创建较小和较大的版本并进行比较。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,90,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,91,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,93,### Create a baseline model,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,95,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,99,`input_shape` is only required here so that `.summary` works.,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,112,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,123,### 创建 smaller model,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,124,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,125,让我们创建一个隐藏单元更少的模型，以与我们刚刚创建的基线模型进行比较：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,127,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,143,并使用相同的数据训练模型：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,145,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,156,### 创建 bigger model,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,157,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,158,作为练习，您可以创建一个更大的模型，并查看它开始过拟合的速度。 接下来，让我们将具有更大容量的网络添加到此基准网络中，远远超出问题所能保证的范围：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,160,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,176,再次，使用相同的数据训练模型：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,178,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,188,### 绘制训练和验证损失,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,189,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,190,<!--TODO(markdaoust): This should be a one-liner with tensorboard -->,SATD
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,191,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,192,实线表示训练损失，而虚线表示验证损失（请记住：验证损失越小表示模型越好）。 在这里，较小的网络比基准模型开始过度拟合（在6个时期而不是4个周期之后），并且一旦开始过度拟合，其性能下降的速度就会慢得多。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,193,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,195,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,219,请注意，较大的网络仅在一个时期后就开始过拟合，而且过拟合严重。网络的容量越多，将能够更快地对训练数据进行建模（导致较低的训练损失），但网络越容易过拟合（导致训练和验证损失之间存在较大差异）。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,221,## 防止过度拟合的策略,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,223,### 添加权重正则化,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,225,您可能熟悉Occam的Razor原理：给某事两种解释，最可能正确的解释是“最简单”的解释，即假设最少的一种。这也适用于通过神经网络学习的模型：给定一些训练数据和网络体系结构，可以使用多组权重值（多个模型）来解释数据，并且较简单的模型比复杂的模型不太可能过拟合。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,226,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,227,在这种情况下，“简单模型”是参数值的分布具有较小熵的模型（或如上节所述，具有总共较少参数的模型）。因此，减轻过拟合的一种通用方法是通过仅将网络的权重强制取小的值来对网络的复杂性施加约束，这使得权重值的分布更加“规则”。这称为“权重调整”，它是通过向网络的损失函数中添加与权重较大相关的成本来完成的。以下有两种形式：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,228,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,229,* [L1正则化](https://developers.google.com/machine-learning/glossary/#L1_regularization)，其中增加的成本与权重系数的绝对值成正比（即所谓的“ L1规范” ”）。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,230,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,231,* [L2正则化](https://developers.google.com/machine-learning/glossary/#L2_regularization)，其中增加的成本与权重系数的值的平方成正比（即与平方的平方成正比）权重的“ L2规范”。 L2正则化在神经网络中也称为权重衰减。不要让其他名称使您感到困惑：权重衰减在数学上与L2正则化完全相同。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,232,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,233,L1正则化引入稀疏性，以使您的某些权重参数为零。 L2正则化将惩罚权重参数而不使其稀疏，这是L2更为常见的原因之一。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,234,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,235,在 `tf.keras` 中，通过将权重正则化器实例作为关键字参数传递给图层来添加权重正则化。让我们现在添加L2权重正则化。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,237,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,259,`l2(0.001)` 表示该层权重矩阵中的每个系数将为网络的总损耗增加 `0.001 * weight_coefficient_value**2`。 请注意，由于此惩罚仅在训练时增加，因此在训练时此网络的损失将比在测试时高得多。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,260,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,261,这是我们的L2正则化惩罚的影响：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,262,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,264,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,271,如您所见，即使两个模型具有相同数量的参数，L2正则化模型也比基线模型具有更高的抗过度拟合能力。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,273,### 添加 dropout,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,274,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,275,"dropout 是 Hinton 和他在多伦多大学的学生开发的最有效，最常用的神经网络正则化技术之一。应用于图层的辍学包括在训练过程中随机“dropping out”（即设置为零）该图层的许多输出特征。假设在训练过程中，给定的图层通常会为给定的输入样本返回向量  [0.2, 0.5, 1.3, 0.8, 1.1]；应用删除后，此向量将有一些零个条目随机分布，例如 [0, 0.5, 1.3, 0, 1.1]。 “dropout 率”是被清零的特征的一部分。通常设置在0.2到0.5之间。在测试时，不会丢失任何单元，而是将图层的输出值按等于丢失率的比例缩小，以平衡一个活跃的单元（而不是训练时）的事实。",not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,276,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,277,在tf.keras中，您可以通过Dropout层在网络中引入Dropout，该层将立即应用于该层的输出。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,278,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,279,让我们在IMDB网络中添加两个Dropout层，看看它们在减少过拟合方面的表现如何：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,281,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,303,In[ ]:,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,310,添加 dropout 是对基线模型的明显改进。,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,311,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,312,回顾一下：以下是防止神经网络过拟合的最常用方法：,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,313,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,314,* 获取更多训练数据,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,315,* 减少网络容量,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,316,* 添加权重调整,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,317,* 添加 dropout,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,318,,not
AiLearning/src/py3.x/tensorflow2.x/overfit_and_underfit.py,319,本指南未涵盖的两个重要方法是数据增强和批处理规范化。,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/train.py,5,train model,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,16,save initial config data,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,26,"in windows the new line is '\r\n\r\n' the space is '\r\n' . so if you use windows system,",not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,27,you have to use recorsponding instructions,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,46,set to <unk> (index 1) if not in vocab,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,50,left padding,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/process_data.py,65,left padding,not
AiLearning/src/py3.x/tensorflow2.x/zh-NER-keras-master/bilsm_crf_model.py,18,Random embedding,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,13,逻辑回归中的 L1 惩罚和稀缺性 L1 Penalty and Sparsity in Logistic Regression,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,77,具有 L1-逻辑回归的路径,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,121,绘制多项式和一对二的逻辑回归 Plot multinomial and One-vs-Rest Logistic Regression,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,183,Logistic Regression 3-class Classifier 逻辑回归 3-类 分类器,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,191,引入一些数据来玩,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,193,我们只采用样本数据的前两个feature,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,197,网格中的步长,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,201,我们创建了一个 Neighbours Classifier 的实例，并拟合数据。,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,204,"绘制决策边界。为此我们将为网格 [x_min, x_max]x[y_min, y_max] 中的每个点分配一个颜色。",not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,210,将结果放入彩色图中,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,215,将训练点也同样放入彩色图中,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,227,Logistic function 逻辑回归函数,not
AiLearning/src/py3.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,228,这个类似于咱们之前讲解 logistic 回归的 Sigmoid 函数，模拟的阶跃函数,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,15,------使用 Logistic 回归在简单数据集上的分类-----------,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,29,为了方便计算，我们将 X0 的值设为 1.0 ，也就是在每一行的开头添加一个 1.0 作为 X0,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,36,这里其实非常有必要解释一下，会出现的错误 RuntimeWarning: overflow encountered in exp,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,37,这个错误在学习阶段虽然可以忽略，但是我们至少应该知道为什么,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,38,这里是因为我们输入的有的 x 实在是太小了，比如 -6000之类的，那么计算一个数字 np.exp(6000)这个结果太大了，没法表示，所以就溢出了,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,39,如果是计算 np.exp（-6000），这样虽然也会溢出，但是这是下溢，就是表示成零,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,40,去网上搜了很多方法，比如 使用bigfloat这个库（我竟然没有安装成功，就不尝试了，反正应该是有用的,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,52,"注意一下，我把原来 data_mat_in 改成data_arr,因为传进来的是一个数组，用这个比较不容易搞混",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,53,turn the data_arr to numpy matrix,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,55,变成矩阵之后进行转置,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,57,m->数据量，样本数 n->特征数,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,59,学习率，learning rate,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,61,最大迭代次数，假装迭代这么多次就能收敛2333,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,63,"生成一个长度和特征数相同的矩阵，此处n为3 -> [[1],[1],[1]]",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,64,"weights 代表回归系数， 此处的 ones((n,1)) 创建一个长度和特征数相同的矩阵，其中的数全部都是 1",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,67,这里是点乘  m x 3 dot 3 x 1,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,70,这里比较建议看一下推导，为什么这么做可以，这里已经是求导之后的,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,127,"sum(data_mat[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn,",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,128,此处求出的 h 是一个具体的数值，而不是一个矩阵,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,131,还是和上面一样，这个先去看推导，再写程序,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,147,这里必须要用list，不然后面的del没法使用,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,150,i和j的不断增大，导致alpha的值不断减少，但是不为0,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,152,随机产生一个 0～len()之间的一个值,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,153,"random.uniform(x, y) 方法将随机生成下一个实数，它在[x,y]范围内,x是这个范围内的最小值，y是这个范围内的最大值。",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,168,"注意，这里的grad_ascent返回的是一个 matrix, 所以要使用getA方法变成ndarray类型",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,169,"weights = grad_ascent(data_arr, class_labels).getA()",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,170,"weights = stoc_grad_ascent0(np.array(data_arr), class_labels)",not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,175,-------从疝气病症预测病马的死亡率------,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,185,print(np.sum(in_x * weights)),not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,201,解析训练数据集中的数据特征和Labels,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,202,trainingSet 中存储训练数据集的特征，trainingLabels 存储训练数据集的样本对应的分类标签,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,206,这里如果就一个空的元素，则跳过本次循环,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,210,使用 改进后的 随机梯度下降算法 求得在此数据集上的最佳回归系数 trainWeights,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,214,读取 测试数据集 进行测试，计算分类错误的样本条数和最终的错误率,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,219,这里如果就一个空的元素，则跳过本次循环,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,241,请依次运行下面三个函数做代码测试,not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,243,colic_test(),not
AiLearning/src/py3.x/ml/5.Logistic/logistic.py,244,multi_test(),not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于物品.py,6,calculate co-rated users between items,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于物品.py,17,calculate finial similarity matrix W,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于物品.py,26,calculate co-rated users between items,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于物品.py,37,calculate finial similarity matrix W,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-item.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-item.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,18,加载数据集,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,33,创建用户产品矩阵，针对测试数据和训练数据，创建两个矩阵：,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,41,使用sklearn的pairwise_distances函数来计算余弦相似性。,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,42,行：人，列：电影,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,43,行：电影，列：人,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,50,统计在所有的用户中，不同电影的总出现次数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,54,"print ""pop="", i_index, self.item_popular[i_index]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,56,save the total number of items,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,68,求出每一个用户，所有电影的综合评分（axis=0 表示对列操作， 1表示对行操作）,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,69,"print ""rating="", np.shape(rating)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,71,np.newaxis参考地址: http://blog.csdn.net/xtingjie/article/details/72510834,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,72,"print ""mean_user_rating="", np.shape(mean_user_rating)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,73,"print ""mean_user_rating.newaxis="", np.shape(mean_user_rating[:, np.newaxis])",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,75,"print ""rating="", rating[:3, :3]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,76,"print ""mean_user_rating[:, np.newaxis]="", mean_user_rating[:, np.newaxis][:3, :3]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,77,"print ""rating_diff="", rating_diff[:3, :3]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,79,"均分  +  人-人-距离(943, 943)*人-电影-评分diff(943, 1682)=结果-人-电影（每个人对同一电影的综合得分）(943, 1682)  再除以  个人与其他人总的距离 = 人-电影综合得分",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,83,"综合打分： 人-电影-评分(943, 1682)*电影-电影-距离(1682, 1682)=结果-人-电影(各个电影对同一电影的综合得分)(943, 1682)  ／  再除以  电影与其他电影总的距离 = 人-电影综合得分",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,109,"对比测试集和推荐集的差异 item, w",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,115,计算用户对应的电影出现次数log值的sum加和,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,144,基于内存的协同过滤,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,145,...,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,146,拆分数据集,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,147,http://files.grouplens.org/datasets/movielens/ml-100k.zip,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,152,计算相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,159,评估：均方根误差,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,165,基于模型的协同过滤,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,166,...,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,167,计算MovieLens数据集的稀疏度 （n_users，n_items 是常量，所以，用户行为数据越少，意味着信息量少；越稀疏，优化的空间也越大）,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,171,计算稀疏矩阵的最大k个奇异值/向量,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-sklearn-rating.py,189,推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-user.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-user.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_graph-based.py,8,"j, wij",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_evaluation_model.py,16,准确率,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_evaluation_model.py,30,召回率,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_evaluation_model.py,44,覆盖率,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_evaluation_model.py,57,新颖度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo.py,11,设有2个隐主题,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,22,作用：使得随机数据可预测,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,30,拆分数据集,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,34,总用户数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,38,n_sim_user: top 20个用户， n_rec_item: top 10个推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,42,item_mat_similarity: 电影之间的相似度， item_popular: 电影的出现次数， item_count: 总电影数量,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,51,加载数据集,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,61,拆分数据集： 用户+电影,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,69,创建用户产品矩阵，针对测试数据和训练数据，创建两个矩阵：,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,76,"print ""line"", line.user_id-1, line.item_id-1, line.rating",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,80,使用sklearn的pairwise_distances函数来计算余弦相似性。,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,81,行：电影，列：人,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,82,"电影-电影-距离(1682, 1682)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,90,统计在所有的用户中，不同电影的总出现次数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,95,"print ""pop="", i_index, self.item_popular[i_index]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,97,save the total number of items,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,101,@profile,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,115,"print ""i_items="", i_items",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,118,计算top K 电影的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,119,"rating=电影评分, w=不同电影出现的次数",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,120,耗时分析：98.2%的时间在 line-154行,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,135,return the N best items,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,142,varables for precision and recall,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,143,hit表示命中(测试集和推荐集相同+1)，rec_count 每个用户的推荐数， test_count 每个用户对应的测试数据集的电影数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,147,varables for coverage,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,149,varables for popularity,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,152,enumerate 将其组成一个索引序列，利用它可以同时获得索引和值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,153,参考地址：http://blog.csdn.net/churximi/article/details/51648388,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,159,对比测试集和推荐集的差异,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,162,"item, w",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,164,"print 'test_mat[u_index, item]=', item, self.test_mat[u_index, item]",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,170,计算用户对应的电影出现次数log值的sum加和,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,176,"print ""test_count="", np.sum(self.test_mat[u_index, :] != 0), np.sum(self.train_mat[u_index, :] != 0)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,191,创建ItemCF对象,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,193,将数据按照 7:3的比例，拆分成：训练集和测试集，存储在usercf的trainset和testset中,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,195,计算用户之间的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,197,评估推荐效果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,198,itemcf.evaluate(),not
AiLearning/src/py3.x/ml/16.RecommenderSystems/sklearn-RS-demo-cf-item-test.py,199,查看推荐结果用户,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_lfm.py,4,负样本采样过程,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,17,作用：使得随机数据可预测,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,28,n_sim_user: top 20个用户， n_rec_movie: top 10个推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,32,user_sim_mat: 用户之间的相似度， movie_popular: 电影的出现次数， movie_count: 总电影数量,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,68,用户ID，电影名称，评分，时间戳timestamp,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,69,"user, movie, rating, timestamp = line.split('::')",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,71,通过pivot和随机函数比较，然后初始化用户和对应的值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,74,"dict.setdefault(key, default=None)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,75,key -- 查找的键值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,76,default -- 键不存在时，设置的默认键值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,92,build inverse table for item-users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,93,"key=movieID, value=list of userIDs who have seen this movie",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,97,同一个电影中，收集用户的集合,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,98,统计在所有的用户中，不同电影的总出现次数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,101,inverse table for item-users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,105,count item popularity at the same time,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,112,"save the total movie number, which will be used in evaluation",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,117,统计在相同电影时，不同用户同时出现的次数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,130,calculate similarity matrix,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,136,余弦相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,140,打印进度条,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,147,@profile,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,162,计算top K 用户的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,163,"v=similar user, wuv=不同用户同时出现的次数，根据wuv倒序从大到小选出K个用户进行排列",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,164,耗时分析：50.4%的时间在 line-160行,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,171,"predict the user's ""interest"" for each movie",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,174,return the N best movies,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,188,返回top N的推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,190,varables for precision and recall,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,191,hit表示命中(测试集和推荐集相同+1)，rec_count 每个用户的推荐数， test_count 每个用户对应的测试数据集的电影数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,195,varables for coverage,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,197,varables for popularity,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,200,enumerate将其组成一个索引序列，利用它可以同时获得索引和值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,201,参考地址：http://blog.csdn.net/churximi/article/details/51648388,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,208,"对比测试集和推荐集的差异 movie, w",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,213,计算用户对应的电影出现次数log值的sum加和,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,228,ratingfile = 'data/16.RecommenderSystems/ml-1m/ratings.dat',not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,231,创建UserCF对象,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,233,将数据按照 7:3的比例，拆分成：训练集和测试集，存储在usercf的trainset和testset中,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,235,计算用户之间的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-usercf.py,237,评估推荐效果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,17,作用：使得随机数据可预测,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,28,n_sim_user: top 20个用户， n_rec_movie: top 10个推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,32,user_sim_mat: 电影之间的相似度， movie_popular: 电影的出现次数， movie_count: 总电影数量,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,68,用户ID，电影名称，评分，时间戳,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,69,"user, movie, rating, _ = line.split('::')",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,71,通过pivot和随机函数比较，然后初始化用户和对应的值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,74,"dict.setdefault(key, default=None)",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,75,key -- 查找的键值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,76,default -- 键不存在时，设置的默认键值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,94,"统计在所有的用户中，不同电影的总出现次数， user, movies",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,97,count item popularity,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,104,save the total number of movies,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,108,统计在相同用户时，不同电影同时出现的次数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,111,"user, movies",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,122,calculate similarity matrix,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,128,余弦相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,132,打印进度条,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,139,@profile,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,154,计算top K 电影的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,155,"rating=电影评分, w=不同电影出现的次数",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,156,耗时分析：98.2%的时间在 line-154行,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,166,return the N best movies,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,173,返回top N的推荐结果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,175,varables for precision and recall,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,176,hit表示命中(测试集和推荐集相同+1)，rec_count 每个用户的推荐数， test_count 每个用户对应的测试数据集的电影数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,180,varables for coverage,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,182,varables for popularity,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,185,enumerate将其组成一个索引序列，利用它可以同时获得索引和值,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,186,参考地址：http://blog.csdn.net/churximi/article/details/51648388,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,193,"对比测试集和推荐集的差异 movie, w",not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,198,计算用户对应的电影出现次数log值的sum加和,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,213,ratingfile = 'data/16.RecommenderSystems/ml-1m/ratings.dat',not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,216,创建ItemCF对象,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,218,将数据按照 7:3的比例，拆分成：训练集和测试集，存储在usercf的trainset和testset中,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,220,计算用户之间的相似度,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,222,评估推荐效果,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,223,itemcf.evaluate(),not
AiLearning/src/py3.x/ml/16.RecommenderSystems/RS-itemcf.py,224,查看推荐结果用户,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,16,build inverse table for item_users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,24,calculate co-rated items between users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,35,calculate finial similarity matrix W,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,44,build inverse table for item_users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,52,calculate co-rated items between users,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,63,calculate finial similarity matrix W,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/test_基于用户.py,77,we should filter items user interacted before,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/python/Recommender.py,4,自定义杰卡德相似系数函数，仅对0-1矩阵有效,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/python/Recommender.py,11,相似度矩阵,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/python/Recommender.py,14,计算相似度矩阵的函数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/python/Recommender.py,22,训练函数,not
AiLearning/src/py3.x/ml/16.RecommenderSystems/python/Recommender.py,26,推荐函数,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,2,coding: utf-8,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,15,利用SVD提高推荐效果，菜肴矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,30,书上代码给的示例矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,55,# 原矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,56,"return[[1, 1, 1, 0, 0],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,57,"[2, 2, 2, 0, 0],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,58,"[1, 1, 1, 0, 0],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,59,"[5, 5, 5, 0, 0],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,60,"[1, 1, 0, 2, 2],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,61,"[0, 0, 0, 3, 3],",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,62,"[0, 0, 0, 1, 1]]",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,64,原矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,71,相似度计算，假定inA和inB 都是列向量,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,72,基于欧氏距离,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,77,pearsSim()函数会检查是否存在3个或更多的点。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,78,"corrcoef直接计算皮尔逊相关系数，范围[-1, 1]，归一化后[0, 1]",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,80,如果不存在，该函数返回1.0，此时两个向量完全相关。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,86,计算余弦相似度，如果夹角为90度，相似度为0；如果两个向量的方向相同，相似度为1.0,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,93,基于物品相似度的推荐引擎,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,104,得到数据集中的物品数目,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,106,初始化两个评分值,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,109,遍历行中的每个物品（对用户评过分的物品进行遍历，并将它与其他物品进行比较）,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,112,如果某个物品的评分值为0，则跳过这个物品,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,115,寻找两个用户都评级的物品,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,116,变量 overLap 给出的是两个物品当中已经被评分的那个元素的索引ID,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,117,logical_and 计算x1和x2元素的真值。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,119,如果相似度为0，则两着没有任何重合元素，终止本次循环,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,122,如果存在重合的物品，则基于这些重合物重新计算相似度。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,125,"print('the %d and %d similarity is : %f'(iten,j,similarity))",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,126,相似度会不断累加，每次计算时还考虑相似度和当前用户评分的乘积,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,127,similarity  用户相似度，   userRating 用户评分,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,132,通过除以所有的评分总和，对上述相似度评分的乘积进行归一化，使得最后评分在0~5之间，这些评分用来对预测值进行排序,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,137,基于SVD的评分估计,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,138,在recommend() 中，这个函数用于替换对standEst()的调用，该函数对给定用户给定物品构建了一个评分估计值,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,149,物品数目,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,151,对数据集进行SVD分解,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,154,奇异值分解,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,155,在SVD分解之后，我们只利用包含了90%能量值的奇异值，这些奇异值会以NumPy数组的形式得以保存,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,158,# 分析 Sigma 的长度取值,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,159,"analyse_data(Sigma, 20)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,161,如果要进行矩阵运算，就必须要用这些奇异值构建出一个对角矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,164,利用U矩阵将物品转换到低维空间中，构建转换后的物品(物品+4个主要的特征),not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,172,对于给定的用户，for循环在用户对应行的元素上进行遍历,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,173,这和standEst()函数中的for循环的目的一样，只不过这里的相似度计算时在低维空间下进行的。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,178,相似度的计算方法也会作为一个参数传递给该函数,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,180,for 循环中加入了一条print语句，以便了解相似度计算的进展情况。如果觉得累赘，可以去掉,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,182,对相似度不断累加求和,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,184,对相似度及对应评分值的乘积求和,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,189,计算估计评分,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,193,recommend()函数，就是推荐引擎，它默认调用standEst()函数，产生了最高的N个推荐结果。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,194,如果不指定N的大小，则默认值为3。该函数另外的参数还包括相似度计算方法和估计方法,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,205,寻找未评级的物品,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,206,对给定的用户建立一个未评分的物品列表,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,208,如果不存在未评分物品，那么就退出函数,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,211,物品的编号和评分值,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,213,在未评分物品上进行循环,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,215,获取 item 该物品的评分,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,218,按照评分得分 进行逆排序，获取前N个未评级物品进行推荐,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,228,总方差的集合（总能量值）,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,240,图像压缩函数,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,241,加载并转换数据,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,244,打开文本文件，并从文件以数组方式读入字符,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,250,矩阵调入后，就可以在屏幕上输出该矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,255,打印矩阵,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,257,由于矩阵保护了浮点数，因此定义浅色和深色，遍历所有矩阵元素，当元素大于阀值时打印1，否则打印0,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,267,实现图像压缩，允许基于任意给定的奇异值数目来重构图像,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,274,构建一个列表,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,278,对原始图像进行SVD分解并重构图像e,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,281,通过Sigma 重新构成SigRecom来实现,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,282,Sigma是一个对角矩阵，因此需要建立一个全0矩阵，然后将前面的那些奇异值填充到对角线上。,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,284,"SigRecon = mat(zeros((numSV, numSV)))",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,285,for k in range(numSV):,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,286,"SigRecon[k, k] = Sigma[k]",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,288,分析插入的 Sigma 长度,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,299,# 对矩阵进行SVD分解(用python实现SVD),not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,300,Data = loadExData(),not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,301,"print('Data:', Data)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,302,"U, Sigma, VT = linalg.svd(Data)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,303,# 打印Sigma的结果，因为前3个数值比其他的值大了很多，为9.72140007e+00，5.29397912e+00，6.84226362e-01,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,304,# 后两个值比较小，每台机器输出结果可能有不同可以将这两个值去掉,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,305,"print('U:', U)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,306,"print('Sigma', Sigma)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,307,"print('VT:', VT)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,308,"print('VT:', VT.T)",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,310,# 重构一个3x3的矩阵Sig3,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,311,"Sig3 = mat([[Sigma[0], 0, 0], [0, Sigma[1], 0], [0, 0, Sigma[2]]])",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,312,"print(U[:, :3] * Sig3 * VT[:3, :])",not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,328,计算相似度的方法,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,330,print(myMat),not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,331,计算相似度的第一种方式,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,333,计算相似度的第二种方式,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,336,默认推荐（菜馆菜肴推荐示例）,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,351,压缩图片,not
AiLearning/src/py3.x/ml/14.SVD/svdRecommend.py,352,imgCompress(2),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,58,"data_mat[:, dimen] 表示数据集中第dimen列的所有值",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,59,thresh_ineq == 'lt'表示修改左边的值，gt表示修改右边的值,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,60,（这里其实我建议理解为转换左右边，就是一棵树的左右孩子，可能有点问题。。。待考证）,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,85,无穷大,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,97,这里是矩阵乘法,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,106,"print('split: dim {}, thresh {}, thresh inequal: {}, the weighted err is {}'.format(",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,107,"i, thresh_val, inequal, weighted_err",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,108,)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,115,best_stump 表示分类器的结果，在第几个列上，用大于／小于比较，阈值是多少 (单个弱分类器),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,130,初始化 D，设置每个特征的权重值，平均分为m份,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,134,得到决策树的模型,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,136,print('D: {}'.format(D.T)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,137,alpha 目的主要是计算每一个分类器实例的权重(加和就是分类结果),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,138,计算每个分类器的 alpha 权重值,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,141,store Stump Params in Array,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,143,print('class_est: {}'.format(class_est.T)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,144,分类正确：乘积为1，不会影响结果，-1主要是下面求e的-alpha次方,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,145,分类错误：乘积为 -1，结果会受影响，所以也乘以 -1,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,147,判断正确的，就乘以-1，否则就乘以1， 为什么？ 书上的公式。,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,148,"print('(-1取反)预测值 expon=', expon.T)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,149,计算e的expon次方，然后计算得到一个综合的概率的值,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,150,结果发现： 判断错误的样本，D对于的样本权重值会变大。,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,151,multiply是对应项相乘,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,154,预测的分类结果值，在上一轮结果的基础上，进行加和操作,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,155,print('叠加前的分类结果class_est: {}'.format(class_est.T)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,157,print('叠加后的分类结果agg_class_est: {}'.format(agg_class_est.T)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,158,sign 判断正为1， 0为0， 负为-1，通过最终加和的权重值，判断符号。,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,159,"结果为：错误的样本标签集合，因为是 !=,那么结果就是0 正, 1 负",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,163,print('total error: {}\n'.format(error_rate)),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,198,variable to calculate AUC,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,200,对正样本的进行求和,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,202,正样本的概率,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,204,负样本的概率,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,206,np.argsort函数返回的是数组值从小到大的索引值,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,207,"get sorted index, it's reverse",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,209,测试结果是否是从小到大排列,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,210,可以选择打印看一下,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,211,开始创建模版对象,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,215,cursor光标值,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,217,"loop through all the values, drawing a line segment at each point",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,226,"draw line from cur to (cur[0]-delX, cur[1]-delY)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,227,"画点连线 (x1, x2, y1, y2)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,228,"print cur[0], cur[0]-delX, cur[1], cur[1]-delY",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,231,画对角的虚线线,not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,236,"设置画图的范围区间 (x1, x2, y1, y2)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,249,"D = np.mat(np.ones((5, 1)) / 5)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,250,"data_mat, class_labels = load_sim_data()",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,251,print(data_mat.shape),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,252,"result = build_stump(data_mat, class_labels, D)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,253,print(result),not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,254,"classifier_array, agg_class_est = ada_boost_train_ds(data_mat, class_labels, 9)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,255,"print(classifier_array, agg_class_est)",not
AiLearning/src/py3.x/ml/7.AdaBoost/adaboost.py,265,测试：计算总样本数，错误样本数，错误率,not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,7,"D = np.mat(np.ones((5, 1)) / 5)",not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,8,"data_mat, class_labels = load_sim_data()",not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,9,print(data_mat.shape),not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,10,"result = build_stump(data_mat, class_labels, D)",not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,11,print(result),not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,12,"classifier_array, agg_class_est = ada_boost_train_ds(data_mat, class_labels, 9)",not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,13,"print(classifier_array, agg_class_est)",not
AiLearning/src/py3.x/ml/7.AdaBoost/roc_test.py,26,测试：计算总样本数，错误样本数，错误率,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,12,importing necessary libraries,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,21,Create the dataset,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,25,"dataArr, labelArr = loadDataSet(""data/7.AdaBoost/horseColicTraining2.txt"")",not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,28,Fit regression model,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,35,Predict,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,39,Plot the results,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,54,适合2分类,not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,60,"print(""-"" * 100)",not
AiLearning/src/py3.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,61,"print(metrics.roc_auc_score(y[:1], y_2[:1]))",not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,19,参数,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,24,加载数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,28,我们只用两个相应的features,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,32,训练,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,35,绘制决策边界,not
AiLearning/src/py3.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,51,绘制训练点,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,3,原始链接： http://blog.csdn.net/lsldd/article/details/41223147,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,4,GitHub: https://github.com/apachecn/AiLearning,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,18,特征： 身高 体重   label： 胖瘦,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,22,特征数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,24,label分类的标签数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,26,预估结果的标签数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,41,print(clf),not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,48,print(x_train),not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,61,计算全量的预估结果,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,72,target_names 以 y的label分类为准,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,88,"with open(""testResult/tree.dot"", 'w') as f:",not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,89,from sklearn.externals.six import StringIO,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,90,"tree.export_graphviz(clf, out_file=f)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,99,from IPython.display import Image,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,100,Image(graph.create_png()),not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,110,得到训练的预测结果集,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,113,展现 准确率与召回率,not
AiLearning/src/py3.x/ml/3.DecisionTree/DTSklearn.py,116,可视化输出,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,12,"定义文本框 和 箭头格式 【 sawtooth 波浪方框, round4 矩形方框 , fc表示字体颜色的深浅 0.1~0.9 依次变浅，没错是变浅】",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,22,根节点开始遍历,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,24,"判断子节点是否为dict, 不是+1",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,36,根节点开始遍历,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,38,"判断子节点是不是dict, 求分枝的深度",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,39,----------写法1 start ---------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,44,----------写法1 end ---------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,46,----------写法2 start --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,47,thisDepth = 1 + getTreeDepth(secondDict[key]) if type(secondDict[key]) is dict else 1,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,48,----------写法2 end --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,49,记录最大的分支深度,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,65,获取叶子节点的数量,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,67,获取树的深度,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,68,depth = getTreeDepth(myTree),not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,70,找出第1个中心点的位置，然后与 parentPt定点进行划线,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,72,print(cntrPt),not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,73,并打印输入对应的文字,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,77,可视化Node分支点,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,79,根节点的值,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,81,y值 = 最高点-层数的高度[第二个节点位置],not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,84,判断该节点是否是Node节点,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,86,如果是就递归调用[recursion],not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,89,如果不是，就在原来节点一半的地方找到节点的坐标,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,91,可视化该节点位置,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,93,并打印输入对应的文字,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,99,创建一个figure的模版,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,104,表示创建一个1行，1列的图，createPlot.ax1 为第 1 个子图，,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,109,半个节点的长度,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,116,# 测试画图,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,117,def createPlot():,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,118,"fig = plt.figure(1, facecolor='white')",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,119,fig.clf(),not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,120,# ticks for demo puropses,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,121,"createPlot.ax1 = plt.subplot(111, frameon=False)",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,122,"plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode)",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,123,"plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode)",not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,124,plt.show(),not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,127,测试数据集,not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,136,myTree = retrieveTree(1),not
AiLearning/src/py3.x/ml/3.DecisionTree/decisionTreePlot.py,137,createPlot(myTree),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,14,引入必要的模型和库,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,19,创建一个随机的数据集,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,20,参考 https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.random.mtrand.RandomState.html,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,22,"print('lalalalala===', rng)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,23,"rand() 是给定形状的随机值，rng.rand(80, 1)即矩阵的形状是 80行，1列",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,24,sort(),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,26,"print('X=', X)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,28,"print('y=', y)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,30,"print('yyy=', y)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,32,拟合回归模型,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,33,regr_1 = DecisionTreeRegressor(max_depth=2),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,34,保持 max_depth=5 不变，增加 min_samples_leaf=6 的参数，效果进一步提升了,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,37,regr_3 = DecisionTreeRegressor(max_depth=4),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,38,"regr_1.fit(X, y)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,40,"regr_3.fit(X, y)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,42,预测,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,44,y_1 = regr_1.predict(X_test),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,46,y_3 = regr_3.predict(X_test),not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,48,绘制结果,not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,51,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py3.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,53,"plt.plot(X_test, y_3, color=""red"", label=""max_depth=3"", linewidth=2)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,27,dataSet 前两列是特征，最后一列对应的是每条数据对应的分类标签,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,33,"dataSet = [['yes'],",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,34,"['yes'],",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,35,"['no'],",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,36,"['no'],",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,37,['no']],not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,38,labels  露出水面   脚蹼，注意：这里的labels是写的 dataSet 中特征的含义，并不是对应的分类标签或者说目标变量,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,40,返回,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,53,-----------计算香农熵的第一种实现方式start--------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,54,求list的长度，表示计算参与训练的数据量,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,56,下面输出我们测试的数据集的一些信息,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,57,例如：<type 'list'> numEntries:  5 是下面的代码的输出,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,58,"print(type(dataSet), 'numEntries: ', numEntries)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,60,计算分类标签label出现的次数,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,62,the the number of unique elements and their occurance,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,64,将当前实例的标签存储，即每一行数据的最后一个数据代表的是标签,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,66,为所有可能的分类创建字典，如果当前的键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,70,"print('-----', featVec, labelCounts)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,72,对于label标签的占比，求出label标签的香农熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,75,使用所有类标签的发生频率计算类别出现的概率。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,77,log base 2,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,78,计算香农熵，以 2 为底求对数,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,80,"print('---', prob, prob * log(prob, 2), shannonEnt)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,81,-----------计算香农熵的第一种实现方式end--------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,83,# -----------计算香农熵的第二种实现方式start--------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,84,# 统计标签出现的次数,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,85,label_count = Counter(data[-1] for data in dataSet),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,86,# 计算概率,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,87,probs = [p[1] / len(dataSet) for p in label_count.items()],not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,88,# 计算香农熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,89,"shannonEnt = sum([-p * log(p, 2) for p in probs])",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,90,# -----------计算香农熵的第二种实现方式end--------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,107,-----------切分数据集的第一种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,110,index列为value的数据集【该数据集需要排除index列】,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,111,判断index列的值是否为value,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,113,chop out index used for splitting,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,114,[:index]表示前index行，即若 index 为2，就是取 featVec 的前 index 行,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,135,[index+1:]表示从跳过 index 的 index+1行，取接下来的数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,136,收集结果值 index列为value的行【该行需要排除index列】,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,138,-----------切分数据集的第一种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,140,# -----------切分数据集的第二种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,141,"retDataSet = [data[:index] + data[index + 1:] for data in dataSet for i, v in enumerate(data) if i == index and v == value]",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,142,# -----------切分数据集的第二种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,156,-----------选择最优特征的第一种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,157,"求第一行有多少列的 Feature, 最后一列是label列嘛",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,159,label的信息熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,161,"最优的信息增益值, 和最优的Featurn编号",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,163,iterate over all the features,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,165,create a list of all the examples of this feature,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,166,获取每一个实例的第i+1个feature，组成list集合,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,168,get a set of unique values,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,169,获取剔重后的集合，使用set对list数据进行去重,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,171,创建一个临时的信息熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,173,遍历某一列的value集合，计算该列的信息熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,174,遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,179,gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,180,信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,187,-----------选择最优特征的第一种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,189,# -----------选择最优特征的第二种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,190,# 计算初始香农熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,191,base_entropy = calcShannonEnt(dataSet),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,192,best_info_gain = 0,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,193,best_feature = -1,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,194,# 遍历每一个特征,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,195,for i in range(len(dataSet[0]) - 1):,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,196,# 对当前特征进行统计,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,197,feature_count = Counter([data[i] for data in dataSet]),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,198,# 计算分割后的香农熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,199,"new_entropy = sum(feature[1] / float(len(dataSet)) * calcShannonEnt(splitDataSet(dataSet, i, feature[0])) \",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,200,for feature in feature_count.items()),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,201,# 更新值,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,202,info_gain = base_entropy - new_entropy,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,203,"print('No. {0} feature info gain is {1:.3f}'.format(i, info_gain))",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,204,if info_gain > best_info_gain:,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,205,best_info_gain = info_gain,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,206,best_feature = i,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,207,return best_feature,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,208,# -----------选择最优特征的第二种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,220,-----------majorityCnt的第一种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,226,倒叙排列classCount得到一个字典集合，然后取出第一个就是结果（yes/no），即出现次数最多的结果,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,228,"print('sortedClassCount:', sortedClassCount)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,230,-----------majorityCnt的第一种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,232,# -----------majorityCnt的第二种方式 start------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,233,major_label = Counter(classList).most_common(1)[0],not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,234,return major_label,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,235,# -----------majorityCnt的第二种方式 end------------------------------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,249,如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,250,第一个停止条件：所有的类标签完全相同，则直接返回该类标签。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,251,count() 函数是统计括号中的值在list中出现的次数,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,254,如果数据集只有1列，那么最初出现label次数最多的一类，作为结果,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,255,第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,259,选择最优的列，得到最优列对应的label含义,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,261,获取label的名称,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,263,初始化myTree,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,265,注：labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,266,所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,268,取出最优列，然后它的branch做分类,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,272,求出剩余的标签label,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,274,遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree(),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,276,"print('myTree', value, myTree)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,291,获取tree的根节点对于的key值,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,293,通过key得到根节点对应的value,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,295,判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,297,测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,301,判断分枝是否结束: 判断valueOfFeat是否是dict类型,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,320,-------------- 第一种方法 start --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,324,-------------- 第一种方法 end --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,326,-------------- 第二种方法 start --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,329,-------------- 第二种方法 start --------------,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,355,1.创建数据和结果标签,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,357,"print(myDat, labels)",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,359,计算label分类标签的香农熵,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,360,calcShannonEnt(myDat),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,362,# 求第0列 为 1/0的列的数据集【排除第0列】,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,363,"print('1---', splitDataSet(myDat, 0, 1))",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,364,"print('0---', splitDataSet(myDat, 0, 0))",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,366,# 计算最好的信息增益的列,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,367,print(chooseBestFeatureToSplit(myDat)),not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,372,"[1, 1]表示要取的分支上的节点位置，对应的结果值",not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,375,画图可视化展现,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,389,加载隐形眼镜相关的 文本文件 数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,391,解析数据，获得 features 数据,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,393,得到数据的对应的 Labels,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,395,使用上面的创建决策树的代码，构造预测隐形眼镜的决策树,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,398,画图可视化展现,not
AiLearning/src/py3.x/ml/3.DecisionTree/DecisionTree.py,403,fishTest(),not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,17,初始化一个空列表,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,19,读取文件,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,21,循环遍历文件所有行,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,23,切割每一行的数据,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,25,"将数据转换为浮点类型,便于后面的计算",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,26,fltLine = [float(x) for x in curLine],not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,27,将数据追加到dataMat,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,28,映射所有的元素为 float（浮点数）类型,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,30,返回dataMat,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,53,获取样本数与特征值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,55,"初始化质心,创建(k,n)个以零填充的矩阵",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,57,循环遍历特征值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,59,计算每一列的最小值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,61,计算每一列的范围值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,63,"计算每一列的质心,并将值赋给centroids",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,65,返回质心,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,79,获取样本数和特征数,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,81,初始化一个矩阵来存储每个点的簇分配结果,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,82,"clusterAssment包含两个列:一列记录簇索引值,第二列存储误差(误差是指当前点到簇质心的距离,后面会使用该误差来评价聚类的效果)",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,84,"创建质心,随机K个质心",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,86,"初始化标志变量,用于判断迭代是否继续,如果True,则继续迭代",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,90,"遍历所有数据找到距离每个点最近的质心,",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,91,可以通过对每个点遍历所有质心并计算点到每个质心的距离来完成,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,96,计算数据点到质心的距离,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,97,"计算距离是使用distMeas参数给出的距离公式,默认距离函数是distEclud",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,99,"如果距离比minDist(最小距离)还小,更新minDist(最小距离)和最小质心的index(索引)",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,103,"如果任一点的簇分配结果发生改变,则更新clusterChanged标志",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,105,"更新簇分配结果为最小质心的index(索引),minDist(最小距离)的平方",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,107,print(centroids),not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,108,遍历所有质心并更新它们的取值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,110,通过数据过滤来获得给定簇的所有点,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,112,"计算所有点的均值,axis=0表示沿矩阵的列方向进行均值计算",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,114,返回所有的类质心与点分配结果,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,127,创建一个矩阵来存储数据集中每个点的簇分配结果及平方误差,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,129,"计算整个数据集的质心,并使用一个列表来保留所有的质心",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,132,遍历数据集中所有点来计算每个点到质心的误差值,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,135,"对簇不停的进行划分,直到得到想要的簇数目为止",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,137,"初始化最小SSE为无穷大,用于比较划分前后的SSE",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,139,"通过考察簇列表中的值来获得当前簇的数目,遍历所有的簇来决定最佳的簇进行划分",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,141,"对每一个簇,将该簇中的所有点堪称一个小的数据集",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,143,"将ptsInCurrCluster输入到函数kMeans中进行处理,k=2,",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,144,"kMeans会生成两个质心(簇),同时给出每个簇的误差值",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,146,将误差值与剩余数据集的误差之和作为本次划分的误差,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,150,"如果本次划分的SSE值最小,则本次划分被保存",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,156,找出最好的簇分配结果,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,157,"调用kmeans函数并且指定簇数为2时,会得到两个编号分别为0和1的结果簇",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,159,更新为最佳质心,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,163,更新质心列表,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,164,更新原质心list中的第i个质心为使用二分kMeans后bestNewCents的第一个质心,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,166,添加bestNewCents的第二个质心,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,168,重新分配最好簇下的数据(质心)以及SSE,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,181,"经度和维度用角度作为单位,但是sin()和cos()以弧度为输入.",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,182,可以将江都除以180度然后再诚意圆周率pi转换为弧度,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,197,创建一个空列表,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,199,"打开文本文件获取第4列和第5列,这两列分别对应维度和经度,然后将这些值封装到datList",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,204,调用biKmeans并使用distSLC函数作为聚类中使用的距离计算方式,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,206,"创建一幅图和一个举行,使用该矩形来决定绘制图的哪一部分",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,209,构建一个标记形状的列表用于绘制散点图,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,213,使用imread函数基于一幅图像来创建矩阵,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,215,使用imshow绘制该矩阵,not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,217,"再同一幅图上绘制一张新图,允许使用两套坐标系统并不做任何缩放或偏移",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,219,"遍历每一个簇并将它们一一画出来,标记类型从前面创建的scatterMarkers列表中得到",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,222,"使用索引i % len(scatterMarkers)来选择标记形状,这意味这当有更多簇时,可以循环使用这标记",not
AiLearning/src/py3.x/ml/10.kmeans/kMeans.py,224,使用十字标记来表示簇中心并在图中显示,not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,9,dataMat = mat(kMeans.loadDataSet('../../../../data/k-means/testSet.txt')),not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,10,"print('min(dataMat[:, 0])', min(dataMat[:, 0]), '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,11,"print('min(dataMat[:, 1])', min(dataMat[:, 1]), '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,12,"print('max(dataMat[:, 0])', max(dataMat[:, 0]), '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,13,"print('max(dataMat[:, 1])', max(dataMat[:, 1]), '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,14,"print(kMeans.randCent(dataMat, 2),'\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,15,"print(kMeans.distEclud(dataMat[0],dataMat[1]))",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,16,"centroids, clusterAssment = kMeans.kMeans(dataMat, 4)",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,17,"print('centroids:\n', centroids, '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,18,"print('clusterAssment:\n',clusterAssment, '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,19,dataMat3 = mat(kMeans.loadDataSet('../../../../data/k-means/testSet2.txt')),not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,20,"centList, myNewAssments = kMeans.biKmeans(dataMat3, 3)",not
AiLearning/src/py3.x/ml/10.kmeans/__init__.py,21,"print('centList: \n', centList, '\n')",not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,1,-*- coding:UTF-8 -*-,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,7,加载数据集,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,9,注意，这个是相对路径，请保证是在 MachineLearning 这个目录下执行。,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,12,映射所有的元素为 float（浮点数）类型,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,15,训练模型,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,16,初始化,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,17,拟合,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,18,预测,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,19,质心,not
AiLearning/src/py3.x/ml/10.kmeans/kMeansSklearn.py,21,可视化结果,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,18,导入csv文件,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,27,strip()返回移除字符串头尾指定的字符生成的新字符串,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,29,判断是否是数字,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,30,将数据集的第column列转换成float形式,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,33,添加分类标签,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,49,"复制一份 dataset,防止 dataset 的内容改变",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,52,每次循环 fold 清零，防止重复导入 dataset_split,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,53,这里不能用 if，if 只是在第一次判断时起作用，while 执行循环，直到条件不成立,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,54,有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此则自助采样法。从而保证每棵决策树训练集的差异性,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,56,将对应索引 index 的内容从 dataset_copy 中导出，并将该内容从 dataset_copy 中删除。,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,57,pop() 函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,58,fold.append(dataset_copy.pop(index))  # 无放回的方式,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,59,有放回的方式,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,61,由dataset分割出的n_folds个数据构成的列表，为了用于交叉验证,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,65,Split a dataset based on an attribute and an attribute value # 根据特征和特征值分割数据集,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,76,Calculate the Gini index for a split dataset,SATD
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,77,个人理解：计算代价，分类越准确，则 gini 越小,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,79,"class_values = [0, 1]",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,80,"groups = (left, right)",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,85,个人理解：计算代价，分类越准确，则 gini 越小,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,89,"找出分割数据集的最优特征，得到最优的特征 index，特征值 row[index]，以及分割完的数据 groups（left, right）",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,91,"class_values =[0, 1]",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,95,往 features 添加 n_features 个特征（ n_feature 等于特征数的根号），特征索引从 dataset 中随机取,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,98,在 n_features 个特征中选出最优的特征索引，并没有遍历所有特征，从而保证了每课决策树的差异性,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,100,"groups=(left, right), row[index] 遍历每一行 index 索引下的特征值作为分类值 value, 找出最优的分类特征和特征值",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,102,左右两边的数量越一样，说明数据区分度不高，gini系数越大,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,104,"最后得到最优的分类特征 b_index,分类特征值 b_value,分类结果 b_groups。b_value 为分错的代价成本",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,105,print(b_score),not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,109,Create a terminal node value # 输出group中出现次数较多的标签,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,111,max() 函数中，当 key 参数不为空时，就以 key 的函数对象为判断的标准,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,112,输出 group 中出现次数较多的标签,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,115,Create child splits for a node or make terminal  # 创建子分割器，递归分类，直到分类结束,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,116,"max_depth = 10, min_size = 1, n_features = int(sqrt((dataset[0])-1))",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,119,check for a no split,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,123,check for max depth,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,124,max_depth=10 表示递归十次，若分类还未结束，则选取数据中分类标签较多的作为结果，使分类提前结束，防止过拟合,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,127,process left child,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,131,"node['left']是一个字典，形式为{'index':b_index, 'value':b_value, 'groups':b_groups}，所以node是一个多层字典",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,132,递归，depth+1计算递归层数,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,133,process right child,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,141,Build a decision tree,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,154,返回最优列和相关的信息,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,157,对左右2边的数据 进行递归的调用，由于最优特征使用过，所以在后面进行使用的时候，就没有意义了,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,158,例如： 性别-男女，对男使用这一特征就没任何意义了,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,163,Make a prediction with a decision tree,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,164,预测模型分类结果,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,166,isinstance 是 Python 中的一个内建函数。是用来判断一个对象是否是一个已知的类型。,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,177,Make a prediction with a list of bagged trees,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,188,使用多个决策树trees对测试集test的第row行进行预测，再使用简单投票法判断出该行所属分类,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,193,Create a random subsample from the dataset with replacement,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,194,创建数据集的随机子样本,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,205,训练样本的按比例抽样。,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,206,round() 方法返回浮点数x的四舍五入值。,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,209,有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此则自助采样法。从而保证每棵决策树训练集的差异性,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,215,Random Forest Algorithm,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,232,n_trees 表示决策树的数量,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,234,随机抽样的训练样本， 随机采样保证了每棵决策树训练集的差异性,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,236,创建一个决策树,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,240,每一行的预测结果，bagging 预测最后的分类结果,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,245,Calculate accuracy percentage,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,246,导入实际值和预测值，计算精确度,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,254,评估算法性能，返回模型得分,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,267,将数据集进行抽重抽样 n_folds 份，数据可以重复重复抽取，每一次 list 的元素是无重复的,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,270,每次循环从 folds 从取出一个 fold 作为测试集，其余作为训练集，遍历整个 folds ，实现交叉验证,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,274,"将多个 fold 列表组合成一个 train_set 列表, 类似 union all",not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,288,fold 表示从原始数据集 dataset 提取出来的测试集,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,296,计算随机森林的预测结果的正确率,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,304,加载数据,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,306,print(dataset),not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,308,分成5份数据，进行交叉验证,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,309,调参（自己修改） #决策树深度不能太深，不然容易导致过拟合,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,310,决策树的叶子节点最少的元素数量,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,311,做决策树时候的样本的比例,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,312,n_features = int((len(dataset[0])-1)),not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,313,调参（自己修改） #准确性与多样性之间的权衡,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,314,理论上树是越多越好,not
AiLearning/src/py3.x/ml/7.RandomForest/randomForest.py,316,每一次执行本文件时都能产生同一个随机数,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,2,coding: utf8,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,13,加载数据集,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,17,创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,31,遍历所有的元素，如果不在 C1 出现过，那么就 append,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,33,对数组进行 `从小到大` 的排序,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,34,"print 'sort 前=', C1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,36,frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,37,"print 'sort 后=', C1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,38,"print 'frozenset=', map(frozenset, C1)",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,41,计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,54,"ssCnt 临时存放选数据集 Ck 的频率. 例如: a->10, b->5, c->8",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,58,s.issubset(t)  测试是否 s 中的每一个元素都在 t 中,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,64,数据集 D 的数量,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,68,支持度 = 候选项（key）出现的次数 / 所有数据集的数量,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,71,在 retList 的首位插入元素，只存储支持度满足频繁项集的值,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,73,存储所有的候选项（key）和对应的支持度（support）,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,77,输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,97,"print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,98,"print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,101,"第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,102,if first k-2 elements are equal,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,104,set union,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,105,"print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,109,找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,120,C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,122,"print 'C1: ', C1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,123,对每一行进行 set 转换，然后存放到集合中,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,125,"print 'D=', D",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,126,计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,128,"print ""L1="", L1, ""\n"", ""outcome: "", supportData",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,130,"L 加了一层 list, L 一共 2 层 list",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,133,"判断 L 的第 k-2 项的数据长度是否 > 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,135,"print 'k=', k, L, L[k-2]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,136,"例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,137,"print 'Ck', Ck",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,139,计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,140,保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,144,Lk 表示满足频繁子项的集合，L 元素在增加，例如:,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,145,"l=[[set(1), set(2), set(3)]]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,146,"l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,149,"print 'k=', k, len(L[k-2])",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,152,计算可信度（confidence）,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,165,记录可信度大于最小可信度（minConf）的集合,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,167,"假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,169,"print 'confData=', freqSet, H, conseq, freqSet-conseq",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,170,"支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,172,只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq集合 是全集）,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,178,递归计算频繁项集的规则,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,189,"H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,190,该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,191,"假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,192,那么 m = len(H[0]) 的递归的值依次为 1 2,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,193,"在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,196,"print 'freqSet******************', len(freqSet), m + 1, freqSet, H, H[0]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,197,"生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,198,"第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,199,第二次 。。。没有第二次，递归条件判断时已经退出了,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,201,返回可信度大于最小可信度的集合,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,205,计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,207,"print '----------------------', Hmp1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,208,"print len(freqSet),  len(Hmp1[0]) + 1",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,211,生成关联规则,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,223,"假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,225,获取频繁项集中每个组合的所有元素,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,227,"假设：freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,228,组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,230,"2 个的组合，走 else, 2 个以上的组合，走 if",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,241,votesmart.apikey = 'get your api key first',not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,249,api call,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,258,delay to be polite,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,262,this will return a list of lists containing ints,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,263,list of what each item stands for,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,264,fill up itemMeaning list,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,267,list of items in each transaction (politician),not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,291,暂时没用上,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,292,"def pntRules(ruleList, itemMeaning):",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,293,for ruleTup in ruleList:,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,294,for item in ruleTup[0]:,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,295,print itemMeaning[item],not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,296,"print ""           -------->""",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,297,for item in ruleTup[1]:,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,298,print itemMeaning[item],not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,299,"print ""confidence: %f"" % ruleTup[2]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,300,print       #print a blank line,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,303,加载测试数据集,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,307,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,314,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,320,加载测试数据集,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,324,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,329,生成关联规则,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,334,测试 Apriori 算法,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,335,testApriori(),not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,337,生成关联规则,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,338,testGenerateRules(),not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,340,项目案例,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,341,# 构建美国国会投票记录的事务数据集,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,342,"actionIdList, billTitleList = getActionIds()",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,343,# 测试前2个,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,344,"transDict, itemMeaning = getTransList(actionIdList[: 2], billTitleList[: 2])",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,345,"transDict 表示 action_id的集合，transDict[key]这个就是action_id对应的选项，例如 [1, 2, 3]",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,346,"transDict, itemMeaning = getTransList(actionIdList, billTitleList)",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,347,# 得到全集的数据,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,348,dataSet = [transDict[key] for key in transDict.keys()],not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,349,"L, supportData = apriori(dataSet, minSupport=0.3)",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,350,"rules = generateRules(L, supportData, minConf=0.95)",not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,351,print (rules),not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,353,# 项目案例,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,354,# 发现毒蘑菇的相似特性,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,355,# 得到全集的数据,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,358,# 2表示毒蘑菇，1表示可食用的蘑菇,not
AiLearning/src/py3.x/ml/11.Apriori/apriori.py,359,# 找出关于2的频繁子项出来，就知道如果是毒蘑菇，那么出现频繁的也可能是毒蘑菇,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,16,"在Python3中将urllib2和urllib3合并为一个标准库urllib,其中的urllib2.urlopen更改为urllib.request.urlopen",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,26,获取样本特征的总数，不算最后的目标变量,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,32,读取每一行,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,34,删除一行中以tab分隔的数据前后的空白符号,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,36,i 从0到2，不包括2,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,38,将数据添加到lineArr List中，每一行数据测试数据组成一个行向量,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,40,将测试数据的输入数据部分存储到dataMat 的List中,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,42,将每一行的最后一个数据，即类别，或者叫目标变量存储到labelMat List中,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,58,mat()函数将xArr，yArr转换为矩阵 mat().T 代表的是对矩阵进行转置操作,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,61,矩阵乘法的条件是左矩阵的列数等于右矩阵的行数,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,63,因为要用到xTx的逆矩阵，所以事先需要确定计算得到的xTx是否可逆，条件是矩阵的行列式不为0,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,64,linalg.det() 函数是用来求得矩阵的行列式的，如果矩阵的行列式为0，则这个矩阵是不可逆的，就无法进行接下来的运算,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,68,最小二乘法,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,69,http://cwiki.apachecn.org/pages/viewpage.action?pageId=5505133,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,70,书中的公式，求得w的最优解,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,93,mat() 函数是将array转换为矩阵的函数， mat().T 是转换为矩阵之后，再进行转置操作,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,96,获得xMat矩阵的行数,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,98,eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,101,testPoint 的形式是 一个行向量的形式,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,102,计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,104,k控制衰减的速度,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,106,根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,111,计算出回归系数的一个估计,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,128,得到样本点的总数,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,130,构建一个全部都是 0 的 1 * m 的矩阵,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,132,循环所有的数据点，并将lwlr运用于所有的数据点,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,135,返回估计值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,151,生成一个与目标变量数目相同的 0 向量,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,153,将 xArr 转换为 矩阵形式,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,155,排序,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,157,开始循环，为每个样本点进行局部加权线性回归，得到最终的目标变量估计值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,192,岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,194,检查行列式是否为零，即矩阵是否可逆，行列式为0的话就不可逆，不为0的话就是可逆。,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,215,计算Y的均值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,217,Y的所有的特征减去均值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,219,标准化 x，计算 xMat 平均值,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,221,然后计算 X的方差,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,223,所有特征都减去各自的均值并除以方差,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,225,可以在 30 个不同的 lambda 下调用 ridgeRegres() 函数。,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,227,创建30 * m 的全部数据为0 的矩阵,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,230,exp() 返回 e^x,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,236,按列进行规范化,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,238,计算平均值然后减去它,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,239,计算除以Xi的方差,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,248,也可以规则化ys但会得到更小的coef,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,251,测试代码删除,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,272,"def scrapePage(inFile, outFile, yr, numPce, origPrc):",SATD
AiLearning/src/py3.x/ml/8.Regression/regression.py,273,fr = open(inFile),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,274,"fw = open(outFile, 'a')  # a is append mode writing",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,275,soup = BeautifulSoup(fr.read()),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,276,i = 1,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,277,"currentRow = soup.findAll('table', r=""%d"" % i)",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,278,while (len(currentRow) != 0):,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,279,title = currentRow[0].findAll('a')[1].text,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,280,lwrTitle = title.lower(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,281,if (lwrTitle.find('new') > -1) or (lwrTitle.find('nisb') > -1):,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,282,newFlag = 1.0,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,283,else:,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,284,newFlag = 0.0,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,285,soldUnicde = currentRow[0].findAll('td')[3].findAll('span'),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,286,if len(soldUnicde) == 0:,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,287,"print(""item #%d did not sell"" % i)",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,288,else:,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,289,soldPrice = currentRow[0].findAll('td')[4],not
AiLearning/src/py3.x/ml/8.Regression/regression.py,290,priceStr = soldPrice.text,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,291,"priceStr = priceStr.replace('$', '')  # strips out $",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,292,"priceStr = priceStr.replace(',', '')  # strips out ,",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,293,if len(soldPrice) > 1:,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,294,"priceStr = priceStr.replace('Free shipping', '')  # strips out Free Shipping",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,295,"print(""%s\t%d\t%s"" % (priceStr, newFlag, title))",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,296,"fw.write(""%d\t%d\t%d\t%f\t%s\n"" % (yr, numPce, newFlag, origPrc, priceStr))",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,297,i += 1,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,298,"currentRow = soup.findAll('table', r=""%d"" % i)",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,299,fw.close(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,302,--------------------------------------------------------------,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,303,预测乐高玩具套装的价格 ------ 最初的版本，因为现在 google 的 api 变化，无法获取数据,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,304,故改为了下边的样子，但是需要安装一个 beautifulSoup 这个第三方网页文本解析器，安装很简单，见下边,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,305,from time import sleep,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,306,import json,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,307,"这里特别指出 正确的使用方法为下面的语句使用,from urllib import request 将会报错,具体细节查看官方文档",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,308,"import urllib.request   # 在Python3中将urllib2和urllib等五个模块合并为一个标准库urllib,其中的urllib2.urlopen更改为urllib.request.urlopen",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,315,转换为json格式,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,342,create error mat 30columns numVal rows创建error mat 30columns numVal 行,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,347,create training set based on first 90% of values in indexList,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,348,基于indexList中的前90%的值创建训练集,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,355,get 30 weight vectors from ridge,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,356,loop over all of the ridge estimates,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,360,regularize test with training params,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,361,test ridge results and store,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,363,"print (errorMat[i,k])",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,364,calc avg performance of the different ridge weight vectors,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,367,can unregularize to get model,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,368,when we regularized we wrote Xreg = (x-meanX)/var(x),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,369,we can now write in terms of x not Xreg:  x*w/var(x) - meanX/var(x) +meanY,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,376,----------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,377,"预测乐高玩具套装的价格 可运行版本，我们把乐高数据存储到了我们的 input 文件夹下，使用 urllib爬取,bs4解析内容",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,378,前提：安装 BeautifulSoup，步骤如下,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,379,在这个页面 https://www.crummy.com/software/BeautifulSoup/bs4/download/4.4/ 下载，beautifulsoup4-4.4.1.tar.gz,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,380,将下载文件解压，使用 windows 版本的 cmd 命令行，进入解压的包，输入以下两行命令即可完成安装,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,381,python setup.py build,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,382,python setup.py install,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,383,如果为linux或者mac系统可以直接使用pip进行安装 pip3 install bs4,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,384,----------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,387,从页面读取数据，生成retX和retY列表,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,389,打开并读取HTML文件,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,390,"这里推荐使用with open() 生成器,这样节省内存也可以避免最后忘记关闭文件的问题",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,393,根据HTML页面结构进行解析,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,399,查找是否有全新标签,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,404,查找是否已经标志出售，我们只收集已出售的数据,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,409,解析页面获取当前价格,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,412,strips out $,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,413,"strips out ,",not
AiLearning/src/py3.x/ml/8.Regression/regression.py,417,去掉不完整的套装价格,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,483,test for standRegression,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,490,add_subplot(349)函数的参数的意思是，将画布分成3行4列图像画在从左到右从上到下第9块,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,491,scatter 的x是xMat中的第二列，y是yMat的第一列,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,503,argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)，然后输出,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,512,test for abloneDataSet,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,522,加载数据,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,524,使用不同的核进行预测,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,528,打印出不同的核预测值与训练数据集上的真实值之间的误差大小,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,533,打印出 不同的核预测值 与 新数据集（测试数据集）上的真实值之间的误差大小,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,541,使用简单的 线性回归 进行预测，与上面的计算进行比较,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,547,test for ridgeRegression,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,557,test for stageWise,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,570,predict for lego's price,not
AiLearning/src/py3.x/ml/8.Regression/regression.py,579,regression1(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,580,regression2(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,581,abaloneTest(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,582,regression3(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,583,regression4(),not
AiLearning/src/py3.x/ml/8.Regression/regression.py,584,regression5(),not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,12,Isotonic Regression 等式回归,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,15,Author: Nelle Varoquaux <nelle.varoquaux@gmail.com>,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,16,Alexandre Gramfort <alexandre.gramfort@inria.fr>,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,17,License: BSD,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,37,线性回归的 x 需要为 2d,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,53,Kernel ridge regression ( 内核岭回归 ),not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,55,2.1 Comparison of kernel ridge regression and SVR ( 内核岭回归与 SVR 的比较 ),not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,57,Authors: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>,not
AiLearning/src/py3.x/ml/8.Regression/sklearn-regression-demo.py,58,License: BSD 3 clause,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,19,注意这里和python2的区别，需要在map函数外加一个list（），否则显示结果为 map at 0x3fed1d0,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,34,计算每一列的均值,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,36,"print('meanVals', meanVals)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,38,每个向量同时都减去 均值,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,40,"print('meanRemoved=', meanRemoved)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,42,cov协方差=[(x1-x均值)*(y1-y均值)+(x2-x均值)*(y2-y均值)+...+(xn-x均值)*(yn-y均值)+]/(n-1),not
AiLearning/src/py3.x/ml/13.PCA/pca.py,54,eigVals为特征值， eigVects为特征向量,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,56,"print('eigVals=', eigVals)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,57,"print('eigVects=', eigVects)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,58,对特征值，进行从小到大的排序，返回从小到大的index序号,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,59,特征值的逆序就可以得到topNfeat个最大的特征向量,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,73,"print('eigValInd1=', eigValInd)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,75,-1表示倒序，返回topN的特征值[-1 到 -(topNfeat+1) 但是不包括-(topNfeat+1)本身的倒叙],not
AiLearning/src/py3.x/ml/13.PCA/pca.py,77,"print('eigValInd2=', eigValInd)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,78,重组 eigVects 最大到最小,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,80,"print('redEigVects=', redEigVects.T)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,81,将数据转换到新空间,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,82,"print( ""---"", shape(meanRemoved), shape(redEigVects))",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,85,"print('lowDDataMat=', lowDDataMat)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,86,"print('reconMat=', reconMat)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,94,对value不为NaN的求均值,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,95,.A 返回矩阵基于的数组,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,97,将value为NaN的值赋值为均值,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,137,# 加载数据，并转化数据类型为float,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,138,dataMat = loadDataSet('data/13.PCA/testSet.txt'),not
AiLearning/src/py3.x/ml/13.PCA/pca.py,139,# 只需要1个特征向量,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,140,"lowDmat, reconMat = pca(dataMat, 1)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,141,# 只需要2个特征向量，和原始数据一致，没任何变化,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,142,"# lowDmat, reconMat = pca(dataMat, 2)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,143,# print(shape(lowDmat)),not
AiLearning/src/py3.x/ml/13.PCA/pca.py,144,"show_picture(dataMat, reconMat)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,146,利用PCA对半导体制造数据降维,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,149,分析数据,not
AiLearning/src/py3.x/ml/13.PCA/pca.py,151,"lowDmat, reconMat = pca(dataMat, 20)",not
AiLearning/src/py3.x/ml/13.PCA/pca.py,152,print(shape(lowDmat)),not
AiLearning/src/py3.x/ml/13.PCA/pca.py,153,"show_picture(dataMat, reconMat)",not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,19,创建40个分离点,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,21,"X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]",not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,22,Y = [0] * 20 + [1] * 20,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,50,拟合一个SVM模型,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,54,获取分割超平面,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,56,斜率,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,58,从-5到5，顺序间隔采样50个样本，默认是num=50,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,59,"xx = np.linspace(-5, 5)  # , num=50)",not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,60,", num=50)",not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,61,二维的直线方程,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,65,plot the parallels to the separating hyperplane that pass through the support vectors,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,66,通过支持向量绘制分割超平面,not
AiLearning/src/py3.x/ml/6.SVM/sklearn-svm-demo.py,73,"plot the line, the points, and the nearest vectors to the plane",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,36,数据的行数,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,41,误差缓存，第一列给出的是eCache是否有效的标志位，第二列给出的是实际的E值。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,44,m行m列的矩阵,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,50,calc the kernel or transform data to a higher dimensional space,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,64,linear kernel:   m*n * n*1 = m*1,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,70,径向基函数的高斯版本,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,71,divide in NumPy is element-wise not matrix like Matlab,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,127,"this is the second choice -heurstic, and calcs Ej",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,146,首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,149,"print('oS.eCache[%s]=%s' % (i, oS.eCache[i]))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,150,"print('oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,151,"""""""",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,152,# 返回非0的：行列值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,153,"nonzero(oS.eCache[:, 0].A)= (",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,154,"行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]),",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,155,"列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,156,),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,157,"""""""",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,158,"print('nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,159,# 取行的list,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,160,"print('nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,161,非零E值的行的list列表，所对应的alpha值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,164,在所有的值上进行循环，并选择其中使得改变最大的那个值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,166,"don't calc for i, waste of time",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,168,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,172,选择具有最大步长的j,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,177,如果是第一次循环，则随机选择一个alpha值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,180,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,194,求 误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,225,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,228,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,229,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,230,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,238,选择最大的误差对应的j进行优化。效果更明显,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,243,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,251,"print(""L==H"")",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,254,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,255,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,256,changed for kernel,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,261,计算出一个新的alphas[j]值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,263,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,265,更新误差缓存,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,268,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,270,"print(""j not moving enough"")",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,273,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,275,更新误差缓存,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,278,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,279,w= Σ[1~n] ai*yi*xi => b = yi- Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,280,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,281,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,312,创建一个 optStruct 对象,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,318,循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,321,----------- 第一种写法 start -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,322,当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,324,在数据集上遍历所有可能的alpha,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,326,是否存在alpha对，存在就+1,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,328,"print(""fullSet, iter: %d i:%d, pairs changed %d"" % (iter, i, alphaPairsChanged))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,331,对已存在 alpha对，选出非边界的alpha值，进行优化。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,333,遍历所有的非边界alpha值，也就是不在边界0或C上的值。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,337,"print(""non-bound, iter: %d i:%d, pairs changed %d"" % (iter, i, alphaPairsChanged))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,339,----------- 第一种写法 end -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,341,----------- 第二种方法 start -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,342,if entireSet:																				#遍历整个数据集,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,343,"alphaPairsChanged += sum(innerL(i, oS) for i in range(oS.m))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,344,else: 																						#遍历非边界值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,345,nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]						#遍历不在边界0和C的alpha,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,346,"alphaPairsChanged += sum(innerL(i, oS) for i in nonBoundIs)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,347,iter += 1,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,348,----------- 第二种方法 end -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,349,如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,351,toggle entire set loop,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,380,C=200 important,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,384,get matrix of only support vectors,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,392,"和这个svm-simple类似： fXi = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[i, :].T)) + b",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,425,load the training set,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,430,take off .txt,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,442,1. 导入训练数据,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,450,"print(""there are %d Support Vectors"" % shape(sVs)[0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,455,1*m * m*1 = 1*1 单个预测结果,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,459,2. 导入测试数据,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,483,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,488,注意flatten的用法,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,491,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,494,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,504,找到支持向量，并在图中标红,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,513,# 无核函数的测试,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,514,# 获取特征和目标变量,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,515,"dataArr, labelArr = loadDataSet('data/6.SVM/testSet.txt')",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,516,# print(labelArr),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,518,# b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,519,"b, alphas = smoP(dataArr, labelArr, 0.6, 0.001, 40)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,520,print('/n/n/n'),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,521,"print('b=', b)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,522,"print('alphas[alphas>0]=', alphas[alphas > 0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,523,"print('shape(alphas[alphas > 0])=', shape(alphas[alphas > 0]))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,524,for i in range(100):,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,525,if alphas[i] > 0:,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,526,"print(dataArr[i], labelArr[i])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,527,# 画图,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,528,"ws = calcWs(alphas, dataArr, labelArr)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,529,"plotfig_SVM(dataArr, labelArr, ws, b, alphas)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,531,有核函数的测试,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,532,testRbf(0.8),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,534,项目实战,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,535,示例：手写识别问题回顾,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,536,"testDigits(('rbf', 0.1))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,537,"testDigits(('rbf', 5))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,539,"testDigits(('rbf', 50))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,540,"testDigits(('rbf', 100))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete.py,541,"testDigits(('lin', 10))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,16,Initialize the structure with the parameters,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,24,first column is valid flag,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,91,"this is the second choice -heurstic, and calcs Ej",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,110,首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,113,"print('oS.eCache[%s]=%s' % (i, oS.eCache[i]))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,114,"print('oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,115,"""""""",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,116,# 返回非0的：行列值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,117,"nonzero(oS.eCache[:, 0].A)= (",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,118,"行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]),",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,119,"列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,120,),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,121,"""""""",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,122,"print('nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,123,# 取行的list,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,124,"print('nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0])",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,125,非零E值的行的list列表，所对应的alpha值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,128,在所有的值上进行循环，并选择其中使得改变最大的那个值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,130,"don't calc for i, waste of time",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,132,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,140,如果是第一次循环，则随机选择一个alpha值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,143,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,148,after any alpha has changed update the new value in the cache,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,157,求 误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,174,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,177,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,178,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,179,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,187,选择最大的误差对应的j进行优化。效果更明显,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,192,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,203,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,204,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,211,计算出一个新的alphas[j]值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,213,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,215,更新误差缓存,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,218,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,223,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,225,更新误差缓存,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,228,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,229,w= Σ[1~n] ai*yi*xi => b = yj Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,230,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,231,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,261,创建一个 optStruct 对象,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,267,循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,268,循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,271,----------- 第一种写法 start -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,272,当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,274,在数据集上遍历所有可能的alpha,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,276,是否存在alpha对，存在就+1,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,280,对已存在 alpha对，选出非边界的alpha值，进行优化。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,282,遍历所有的非边界alpha值，也就是不在边界0或C上的值。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,288,----------- 第一种写法 end -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,290,----------- 第二种方法 start -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,291,if entireSet:																				#遍历整个数据集,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,292,"alphaPairsChanged += sum(innerL(i, oS) for i in range(oS.m))",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,293,else: 																						#遍历非边界值,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,294,nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]						#遍历不在边界0和C的alpha,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,295,"alphaPairsChanged += sum(innerL(i, oS) for i in nonBoundIs)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,296,iter += 1,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,297,----------- 第二种方法 end -------------------------,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,298,如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,300,toggle entire set loop,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,338,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,343,注意flatten的用法,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,346,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,349,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,359,找到支持向量，并在图中标红,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,367,获取特征和目标变量,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,369,print(labelArr),not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,371,b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py3.x/ml/6.SVM/svm-complete_Non-Kernel.py,380,画图,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,81,矩阵转置 和 .T 一样的功能,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,85,初始化 b和alphas(alpha有点类似权重值。),not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,89,没有任何alpha改变的情况下遍历数据的次数,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,92,"w = calcWs(alphas, dataMatIn, classLabels)",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,93,"print(""w:"", w)",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,95,记录alpha是否已经进行优化，每次循环时设为0，然后再对整个集合顺序遍历,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,98,"print('alphas=', alphas)",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,99,"print('labelMat=', labelMat)",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,100,"print('multiply(alphas, labelMat)=', multiply(alphas, labelMat))",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,101,我们预测的类别 y = w^Tx[i]+b; 其中因为 w = Σ(1~n) a[n]*lable[n]*x[n],not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,103,预测结果与真实结果比对，计算误差Ei,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,106,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,107,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,108,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,117,如果满足优化的条件，我们就随机选取非i的一个点，进行优化比较,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,119,预测j的结果,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,125,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接执行continue语句,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,126,labelMat[i] != labelMat[j] 表示异侧，就相减，否则是同侧，就相加。,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,133,如果相同，就没发优化了,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,138,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,139,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,145,计算出一个新的alphas[j]值,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,147,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,149,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,153,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,155,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,156,w= Σ[1~n] ai*yi*xi => b = yj- Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,157,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,158,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,169,在for循环外，检查alpha值是否做了更新，如果在更新则将iter设为0后继续运行程序,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,170,知道更新完毕后，iter次循环无变化，才推出循环。,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,210,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,215,注意flatten的用法,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,218,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,221,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,231,找到支持向量，并在图中标红,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,239,获取特征和目标变量,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,241,print(labelArr),not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,243,b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py3.x/ml/6.SVM/svm-simple.py,252,画图,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,25,生成一个 4*4 的随机数组,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,28,转化关系， 数组转化为矩阵,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,45,输出结果,not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,51,矩阵和逆矩阵 进行求积 (单位矩阵，对角线都为1嘛，理论上4*4的矩阵其他的都为0),not
AiLearning/src/py3.x/ml/1.MLFoundation/NumPy.py,53,误差,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,14,默认解析的数据是用tab分隔，并且是数值类型,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,15,general function to parse tab -delimited floats,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,25,假定最后一列是结果值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,26,assume last column is target value,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,31,将每行转换成浮点数,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,49,# 测试案例,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,50,"print 'dataSet[:, feature]=', dataSet[:, feature]",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,51,"print 'nonzero(dataSet[:, feature] > value)[0]=', nonzero(dataSet[:, feature] > value)[0]",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,52,"print 'nonzero(dataSet[:, feature] <= value)[0]=', nonzero(dataSet[:, feature] <= value)[0]",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,54,"dataSet[:, feature] 取去每一行中，第1列的值(从0开始算)",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,55,"nonzero(dataSet[:, feature] > value)  返回结果为true行的index下标",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,61,返回每一个叶子结点的均值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,62,returns the value used for each leaf,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,63,我的理解是：regLeaf 是产生叶节点的函数，就是求均值，即用聚类中心点来代表这类数据,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,68,计算总方差=方差*样本数,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,69,我的理解是：求这组数据的方差，即通过决策树划分，可以让靠近的数据分到同一类中去,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,71,shape(dataSet)[0] 表示行数,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,75,1.用最佳方式切分数据集,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,76,2.生成相应的叶节点,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,91,"ops=(1,4)，非常重要，因为它决定了决策树划分停止的threshold值，被称为预剪枝（prepruning），其实也就是用于控制函数的停止时机。",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,92,之所以这样说，是因为它防止决策树的过拟合，所以当误差的下降值小于tolS，或划分后的集合size小于tolN时，选择停止继续划分。,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,93,最小误差下降值，划分后的误差减小小于这个差值，就不用继续划分,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,95,划分最小 size 小于，就不继续划分了,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,97,如果数据集的最后一列所有值相等就退出,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,98,"dataSet[:, -1].T.tolist()[0] 取数据集的最后一列，转置为行向量，然后转换为list,取该list中的第一个元素。",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,99,如果集合size为1，也就是说全部的数据都是同一个类别，不用继续划分。,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,100,exit cond 1,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,102,计算行列值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,104,无分类误差的总方差和,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,105,the choice of the best feature is driven by Reduction in RSS error from mean,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,107,inf 正无穷大,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,109,循环处理每一列对应的feature值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,110,对于每个特征,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,111,下面的一行表示的是将某一列全部的数据转换为行，然后设置为list形式,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,113,对该列进行分组，然后组内的成员的val值进行 二元切分,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,115,判断二元切分的方式的元素数量是否符合预期,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,119,如果二元切分，算出来的误差在可接受范围内，那么就记录切分点，并记录最小误差,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,120,如果划分后误差小于 bestS，则说明找到了新的bestS,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,125,判断二元切分的方式的元素误差是否符合预期,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,126,if the decrease (S-bestS) is less than a threshold don't do the split,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,130,对整体的成员进行判断，是否符合预期,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,131,如果集合的 size 小于 tolN,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,132,当最佳划分后，集合过小，也不划分，产生叶节点,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,137,assume dataSet is NumPy Mat so we can array filtering,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,138,假设 dataSet 是 NumPy Mat 类型的，那么我们可以进行 array 过滤,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,150,选择最好的切分方式： feature索引值，最优切分值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,151,choose the best split,SATD
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,153,if the splitting hit a stop condition return val,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,154,如果 splitting 达到一个停止条件，那么返回 val,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,160,大于在右边，小于在左边，分为2个数据集,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,162,递归的进行调用，在左右子树中继续递归生成树,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,168,判断节点是否是一个字典,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,181,计算左右枝丫的均值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,199,检查是否适合合并分枝,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,210,判断是否测试数据集没有数据，如果没有，就直接返回tree本身的均值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,214,判断分枝是否是dict字典，如果是就将测试数据集进行切分,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,217,如果是左边分枝是字典，就传入左边的数据集和左边的分枝，进行递归,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,220,如果是右边分枝是字典，就传入左边的数据集和左边的分枝，进行递归,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,224,上面的一系列操作本质上就是将测试数据集按照训练完成的树拆分好，对应的值放到对应的节点,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,226,如果左右两边同时都不是dict字典，也就是左右两边都是叶节点，而不是子树了，那么分割测试数据集。,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,227,1. 如果正确,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,228,* 那么计算一下总方差 和 该结果集的本身不分枝的总方差比较,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,229,* 如果 合并的总方差 < 不合并的总方差，那么就进行合并,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,230,注意返回的结果： 如果可以合并，原来的dict就变为了 数值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,233,"power(x, y)表示x的y次方",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,237,如果 合并的总方差 < 不合并的总方差，那么就进行合并,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,247,得到模型的ws系数：f(x) = x0 + x1*featrue1+ x3*featrue2 ...,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,248,create linear model and return coeficients,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,262,计算线性模型的误差值,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,274,"print corrcoef(yHat, Y, rowvar=0)",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,278,helper function used in two places,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,291,产生一个关于1的矩阵,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,294,X的0列为1，常数项，用于计算平衡误差,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,298,转置矩阵*矩阵,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,300,如果矩阵的逆不存在，会造成程序异常,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,303,最小二乘法求最优解:  w0*1+w1*x1=y,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,308,回归树测试案例,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,309,为了和 modelTreeEval() 保持一致，保留两个输入参数,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,323,模型树测试案例,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,324,对输入数据进行格式化处理，在原数据矩阵上增加第0列，元素的值都是1，,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,325,也就是增加偏移值，和我们之前的简单线性回归是一个套路，增加一个偏移量,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,339,"print X, model",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,343,计算预测的结果,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,344,在给定树结构的情况下，对于单个数据点，该函数会给出一个预测值。,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,345,modelEval是对叶节点进行预测的函数引用，指定树的类型，以便在叶节点上调用合适的模型。,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,346,此函数自顶向下遍历整棵树，直到命中叶节点为止，一旦到达叶节点，它就会在输入数据上,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,347,调用modelEval()函数，该函数的默认值为regTreeEval(),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,373,预测结果,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,387,print yHat,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,390,"print ""yHat==>"", yHat[i, 0]",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,395,# 测试数据集,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,396,testMat = mat(eye(4)),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,397,print testMat,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,398,print type(testMat),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,399,"mat0, mat1 = binSplitDataSet(testMat, 1, 0.5)",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,400,"print mat0, '\n-----------\n', mat1",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,402,# 回归树,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,403,myDat = loadDataSet('data/9.RegTrees/data1.txt'),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,404,# myDat = loadDataSet('data/9.RegTrees/data2.txt'),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,405,"# print 'myDat=', myDat",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,406,myMat = mat(myDat),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,407,"# print 'myMat=',  myMat",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,408,myTree = createTree(myMat),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,409,print myTree,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,411,# 1. 预剪枝就是：提起设置最大误差数和最少元素数,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,412,myDat = loadDataSet('data/9.RegTrees/data3.txt'),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,413,myMat = mat(myDat),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,414,"myTree = createTree(myMat, ops=(0, 1))",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,415,print myTree,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,417,# 2. 后剪枝就是：通过测试数据，对预测模型进行合并判断,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,418,myDatTest = loadDataSet('data/9.RegTrees/data3test.txt'),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,419,myMat2Test = mat(myDatTest),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,420,"myFinalTree = prune(myTree, myMat2Test)",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,421,print '\n\n\n-------------------',not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,422,print myFinalTree,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,424,# --------,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,425,# 模型树求解,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,426,myDat = loadDataSet('data/9.RegTrees/data4.txt'),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,427,myMat = mat(myDat),not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,428,"myTree = createTree(myMat, modelLeaf, modelErr)",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,429,print myTree,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,431,# 回归树 VS 模型树 VS 线性回归,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,434,# 回归树,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,439,print yHat1,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,440,"print ""ssss==>"", testMat[:, 1]",not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,443,模型树,not
AiLearning/src/py3.x/ml/9.RegTrees/regTrees.py,449,线性回归,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,23,"相当于告诉 布局管理器(Geometry Manager),如果不设定位置，默认在 0行0列的位置",not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,27,最大为误差， 最大子叶节点的数量,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,29,clear the figure,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,33,检查复选框是否选中,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,43,use scatter for data set,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,45,use plot for yHat,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,68,画新的tree,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,70,#get values from Entry boxes,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,76,标题,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,78,"输入栏1, 叶子的数量",not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,84,"输入栏2, 误差量",not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,89,设置输出值,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,92,设置提交的按钮,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,95,设置复选按钮,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,101,退出按钮,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,104,创建一个画板 canvas,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,117,创建一个事件,not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,119,test_widget_text(root),not
AiLearning/src/py3.x/ml/9.RegTrees/treeExplore.py,122,启动事件循环,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,14,引入必要的模型和库,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,19,创建一个随机的数据集,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,20,参考 https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.random.mtrand.RandomState.html,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,22,"print 'lalalalala===', rng",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,23,"rand() 是给定形状的随机值，rng.rand(80, 1)即矩阵的形状是 80行，1列",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,24,sort(),not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,26,"print 'X=', X",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,28,"print 'y=', y",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,30,"print 'yyy=', y",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,32,拟合回归模型,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,33,regr_1 = DecisionTreeRegressor(max_depth=2),not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,34,保持 max_depth=5 不变，增加 min_samples_leaf=6 的参数，效果进一步提升了,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,37,regr_3 = DecisionTreeRegressor(max_depth=4),not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,38,"regr_1.fit(X, y)",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,40,"regr_3.fit(X, y)",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,42,预测,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,44,y_1 = regr_1.predict(X_test),not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,46,y_3 = regr_3.predict(X_test),not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,48,绘制结果,not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,51,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py3.x/ml/9.RegTrees/sklearn-regressTree-demo.py,53,"plt.plot(X_test, y_3, color=""red"", label=""max_depth=3"", linewidth=2)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,4,''',not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,5,Created on 2017-03-10,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,6,Update on 2017-03-10,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,7,author: jiangzhonglian,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,8,content: 回归树,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,9,''',not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,11,print(__doc__),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,14,# Import the necessary modules and libraries,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,15,import numpy as np,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,16,from sklearn.tree import DecisionTreeRegressor,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,17,import matplotlib.pyplot as plt,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,20,# Create a random dataset,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,21,rng = np.random.RandomState(1),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,22,"X = np.sort(5 * rng.rand(80, 1), axis=0)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,23,y = np.sin(X).ravel(),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,24,"print X, '\n\n\n-----------\n\n\n', y",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,25,y[::5] += 3 * (0.5 - rng.rand(16)),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,28,# Fit regression model,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,29,"regr_1 = DecisionTreeRegressor(max_depth=2, min_samples_leaf=5)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,30,"regr_2 = DecisionTreeRegressor(max_depth=5, min_samples_leaf=5)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,31,"regr_1.fit(X, y)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,32,"regr_2.fit(X, y)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,35,# Predict,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,36,"X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,37,y_1 = regr_1.predict(X_test),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,38,y_2 = regr_2.predict(X_test),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,41,# Plot the results,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,42,plt.figure(),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,43,"plt.scatter(X, y, c=""darkorange"", label=""data"")",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,44,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,45,"plt.plot(X_test, y_2, color=""yellowgreen"", label=""max_depth=5"", linewidth=2)",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,46,"plt.xlabel(""data"")",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,47,"plt.ylabel(""target"")",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,48,"plt.title(""Decision Tree Regression"")",not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,49,plt.legend(),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,50,plt.show(),not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,68,Author: Noel Dawe <noel.dawe@gmail.com>,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,69,,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,70,License: BSD 3 clause,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,72,importing necessary libraries,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,78,Create the dataset,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,83,Fit regression model,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,92,Predict,not
AiLearning/src/py3.x/ml/9.RegTrees/RTSklearn.py,96,Plot the results,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,23,needs to be updated,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,46,"['r', 'x', 'n', 'o', 's'],",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,62,this version does not use recursion,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,73,建立相同元素之间的关系，例如： 左边的r指向右边的r值,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,90,取出 元素 出现次数最高的,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,91,如果该元素在 inTree.children 这个字典中，就进行累加,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,92,如果该元素不存在 就 inTree.children 字典中新增key，value为初始化的 treeNode 对象,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,94,更新 最大元素，对应的 treeNode 对象的count进行叠加,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,97,如果不存在子节点，我们为该inTree添加子节点,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,99,如果满足minSup的dist字典的value值第二位为null， 我们就设置该元素为 本节点对应的tree节点,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,100,如果元素第二位不为null，我们就更新header节点,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,102,headerTable只记录第一次节点出现的位置,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,105,本质上是修改headerTable的key对应的Tree，的nodeLink值,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,108,递归的调用，在items[0]的基础上，添加item0[1]做子节点， count只要循环的进行累计加和而已，统计出节点的最后的统计值。,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,122,支持度>=minSup的dist{所有元素：出现的次数},not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,124,循环 dist{行：出现次数}的样本数据,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,126,对所有的行进行循环，得到行里面的所有元素,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,127,统计每一行中，每个元素出现的总次数,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,129,例如： {'ababa': 3}  count(a)=3+3+3=9   count(b)=3+3=6,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,131,删除 headerTable中，元素次数<最小支持度的元素,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,132,"python3中.keys()返回的是迭代器不是list,不能在遍历时对其改变。",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,136,满足minSup: set(各元素集合),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,138,如果不存在，直接返回None,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,142,"格式化： dist{元素key: [元素次数, None]}",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,145,create tree,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,147,循环 dist{行：出现次数}的样本数据,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,149,"print('tranSet, count=', tranSet, count)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,150,localD = dist{元素key: 元素总出现次数},not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,153,判断是否在满足minSup的集合中,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,155,"print('headerTable[item][0]=', headerTable[item][0], headerTable[item])",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,157,"print('localD=', localD)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,158,对每一行的key 进行排序，然后开始往树添加枝丫，直到丰满,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,159,第二次，如果在同一个排名下出现，那么就对该枝丫的值进行追加，继续递归调用！,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,161,"p=key,value; 所以是通过value值的大小，进行从大到小进行排序",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,162,orderedItems 表示取出元组的key值，也就是字母本身，但是字母本身是大到小的顺序,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,164,"print 'orderedItems=', orderedItems, 'headerTable', headerTable, '\n\n\n'",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,165,填充树，通过有序的orderedItems的第一位，进行顺序填充 第一层的子节点。,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,193,对 treeNode的link进行循环,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,196,寻找改节点的父节点，相当于找到了该节点的频繁项集,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,198,"排除自身这个元素，判断是否存在父元素（所以要>1, 说明存在父元素）",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,200,"对非basePat的倒叙值作为key,赋值为count数",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,201,prefixPath[1:] 变frozenset后，字母就变无序了,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,202,condPats[frozenset(prefixPath)] = treeNode.count,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,204,递归，寻找改节点的下一个 相同值的链接节点,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,206,print(treeNode),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,220,通过value进行从小到大的排序， 得到频繁项集的key,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,221,最小支持项集的key的list集合,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,225,循环遍历 最频繁项集的key，从小到大的递归寻找对应的频繁项集,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,227,preFix为newFreqSet上一次的存储记录，一旦没有myHead，就不会更新,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,237,构建FP-tree,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,240,"挖掘条件 FP-tree, 如果myHead不为空，表示满足minSup {所有的元素+(value, treeNode)}",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,244,递归 myHead 找出频繁项集,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,249,import twitter,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,250,from time import sleep,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,251,import re,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,254,def getLotsOfTweets(searchStr):,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,255,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,256,获取 100个搜索结果页面,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,257,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,258,CONSUMER_KEY = '',not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,259,CONSUMER_SECRET = '',not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,260,ACCESS_TOKEN_KEY = '',not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,261,ACCESS_TOKEN_SECRET = '',not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,262,"api = twitter.Api(consumer_key=CONSUMER_KEY, consumer_secret=CONSUMER_SECRET, access_token_key=ACCESS_TOKEN_KEY, access_token_secret=ACCESS_TOKEN_SECRET)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,264,# you can get 1500 results 15 pages * 100 per page,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,265,resultsPages = [],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,266,"for i in range(1, 15):",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,267,"print(""fetching page %d"" % i)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,268,"searchResults = api.GetSearch(searchStr, per_page=100, page=i)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,269,resultsPages.append(searchResults),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,270,sleep(6),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,271,return resultsPages,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,274,def textParse(bigString):,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,275,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,276,解析页面内容,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,277,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,278,"urlsRemoved = re.sub('(http:[/][/]|www.)([a-z]|[A-Z]|[0-9]|[/.]|[~])*', '', bigString)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,279,"listOfTokens = re.split(r'\W*', urlsRemoved)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,280,return [tok.lower() for tok in listOfTokens if len(tok) > 2],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,283,"def mineTweets(tweetArr, minSup=5):",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,284,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,285,获取频繁项集,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,286,"""""""",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,287,parsedList = [],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,288,for i in range(14):,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,289,for j in range(100):,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,290,parsedList.append(textParse(tweetArr[i][j].text)),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,291,initSet = createInitSet(parsedList),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,292,"myFPtree, myHeaderTab = createTree(initSet, minSup)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,293,myFreqList = [],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,294,"mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,295,return myFreqList,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,299,"rootNode = treeNode('pyramid', 9, None)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,300,"rootNode.children['eye'] = treeNode('eye', 13, None)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,301,"rootNode.children['phoenix'] = treeNode('phoenix', 3, None)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,302,# 将树以文本形式显示,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,303,# print(rootNode.disp()),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,305,load样本数据,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,307,"print(simpDat, '\n')",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,308,frozen set 格式化 并 重新装载 样本数据，对所有的行进行统计求和，格式: {行：出现次数},not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,312,创建FP树,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,313,输入：dist{行：出现次数}的样本数据  和  最小的支持度,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,314,输出：最终的PF-tree，通过循环获取第一层的节点，然后每一层的节点进行递归的获取每一行的字节点，也就是分支。然后所谓的指针，就是后来的指向已存在的,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,318,抽取条件模式基,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,319,查询树节点的，频繁子项,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,324,创建条件模式基,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,329,# 项目实战,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,330,# 1.twitter项目案例,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,331,# 无法运行，因为没发链接twitter,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,332,lotsOtweets = getLotsOfTweets('RIMM'),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,333,"listOfTerms = mineTweets(lotsOtweets, 20)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,334,print(len(listOfTerms)),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,335,for t in listOfTerms:,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,336,print(t),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,338,# 2.新闻网站点击流中挖掘，例如：文章1阅读过的人，还阅读过什么？,not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,339,parsedDat = [line.split() for line in open('data/12.FPGrowth/kosarak.dat').readlines()],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,340,initSet = createInitSet(parsedDat),not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,341,"myFPtree, myHeaderTab = createTree(initSet, 100000)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,343,myFreList = [],not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,344,"mineTree(myFPtree, myHeaderTab, 100000, set([]), myFreList)",not
AiLearning/src/py3.x/ml/12.FrequentPattemTree/fpGrowth.py,345,print myFreList,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,20,"dataMat.append([float(lineArr[0]), float(lineArr[1]), float(lineArr[2])])",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,42,就是预测 y 的值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,58,回归系数,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,61,重置 wDelta,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,63,它是学习率，代表了权重调整幅度的大小。（也可以理解为随机梯度的步长，使它不断减小，便于拟合）,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,64,输入T和K分别设定了迭代次数和待处理列表的大小。在T次迭代过程中，每次需要重新计算eta,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,67,全部的训练集  内循环中执行批处理，将分类错误的值全部做累加后更新权重向量,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,69,mapper 代码,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,71,"如果预测正确，并且预测结果的绝对值>=1，因为最大间隔为1, 认为没问题。",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,72,"否则算是预测错误, 通过预测错误的结果，来累计更新w.",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,73,mapper 代码,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,74,累积变化,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,75,w通过不断的随机梯度的方式来优化,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,76,在每个 T上应用更改,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,77,"print '-----', w",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,78,"print '++++++', w",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,84,"finalWs = seqPegasos(datMat, labelList, 2, 5000)",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,107,y2 = (0.43799*x)/0.12316,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/pegasos.py,108,2 iterations,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,16,"input key= class for one training example, e.g. ""-1.0""",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,17,e.g. [-1.0],not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,20,"input value = feature vector for one training example, e.g. ""3.0, 7.0, 2.0""",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,24,create matrix E and vector e,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,28,create a tuple with the values to be used by reducer,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,29,and encode it with base64 to avoid potential trouble with '\t' and '\n' used,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,30,as default separators in Hadoop Streaming,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,33,"note: a single constant key ""producedkey"" sends to only one reducer",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,34,"somewhat ""atypical"" due to low degree of parallism on reducer side",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,41,"key isn't used, so ignoring it with _ (underscore).",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,43,unpickle values,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,46,create the I/mu with correct dimensions,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,51,create sumETDe with correct dimensions,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,56,note: omega = result[:-1] and gamma = result[-1],not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/proximalSVM.py,57,but printing entire vector as output,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,16,对数据初始化,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,22,接受输入数据流,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,23,需要 2 个参数，求数据的和与平方和,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,31,所有输入到达后开始处理,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,32,计算数据的平均值，平方的均值，并返回,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,41,从输入流中获取值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMean.py,48,发出平均值和方差,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,24,返回值中包含输入文件的每一行的数据的一个大的List,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,27,创建一个输入的数据行的列表list,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,29,将输入行分割成单独的项目并存储在列表的列表中,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,31,输入 数据的个数，n个数据的均值，n个数据平方之后的均值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,34,累计样本总和，总和 和 平分和的总和,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,42,计算均值( varSum是计算方差的展开形式 ),not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanReducer.py,45,输出 数据总量，均值，平方的均值（方差）,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,28,返回一个 yield 迭代器，每次获取下一个值，节约内存。,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,31,创建一个输入的数据行的列表list,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,32,将得到的数据转化为 float 类型,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,33,获取数据的个数，即输入文件的数据的行数,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,34,将 List 转换为矩阵,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,35,将矩阵的数据分别求 平方，即 2次方,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,37,输出 数据的个数，n个数据的均值，n个数据平方之后的均值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,38,第一行是标准输出，也就是reducer的输出,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,39,第二行识标准错误输出，即对主节点作出的响应报告，表明本节点工作正常。,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,40,【这不就是面试的装逼重点吗？如何设计监听架构细节】注意：一个好的习惯是想标准错误输出发送报告。如果某任务10分钟内没有报告输出，则将被Hadoop中止。,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrMeanMapper.py,41,计算均值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,2,coding:utf-8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,28,iteration number,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,39,需要 2 个参数,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,40,"input: nodeId, ('w', w-vector) OR nodeId, ('x', int)",not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,43,积累 w向量,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,46,累积数据点计算,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,47,迭代次数,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,50,这用于 debug， eta未在map中使用,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,54,将数据重新形成 X 和 Y,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,56,在第一次迭代时，初始化 w,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,58,calc p=w*dataSet[key].T,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,60,确保一切数据包含相同的key,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,61,它们将在同一个 reducer,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,65,从流输入获取值,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,79,wDelta += label*dataSet,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,80,calc new: eta,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,81,calc new: w = (1.0 - 1/t)*w + (eta/k)*wDelta,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,84,发出 w,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,86,增量 T,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/mrSVM.py,87,emit random ints for mappers iid,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/wc.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/wc.py,2,coding:utf8,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/wc.py,16,I'm a generator!,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/wc.py,18,+1 for newline,not
AiLearning/src/py3.x/ml/15.BigData_MapReduce/py27dbg.py,14,needs exactly 2 arguments,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,10,导入科学计算包numpy和运算符模块operator,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,53,-----------实现 classify0() 方法的第一种方式----------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,54,1. 距离计算,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,56,tile生成和训练样本对应的矩阵，并与训练样本求差,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,83,取平方,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,85,将矩阵的每一行相加,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,87,开方,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,89,根据距离排序从小到大的排序，返回对应的索引位置,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,90,argsort() 是将x中的元素从小到大排列，提取其对应的index（索引），然后输出到y。,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,91,"例如：y=array([3,0,2,1,4,5]) 则，x[3]=1最小，所以y[0]=3;x[5]=5最大，所以y[5]=5。",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,92,"print 'distances=', distances",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,94,"print 'distances.argsort()=', sortedDistIndicies",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,96,2. 选择距离最小的k个点,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,99,找到该样本的类型,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,101,在字典中将该类型加一,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,102,字典的get方法,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,103,"如：list.get(k,d) 其中 get相当于一条if...else...语句,参数k在字典中，字典将返回list[k];如果参数k不在字典中则返回参数d,如果K在字典中则返回k对应的value值",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,104,"l = {5:2,3:4}",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,105,"print l.get(3,0)返回的值是4；",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,106,"Print l.get（1,0）返回值是0；",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,108,3. 排序并返回出现最多的那个类型,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,109,字典的 items() 方法，以列表返回可遍历的(键，值)元组数组。,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,110,"例如：dict = {'Name': 'Zara', 'Age': 7}   print ""Value : %s"" %  dict.items()   Value : [('Age', 7), ('Name', 'Zara')]",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,111,sorted 中的第2个参数 key=operator.itemgetter(1) 这个参数的意思是先比较第几个元素,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,112,"例如：a=[('b',2),('a',1),('c',0)]  b=sorted(a,key=operator.itemgetter(1)) >>>b=[('c',0),('a',1),('b',2)] 可以看到排序是按照后边的0,1,2进行排序的，而不是a,b,c",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,113,"b=sorted(a,key=operator.itemgetter(0)) >>>b=[('a',1),('b',2),('c',0)] 这次比较的是前边的a,b,c而不是0,1,2",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,114,"b=sorted(a,key=opertator.itemgetter(1,0)) >>>b=[('c',0),('a',1),('b',2)] 这个是先比较第2个元素，然后对第一个元素进行排序，形成多级排序。",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,118,------------------------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,119,实现 classify0() 方法的第二种方式,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,121,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,122,1. 计算距离,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,124,欧氏距离： 点到点之间的距离,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,125,第一行： 同一个点 到 dataSet的第一个点的距离。,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,126,第二行： 同一个点 到 dataSet的第二个点的距离。,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,127,...,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,128,第N行： 同一个点 到 dataSet的第N个点的距离。,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,130,"[[1,2,3],[1,2,3]]-[[1,2,3],[1,2,0]]",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,131,(A1-A2)^2+(B1-B2)^2+(c1-c2)^2,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,133,inx - dataset 使用了numpy broadcasting，见 https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,134,np.sum() 函数的使用见 https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,135,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,136,"dist = np.sum((inx - dataset)**2, axis=1)**0.5",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,138,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,139,2. k个最近的标签,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,141,对距离排序使用numpy中的argsort函数， 见 https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sort.html#numpy.sort,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,142,函数返回的是索引，因此取前k个索引使用[0 : k],not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,143,将这k个标签存在列表k_labels中,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,144,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,145,k_labels = [labels[index] for index in dist.argsort()[0 : k]],not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,146,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,147,3. 出现次数最多的标签即为最终类别,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,149,"使用collections.Counter可以统计各个标签的出现次数，most_common返回出现次数最多的标签tuple，例如[('lable1', 2)]，因此[0][0]可以取出标签值",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,150,"""""""",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,151,label = Counter(k_labels).most_common(1)[0][0],not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,152,return label,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,154,------------------------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,167,----------------------------------------------------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,175,获得文件中的数据行的行数,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,177,生成对应的空矩阵,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,178,例如：zeros(2，3)就是生成一个 2*3 的矩阵，各个位置上全是 0,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,179,prepare matrix to return,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,180,prepare labels return,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,184,str.strip([chars]) --返回移除字符串头尾指定的字符生成的新字符串,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,186,以 '\t' 切割字符串,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,188,每列的属性数据，即 features,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,190,每列的类别数据，就是 label 标签数据,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,193,返回数据矩阵returnMat和对应的类别classLabelVector,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,212,计算每种属性的最大值、最小值、范围,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,215,极差,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,217,-------第一种实现方式---start-------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,220,生成与最小值之差组成的矩阵,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,222,将最小值之差除以范围组成矩阵,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,223,element wise divide,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,224,-------第一种实现方式---end---------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,226,# -------第二种实现方式---start---------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,227,norm_dataset = (dataset - minvalue) / ranges,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,228,# -------第二种实现方式---end---------------------------------------------,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,241,设置测试数据的的一个比例（训练数据集比例=1-hoRatio）,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,242,"测试范围,一部分测试一部分作为样本",not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,243,从文件中加载数据,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,244,load data setfrom file,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,245,归一化数据,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,247,m 表示数据的行数，即矩阵的第一维,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,249,设置测试的样本数量， numTestVecs:m表示训练样本的数量,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,254,对数据测试,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,292,1. 导入数据,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,294,load the training set,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,297,hwLabels存储0～9对应的index位置， trainingMat存放的每个位置对应的图片向量,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,300,take off .txt,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,303,将 32*32的矩阵->1*1024的矩阵,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,306,2. 导入测试数据,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,307,iterate through the test set,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,312,take off .txt,not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,323,test1(),not
AiLearning/src/py3.x/ml/2.KNN/kNN.py,324,datingClassTest(),not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,21,导入一些要玩的数据,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,23,我们只采用前两个feature. 我们可以使用二维数据集避免这个丑陋的切片,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,26,"print 'X=', type(X), X",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,27,"print 'y=', type(y), y",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,29,"X = array([[-1.0, -1.1], [-1.0, -1.0], [0, 0], [1.0, 1.1], [2.0, 2.0], [2.0, 2.1]])",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,30,"y = array([0, 0, 0, 1, 1, 1])",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,32,"print 'X=', type(X), X",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,33,"print 'y=', type(y), y",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,35,网格中的步长,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,37,创建彩色的图,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,41,"cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,42,"cmap_bold = ListedColormap(['#FF0000', '#00FF00'])",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,45,我们创建了一个knn分类器的实例，并拟合数据。,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,49,绘制决策边界。为此，我们将为每个分配一个颜色,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,50,"来绘制网格中的点 [x_min, x_max]x[y_min, y_max].",not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,57,将结果放入一个彩色图中,not
AiLearning/src/py3.x/ml/2.KNN/sklearn-knn-demo.py,62,绘制训练点,not
AiLearning/src/py3.x/ml/4.NaiveBayes/sklearn-nb-demo.py,1,!/usr/bin/python,not
AiLearning/src/py3.x/ml/4.NaiveBayes/sklearn-nb-demo.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/4.NaiveBayes/sklearn-nb-demo.py,13,GaussianNB_高斯朴素贝叶斯,not
AiLearning/src/py3.x/ml/4.NaiveBayes/sklearn-nb-demo.py,25,MultinomialNB_多项朴素贝叶斯,not
AiLearning/src/py3.x/ml/4.NaiveBayes/sklearn-nb-demo.py,36,BernoulliNB_伯努利朴素贝叶斯,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,10,我个人非常不喜欢 from numpy import *,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,11,"因为这样会和一些系统函数冲突，比如log, sum之类的",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,20,------项目案例1: 屏蔽社区留言板的侮辱性言论------,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,35,"1 is 侮辱性的文字, 0 is not",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,45,create empty set,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,47,| 求两个集合的并集,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,59,创建一个和词汇表等长的向量，并将其元素都设置为0,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,61,遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,66,这个后面应该注释掉，因为对你没什么用，这只是为了辅助调试的,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,67,print('the word: {} is not in my vocabulary'.format(word)),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,83,因为侮辱性的被标记为了1， 所以只要把他们相加就可以得到侮辱性的有多少,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,84,侮辱性文件的出现概率，即train_category中所有的1的个数，,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,85,代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,87,单词出现的次数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,88,原版,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,92,整个数据集单词出现的次数（原来是0，后面改成2了）,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,97,遍历所有的文件，如果是侮辱性文件，就计算此侮辱性文件中出现的侮辱性单词的个数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,104,后面需要改成改成取 log 函数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,121,因为侮辱性的被标记为了1， 所以只要把他们相加就可以得到侮辱性的有多少,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,122,侮辱性文件的出现概率，即train_category中所有的1的个数，,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,123,代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,125,单词出现的次数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,126,原版，变成ones是修改版，这是为了防止数字过小溢出,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,127,p0num = np.zeros(words_num),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,128,p1num = np.zeros(words_num),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,131,整个数据集单词出现的次数（原来是0，后面改成2了）,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,136,遍历所有的文件，如果是侮辱性文件，就计算此侮辱性文件中出现的侮辱性单词的个数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,143,后面改成取 log 函数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,161,计算公式  log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C)),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,162,使用 NumPy 数组来计算两个向量相乘的结果，这里的相乘是指对应元素相乘，即先将两个向量中的第一个元素相乘，然后将第2个元素相乘，以此类推。,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,163,我的理解是：这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,164,可以理解为 1.单词在词汇表中的条件下，文件是good 类别的概率 也可以理解为 2.在整个空间下，文件既在词汇表中又是good类别的概率,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,174,注意和原来的做对比,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,189,1. 加载数据集,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,191,2. 创建单词集合,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,194,3. 计算单词是否出现并创建数据矩阵,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,198,返回m*len(vocab_list)的矩阵， 记录的都是0，1信息,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,199,"其实就是那个东西的句子向量（就是data_set里面每一行,也不算句子吧)",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,202,4. 训练数据,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,204,5. 测试数据,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,213,--------项目案例2: 使用朴素贝叶斯过滤垃圾邮件--------------,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,223,其实这里比较推荐用　\W+ 代替 \W*，,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,224,因为 \W*会match empty patten，在py3.5+之后就会出现什么问题，推荐自己修改尝试一下，可能就会re.split理解更深了,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,240,添加垃圾邮件信息,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,241,这里需要做一个说明，为什么我会使用try except 来做,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,242,"因为我们其中有几个文件的编码格式是 windows 1252　（spam: 17.txt, ham: 6.txt...)",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,243,这里其实还可以 :,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,244,import os,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,245,然后检查 os.system(' file {}.txt'.format(i))，看一下返回的是什么,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,246,如果正常能读返回的都是：　ASCII text,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,247,"对于except需要处理的都是返回： Non-ISO extended-ASCII text, with very long lines",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,256,添加非垃圾邮件,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,263,创建词汇表,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,267,"生成随机取10个数, 为了避免警告将每个数都转换为整型",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,269,并在原来的training_set中去掉这10个数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,282,开始测试,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,297,----- 项目案例3: 使用朴素贝叶斯从个人广告中获取区域倾向 ------,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,298,其中有几个函数上面都写过了，没必要再写一遍了，所以删了,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,302,RSS源分类器及高频词去除函数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,312,import feedparser # 其实呢，这一行没用到，最好删了,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,313,下面操作和上面那个 spam_test函数基本一样，理解了一个，两个都ok,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,317,找出两个中最小的一个,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,320,类别　１,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,325,类别　０,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,331,去掉高频词,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,336,获取训练数据和测试数据,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,339,"生成随机取10个数, 为了避免警告将每个数都转换为整型",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,341,并在原来的training_set中去掉这10个数,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,344,把这些训练集和测试集变成向量的形式,not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,373,"返回值都没用上，可以用_, _, _代替",not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,399,testing_naive_bayes(),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,400,spam_test(),not
AiLearning/src/py3.x/ml/4.NaiveBayes/bayes.py,401,test_rss(),not
AiLearning/src/py3.x/dl/mnist.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/mnist.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/mnist.py,8,忽略警告一把梭，忽略了sigmoid函数位数溢出的警告,not
AiLearning/src/py3.x/dl/mnist.py,12,数据加载器基类,not
AiLearning/src/py3.x/dl/mnist.py,36,"return struct.unpack('B', byte)[0]",not
AiLearning/src/py3.x/dl/mnist.py,39,图像数据加载器,not
AiLearning/src/py3.x/dl/mnist.py,77,标签数据加载器,not
AiLearning/src/py3.x/dl/activators.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/activators.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/activators.py,10,return weighted_input,not
AiLearning/src/py3.x/dl/cnn.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/cnn.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/cnn.py,9,获取卷积区域,not
AiLearning/src/py3.x/dl/cnn.py,28,获取一个2D区域的最大值所在的索引,not
AiLearning/src/py3.x/dl/cnn.py,41,计算卷积,not
AiLearning/src/py3.x/dl/cnn.py,62,为数组增加Zero padding,not
AiLearning/src/py3.x/dl/cnn.py,93,对numpy数组进行element wise操作,not
AiLearning/src/py3.x/dl/cnn.py,197,处理卷积步长，对原始sensitivity map进行扩展,not
AiLearning/src/py3.x/dl/cnn.py,200,full卷积，对sensitivitiy map进行zero padding,not
AiLearning/src/py3.x/dl/cnn.py,201,虽然原始输入的zero padding单元也会获得残差,not
AiLearning/src/py3.x/dl/cnn.py,202,但这个残差不需要继续向上传递，因此就不计算了,not
AiLearning/src/py3.x/dl/cnn.py,207,初始化delta_array，用于保存传递到上一层的,not
AiLearning/src/py3.x/dl/cnn.py,208,sensitivity map,not
AiLearning/src/py3.x/dl/cnn.py,210,对于具有多个filter的卷积层来说，最终传递到上一层的,not
AiLearning/src/py3.x/dl/cnn.py,211,sensitivity map相当于所有的filter的,not
AiLearning/src/py3.x/dl/cnn.py,212,sensitivity map之和,not
AiLearning/src/py3.x/dl/cnn.py,215,将filter权重翻转180度,not
AiLearning/src/py3.x/dl/cnn.py,217,计算与一个filter对应的delta_array,not
AiLearning/src/py3.x/dl/cnn.py,223,将计算结果与激活函数的偏导数做element-wise乘法操作,not
AiLearning/src/py3.x/dl/cnn.py,230,处理卷积步长，对原始sensitivity map进行扩展,not
AiLearning/src/py3.x/dl/cnn.py,234,计算每个权重的梯度,not
AiLearning/src/py3.x/dl/cnn.py,240,计算偏置项的梯度,not
AiLearning/src/py3.x/dl/cnn.py,245,确定扩展后sensitivity map的大小,not
AiLearning/src/py3.x/dl/cnn.py,246,计算stride为1时sensitivity map的大小,not
AiLearning/src/py3.x/dl/cnn.py,251,构建新的sensitivity_map,not
AiLearning/src/py3.x/dl/cnn.py,254,从原始sensitivity map拷贝误差值,not
AiLearning/src/py3.x/dl/cnn.py,387,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py3.x/dl/cnn.py,390,计算forward值,not
AiLearning/src/py3.x/dl/cnn.py,394,求取sensitivity map,not
AiLearning/src/py3.x/dl/cnn.py,397,计算梯度,not
AiLearning/src/py3.x/dl/cnn.py,400,检查梯度,not
AiLearning/src/py3.x/dl/recursive.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/recursive.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/recursive.py,18,递归神经网络实现,not
AiLearning/src/py3.x/dl/recursive.py,33,权重数组W,not
AiLearning/src/py3.x/dl/recursive.py,36,偏置项b,not
AiLearning/src/py3.x/dl/recursive.py,38,递归神经网络生成的树的根节点,not
AiLearning/src/py3.x/dl/recursive.py,84,根据式2计算每个子节点的delta,not
AiLearning/src/py3.x/dl/recursive.py,88,slices = [(子节点编号，子节点delta起始位置，子节点delta结束位置)],not
AiLearning/src/py3.x/dl/recursive.py,92,针对每个子节点，递归调用calc_delta函数,not
AiLearning/src/py3.x/dl/recursive.py,138,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py3.x/dl/recursive.py,143,计算forward值,not
AiLearning/src/py3.x/dl/recursive.py,148,求取sensitivity map,not
AiLearning/src/py3.x/dl/recursive.py,151,计算梯度,not
AiLearning/src/py3.x/dl/recursive.py,154,检查梯度,not
AiLearning/src/py3.x/dl/bp.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/bp.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/bp.py,8,sigmoid 函数,not
AiLearning/src/py3.x/dl/bp.py,21,定义神经网络的节点类,not
AiLearning/src/py3.x/dl/bp.py,37,设置节点所在的层的位置,not
AiLearning/src/py3.x/dl/bp.py,39,设置层中的节点的索引,not
AiLearning/src/py3.x/dl/bp.py,41,设置此节点的下游节点，也就是这个节点与下一层的哪个节点相连,not
AiLearning/src/py3.x/dl/bp.py,43,设置此节点的上游节点，也就是哪几个节点的下游节点与此节点相连,not
AiLearning/src/py3.x/dl/bp.py,45,此节点的输出,not
AiLearning/src/py3.x/dl/bp.py,47,此节点真实值与计算值之间的差值,not
AiLearning/src/py3.x/dl/bp.py,70,使用 list 的 append 方法来将 conn 中的节点添加到 downstream 中,not
AiLearning/src/py3.x/dl/bp.py,82,使用 list 的 append 方法来将 conn 中的节点添加到 upstream 中,not
AiLearning/src/py3.x/dl/bp.py,94,使用 reduce() 函数对其中的因素求和,not
AiLearning/src/py3.x/dl/bp.py,96,对上游节点的 output 乘 weights 之后求和得到的结果应用 sigmoid 函数，得到当前节点的 output,not
AiLearning/src/py3.x/dl/bp.py,108,根据 https://www.zybuluo.com/hanbingtao/note/476663 的 式4 计算隐藏层的delta,not
AiLearning/src/py3.x/dl/bp.py,110,计算此节点的 delta,not
AiLearning/src/py3.x/dl/bp.py,122,就是那输出层的 delta,not
AiLearning/src/py3.x/dl/bp.py,134,打印格式：第几层 - 第几个节点，output 是多少，delta 是多少,not
AiLearning/src/py3.x/dl/bp.py,136,下游节点,not
AiLearning/src/py3.x/dl/bp.py,138,上游节点,not
AiLearning/src/py3.x/dl/bp.py,140,将本节点 + 下游节点 + 上游节点 的信息打印出来,not
AiLearning/src/py3.x/dl/bp.py,144,ConstNode 对象，为了实现一个输出恒为 1 的节点（计算偏置项 wb 时需要）,not
AiLearning/src/py3.x/dl/bp.py,175,使用 list 的 append 方法将包含下游节点的 conn 添加到 downstream 中,not
AiLearning/src/py3.x/dl/bp.py,188,使用我们的 公式 4 来计算下游节点的 delta，求和,not
AiLearning/src/py3.x/dl/bp.py,190,计算隐藏层的本节点的 delta,not
AiLearning/src/py3.x/dl/bp.py,203,将节点的信息打印出来,not
AiLearning/src/py3.x/dl/bp.py,204,格式 第几层-第几个节点的 output,not
AiLearning/src/py3.x/dl/bp.py,206,此节点的下游节点的信息,not
AiLearning/src/py3.x/dl/bp.py,208,将此节点与下游节点的信息组合，一起打印出来,not
AiLearning/src/py3.x/dl/bp.py,212,神经网络的层对象，负责初始化一层。此外，作为 Node 的集合对象，提供对 Node 集合的操作,not
AiLearning/src/py3.x/dl/bp.py,229,设置 层的索引,not
AiLearning/src/py3.x/dl/bp.py,231,设置层中的节点的 list,not
AiLearning/src/py3.x/dl/bp.py,233,将 Node 节点添加到 nodes 中,not
AiLearning/src/py3.x/dl/bp.py,236,将 ConstNode 节点也添加到 nodes 中,not
AiLearning/src/py3.x/dl/bp.py,248,设置输入层中各个节点的 output,not
AiLearning/src/py3.x/dl/bp.py,261,遍历本层的所有节点（除去最后一个节点，因为它是恒为常数的偏置项b）,not
AiLearning/src/py3.x/dl/bp.py,262,调用节点的 calc_output 方法来计算输出向量,not
AiLearning/src/py3.x/dl/bp.py,275,遍历层的所有的节点 nodes，将节点信息打印出来,not
AiLearning/src/py3.x/dl/bp.py,280,Connection 对象类，主要负责记录连接的权重，以及这个连接所关联的上下游的节点,not
AiLearning/src/py3.x/dl/bp.py,296,设置上游节点,not
AiLearning/src/py3.x/dl/bp.py,298,设置下游节点,not
AiLearning/src/py3.x/dl/bp.py,300,设置权重，这里设置的权重是 -0.1 到 0.1 之间的任何数,not
AiLearning/src/py3.x/dl/bp.py,302,设置梯度 为 0.0,not
AiLearning/src/py3.x/dl/bp.py,314,下游节点的 delta * 上游节点的 output 计算得到梯度,not
AiLearning/src/py3.x/dl/bp.py,326,调用计算梯度的函数来将梯度计算出来,not
AiLearning/src/py3.x/dl/bp.py,328,使用梯度下降算法来更新权重,not
AiLearning/src/py3.x/dl/bp.py,351,格式为：上游节点的层的索引+上游节点的节点索引 ---> 下游节点的层的索引+下游节点的节点索引，最后一个数是权重,not
AiLearning/src/py3.x/dl/bp.py,361,Connections 对象，提供 Connection 集合操作。,not
AiLearning/src/py3.x/dl/bp.py,376,初始化一个列表 list,not
AiLearning/src/py3.x/dl/bp.py,403,Network 对象，提供相应 API,not
AiLearning/src/py3.x/dl/bp.py,418,初始化 connections，使用的是 Connections 对象,not
AiLearning/src/py3.x/dl/bp.py,420,初始化 layers,not
AiLearning/src/py3.x/dl/bp.py,422,我们的神经网络的层数,not
AiLearning/src/py3.x/dl/bp.py,424,节点数,not
AiLearning/src/py3.x/dl/bp.py,426,遍历所有的层，将每层信息添加到 layers 中去,not
AiLearning/src/py3.x/dl/bp.py,429,遍历除去输出层之外的所有层，将连接信息添加到 connections 对象中,not
AiLearning/src/py3.x/dl/bp.py,432,遍历 connections，将 conn 添加到 connections 中,not
AiLearning/src/py3.x/dl/bp.py,435,为下游节点添加上游节点为 conn,not
AiLearning/src/py3.x/dl/bp.py,437,为上游节点添加下游节点为 conn,not
AiLearning/src/py3.x/dl/bp.py,453,循环迭代 epoch 次,not
AiLearning/src/py3.x/dl/bp.py,455,遍历每个训练样本,not
AiLearning/src/py3.x/dl/bp.py,457,使用此样本进行训练（一条样本进行训练）,not
AiLearning/src/py3.x/dl/bp.py,459,print 'sample %d training finished' % d,not
AiLearning/src/py3.x/dl/bp.py,472,调用 Network 的 predict 方法，对这个样本进行预测,not
AiLearning/src/py3.x/dl/bp.py,474,计算根据此样本得到的结果的 delta,not
AiLearning/src/py3.x/dl/bp.py,476,更新权重,not
AiLearning/src/py3.x/dl/bp.py,488,获取输出层的所有节点,not
AiLearning/src/py3.x/dl/bp.py,490,遍历所有的 label,not
AiLearning/src/py3.x/dl/bp.py,492,计算输出层节点的 delta,not
AiLearning/src/py3.x/dl/bp.py,494,"这个用法就是切片的用法， [-2::-1] 就是将 layers 这个数组倒过来，从没倒过来的时候的倒数第二个元素开始，到翻转过来的倒数第一个数，比如这样：aaa = [1,2,3,4,5,6,7,8,9],bbb = aaa[-2::-1] ==> bbb = [8, 7, 6, 5, 4, 3, 2, 1]",not
AiLearning/src/py3.x/dl/bp.py,495,实际上就是除掉输出层之外的所有层按照相反的顺序进行遍历,not
AiLearning/src/py3.x/dl/bp.py,497,遍历每层的所有节点,not
AiLearning/src/py3.x/dl/bp.py,499,计算隐藏层的 delta,not
AiLearning/src/py3.x/dl/bp.py,511,按照正常顺序遍历除了输出层的层,not
AiLearning/src/py3.x/dl/bp.py,513,遍历每层的所有节点,not
AiLearning/src/py3.x/dl/bp.py,515,遍历节点的下游节点,not
AiLearning/src/py3.x/dl/bp.py,517,根据下游节点来更新连接的权重,not
AiLearning/src/py3.x/dl/bp.py,529,按照正常顺序遍历除了输出层之外的层,not
AiLearning/src/py3.x/dl/bp.py,531,遍历层中的所有节点,not
AiLearning/src/py3.x/dl/bp.py,533,遍历节点的下游节点,not
AiLearning/src/py3.x/dl/bp.py,535,计算梯度,not
AiLearning/src/py3.x/dl/bp.py,548,调用 predict() 方法，利用样本的特征数据对样本进行预测,not
AiLearning/src/py3.x/dl/bp.py,550,计算 delta,not
AiLearning/src/py3.x/dl/bp.py,552,计算梯度,not
AiLearning/src/py3.x/dl/bp.py,564,首先为输入层设置输出值output为样本的输入向量，即不发生任何变化,not
AiLearning/src/py3.x/dl/bp.py,566,遍历除去输入层开始到最后一层,not
AiLearning/src/py3.x/dl/bp.py,568,计算 output,not
AiLearning/src/py3.x/dl/bp.py,570,将计算得到的输出，也就是我们的预测值返回,not
AiLearning/src/py3.x/dl/bp.py,582,遍历所有的 layers,not
AiLearning/src/py3.x/dl/bp.py,584,将所有的层的信息打印出来,not
AiLearning/src/py3.x/dl/bp.py,588,# ------------------------- 至此，基本上我们把 我们的神经网络实现完成，下面还会介绍一下对应的梯度检查相关的算法，现在我们首先回顾一下我们上面写道的类及他们的作用 ------------------------,not
AiLearning/src/py3.x/dl/bp.py,637,#--------------------------------------回顾完成了，有些问题可能还是没有弄懂，没事，我们接着看下面---------------------------------------------,not
AiLearning/src/py3.x/dl/bp.py,657,初始化 16 进制的数，用来判断位的，分别是,not
AiLearning/src/py3.x/dl/bp.py,658,0x1 ---- 00000001,not
AiLearning/src/py3.x/dl/bp.py,659,0x2 ---- 00000010,not
AiLearning/src/py3.x/dl/bp.py,660,0x4 ---- 00000100,not
AiLearning/src/py3.x/dl/bp.py,661,0x8 ---- 00001000,not
AiLearning/src/py3.x/dl/bp.py,662,0x10 --- 00010000,not
AiLearning/src/py3.x/dl/bp.py,663,0x20 --- 00100000,not
AiLearning/src/py3.x/dl/bp.py,664,0x40 --- 01000000,not
AiLearning/src/py3.x/dl/bp.py,665,0x80 --- 10000000,not
AiLearning/src/py3.x/dl/bp.py,677,此方法就相当于判断一个 8 位的向量，哪一位上有数字，如果有就将这个数设置为  0.9 ，否则，设置为 0.1，通俗比较来说，就是我们这里用 0.9 表示 1，用 0.1 表示 0,not
AiLearning/src/py3.x/dl/bp.py,689,进行二分类，大于 0.5 就设置为 1，小于 0.5 就设置为 0,not
AiLearning/src/py3.x/dl/bp.py,691,遍历 mask,not
AiLearning/src/py3.x/dl/bp.py,694,将结果相加得到最终的预测结果,not
AiLearning/src/py3.x/dl/bp.py,723,计算网络误差,not
AiLearning/src/py3.x/dl/bp.py,726,获取网络在当前样本下每个连接的梯度,not
AiLearning/src/py3.x/dl/bp.py,729,对每个权重做梯度检查,not
AiLearning/src/py3.x/dl/bp.py,731,获取指定连接的梯度,not
AiLearning/src/py3.x/dl/bp.py,734,增加一个很小的值，计算网络的误差,not
AiLearning/src/py3.x/dl/bp.py,739,减去一个很小的值，计算网络的误差,not
AiLearning/src/py3.x/dl/bp.py,740,刚才加过了一次，因此这里需要减去2倍,not
AiLearning/src/py3.x/dl/bp.py,743,根据式6计算期望的梯度值,not
AiLearning/src/py3.x/dl/bp.py,746,打印,not
AiLearning/src/py3.x/dl/bp.py,759,调用 Normalizer() 类,not
AiLearning/src/py3.x/dl/bp.py,761,初始化一个 list，用来存储后面的数据,not
AiLearning/src/py3.x/dl/bp.py,764,0 到 256 ，其中以 8 为步长,not
AiLearning/src/py3.x/dl/bp.py,766,调用 normalizer 对象的 norm 方法,not
AiLearning/src/py3.x/dl/bp.py,768,在 data_set 中 append n,not
AiLearning/src/py3.x/dl/bp.py,770,在 labels 中 append n,not
AiLearning/src/py3.x/dl/bp.py,772,将它们返回,not
AiLearning/src/py3.x/dl/bp.py,785,获取训练数据集,not
AiLearning/src/py3.x/dl/bp.py,789,调用 network 中的 train方法来训练我们的神经网络,not
AiLearning/src/py3.x/dl/bp.py,794,此函数不明觉厉，但是传参就有问题，如果跑不通就把这段代码注释掉吧。。。,not
AiLearning/src/py3.x/dl/bp.py,805,调用 Normalizer() 类,not
AiLearning/src/py3.x/dl/bp.py,808,调用 norm 方法，对数据进行规范化,not
AiLearning/src/py3.x/dl/bp.py,811,对测试数据进行预测,not
AiLearning/src/py3.x/dl/bp.py,813,将结果打印出来,not
AiLearning/src/py3.x/dl/bp.py,843,创建一个有 3 层的网络，每层有 2 个节点,not
AiLearning/src/py3.x/dl/bp.py,845,样本的特征,not
AiLearning/src/py3.x/dl/bp.py,847,样本对应的标签,not
AiLearning/src/py3.x/dl/bp.py,849,使用梯度检查来查看是否正确,not
AiLearning/src/py3.x/dl/bp.py,862,初始化一个神经网络，输入层 8 个节点，隐藏层 3 个节点，输出层 8 个节点,not
AiLearning/src/py3.x/dl/bp.py,864,训练我们的神经网络,not
AiLearning/src/py3.x/dl/bp.py,866,将我们的神经网络的信息打印出来,not
AiLearning/src/py3.x/dl/bp.py,868,打印出神经网络的正确率,not
AiLearning/src/py3.x/dl/lstm.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/lstm.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/lstm.py,17,门的激活函数,not
AiLearning/src/py3.x/dl/lstm.py,19,输出的激活函数,not
AiLearning/src/py3.x/dl/lstm.py,21,当前时刻初始化为t0,not
AiLearning/src/py3.x/dl/lstm.py,23,各个时刻的单元状态向量c,not
AiLearning/src/py3.x/dl/lstm.py,25,各个时刻的输出向量h,not
AiLearning/src/py3.x/dl/lstm.py,27,各个时刻的遗忘门f,not
AiLearning/src/py3.x/dl/lstm.py,29,各个时刻的输入门i,not
AiLearning/src/py3.x/dl/lstm.py,31,各个时刻的输出门o,not
AiLearning/src/py3.x/dl/lstm.py,33,各个时刻的即时状态c~,not
AiLearning/src/py3.x/dl/lstm.py,35,"遗忘门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py3.x/dl/lstm.py,38,"输入门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py3.x/dl/lstm.py,41,"输出门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py3.x/dl/lstm.py,44,"单元状态权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py3.x/dl/lstm.py,73,遗忘门,not
AiLearning/src/py3.x/dl/lstm.py,77,输入门,not
AiLearning/src/py3.x/dl/lstm.py,81,输出门,not
AiLearning/src/py3.x/dl/lstm.py,85,即时状态,not
AiLearning/src/py3.x/dl/lstm.py,89,单元状态,not
AiLearning/src/py3.x/dl/lstm.py,92,输出,not
AiLearning/src/py3.x/dl/lstm.py,100,上次的LSTM输出,not
AiLearning/src/py3.x/dl/lstm.py,131,初始化各个时刻的误差项,not
AiLearning/src/py3.x/dl/lstm.py,132,输出误差项,not
AiLearning/src/py3.x/dl/lstm.py,133,输出门误差项,not
AiLearning/src/py3.x/dl/lstm.py,134,输入门误差项,not
AiLearning/src/py3.x/dl/lstm.py,135,遗忘门误差项,not
AiLearning/src/py3.x/dl/lstm.py,136,即时输出误差项,not
AiLearning/src/py3.x/dl/lstm.py,138,保存从上一层传递下来的当前时刻的误差项,not
AiLearning/src/py3.x/dl/lstm.py,141,迭代计算每个时刻的误差项,not
AiLearning/src/py3.x/dl/lstm.py,160,获得k时刻前向计算的值,not
AiLearning/src/py3.x/dl/lstm.py,170,根据式9计算delta_o,not
AiLearning/src/py3.x/dl/lstm.py,189,保存全部delta值,not
AiLearning/src/py3.x/dl/lstm.py,197,初始化遗忘门权重梯度矩阵和偏置项,not
AiLearning/src/py3.x/dl/lstm.py,200,初始化输入门权重梯度矩阵和偏置项,not
AiLearning/src/py3.x/dl/lstm.py,203,初始化输出门权重梯度矩阵和偏置项,not
AiLearning/src/py3.x/dl/lstm.py,206,初始化单元状态权重梯度矩阵和偏置项,not
AiLearning/src/py3.x/dl/lstm.py,210,计算对上一次输出h的权重梯度,not
AiLearning/src/py3.x/dl/lstm.py,212,计算各个时刻的梯度,not
AiLearning/src/py3.x/dl/lstm.py,218,实际梯度是各时刻梯度之和,not
AiLearning/src/py3.x/dl/lstm.py,228,计算对本次输入x的权重梯度,not
AiLearning/src/py3.x/dl/lstm.py,263,当前时刻初始化为t0,not
AiLearning/src/py3.x/dl/lstm.py,265,各个时刻的单元状态向量c,not
AiLearning/src/py3.x/dl/lstm.py,267,各个时刻的输出向量h,not
AiLearning/src/py3.x/dl/lstm.py,269,各个时刻的遗忘门f,not
AiLearning/src/py3.x/dl/lstm.py,271,各个时刻的输入门i,not
AiLearning/src/py3.x/dl/lstm.py,273,各个时刻的输出门o,not
AiLearning/src/py3.x/dl/lstm.py,275,各个时刻的即时状态c~,not
AiLearning/src/py3.x/dl/lstm.py,290,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py3.x/dl/lstm.py,295,计算forward值,not
AiLearning/src/py3.x/dl/lstm.py,300,求取sensitivity map,not
AiLearning/src/py3.x/dl/lstm.py,303,计算梯度,not
AiLearning/src/py3.x/dl/lstm.py,306,检查梯度,not
AiLearning/src/py3.x/dl/perceptron.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/perceptron.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/perceptron.py,29,设置的激活函数,not
AiLearning/src/py3.x/dl/perceptron.py,31,权重向量初始化为 0,not
AiLearning/src/py3.x/dl/perceptron.py,33,偏置项初始化为 0,not
AiLearning/src/py3.x/dl/perceptron.py,56,将输入向量的计算结果返回,not
AiLearning/src/py3.x/dl/perceptron.py,57,调用 激活函数 activator ，将输入向量输入，计算感知器的结果,not
AiLearning/src/py3.x/dl/perceptron.py,58,reduce() 函数是 python 2 的内置函数，从 python 3 开始移到了 functools 模块,not
AiLearning/src/py3.x/dl/perceptron.py,59,"reduce() 从左到右对一个序列的项累计地应用有两个参数的函数，以此合并序列到一个单一值，例如 reduce(lambda x,y: x+y, [1,2,3,4,5]) 计算的就是 ((((1+2)+3)+4)+5)",not
AiLearning/src/py3.x/dl/perceptron.py,60,"map() 接收一个函数 f 和一个 list ，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 返回。比如我们的 f 函数是计算平方， map(f, [1,2,3,4,5]) ===> 返回 [1,4,9,16,25]",not
AiLearning/src/py3.x/dl/perceptron.py,61,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py3.x/dl/perceptron.py,68,"此处python3 lambda无法传入一个tuple的两个变量，因此将tuple当作一个整体，tp[0]为input_vec,tp[1]为self.weights",not
AiLearning/src/py3.x/dl/perceptron.py,70,还有一种更加简洁明了的写法，很清楚明白,not
AiLearning/src/py3.x/dl/perceptron.py,71,"return self.activator(sum([x*w for (x,w) in zip(input_vec,self.weights)])+self.bias)",not
AiLearning/src/py3.x/dl/perceptron.py,99,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py3.x/dl/perceptron.py,101,对每个样本，按照感知器规则更新权重,not
AiLearning/src/py3.x/dl/perceptron.py,103,计算感知器在当前权重下的输出,not
AiLearning/src/py3.x/dl/perceptron.py,105,更新权重,not
AiLearning/src/py3.x/dl/perceptron.py,120,利用感知器规则更新权重,not
AiLearning/src/py3.x/dl/perceptron.py,123,"map() 接收一个函数 f 和一个 list ，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 返回。比如我们的 f 函数是计算平方， map(f, [1,2,3,4,5]) ===> 返回 [1,4,9,16,25]",not
AiLearning/src/py3.x/dl/perceptron.py,124,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py3.x/dl/perceptron.py,125,此处python3必须对map函数进行list操作，不然 self.weights为map类型，最后无法打印出具体数值,not
AiLearning/src/py3.x/dl/perceptron.py,131,更新 bias,not
AiLearning/src/py3.x/dl/perceptron.py,158,构建训练数据，输入向量的列表,not
AiLearning/src/py3.x/dl/perceptron.py,160,期望的输出列表，也就是上面的输入向量的列表中数据对应的标签，是一一对应的,not
AiLearning/src/py3.x/dl/perceptron.py,174,创建感知器，输入参数的个数是 2 个（因为 and 是个二元函数），激活函数为 f,not
AiLearning/src/py3.x/dl/perceptron.py,176,进行训练，迭代 10 轮，学习速率是我们设定的 rate ，为 0.1,not
AiLearning/src/py3.x/dl/perceptron.py,179,返回训练好的感知器,not
AiLearning/src/py3.x/dl/perceptron.py,191,训练 and 感知器,not
AiLearning/src/py3.x/dl/perceptron.py,193,打印训练获得的权重,not
AiLearning/src/py3.x/dl/perceptron.py,195,测试,not
AiLearning/src/py3.x/dl/linear_unit.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/linear_unit.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/linear_unit.py,4,引入 Perceptron 类,not
AiLearning/src/py3.x/dl/linear_unit.py,7,定义激活函数 f,not
AiLearning/src/py3.x/dl/linear_unit.py,28,初始化我们的感知器类，设置输入参数的个数 input_num 和 激活函数 f,not
AiLearning/src/py3.x/dl/linear_unit.py,31,构造简单的数据集,not
AiLearning/src/py3.x/dl/linear_unit.py,42,构建数据集，输入向量列表，每一项是工作年限,not
AiLearning/src/py3.x/dl/linear_unit.py,44,期望的输出列表，也就是输入向量的对应的标签，与工作年限对应的收入年薪,not
AiLearning/src/py3.x/dl/linear_unit.py,49,使用我们的训练数据集对线性单元进行训练,not
AiLearning/src/py3.x/dl/linear_unit.py,59,创建感知器对象，输入参数的个数也就是特征数为 1（工作年限）,not
AiLearning/src/py3.x/dl/linear_unit.py,61,获取构建的数据集,not
AiLearning/src/py3.x/dl/linear_unit.py,63,训练感知器，迭代 10 轮，学习率为 0.01,not
AiLearning/src/py3.x/dl/linear_unit.py,65,返回训练好的线性单元,not
AiLearning/src/py3.x/dl/linear_unit.py,69,将图像画出来,not
AiLearning/src/py3.x/dl/linear_unit.py,79,引入绘图的库,not
AiLearning/src/py3.x/dl/linear_unit.py,81,获取训练数据：特征 input_vecs 与 对应的标签 labels,not
AiLearning/src/py3.x/dl/linear_unit.py,83,figure() 创建一个 Figure 对象，与用户交互的整个窗口，这个 figure 中容纳着 subplots,not
AiLearning/src/py3.x/dl/linear_unit.py,85,在 figure 对象中创建 1行1列中的第一个图,not
AiLearning/src/py3.x/dl/linear_unit.py,87,"scatter(x, y) 绘制散点图，其中的 x,y 是相同长度的数组序列",not
AiLearning/src/py3.x/dl/linear_unit.py,91,设置权重,not
AiLearning/src/py3.x/dl/linear_unit.py,93,设置偏置项,not
AiLearning/src/py3.x/dl/linear_unit.py,98,将图画出来,not
AiLearning/src/py3.x/dl/linear_unit.py,101,将最终的图展示出来,not
AiLearning/src/py3.x/dl/linear_unit.py,114,首先训练我们的线性单元,not
AiLearning/src/py3.x/dl/linear_unit.py,116,打印训练获得的权重 和 偏置,not
AiLearning/src/py3.x/dl/linear_unit.py,118,测试,not
AiLearning/src/py3.x/dl/linear_unit.py,127,定义激活函数f,not
AiLearning/src/py3.x/dl/rnn.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/rnn.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/rnn.py,18,当前时刻初始化为t0,not
AiLearning/src/py3.x/dl/rnn.py,19,保存各个时刻的state,not
AiLearning/src/py3.x/dl/rnn.py,21,初始化s0,not
AiLearning/src/py3.x/dl/rnn.py,23,初始化U,not
AiLearning/src/py3.x/dl/rnn.py,25,初始化W,not
AiLearning/src/py3.x/dl/rnn.py,52,用来保存各个时刻的误差项,not
AiLearning/src/py3.x/dl/rnn.py,57,迭代计算每个时刻的误差项,not
AiLearning/src/py3.x/dl/rnn.py,73,保存各个时刻的权重梯度,not
AiLearning/src/py3.x/dl/rnn.py,79,实际的梯度是各个时刻梯度之和,not
AiLearning/src/py3.x/dl/rnn.py,82,[0]被初始化为0且没有被修改过,not
AiLearning/src/py3.x/dl/rnn.py,93,当前时刻初始化为t0,not
AiLearning/src/py3.x/dl/rnn.py,94,保存各个时刻的state,not
AiLearning/src/py3.x/dl/rnn.py,96,初始化s0,not
AiLearning/src/py3.x/dl/rnn.py,110,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py3.x/dl/rnn.py,115,计算forward值,not
AiLearning/src/py3.x/dl/rnn.py,120,求取sensitivity map,not
AiLearning/src/py3.x/dl/rnn.py,123,计算梯度,not
AiLearning/src/py3.x/dl/rnn.py,126,检查梯度,not
AiLearning/src/py3.x/dl/fc.py,1,!/usr/bin/env python,not
AiLearning/src/py3.x/dl/fc.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py3.x/dl/fc.py,11,全连接层实现类,not
AiLearning/src/py3.x/dl/fc.py,24,权重数组W,not
AiLearning/src/py3.x/dl/fc.py,27,偏置项b,not
AiLearning/src/py3.x/dl/fc.py,29,输出向量,not
AiLearning/src/py3.x/dl/fc.py,37,式2,not
AiLearning/src/py3.x/dl/fc.py,47,式8,not
AiLearning/src/py3.x/dl/fc.py,64,神经网络类,not
AiLearning/src/py3.x/dl/fc.py,136,获取网络在当前样本下每个连接的梯度,not
AiLearning/src/py3.x/dl/fc.py,140,检查梯度,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,2,coding: utf8,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,13,逻辑回归中的 L1 惩罚和稀缺性 L1 Penalty and Sparsity in Logistic Regression,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,77,具有 L1-逻辑回归的路径,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,121,绘制多项式和一对二的逻辑回归 Plot multinomial and One-vs-Rest Logistic Regression,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,184,Logistic Regression 3-class Classifier 逻辑回归 3-类 分类器,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,192,引入一些数据来玩,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,194,我们只采用样本数据的前两个feature,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,198,网格中的步长,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,202,我们创建了一个 Neighbours Classifier 的实例，并拟合数据。,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,205,"绘制决策边界。为此我们将为网格 [x_min, x_max]x[y_min, y_max] 中的每个点分配一个颜色。",not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,211,将结果放入彩色图中,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,216,将训练点也同样放入彩色图中,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,228,Logistic function 逻辑回归函数,not
AiLearning/src/py2.x/ml/5.Logistic/sklearn_logisticRegression_demo.py,229,这个类似于咱们之前讲解 logistic 回归的 Sigmoid 函数，模拟的阶跃函数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,2,coding: utf8,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,14,---------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,15,使用 Logistic 回归在简单数据集上的分类,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,18,解析数据,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,29,dataMat为原始数据， labelMat为原始数据的标签,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,36,这里如果就一个空的元素，则跳过本次循环,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,37,为了方便计算，我们将 X0 的值设为 1.0 ，也就是在每一行的开头添加一个 1.0 作为 X0,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,43,sigmoid跳跃函数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,45,return 1.0 / (1 + exp(-inX)),not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,47,Tanh是Sigmoid的变形，与 sigmoid 不同的是，tanh 是0均值的。因此，实际应用中，tanh 会比 sigmoid 更好。,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,51,正常的处理方案,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,52,两个参数：第一个参数==> dataMatIn 是一个2维NumPy数组，每列分别代表每个不同的特征，每行则代表每个训练样本。,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,53,第二个参数==> classLabels 是类别标签，它是一个 1*100 的行向量。为了便于矩阵计算，需要将该行向量转换为列向量，做法是将原向量转置，再将它赋值给labelMat。,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,65,"转化为矩阵[[1,1,2],[1,1,2]....]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,66,转换为 NumPy 矩阵,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,67,"转化为矩阵[[0,1,0,1,0,1.....]]，并转制[[0],[1],[0].....]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,68,transpose() 行列转置函数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,69,将行向量转化为列向量   =>  矩阵的转置,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,70,首先将数组转换为 NumPy 矩阵，然后再将行向量转置为列向量,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,71,m->数据量，样本数 n->特征数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,73,"print m, n, '__'*10, shape(dataMatrix.transpose()), '__'*100",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,74,alpha代表向目标移动的步长,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,76,迭代次数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,78,"生成一个长度和特征数相同的矩阵，此处n为3 -> [[1],[1],[1]]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,79,"weights 代表回归系数， 此处的 ones((n,1)) 创建一个长度和特征数相同的矩阵，其中的数全部都是 1",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,81,heavy on matrix operations,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,82,m*3 的矩阵 * 3*1 的单位矩阵 ＝ m*1的矩阵,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,83,那么乘上单位矩阵的意义，就代表：通过公式得到的理论值,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,84,参考地址： 矩阵乘法的本质是什么？ https://www.zhihu.com/question/21351965/answer/31050145,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,85,"print 'dataMatrix====', dataMatrix",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,86,"print 'weights====', weights",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,87,n*3   *  3*1  = n*1,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,88,矩阵乘法,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,89,"print 'hhhhhhh====', h",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,90,labelMat是实际值,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,91,向量相减,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,92,"0.001* (3*m)*(m*1) 表示在每一个列上的一个误差情况，最后得出 x1,x2,xn的系数的偏移量",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,93,矩阵乘法，最后得到回归系数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,97,随机梯度下降,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,98,梯度下降优化算法在每次更新数据集时都需要遍历整个数据集，计算复杂都较高,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,99,随机梯度下降一次只用一个样本点来更新回归系数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,112,n*1的矩阵,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,113,函数ones创建一个全1的数组,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,114,初始化长度为n的数组，元素全部为 1,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,116,"sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn,此处求出的 h 是一个具体的数值，而不是一个矩阵",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,118,"print 'dataMatrix[i]===', dataMatrix[i]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,119,计算真实类别与预测类别之间的差值，然后按照该差值调整回归系数,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,121,0.01*(1*1)*(1*n),not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,122,"print weights, ""*"" * 10, dataMatrix[i], ""*"" * 10, error",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,127,随机梯度下降算法（随机化）,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,140,创建与列数相同的矩阵的系数矩阵，所有的元素都是1,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,141,"随机梯度, 循环150,观察是否收敛",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,143,"[0, 1, 2 .. m-1]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,146,i和j的不断增大，导致alpha的值不断减少，但是不为0,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,149,alpha 会随着迭代不断减小，但永远不会减小到0，因为后边还有一个常数项0.0001,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,150,随机产生一个 0～len()之间的一个值,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,151,"random.uniform(x, y) 方法将随机生成下一个实数，它在[x,y]范围内,x是这个范围内的最小值，y是这个范围内的最大值。",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,153,sum(dataMatrix[i]*weights)为了求 f(x)的值， f(x)=a1*x1+b2*x2+..+nn*xn,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,156,"print weights, '__h=%s' % h, '__'*20, alpha, '__'*20, error, '__'*20, dataMatrix[randIndex]",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,162,可视化展示,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,208,1.收集并准备数据,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,211,"print dataMat, '---\n', labelMat",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,212,"2.训练模型，  f(x)=a1*x1+b2*x2+..+nn*xn中 (a1,b2, .., nn).T的矩阵值",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,213,因为数组没有是复制n份， array的乘法就是乘法,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,215,print dataArr,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,216,"weights = gradAscent(dataArr, labelMat)",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,217,"weights = stocGradAscent0(dataArr, labelMat)",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,219,"print '*'*30, weights",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,221,数据可视化,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,225,--------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,226,从疝气病症预测病马的死亡率,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,227,分类函数，根据回归系数和特征向量来计算 Sigmoid的值,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,244,"打开测试集和训练集,并对数据进行格式化处理",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,258,解析训练数据集中的数据特征和Labels,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,259,trainingSet 中存储训练数据集的特征，trainingLabels 存储训练数据集的样本对应的分类标签,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,267,使用 改进后的 随机梯度下降算法 求得在此数据集上的最佳回归系数 trainWeights,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,269,"trainWeights = stocGradAscent0(array(trainingSet), trainingLabels)",not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,272,读取 测试数据集 进行测试，计算分类错误的样本条数和最终的错误率,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,287,调用 colicTest() 10次并求结果的平均值,not
AiLearning/src/py2.x/ml/5.Logistic/logistic.py,298,multiTest(),not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,2,coding: utf-8,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,16,利用SVD提高推荐效果，菜肴矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,31,书上代码给的示例矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,56,# 原矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,57,"return[[1, 1, 1, 0, 0],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,58,"[2, 2, 2, 0, 0],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,59,"[1, 1, 1, 0, 0],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,60,"[5, 5, 5, 0, 0],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,61,"[1, 1, 0, 2, 2],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,62,"[0, 0, 0, 3, 3],",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,63,"[0, 0, 0, 1, 1]]",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,65,原矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,72,相似度计算，假定inA和inB 都是列向量,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,73,基于欧氏距离,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,78,pearsSim()函数会检查是否存在3个或更多的点。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,79,"corrcoef直接计算皮尔逊相关系数，范围[-1, 1]，归一化后[0, 1]",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,81,如果不存在，该函数返回1.0，此时两个向量完全相关。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,87,计算余弦相似度，如果夹角为90度，相似度为0；如果两个向量的方向相同，相似度为1.0,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,94,基于物品相似度的推荐引擎,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,106,得到数据集中的物品数目,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,108,初始化两个评分值,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,111,遍历行中的每个物品（对用户评过分的物品进行遍历，并将它与其他物品进行比较）,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,114,如果某个物品的评分值为0，则跳过这个物品,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,117,寻找两个用户都评级的物品,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,118,变量 overLap 给出的是两个物品当中已经被评分的那个元素的索引ID,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,119,logical_and 计算x1和x2元素的真值。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,121,如果相似度为0，则两着没有任何重合元素，终止本次循环,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,124,如果存在重合的物品，则基于这些重合物重新计算相似度。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,127,"print 'the %d and %d similarity is : %f'(iten,j,similarity)",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,128,相似度会不断累加，每次计算时还考虑相似度和当前用户评分的乘积,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,129,similarity  用户相似度，   userRating 用户评分,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,134,通过除以所有的评分总和，对上述相似度评分的乘积进行归一化，使得最后评分在0~5之间，这些评分用来对预测值进行排序,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,139,基于SVD的评分估计,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,140,在recommend() 中，这个函数用于替换对standEst()的调用，该函数对给定用户给定物品构建了一个评分估计值,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,152,物品数目,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,154,对数据集进行SVD分解,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,157,奇异值分解,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,158,在SVD分解之后，我们只利用包含了90%能量值的奇异值，这些奇异值会以NumPy数组的形式得以保存,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,161,# 分析 Sigma 的长度取值,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,162,"analyse_data(Sigma, 20)",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,164,如果要进行矩阵运算，就必须要用这些奇异值构建出一个对角矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,167,利用U矩阵将物品转换到低维空间中，构建转换后的物品(物品+4个主要的特征),not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,175,对于给定的用户，for循环在用户对应行的元素上进行遍历,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,176,这和standEst()函数中的for循环的目的一样，只不过这里的相似度计算时在低维空间下进行的。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,181,相似度的计算方法也会作为一个参数传递给该函数,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,183,for 循环中加入了一条print语句，以便了解相似度计算的进展情况。如果觉得累赘，可以去掉,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,185,对相似度不断累加求和,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,187,对相似度及对应评分值的乘积求和,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,192,计算估计评分,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,196,recommend()函数，就是推荐引擎，它默认调用standEst()函数，产生了最高的N个推荐结果。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,197,如果不指定N的大小，则默认值为3。该函数另外的参数还包括相似度计算方法和估计方法,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,209,寻找未评级的物品,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,210,对给定的用户建立一个未评分的物品列表,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,212,如果不存在未评分物品，那么就退出函数,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,215,物品的编号和评分值,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,217,在未评分物品上进行循环,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,219,获取 item 该物品的评分,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,222,按照评分得分 进行逆排序，获取前N个未评级物品进行推荐,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,233,总方差的集合（总能量值）,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,246,图像压缩函数,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,247,加载并转换数据,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,250,打开文本文件，并从文件以数组方式读入字符,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,256,矩阵调入后，就可以在屏幕上输出该矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,261,打印矩阵,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,263,由于矩阵保护了浮点数，因此定义浅色和深色，遍历所有矩阵元素，当元素大于阀值时打印1，否则打印0,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,273,实现图像压缩，允许基于任意给定的奇异值数目来重构图像,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,281,构建一个列表,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,285,对原始图像进行SVD分解并重构图像e,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,288,通过Sigma 重新构成SigRecom来实现,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,289,Sigma是一个对角矩阵，因此需要建立一个全0矩阵，然后将前面的那些奇异值填充到对角线上。,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,291,"SigRecon = mat(zeros((numSV, numSV)))",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,292,for k in range(numSV):,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,293,"SigRecon[k, k] = Sigma[k]",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,295,分析插入的 Sigma 长度,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,306,# 对矩阵进行SVD分解(用python实现SVD),not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,307,Data = loadExData(),not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,308,"print 'Data:', Data",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,309,"U, Sigma, VT = linalg.svd(Data)",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,310,# 打印Sigma的结果，因为前3个数值比其他的值大了很多，为9.72140007e+00，5.29397912e+00，6.84226362e-01,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,311,# 后两个值比较小，每台机器输出结果可能有不同可以将这两个值去掉,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,312,"print 'U:', U",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,313,"print 'Sigma', Sigma",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,314,"print 'VT:', VT",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,315,"print 'VT:', VT.T",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,317,# 重构一个3x3的矩阵Sig3,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,318,"Sig3 = mat([[Sigma[0], 0, 0], [0, Sigma[1], 0], [0, 0, Sigma[2]]])",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,319,"print U[:, :3] * Sig3 * VT[:3, :]",not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,338,计算相似度的方法,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,340,print myMat,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,341,计算相似度的第一种方式,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,343,计算相似度的第二种方式,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,346,默认推荐（菜馆菜肴推荐示例）,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,362,压缩图片,not
AiLearning/src/py2.x/ml/14.SVD/svdRecommend.py,363,imgCompress(2),not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,26,general function to parse tab -delimited floats,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,28,get number of fields,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,53,默认都是1,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,55,"dataMat[:, dimen] 表示数据集中第dimen列的所有值",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,56,threshIneq == 'lt'表示修改左边的值，gt表示修改右边的值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,57,"print '-----', threshIneq, dataMat[:, dimen], threshVal",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,77,转换数据,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,80,m行 n列,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,83,初始化数据,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,87,初始化的最小误差为无穷大,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,90,循环所有的feature列，将列切分成 若干份，每一段以最左边的点作为分类节点,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,94,"print 'rangeMin=%s, rangeMax=%s' % (rangeMin, rangeMax)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,95,计算每一份的元素个数,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,97,例如： 4=(10-1)/2   那么  1-4(-1次)   1(0次)  1+1*4(1次)   1+2*4(2次),not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,98,所以： 循环 -1/0/1/2,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,100,go over less than and greater than,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,102,如果是-1，那么得到rangeMin-stepSize; 如果是numSteps，那么得到rangeMax,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,104,对单层决策树进行简单分类，得到预测的分类值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,106,print predictedVals,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,108,正确为0，错误为1,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,110,计算 平均每个特征的概率0.2*错误概率的总和为多少，就知道错误率多高,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,111,例如： 一个都没错，那么错误率= 0.2*0=0 ， 5个都错，那么错误率= 0.2*5=1， 只错3个，那么错误率= 0.2*3=0.6,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,120,"print ""split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f"" % (i, threshVal, inequal, weightedError)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,128,bestStump 表示分类器的结果，在第几个列上，用大于／小于比较，阈值是多少,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,145,初始化 D，设置每行数据的样本的所有特征权重集合，平均分为m份,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,149,得到决策树的模型,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,152,alpha 目的主要是计算每一个分类器实例的权重(加和就是分类结果),not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,153,计算每个分类器的 alpha 权重值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,156,store Stump Params in Array,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,159,"print ""alpha=%s, classEst=%s, bestStump=%s, error=%s "" % (alpha, classEst.T, bestStump, error)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,160,分类正确：乘积为1，不会影响结果，-1主要是下面求e的-alpha次方,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,161,分类错误：乘积为 -1，结果会受影响，所以也乘以 -1,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,163,print '\n',not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,164,"print 'labelArr=', labelArr",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,165,"print 'classEst=', classEst.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,166,print '\n',not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,167,"print '乘积: ', multiply(mat(labelArr).T, classEst).T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,168,判断正确的，就乘以-1，否则就乘以1， 为什么？ 书上的公式。,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,169,"print '(-1取反)预测值expon=', expon.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,170,计算e的expon次方，然后计算得到一个综合的概率的值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,171,结果发现： 判断错误的样本，D对于的样本权重值会变大。,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,174,"print ""D: "", D.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,175,print '\n',not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,177,预测的分类结果值，在上一轮结果的基础上，进行加和操作,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,178,"print '当前的分类结果：', alpha*classEst.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,180,"print ""叠加后的分类结果aggClassEst: "", aggClassEst.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,181,sign 判断正为1， 0为0， 负为-1，通过最终加和的权重值，判断符号。,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,182,"结果为：错误的样本标签集合，因为是 !=,那么结果就是0 正, 1 负",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,185,"print ""total error=%s "" % (errorRate)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,192,do stuff similar to last aggClassEst in adaBoostTrainDS,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,197,循环 多个分类器,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,199,前提： 我们已经知道了最佳的分类器的实例,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,200,通过分类器来核算每一次的分类结果，然后通过alpha*每一次的结果 得到最后的权重加和的值。,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,203,print aggClassEst,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,218,variable to calculate AUC,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,220,对正样本的进行求和,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,222,正样本的概率,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,224,负样本的概率,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,226,argsort函数返回的是数组值从小到大的索引值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,227,"get sorted index, it's reverse",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,229,测试结果是否是从小到大排列,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,232,开始创建模版对象,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,236,cursor光标值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,238,"loop through all the values, drawing a line segment at each point",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,247,"draw line from cur to (cur[0]-delX, cur[1]-delY)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,248,"画点连线 (x1, x2, y1, y2)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,252,画对角的虚线线,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,257,"设置画图的范围区间 (x1, x2, y1, y2)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,270,# 我们要将5个点进行分类,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,271,"dataArr, labelArr = loadSimpData()",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,272,"print 'dataArr', dataArr, 'labelArr', labelArr",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,274,# D表示最初值，对1进行均分为5份，平均每一个初始的概率都为0.2,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,275,# D的目的是为了计算错误概率： weightedError = D.T*errArr,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,276,"D = mat(ones((5, 1))/5)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,277,"print 'D=', D.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,279,"# bestStump, minError, bestClasEst = buildStump(dataArr, labelArr, D)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,280,"# print 'bestStump=', bestStump",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,281,"# print 'minError=', minError",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,282,"# print 'bestClasEst=', bestClasEst.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,284,# 分类器：weakClassArr,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,285,# 历史累计的分类结果集,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,286,"weakClassArr, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 9)",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,287,"print '\nweakClassArr=', weakClassArr, '\naggClassEst=', aggClassEst.T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,289,"""""""",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,290,发现:,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,291,分类的权重值：最大的值，为alpha的加和，最小值为-最大值,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,292,特征的权重值：如果一个值误判的几率越小，那么D的特征权重越少,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,293,"""""""",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,295,"# 测试数据的分类结果, 观测：aggClassEst分类的最终权重",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,296,"print adaClassify([0, 0], weakClassArr).T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,297,"print adaClassify([[5, 5], [0, 0]], weakClassArr).T",not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,299,马疝病数据集,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,300,训练集合,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,304,计算ROC下面的AUC的面积大小,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,306,测试集合,not
AiLearning/src/py2.x/ml/7.AdaBoost/adaboost.py,311,测试：计算总样本数，错误样本数，错误率,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,13,importing necessary libraries,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,22,Create the dataset,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,26,"dataArr, labelArr = loadDataSet(""data/7.AdaBoost/horseColicTraining2.txt"")",not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,29,Fit regression model,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,36,Predict,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,40,Plot the results,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,55,适合2分类,not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,61,"print ""-"" * 100",not
AiLearning/src/py2.x/ml/7.AdaBoost/sklearn-adaboost-demo.py,62,"print metrics.roc_auc_score(y[:1], y_2[:1])",not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,2,coding:utf-8,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,20,参数,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,25,加载数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,29,我们只用两个相应的features,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,33,训练,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,36,绘制决策边界,not
AiLearning/src/py2.x/ml/3.DecisionTree/sklearn_dts_classify_demo.py,52,绘制训练点,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,2,coding: utf8,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,3,原始链接： http://blog.csdn.net/lsldd/article/details/41223147,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,4,GitHub: https://github.com/apachecn/AiLearning,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,19,特征： 身高 体重   label： 胖瘦,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,23,特征数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,25,label分类的标签数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,27,预估结果的标签数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,42,print(clf),not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,49,print(x_train),not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,62,计算全量的预估结果,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,73,target_names 以 y的label分类为准,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,89,"with open(""testResult/tree.dot"", 'w') as f:",not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,90,from sklearn.externals.six import StringIO,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,91,"tree.export_graphviz(clf, out_file=f)",not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,100,from IPython.display import Image,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,101,Image(graph.create_png()),not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,111,得到训练的预测结果集,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,114,展现 准确率与召回率,not
AiLearning/src/py2.x/ml/3.DecisionTree/DTSklearn.py,117,可视化输出,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,12,"定义文本框 和 箭头格式 【 sawtooth 波浪方框, round4 矩形方框 , fc表示字体颜色的深浅 0.1~0.9 依次变浅，没错是变浅】",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,22,根节点开始遍历,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,24,"判断子节点是否为dict, 不是+1",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,36,根节点开始遍历,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,38,"判断子节点是不是dict, 求分枝的深度",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,43,记录最大的分支深度,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,61,获取叶子节点的数量,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,63,获取树的深度,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,64,depth = getTreeDepth(myTree),not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,66,找出第1个中心点的位置，然后与 parentPt定点进行划线,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,67,x坐标为 (numLeafs-1.)/plotTree.totalW/2+1./plotTree.totalW，化简如下,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,69,print cntrPt,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,70,并打印输入对应的文字,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,74,可视化Node分支点；第一次调用plotTree时，cntrPt与parentPt相同,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,76,根节点的值,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,78,y值 = 最高点-层数的高度[第二个节点位置]；1.0相当于树的高度,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,81,判断该节点是否是Node节点,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,83,如果是就递归调用[recursion],not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,86,如果不是，就在原来节点一半的地方找到节点的坐标,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,88,可视化该节点位置,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,90,并打印输入对应的文字,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,96,创建一个figure的模版,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,101,表示创建一个1行，1列的图，createPlot.ax1 为第 1 个子图，,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,106,半个节点的长度；xOff表示当前plotTree未遍历到的最左的叶节点的左边一个叶节点的x坐标,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,107,"所有叶节点中，最左的叶节点的x坐标是0.5/plotTree.totalW（因为totalW个叶节点在x轴方向是平均分布在[0, 1]区间上的）",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,108,因此，xOff的初始值应该是 0.5/plotTree.totalW-相邻两个叶节点的x轴方向距离,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,110,根节点的y坐标为1.0，树的最低点y坐标为0,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,112,第二个参数是根节点的坐标,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,117,# 测试画图,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,118,def createPlot():,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,119,"fig = plt.figure(1, facecolor='white')",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,120,fig.clf(),not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,121,# ticks for demo puropses,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,122,"createPlot.ax1 = plt.subplot(111, frameon=False)",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,123,"plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode)",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,124,"plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode)",not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,125,plt.show(),not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,128,测试数据集,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,136,用测试数据绘制树,not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,137,myTree = retrieveTree(1),not
AiLearning/src/py2.x/ml/3.DecisionTree/decisionTreePlot.py,138,createPlot(myTree),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,15,引入必要的模型和库,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,20,创建一个随机的数据集,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,21,参考 https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.random.mtrand.RandomState.html,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,23,"print 'lalalalala===', rng",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,24,"rand() 是给定形状的随机值，rng.rand(80, 1)即矩阵的形状是 80行，1列",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,25,sort(),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,27,"print 'X=', X",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,29,"print 'y=', y",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,31,"print 'yyy=', y",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,33,拟合回归模型,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,34,regr_1 = DecisionTreeRegressor(max_depth=2),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,35,保持 max_depth=5 不变，增加 min_samples_leaf=6 的参数，效果进一步提升了,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,38,regr_3 = DecisionTreeRegressor(max_depth=4),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,39,"regr_1.fit(X, y)",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,41,"regr_3.fit(X, y)",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,43,预测,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,45,y_1 = regr_1.predict(X_test),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,47,y_3 = regr_3.predict(X_test),not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,49,绘制结果,not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,52,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py2.x/ml/3.DecisionTree/skelearn_dts_regressor_demo.py,54,"plt.plot(X_test, y_3, color=""red"", label=""max_depth=3"", linewidth=2)",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,2,coding:utf-8,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,31,"dataSet = [['yes'],",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,32,"['yes'],",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,33,"['no'],",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,34,"['no'],",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,35,['no']],not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,36,labels  露出水面   脚蹼,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,38,change to discrete values,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,50,-----------计算香农熵的第一种实现方式start--------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,51,求list的长度，表示计算参与训练的数据量,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,53,下面输出我们测试的数据集的一些信息,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,54,例如：<type 'list'> numEntries:  5 是下面的代码的输出,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,55,"print type(dataSet), 'numEntries: ', numEntries",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,57,计算分类标签label出现的次数,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,59,the the number of unique elements and their occurance,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,61,将当前实例的标签存储，即每一行数据的最后一个数据代表的是标签,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,63,为所有可能的分类创建字典，如果当前的键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,67,"print '-----', featVec, labelCounts",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,69,对于label标签的占比，求出label标签的香农熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,72,使用所有类标签的发生频率计算类别出现的概率。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,74,log base 2,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,75,计算香农熵，以 2 为底求对数,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,77,"print '---', prob, prob * log(prob, 2), shannonEnt",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,78,-----------计算香农熵的第一种实现方式end--------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,80,# -----------计算香农熵的第二种实现方式start--------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,81,# 统计标签出现的次数,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,82,label_count = Counter(data[-1] for data in dataSet),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,83,# 计算概率,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,84,probs = [p[1] / len(dataSet) for p in label_count.items()],not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,85,# 计算香农熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,86,"shannonEnt = sum([-p * log(p, 2) for p in probs])",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,87,# -----------计算香农熵的第二种实现方式end--------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,101,-----------切分数据集的第一种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,104,index列为value的数据集【该数据集需要排除index列】,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,105,判断index列的值是否为value,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,107,chop out index used for splitting,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,108,[:index]表示前index行，即若 index 为2，就是取 featVec 的前 index 行,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,129,[index+1:]表示从跳过 index 的 index+1行，取接下来的数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,130,收集结果值 index列为value的行【该行需要排除index列】,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,132,-----------切分数据集的第一种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,134,# -----------切分数据集的第二种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,135,"retDataSet = [data for data in dataSet for i, v in enumerate(data) if i == axis and v == value]",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,136,# -----------切分数据集的第二种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,149,-----------选择最优特征的第一种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,150,"求第一行有多少列的 Feature, 最后一列是label列嘛",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,152,label的信息熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,154,"最优的信息增益值, 和最优的Featurn编号",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,156,iterate over all the features,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,158,create a list of all the examples of this feature,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,159,获取每一个实例的第i+1个feature，组成list集合,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,161,get a set of unique values,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,162,获取剔重后的集合，使用set对list数据进行去重,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,164,创建一个临时的信息熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,166,遍历某一列的value集合，计算该列的信息熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,167,遍历当前特征中的所有唯一属性值，对每个唯一属性值划分一次数据集，计算数据集的新熵值，并对所有唯一特征值得到的熵求和。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,172,gain[信息增益]: 划分数据集前后的信息变化， 获取信息熵最大的值,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,173,信息增益是熵的减少或者是数据无序度的减少。最后，比较所有特征中的信息增益，返回最好特征划分的索引值。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,180,-----------选择最优特征的第一种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,182,# -----------选择最优特征的第二种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,183,# 计算初始香农熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,184,base_entropy = calcShannonEnt(dataSet),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,185,best_info_gain = 0,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,186,best_feature = -1,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,187,# 遍历每一个特征,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,188,for i in range(len(dataSet[0]) - 1):,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,189,# 对当前特征进行统计,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,190,feature_count = Counter([data[i] for data in dataSet]),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,191,# 计算分割后的香农熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,192,"new_entropy = sum(feature[1] / float(len(dataSet)) * calcShannonEnt(splitDataSet(dataSet, i, feature[0])) \",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,193,for feature in feature_count.items()),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,194,# 更新值,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,195,info_gain = base_entropy - new_entropy,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,196,"print('No. {0} feature info gain is {1:.3f}'.format(i, info_gain))",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,197,if info_gain > best_info_gain:,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,198,best_info_gain = info_gain,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,199,best_feature = i,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,200,return best_feature,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,201,# -----------选择最优特征的第二种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,212,-----------majorityCnt的第一种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,218,倒叙排列classCount得到一个字典集合，然后取出第一个就是结果（yes/no），即出现次数最多的结果,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,220,"print 'sortedClassCount:', sortedClassCount",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,222,-----------majorityCnt的第一种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,224,# -----------majorityCnt的第二种方式 start------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,225,major_label = Counter(classList).most_common(1)[0],not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,226,return major_label,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,227,# -----------majorityCnt的第二种方式 end------------------------------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,232,如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,233,第一个停止条件：所有的类标签完全相同，则直接返回该类标签。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,234,count() 函数是统计括号中的值在list中出现的次数,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,237,如果数据集只有1列，那么最初出现label次数最多的一类，作为结果,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,238,第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,242,选择最优的列，得到最优列对应的label含义,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,244,获取label的名称,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,246,初始化myTree,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,248,注：labels列表是可变对象，在PYTHON函数中作为参数时传址引用，能够被全局修改,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,249,所以这行代码导致函数外的同名变量被删除了元素，造成例句无法执行，提示'no surfacing' is not in list,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,251,取出最优列，然后它的branch做分类,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,255,求出剩余的标签label,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,257,遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree(),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,259,"print 'myTree', value, myTree",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,273,获取tree的根节点对于的key值,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,275,通过key得到根节点对应的value,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,277,判断根节点名称获取根节点在label中的先后顺序，这样就知道输入的testVec怎么开始对照树来做分类,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,279,测试数据，找到根节点对应的label位置，也就知道从输入的数据的第几位来开始分类,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,283,判断分枝是否结束: 判断valueOfFeat是否是dict类型,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,293,-------------- 第一种方法 start --------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,297,-------------- 第一种方法 end --------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,299,-------------- 第二种方法 start --------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,302,-------------- 第二种方法 start --------------,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,312,1.创建数据和结果标签,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,314,"print myDat, labels",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,316,计算label分类标签的香农熵,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,317,calcShannonEnt(myDat),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,319,# 求第0列 为 1/0的列的数据集【排除第0列】,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,320,"print '1---', splitDataSet(myDat, 0, 1)",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,321,"print '0---', splitDataSet(myDat, 0, 0)",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,323,# 计算最好的信息增益的列,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,324,print chooseBestFeatureToSplit(myDat),not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,329,"[1, 1]表示要取的分支上的节点位置，对应的结果值",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,332,获得树的高度,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,335,画图可视化展现,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,349,加载隐形眼镜相关的 文本文件 数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,351,解析数据，获得 features 数据,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,353,得到数据的对应的 Labels,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,355,使用上面的创建决策树的代码，构造预测隐形眼镜的决策树,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,358,画图可视化展现,not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,377,"遍历子树, 获得子树的最大高度",not
AiLearning/src/py2.x/ml/3.DecisionTree/DecisionTree.py,390,ContactLensesTest(),not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,14,从文本中构建矩阵，加载文本文件，然后处理,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,15,通用函数，用来解析以 tab 键分隔的 floats（浮点数）,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,20,映射所有的元素为 float（浮点数）类型,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,25,计算两个向量的欧式距离（可根据场景选择）,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,27,la.norm(vecA-vecB),not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,30,为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,32,列的数量,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,33,创建k个质心矩阵,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,34,创建随机簇质心，并且在每一维的边界内,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,35,最小值,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,36,范围 = 最大值 - 最小值,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,37,随机生成,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,41,k-means 聚类算法,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,42,该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,43,这个过程重复数次，知道数据点的簇分配结果不再改变位置。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,44,运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似，也可能会陷入局部最小值）,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,46,行数,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,48,创建一个与 dataMat 行数一样，但是有两列的矩阵，用来保存簇分配结果,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,49,创建质心，随机k个质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,53,循环每一个数据点并分配到最近的质心中去,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,58,计算数据点到质心的距离,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,59,如果距离比 minDist（最小距离）还小，更新 minDist（最小距离）和最小质心的 index（索引）,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,62,簇分配结果改变,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,63,簇改变,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,65,更新簇分配结果为最小质心的 index（索引），minDist（最小距离）的平方,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,67,更新质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,69,获取该簇中的所有点,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,71,将质心修改为簇中所有点的平均值，mean 就是求平均值的,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,75,"二分 KMeans 聚类算法, 基于 kMeans 基础之上的优化，以避免陷入局部最小值",not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,78,保存每个数据点的簇分配结果和平方误差,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,79,质心初始化为所有数据点的均值,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,80,初始化只有 1 个质心的 list,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,81,计算所有数据点到初始质心的距离平方误差,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,83,当质心数量小于 k 时,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,85,对每一个质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,87,获取当前簇 i 下的所有数据点,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,89,将当前簇 i 进行二分 kMeans 处理,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,90,将二分 kMeans 结果中的平方和的距离进行求和,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,93,将未参与二分 kMeans 分配结果中的平方和的距离进行求和,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,100,找出最好的簇分配结果,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,102,"调用二分 kMeans 的结果，默认簇是 0,1. 当然也可以改成其它的数字",not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,104,更新为最佳质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,107,更新质心列表,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,109,更新原质心 list 中的第 i 个质心为使用二分 kMeans 后 bestNewCents 的第一个质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,111,添加 bestNewCents 的第二个质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,113,重新分配最好簇下的数据（质心）以及SSE,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,118,加载测试数据集,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,121,测试 randCent() 函数是否正常运行。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,122,首先，先看一下矩阵中的最大值与最小值,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,128,然后看看 randCent() 函数能否生成 min 到 max 之间的值,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,131,最后测试一下距离计算方法,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,136,加载测试数据集,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,139,该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,140,这个过程重复数次，知道数据点的簇分配结果不再改变位置。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,141,运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似）,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,148,加载测试数据集,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,158,测试基础的函数,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,159,testBasicFunc(),not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,161,测试 kMeans 函数,not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,162,testKMeans(),not
AiLearning/src/py2.x/ml/10.kmeans/kMeans.py,164,测试二分 biKMeans 函数,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,1,-*- coding:UTF-8 -*-,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,7,加载数据集,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,9,注意，这个是相对路径，请保证是在 MachineLearning 这个目录下执行。,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,12,映射所有的元素为 float（浮点数）类型,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,15,训练模型,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,16,初始化,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,17,拟合,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,18,预测,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,19,质心,not
AiLearning/src/py2.x/ml/10.kmeans/kMeansSklearn.py,21,可视化结果,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,18,导入csv文件,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,27,strip()返回移除字符串头尾指定的字符生成的新字符串,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,30,isdigit 如果是浮点型数值，就是 false，所以换成 isalpha() 函数,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,31,if str_f.isdigit():   # 判断是否是数字,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,32,如果是字母，说明是标签,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,33,添加分类标签,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,36,将数据集的第column列转换成float形式,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,52,"复制一份 dataset,防止 dataset 的内容改变",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,55,每次循环 fold 清零，防止重复导入 dataset_split,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,56,这里不能用 if，if 只是在第一次判断时起作用，while 执行循环，直到条件不成立,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,57,有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此则自助采样法。从而保证每棵决策树训练集的差异性,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,59,将对应索引 index 的内容从 dataset_copy 中导出，并将该内容从 dataset_copy 中删除。,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,60,pop() 函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,61,fold.append(dataset_copy.pop(index))  # 无放回的方式,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,62,有放回的方式,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,64,由dataset分割出的n_folds个数据构成的列表，为了用于交叉验证,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,68,Split a dataset based on an attribute and an attribute value # 根据特征和特征值分割数据集,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,102,个人理解：计算代价，分类越准确，则 gini 越小,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,105,"class_values = [0, 1]",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,106,"groups = (left, right)",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,111,个人理解：计算代价，分类越准确，则 gini 越小,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,115,"找出分割数据集的最优特征，得到最优的特征 index，特征值 row[index]，以及分割完的数据 groups（left, right）",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,117,"class_values =[0, 1]",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,121,往 features 添加 n_features 个特征（ n_feature 等于特征数的根号），特征索引从 dataset 中随机取,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,124,在 n_features 个特征中选出最优的特征索引，并没有遍历所有特征，从而保证了每课决策树的差异性,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,126,"groups=(left, right), row[index] 遍历每一行 index 索引下的特征值作为分类值 value, 找出最优的分类特征和特征值",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,128,左右两边的数量越一样，说明数据区分度不高，gini系数越大,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,130,"最后得到最优的分类特征 b_index,分类特征值 b_value,分类结果 b_groups。b_value 为分错的代价成本",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,131,print b_score,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,135,Create a terminal node value # 输出group中出现次数较多的标签,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,137,max() 函数中，当 key 参数不为空时，就以 key 的函数对象为判断的标准,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,138,输出 group 中出现次数较多的标签,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,141,Create child splits for a node or make terminal  # 创建子分割器，递归分类，直到分类结束,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,142,"max_depth = 10, min_size = 1, n_features=int(sqrt((len(dataset[0])-1)",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,145,check for a no split,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,149,check for max depth,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,150,max_depth=10 表示递归十次，若分类还未结束，则选取数据中分类标签较多的作为结果，使分类提前结束，防止过拟合,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,153,process left child,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,157,"node['left']是一个字典，形式为{'index':b_index, 'value':b_value, 'groups':b_groups}，所以node是一个多层字典",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,158,递归，depth+1计算递归层数,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,159,process right child,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,167,Build a decision tree,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,180,返回最优列和相关的信息,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,183,对左右2边的数据 进行递归的调用，由于最优特征使用过，所以在后面进行使用的时候，就没有意义了,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,184,例如： 性别-男女，对男使用这一特征就没任何意义了,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,189,Make a prediction with a decision tree,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,190,预测模型分类结果,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,192,isinstance 是 Python 中的一个内建函数。是用来判断一个对象是否是一个已知的类型。,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,203,Make a prediction with a list of bagged trees,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,214,使用多个决策树trees对测试集test的第row行进行预测，再使用简单投票法判断出该行所属分类,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,219,Create a random subsample from the dataset with replacement,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,220,创建数据集的随机子样本,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,231,训练样本的按比例抽样。,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,232,round() 方法返回浮点数x的四舍五入值。,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,235,有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此则自助采样法。从而保证每棵决策树训练集的差异性,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,241,Random Forest Algorithm,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,258,n_trees 表示决策树的数量,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,260,随机抽样的训练样本， 随机采样保证了每棵决策树训练集的差异性,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,262,创建一个决策树,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,266,每一行的预测结果，bagging 预测最后的分类结果,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,271,Calculate accuracy percentage,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,272,导入实际值和预测值，计算精确度,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,280,评估算法性能，返回模型得分,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,293,将数据集进行抽重抽样 n_folds 份，数据可以重复重复抽取，每一次 list 的元素是无重复的,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,296,每次循环从 folds 从取出一个 fold 作为测试集，其余作为训练集，遍历整个 folds ，实现交叉验证,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,300,"将多个 fold 列表组合成一个 train_set 列表, 类似 union all",not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,314,fold 表示从原始数据集 dataset 提取出来的测试集,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,322,计算随机森林的预测结果的正确率,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,330,加载数据,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,332,print dataset,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,334,分成5份数据，进行交叉验证,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,335,调参（自己修改） #决策树深度不能太深，不然容易导致过拟合,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,336,决策树的叶子节点最少的元素数量,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,337,做决策树时候的样本的比例,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,338,n_features = int((len(dataset[0])-1)),not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,339,调参（自己修改） #准确性与多样性之间的权衡,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,340,理论上树是越多越好,not
AiLearning/src/py2.x/ml/7.RandomForest/randomForest.py,342,每一次执行本文件时都能产生同一个随机数,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,2,coding: utf8,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,15,加载数据集,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,19,创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,33,遍历所有的元素，如果不在 C1 出现过，那么就 append,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,35,对数组进行 `从小到大` 的排序,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,36,"print 'sort 前=', C1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,38,frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,39,"print 'sort 后=', C1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,40,"print 'frozenset=', map(frozenset, C1)",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,43,计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,56,"ssCnt 临时存放选数据集 Ck 的频率. 例如: a->10, b->5, c->8",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,60,s.issubset(t)  测试是否 s 中的每一个元素都在 t 中,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,66,数据集 D 的数量,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,70,支持度 = 候选项（key）出现的次数 / 所有数据集的数量,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,73,在 retList 的首位插入元素，只存储支持度满足频繁项集的值,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,75,存储所有的候选项（key）和对应的支持度（support）,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,79,输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,99,"print '-----i=', i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,100,"print '-----j=', j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,103,"第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,104,if first k-2 elements are equal,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,106,set union,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,107,"print 'union=', Lk[i] | Lk[j], Lk[i], Lk[j]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,111,找出数据集 dataSet 中支持度 >= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,122,C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,124,"print 'C1: ', C1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,125,对每一行进行 set 转换，然后存放到集合中,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,127,"print 'D=', D",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,128,计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,130,"print ""L1="", L1, ""\n"", ""outcome: "", supportData",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,132,"L 加了一层 list, L 一共 2 层 list",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,135,"判断 L 的第 k-2 项的数据长度是否 > 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,137,"print 'k=', k, L, L[k-2]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,138,"例如: 以 {0},{1},{2} 为输入且 k = 2 则输出 {0,1}, {0,2}, {1,2}. 以 {0,1},{0,2},{1,2} 为输入且 k = 3 则输出 {0,1,2}",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,139,"print 'Ck', Ck",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,141,计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,142,保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,146,Lk 表示满足频繁子项的集合，L 元素在增加，例如:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,147,"l=[[set(1), set(2), set(3)]]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,148,"l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,151,"print 'k=', k, len(L[k-2])",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,154,计算可信度（confidence）,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,167,记录可信度大于最小可信度（minConf）的集合,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,169,"假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -> frozenset([3]) 的可信度和 frozenset([3]) -> frozenset([1]) 的可信度",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,171,"print 'confData=', freqSet, H, conseq, freqSet-conseq",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,172,"支持度定义: a -> b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,174,只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq集合 是全集）,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,180,递归计算频繁项集的规则,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,191,"H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,192,该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,193,"假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,194,那么 m = len(H[0]) 的递归的值依次为 1 2,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,195,"在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,198,"print 'freqSet******************', len(freqSet), m + 1, freqSet, H, H[0]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,199,"生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,200,"第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,201,第二次 。。。没有第二次，递归条件判断时已经退出了,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,203,返回可信度大于最小可信度的集合,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,207,计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,209,"print '----------------------', Hmp1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,210,"print len(freqSet),  len(Hmp1[0]) + 1",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,213,生成关联规则,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,225,"假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,227,获取频繁项集中每个组合的所有元素,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,229,"假设：freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,230,组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,232,"2 个的组合，走 else, 2 个以上的组合，走 if",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,243,votesmart.apikey = 'get your api key first',not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,251,api call,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,260,delay to be polite,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,264,this will return a list of lists containing ints,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,265,list of what each item stands for,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,266,fill up itemMeaning list,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,269,list of items in each transaction (politician),not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,293,暂时没用上,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,294,"def pntRules(ruleList, itemMeaning):",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,295,for ruleTup in ruleList:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,296,for item in ruleTup[0]:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,297,print itemMeaning[item],not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,298,"print ""           -------->""",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,299,for item in ruleTup[1]:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,300,print itemMeaning[item],not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,301,"print ""confidence: %f"" % ruleTup[2]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,302,print       #print a blank line,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,305,加载测试数据集,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,309,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,316,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,322,加载测试数据集,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,326,Apriori 算法生成频繁项集以及它们的支持度,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,331,生成关联规则,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,336,测试 Apriori 算法,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,339,生成关联规则,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,340,testGenerateRules(),not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,342,# 项目案例,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,343,# 构建美国国会投票记录的事务数据集,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,344,"actionIdList, billTitleList = getActionIds()",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,345,# 测试前2个,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,346,"# transDict, itemMeaning = getTransList(actionIdList[: 2], billTitleList[: 2])",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,347,"# transDict 表示 action_id的集合，transDict[key]这个就是action_id对应的选项，例如 [1, 2, 3]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,348,"transDict, itemMeaning = getTransList(actionIdList, billTitleList)",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,349,# 得到全集的数据,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,350,dataSet = [transDict[key] for key in transDict.keys()],not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,351,"L, supportData = apriori(dataSet, minSupport=0.3)",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,352,"rules = generateRules(L, supportData, minConf=0.95)",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,353,print rules,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,355,# 项目案例,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,356,# 发现毒蘑菇的相似特性,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,357,# 得到全集的数据,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,358,"dataSet = [line.split() for line in open(""data/11.Apriori/mushroom.dat"").readlines()]",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,359,"L, supportData = apriori(dataSet, minSupport=0.3)",not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,360,# 2表示毒蘑菇，1表示可食用的蘑菇,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,361,# 找出关于2的频繁子项出来，就知道如果是毒蘑菇，那么出现频繁的也可能是毒蘑菇,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,362,for item in L[1]:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,363,if item.intersection('2'):,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,364,print item,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,366,for item in L[2]:,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,367,if item.intersection('2'):,not
AiLearning/src/py2.x/ml/11.Apriori/apriori.py,368,print item,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,22,获取样本特征的总数，不算最后的目标变量,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,28,读取每一行,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,30,删除一行中以tab分隔的数据前后的空白符号,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,32,i 从0到2，不包括2,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,34,将数据添加到lineArr List中，每一行数据测试数据组成一个行向量,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,36,将测试数据的输入数据部分存储到dataMat 的List中,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,38,将每一行的最后一个数据，即类别，或者叫目标变量存储到labelMat List中,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,54,mat()函数将xArr，yArr转换为矩阵 mat().T 代表的是对矩阵进行转置操作,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,57,矩阵乘法的条件是左矩阵的列数等于右矩阵的行数,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,59,因为要用到xTx的逆矩阵，所以事先需要确定计算得到的xTx是否可逆，条件是矩阵的行列式不为0,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,60,linalg.det() 函数是用来求得矩阵的行列式的，如果矩阵的行列式为0，则这个矩阵是不可逆的，就无法进行接下来的运算,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,64,最小二乘法,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,65,http://cwiki.apachecn.org/pages/viewpage.action?pageId=5505133,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,66,书中的公式，求得w的最优解,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,71,局部加权线性回归,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,90,mat() 函数是将array转换为矩阵的函数， mat().T 是转换为矩阵之后，再进行转置操作,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,93,获得xMat矩阵的行数,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,95,eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,98,testPoint 的形式是 一个行向量的形式,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,99,计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,101,k控制衰减的速度,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,103,根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,108,计算出回归系数的一个估计,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,125,得到样本点的总数,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,127,构建一个全部都是 0 的 1 * m 的矩阵,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,129,循环所有的数据点，并将lwlr运用于所有的数据点,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,132,返回估计值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,148,生成一个与目标变量数目相同的 0 向量,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,150,将 xArr 转换为 矩阵形式,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,152,排序,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,154,开始循环，为每个样本点进行局部加权线性回归，得到最终的目标变量估计值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,189,岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,191,检查行列式是否为零，即矩阵是否可逆，行列式为0的话就不可逆，不为0的话就是可逆。,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,212,计算Y的均值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,214,Y的所有的特征减去均值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,216,标准化 x，计算 xMat 平均值,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,218,然后计算 X的方差,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,220,所有特征都减去各自的均值并除以方差,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,222,可以在 30 个不同的 lambda 下调用 ridgeRegres() 函数。,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,224,创建30 * m 的全部数据为0 的矩阵,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,227,exp() 返回 e^x,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,233,按列进行规范化,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,235,计算平均值然后减去它,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,236,计算除以Xi的方差,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,245,也可以规则化ys但会得到更小的coef,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,248,"returnMat = zeros((numIt,n)) # 测试代码删除",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,265,"returnMat[i,:]=ws.T",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,266,return returnMat,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,268,"def scrapePage(inFile,outFile,yr,numPce,origPrc):",SATD
AiLearning/src/py2.x/ml/8.Regression/regression.py,269,from BeautifulSoup import BeautifulSoup,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,270,"fr = open(inFile); fw=open(outFile,'a') #a is append mode writing",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,271,soup = BeautifulSoup(fr.read()),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,272,i=1,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,273,"currentRow = soup.findAll('table', r=""%d"" % i)",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,274,while(len(currentRow)!=0):,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,275,title = currentRow[0].findAll('a')[1].text,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,276,lwrTitle = title.lower(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,277,if (lwrTitle.find('new') > -1) or (lwrTitle.find('nisb') > -1):,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,278,newFlag = 1.0,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,279,else:,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,280,newFlag = 0.0,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,281,soldUnicde = currentRow[0].findAll('td')[3].findAll('span'),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,282,if len(soldUnicde)==0:,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,283,"print ""item #%d did not sell"" % i",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,284,else:,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,285,soldPrice = currentRow[0].findAll('td')[4],not
AiLearning/src/py2.x/ml/8.Regression/regression.py,286,priceStr = soldPrice.text,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,287,"priceStr = priceStr.replace('$','') #strips out $",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,288,"priceStr = priceStr.replace(',','') #strips out ,",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,289,if len(soldPrice)>1:,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,290,"priceStr = priceStr.replace('Free shipping', '') #strips out Free Shipping",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,291,"print ""%s\t%d\t%s"" % (priceStr,newFlag,title)",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,292,"fw.write(""%d\t%d\t%d\t%f\t%s\n"" % (yr,numPce,newFlag,origPrc,priceStr))",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,293,i += 1,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,294,"currentRow = soup.findAll('table', r=""%d"" % i)",not
AiLearning/src/py2.x/ml/8.Regression/regression.py,295,fw.close(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,297,--------------------------------------------------------------,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,298,预测乐高玩具套装的价格 ------ 最初的版本，因为现在 google 的 api 变化，无法获取数据,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,299,故改为了下边的样子，但是需要安装一个 beautifulSoup 这个第三方爬虫库，安装很简单，见下边,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,373,----------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,374,预测乐高玩具套装的价格 可运行版本，我们把乐高数据存储到了我们的 input 文件夹下，使用 beautifulSoup 爬去一下内容,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,375,前提：安装 BeautifulSoup 第三方爬虫库，步骤如下,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,376,在这个页面 https://www.crummy.com/software/BeautifulSoup/bs4/download/4.4/ 下载，beautifulsoup4-4.4.1.tar.gz,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,377,将下载文件解压，使用 windows 版本的 cmd 命令行，进入解压的包，输入以下两行命令即可完成安装,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,378,python setup.py build,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,379,python setup.py install,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,496,test for standRegression,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,504,add_subplot(349)函数的参数的意思是，将画布分成3行4列图像画在从左到右从上到下第9块,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,507,scatter 的x是xMat中的第二列，y是yMat的第一列,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,515,test for LWLR,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,521,argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)，然后输出,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,533,test for abloneDataSet,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,543,加载数据,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,545,使用不同的核进行预测,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,549,打印出不同的核预测值与训练数据集上的真实值之间的误差大小,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,554,打印出 不同的核预测值 与 新数据集（测试数据集）上的真实值之间的误差大小,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,562,使用简单的 线性回归 进行预测，与上面的计算进行比较,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,568,test for ridgeRegression,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,578,test for stageWise,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,591,predict for lego's price,not
AiLearning/src/py2.x/ml/8.Regression/regression.py,602,regression2(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,603,abaloneTest(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,604,regression3(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,605,regression4(),not
AiLearning/src/py2.x/ml/8.Regression/regression.py,606,regression5(),not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,13,Isotonic Regression 等式回归,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,16,Author: Nelle Varoquaux <nelle.varoquaux@gmail.com>,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,17,Alexandre Gramfort <alexandre.gramfort@inria.fr>,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,18,License: BSD,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,38,线性回归的 x 需要为 2d,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,54,Kernel ridge regression ( 内核岭回归 ),not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,56,2.1 Comparison of kernel ridge regression and SVR ( 内核岭回归与 SVR 的比较 ),not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,58,Authors: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>,not
AiLearning/src/py2.x/ml/8.Regression/sklearn-regression-demo.py,59,License: BSD 3 clause,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,2,coding: utf-8,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,34,计算每一列的均值,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,36,"print 'meanVals', meanVals",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,38,每个向量同时都减去 均值,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,40,"print 'meanRemoved=', meanRemoved",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,42,cov协方差=[(x1-x均值)*(y1-y均值)+(x2-x均值)*(y2-y均值)+...+(xn-x均值)*(yn-y均值)+]/(n-1),not
AiLearning/src/py2.x/ml/13.PCA/pca.py,54,eigVals为特征值， eigVects为特征向量,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,56,"print 'eigVals=', eigVals",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,57,"print 'eigVects=', eigVects",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,58,对特征值，进行从小到大的排序，返回从小到大的index序号,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,59,特征值的逆序就可以得到topNfeat个最大的特征向量,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,73,"print 'eigValInd1=', eigValInd",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,75,-1表示倒序，返回topN的特征值[-1 到 -(topNfeat+1) 但是不包括-(topNfeat+1)本身的倒叙],not
AiLearning/src/py2.x/ml/13.PCA/pca.py,77,"print 'eigValInd2=', eigValInd",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,78,重组 eigVects 最大到最小,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,80,"print 'redEigVects=', redEigVects.T",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,81,将数据转换到新空间,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,82,"print ""---"", shape(meanRemoved), shape(redEigVects)",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,85,"print 'lowDDataMat=', lowDDataMat",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,86,"print 'reconMat=', reconMat",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,94,对value不为NaN的求均值,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,95,.A 返回矩阵基于的数组,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,97,将value为NaN的值赋值为均值,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,137,# 加载数据，并转化数据类型为float,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,138,dataMat = loadDataSet('data/13.PCA/testSet.txt'),not
AiLearning/src/py2.x/ml/13.PCA/pca.py,139,# 只需要1个特征向量,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,140,"lowDmat, reconMat = pca(dataMat, 1)",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,141,# 只需要2个特征向量，和原始数据一致，没任何变化,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,142,"# lowDmat, reconMat = pca(dataMat, 2)",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,143,# print shape(lowDmat),not
AiLearning/src/py2.x/ml/13.PCA/pca.py,144,"show_picture(dataMat, reconMat)",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,146,利用PCA对半导体制造数据降维,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,149,分析数据,not
AiLearning/src/py2.x/ml/13.PCA/pca.py,151,"lowDmat, reconMat = pca(dataMat, 20)",not
AiLearning/src/py2.x/ml/13.PCA/pca.py,152,print shape(lowDmat),not
AiLearning/src/py2.x/ml/13.PCA/pca.py,153,"show_picture(dataMat, reconMat)",not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,20,创建40个分离点,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,22,"X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]",not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,23,Y = [0] * 20 + [1] * 20,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,51,拟合一个SVM模型,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,55,获取分割超平面,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,57,斜率,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,59,从-5到5，顺序间隔采样50个样本，默认是num=50,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,60,"xx = np.linspace(-5, 5)  # , num=50)",not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,61,", num=50)",not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,62,二维的直线方程,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,66,plot the parallels to the separating hyperplane that pass through the support vectors,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,67,通过支持向量绘制分割超平面,not
AiLearning/src/py2.x/ml/6.SVM/sklearn-svm-demo.py,74,"plot the line, the points, and the nearest vectors to the plane",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,37,数据的行数,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,42,误差缓存，第一列给出的是eCache是否有效的标志位，第二列给出的是实际的E值。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,45,m行m列的矩阵,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,51,calc the kernel or transform data to a higher dimensional space,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,65,linear kernel:   m*n * n*1 = m*1,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,71,径向基函数的高斯版本,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,72,divide in NumPy is element-wise not matrix like Matlab,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,128,"this is the second choice -heurstic, and calcs Ej",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,147,首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,150,"print 'oS.eCache[%s]=%s' % (i, oS.eCache[i])",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,151,"print 'oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,152,"""""""",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,153,# 返回非0的：行列值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,154,"nonzero(oS.eCache[:, 0].A)= (",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,155,"行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]),",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,156,"列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,157,),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,158,"""""""",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,159,"print 'nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A)",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,160,# 取行的list,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,161,"print 'nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0]",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,162,非零E值的行的list列表，所对应的alpha值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,165,在所有的值上进行循环，并选择其中使得改变最大的那个值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,167,"don't calc for i, waste of time",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,169,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,173,选择具有最大步长的j,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,178,如果是第一次循环，则随机选择一个alpha值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,181,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,195,求 误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,228,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,231,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,232,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,233,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,241,选择最大的误差对应的j进行优化。效果更明显,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,246,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,254,"print(""L==H"")",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,257,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,258,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,259,changed for kernel,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,264,计算出一个新的alphas[j]值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,266,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,268,更新误差缓存,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,271,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,273,"print(""j not moving enough"")",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,276,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,278,更新误差缓存,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,281,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,282,w= Σ[1~n] ai*yi*xi => b = yi- Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,283,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,284,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,315,创建一个 optStruct 对象,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,321,循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,325,当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,327,在数据集上遍历所有可能的alpha,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,329,是否存在alpha对，存在就+1,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,331,"print(""fullSet, iter: %d i:%d, pairs changed %d"" % (iter, i, alphaPairsChanged))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,334,对已存在 alpha对，选出非边界的alpha值，进行优化。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,336,遍历所有的非边界alpha值，也就是不在边界0或C上的值。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,340,"print(""non-bound, iter: %d i:%d, pairs changed %d"" % (iter, i, alphaPairsChanged))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,343,如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,345,toggle entire set loop,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,374,C=200 important,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,378,get matrix of only support vectors,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,386,"和这个svm-simple类似： fXi = float(multiply(alphas, labelMat).T*(dataMatrix*dataMatrix[i, :].T)) + b",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,419,load the training set,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,424,take off .txt,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,436,1. 导入训练数据,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,444,"print(""there are %d Support Vectors"" % shape(sVs)[0])",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,449,1*m * m*1 = 1*1 单个预测结果,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,454,2. 导入测试数据,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,478,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,483,注意flatten的用法,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,486,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,489,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,499,找到支持向量，并在图中标红,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,508,无核函数的测试,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,509,获取特征和目标变量,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,511,print labelArr,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,513,b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,522,画图,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,526,有核函数的测试,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,529,# 项目实战,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,530,# 示例：手写识别问题回顾,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,531,"testDigits(('rbf', 0.1))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,532,"testDigits(('rbf', 5))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,533,"testDigits(('rbf', 10))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,534,"testDigits(('rbf', 50))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,535,"testDigits(('rbf', 100))",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete.py,536,testDigits(('lin')),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,17,Initialize the structure with the parameters,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,25,first column is valid flag,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,94,"this is the second choice -heurstic, and calcs Ej",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,113,首先将输入值Ei在缓存中设置成为有效的。这里的有效意味着它已经计算好了。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,116,"print 'oS.eCache[%s]=%s' % (i, oS.eCache[i])",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,117,"print 'oS.eCache[:, 0].A=%s' % oS.eCache[:, 0].A.T",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,118,"""""""",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,119,# 返回非0的：行列值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,120,"nonzero(oS.eCache[:, 0].A)= (",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,121,"行： array([ 0,  2,  4,  5,  8, 10, 17, 18, 20, 21, 23, 25, 26, 29, 30, 39, 46,52, 54, 55, 62, 69, 70, 76, 79, 82, 94, 97]),",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,122,"列： array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0])",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,123,),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,124,"""""""",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,125,"print 'nonzero(oS.eCache[:, 0].A)=', nonzero(oS.eCache[:, 0].A)",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,126,# 取行的list,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,127,"print 'nonzero(oS.eCache[:, 0].A)[0]=', nonzero(oS.eCache[:, 0].A)[0]",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,128,非零E值的行的list列表，所对应的alpha值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,131,在所有的值上进行循环，并选择其中使得改变最大的那个值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,133,"don't calc for i, waste of time",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,135,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,143,如果是第一次循环，则随机选择一个alpha值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,146,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,151,after any alpha has changed update the new value in the cache,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,160,求 误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,177,求 Ek误差：预测值-真实值的差,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,180,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,181,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,182,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,190,选择最大的误差对应的j进行优化。效果更明显,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,195,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接return 0,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,206,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,207,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,213,计算出一个新的alphas[j]值,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,215,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,217,更新误差缓存,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,220,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,225,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,227,更新误差缓存,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,230,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,231,w= Σ[1~n] ai*yi*xi => b = yj Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,232,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,233,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,263,创建一个 optStruct 对象,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,269,循环遍历：循环maxIter次 并且 （alphaPairsChanged存在可以改变 or 所有行遍历一遍）,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,270,循环迭代结束 或者 循环遍历所有alpha后，alphaPairs还是没变化,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,274,当entireSet=true or 非边界alpha对没有了；就开始寻找 alpha对，然后决定是否要进行else。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,276,在数据集上遍历所有可能的alpha,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,278,是否存在alpha对，存在就+1,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,282,对已存在 alpha对，选出非边界的alpha值，进行优化。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,284,遍历所有的非边界alpha值，也就是不在边界0或C上的值。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,291,如果找到alpha对，就优化非边界alpha值，否则，就重新进行寻找，如果寻找一遍 遍历所有的行还是没找到，就退出循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,293,toggle entire set loop,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,331,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,336,注意flatten的用法,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,339,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,342,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,352,找到支持向量，并在图中标红,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,360,获取特征和目标变量,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,362,print labelArr,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,364,b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py2.x/ml/6.SVM/svm-complete_Non-Kernel.py,373,画图,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,82,矩阵转置 和 .T 一样的功能,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,86,初始化 b和alphas(alpha有点类似权重值。),not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,90,没有任何alpha改变的情况下遍历数据的次数,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,93,"w = calcWs(alphas, dataMatIn, classLabels)",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,94,"print(""w:"", w)",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,96,记录alpha是否已经进行优化，每次循环时设为0，然后再对整个集合顺序遍历,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,99,"print 'alphas=', alphas",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,100,"print 'labelMat=', labelMat",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,101,"print 'multiply(alphas, labelMat)=', multiply(alphas, labelMat)",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,102,我们预测的类别 y = w^Tx[i]+b; 其中因为 w = Σ(1~n) a[n]*lable[n]*x[n],not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,104,预测结果与真实结果比对，计算误差Ei,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,107,约束条件 (KKT条件是解决最优化问题的时用到的一种方法。我们这里提到的最优化问题通常是指对于给定的某一函数，求其在指定作用域上的全局最小值),not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,108,0<=alphas[i]<=C，但由于0和C是边界值，我们无法进行优化，因为需要增加一个alphas和降低一个alphas。,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,109,表示发生错误的概率：labelMat[i]*Ei 如果超出了 toler， 才需要优化。至于正负号，我们考虑绝对值就对了。,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,118,如果满足优化的条件，我们就随机选取非i的一个点，进行优化比较,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,120,预测j的结果,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,126,L和H用于将alphas[j]调整到0-C之间。如果L==H，就不做任何改变，直接执行continue语句,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,127,labelMat[i] != labelMat[j] 表示异侧，就相减，否则是同侧，就相加。,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,134,如果相同，就没发优化了,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,139,eta是alphas[j]的最优修改量，如果eta==0，需要退出for循环的当前迭代过程,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,140,参考《统计学习方法》李航-P125~P128<序列最小最优化算法>,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,146,计算出一个新的alphas[j]值,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,148,并使用辅助函数，以及L和H对其进行调整,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,150,检查alpha[j]是否只是轻微的改变，如果是的话，就退出for循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,154,然后alphas[i]和alphas[j]同样进行改变，虽然改变的大小一样，但是改变的方向正好相反,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,156,"在对alpha[i], alpha[j] 进行优化之后，给这两个alpha值设置一个常数b。",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,157,w= Σ[1~n] ai*yi*xi => b = yj- Σ[1~n] ai*yi(xi*xj),not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,158,所以：  b1 - b = (y1-y) - Σ[1~n] yi*(a1-a)*(xi*x1),not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,159,为什么减2遍？ 因为是 减去Σ[1~n]，正好2个变量i和j，所以减2遍,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,170,在for循环外，检查alpha值是否做了更新，如果在更新则将iter设为0后继续运行程序,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,171,知道更新完毕后，iter次循环无变化，才推出循环。,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,211,"b原来是矩阵，先转为数组类型后其数组大小为（1,1），所以后面加[0]，变为(1,)",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,216,注意flatten的用法,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,219,"x最大值，最小值根据原数据集dataArr[:, 0]的大小而定",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,222,"根据x.w + b = 0 得到，其式子展开为w0.x1 + w1.x2 + b = 0, x2就是y值",not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,232,找到支持向量，并在图中标红,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,240,获取特征和目标变量,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,242,print labelArr,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,244,b是常量值， alphas是拉格朗日乘子,not
AiLearning/src/py2.x/ml/6.SVM/svm-simple.py,253,画图,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,2,coding:utf-8,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,26,生成一个 4*4 的随机数组,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,29,转化关系， 数组转化为矩阵,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,46,输出结果,not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,52,矩阵和逆矩阵 进行求积 (单位矩阵，对角线都为1嘛，理论上4*4的矩阵其他的都为0),not
AiLearning/src/py2.x/ml/1.MLFoundation/NumPy.py,54,误差,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,15,默认解析的数据是用tab分隔，并且是数值类型,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,16,general function to parse tab -delimited floats,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,26,假定最后一列是结果值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,27,assume last column is target value,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,32,将所有的元素转化为float类型,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,33,map all elements to float(),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,34,map() 函数具体的含义，可见 https://my.oschina.net/zyzzy/blog/115096,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,52,# 测试案例,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,53,"print 'dataSet[:, feature]=', dataSet[:, feature]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,54,"print 'nonzero(dataSet[:, feature] > value)[0]=', nonzero(dataSet[:, feature] > value)[0]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,55,"print 'nonzero(dataSet[:, feature] <= value)[0]=', nonzero(dataSet[:, feature] <= value)[0]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,57,"dataSet[:, feature] 取去每一行中，第1列的值(从0开始算)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,58,"nonzero(dataSet[:, feature] > value)  返回结果为true行的index下标",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,64,返回每一个叶子结点的均值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,65,returns the value used for each leaf,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,66,我的理解是：regLeaf 是产生叶节点的函数，就是求均值，即用聚类中心点来代表这类数据,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,71,计算总方差=方差*样本数,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,72,我的理解是：求这组数据的方差，即通过决策树划分，可以让靠近的数据分到同一类中去,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,74,shape(dataSet)[0] 表示行数,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,78,1.用最佳方式切分数据集,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,79,2.生成相应的叶节点,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,94,"ops=(1,4)，非常重要，因为它决定了决策树划分停止的threshold值，被称为预剪枝（prepruning），其实也就是用于控制函数的停止时机。",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,95,之所以这样说，是因为它防止决策树的过拟合，所以当误差的下降值小于tolS，或划分后的集合size小于tolN时，选择停止继续划分。,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,96,最小误差下降值，划分后的误差减小小于这个差值，就不用继续划分,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,98,划分最小 size 小于，就不继续划分了,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,100,如果结果集(最后一列为1个变量)，就返回退出,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,101,.T 对数据集进行转置,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,102,.tolist()[0] 转化为数组并取第0列,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,103,如果集合size为1，也就是说全部的数据都是同一个类别，不用继续划分。,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,104,exit cond 1,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,106,计算行列值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,108,无分类误差的总方差和,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,109,the choice of the best feature is driven by Reduction in RSS error from mean,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,111,inf 正无穷大,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,113,循环处理每一列对应的feature值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,114,对于每个特征,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,115,[0]表示这一列的[所有行]，不要[0]就是一个array[[所有行]]，下面的一行表示的是将某一列全部的数据转换为行，然后设置为list形式,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,117,对该列进行分组，然后组内的成员的val值进行 二元切分,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,119,判断二元切分的方式的元素数量是否符合预期,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,123,如果二元切分，算出来的误差在可接受范围内，那么就记录切分点，并记录最小误差,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,124,如果划分后误差小于 bestS，则说明找到了新的bestS,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,129,判断二元切分的方式的元素误差是否符合预期,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,130,if the decrease (S-bestS) is less than a threshold don't do the split,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,134,对整体的成员进行判断，是否符合预期,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,135,如果集合的 size 小于 tolN,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,136,当最佳划分后，集合过小，也不划分，产生叶节点,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,141,assume dataSet is NumPy Mat so we can array filtering,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,142,假设 dataSet 是 NumPy Mat 类型的，那么我们可以进行 array 过滤,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,154,选择最好的切分方式： feature索引值，最优切分值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,155,choose the best split,SATD
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,157,if the splitting hit a stop condition return val,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,158,如果 splitting 达到一个停止条件，那么返回 val,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,167,大于在右边，小于在左边，分为2个数据集,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,169,递归的进行调用，在左右子树中继续递归生成树,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,175,判断节点是否是一个字典,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,188,计算左右枝丫的均值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,206,检查是否适合合并分枝,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,217,判断是否测试数据集没有数据，如果没有，就直接返回tree本身的均值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,221,判断分枝是否是dict字典，如果是就将测试数据集进行切分,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,224,如果是左边分枝是字典，就传入左边的数据集和左边的分枝，进行递归,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,227,如果是右边分枝是字典，就传入左边的数据集和左边的分枝，进行递归,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,231,上面的一系列操作本质上就是将测试数据集按照训练完成的树拆分好，对应的值放到对应的节点,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,233,如果左右两边同时都不是dict字典，也就是左右两边都是叶节点，而不是子树了，那么分割测试数据集。,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,234,1. 如果正确,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,235,* 那么计算一下总方差 和 该结果集的本身不分枝的总方差比较,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,236,* 如果 合并的总方差 < 不合并的总方差，那么就进行合并,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,237,注意返回的结果： 如果可以合并，原来的dict就变为了 数值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,240,"power(x, y)表示x的y次方；这时tree['left']和tree['right']都是具体数值",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,244,如果 合并的总方差 < 不合并的总方差，那么就进行合并,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,248,两个return可以简化成一个,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,255,得到模型的ws系数：f(x) = x0 + x1*featrue1+ x2*featrue2 ...,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,256,create linear model and return coeficients,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,270,计算线性模型的误差值,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,282,"print corrcoef(yHat, Y, rowvar=0)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,286,helper function used in two places,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,299,产生一个关于1的矩阵,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,302,X的0列为1，常数项，用于计算平衡误差,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,306,转置矩阵*矩阵,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,308,如果矩阵的逆不存在，会造成程序异常,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,311,最小二乘法求最优解:  w0*1+w1*x1=y,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,316,回归树测试案例,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,317,为了和 modelTreeEval() 保持一致，保留两个输入参数,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,331,模型树测试案例,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,332,对输入数据进行格式化处理，在原数据矩阵上增加第0列，元素的值都是1，,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,333,也就是增加偏移值，和我们之前的简单线性回归是一个套路，增加一个偏移量,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,347,"print X, model",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,351,计算预测的结果,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,352,在给定树结构的情况下，对于单个数据点，该函数会给出一个预测值。,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,353,modelEval是对叶节点进行预测的函数引用，指定树的类型，以便在叶节点上调用合适的模型。,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,354,此函数自顶向下遍历整棵树，直到命中叶节点为止，一旦到达叶节点，它就会在输入数据上,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,355,调用modelEval()函数，该函数的默认值为regTreeEval(),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,369,书中写的是inData[tree['spInd']]，只适合inData只有一列的情况，否则会产生异常,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,371,可以把if-else去掉，只留if里面的分支,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,377,同上，可以把if-else去掉，只留if里面的分支,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,384,预测结果,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,398,print yHat,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,401,"print ""yHat==>"", yHat[i, 0]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,406,测试数据集,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,413,# 回归树,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,414,myDat = loadDataSet('data/9.RegTrees/data1.txt'),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,415,# myDat = loadDataSet('data/9.RegTrees/data2.txt'),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,416,"# print 'myDat=', myDat",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,417,myMat = mat(myDat),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,418,"# print 'myMat=',  myMat",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,419,myTree = createTree(myMat),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,420,print myTree,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,422,# 1. 预剪枝就是：提起设置最大误差数和最少元素数,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,423,myDat = loadDataSet('data/9.RegTrees/data3.txt'),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,424,myMat = mat(myDat),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,425,"myTree = createTree(myMat, ops=(0, 1))",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,426,print myTree,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,428,# 2. 后剪枝就是：通过测试数据，对预测模型进行合并判断,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,429,myDatTest = loadDataSet('data/9.RegTrees/data3test.txt'),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,430,myMat2Test = mat(myDatTest),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,431,"myFinalTree = prune(myTree, myMat2Test)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,432,print '\n\n\n-------------------',not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,433,print myFinalTree,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,435,# --------,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,436,# 模型树求解,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,437,myDat = loadDataSet('data/9.RegTrees/data4.txt'),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,438,myMat = mat(myDat),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,439,"myTree = createTree(myMat, modelLeaf, modelErr)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,440,print myTree,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,442,# # 回归树 VS 模型树 VS 线性回归,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,443,trainMat = mat(loadDataSet('data/9.RegTrees/bikeSpeedVsIq_train.txt')),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,444,testMat = mat(loadDataSet('data/9.RegTrees/bikeSpeedVsIq_test.txt')),not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,445,# # 回归树,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,446,"myTree1 = createTree(trainMat, ops=(1, 20))",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,447,print myTree1,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,448,"yHat1 = createForeCast(myTree1, testMat[:, 0])",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,449,"print ""--------------\n""",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,450,# print yHat1,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,451,"# print ""ssss==>"", testMat[:, 1]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,452,# corrcoef 返回皮尔森乘积矩相关系数,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,453,"print ""regTree:"", corrcoef(yHat1, testMat[:, 1],rowvar=0)[0, 1]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,455,# 模型树,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,456,"myTree2 = createTree(trainMat, modelLeaf, modelErr, ops=(1, 20))",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,457,"yHat2 = createForeCast(myTree2, testMat[:, 0], modelTreeEval)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,458,print myTree2,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,459,"print ""modelTree:"", corrcoef(yHat2, testMat[:, 1],rowvar=0)[0, 1]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,461,# 线性回归,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,462,"ws, X, Y = linearSolve(trainMat)",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,463,print ws,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,464,"m = len(testMat[:, 0])",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,465,"yHat3 = mat(zeros((m, 1)))",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,466,for i in range(shape(testMat)[0]):,not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,467,"yHat3[i] = testMat[i, 0]*ws[1, 0] + ws[0, 0]",not
AiLearning/src/py2.x/ml/9.RegTrees/regTrees.py,468,"print ""lr:"", corrcoef(yHat3, testMat[:, 1],rowvar=0)[0, 1]",not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,24,"相当于告诉 布局管理器(Geometry Manager),如果不设定位置，默认在 0行0列的位置",not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,28,最大为误差， 最大子叶节点的数量,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,30,clear the figure,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,34,检查复选框是否选中,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,44,use scatter for data set,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,46,use plot for yHat,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,69,画新的tree,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,71,#get values from Entry boxes,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,77,标题,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,79,"输入栏1, 叶子的数量",not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,85,"输入栏2, 误差量",not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,90,设置输出值,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,93,设置提交的按钮,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,96,设置复选按钮,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,102,退出按钮,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,105,创建一个画板 canvas,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,118,创建一个事件,not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,120,test_widget_text(root),not
AiLearning/src/py2.x/ml/9.RegTrees/treeExplore.py,123,启动事件循环,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,15,引入必要的模型和库,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,20,创建一个随机的数据集,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,21,参考 https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.random.mtrand.RandomState.html,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,23,"print 'lalalalala===', rng",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,24,"rand() 是给定形状的随机值，rng.rand(80, 1)即矩阵的形状是 80行，1列",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,25,sort(),not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,27,"print 'X=', X",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,29,"print 'y=', y",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,31,"print 'yyy=', y",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,33,拟合回归模型,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,34,regr_1 = DecisionTreeRegressor(max_depth=2),not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,35,保持 max_depth=5 不变，增加 min_samples_leaf=6 的参数，效果进一步提升了,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,38,regr_3 = DecisionTreeRegressor(max_depth=4),not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,39,"regr_1.fit(X, y)",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,41,"regr_3.fit(X, y)",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,43,预测,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,45,y_1 = regr_1.predict(X_test),not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,47,y_3 = regr_3.predict(X_test),not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,49,绘制结果,not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,52,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py2.x/ml/9.RegTrees/sklearn-regressTree-demo.py,54,"plt.plot(X_test, y_3, color=""red"", label=""max_depth=3"", linewidth=2)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,4,''',not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,5,Created on 2017-03-10,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,6,Update on 2017-03-10,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,7,author: jiangzhonglian,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,8,content: 回归树,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,9,''',not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,11,print(__doc__),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,14,# Import the necessary modules and libraries,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,15,import numpy as np,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,16,from sklearn.tree import DecisionTreeRegressor,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,17,import matplotlib.pyplot as plt,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,20,# Create a random dataset,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,21,rng = np.random.RandomState(1),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,22,"X = np.sort(5 * rng.rand(80, 1), axis=0)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,23,y = np.sin(X).ravel(),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,24,"print X, '\n\n\n-----------\n\n\n', y",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,25,y[::5] += 3 * (0.5 - rng.rand(16)),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,28,# Fit regression model,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,29,"regr_1 = DecisionTreeRegressor(max_depth=2, min_samples_leaf=5)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,30,"regr_2 = DecisionTreeRegressor(max_depth=5, min_samples_leaf=5)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,31,"regr_1.fit(X, y)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,32,"regr_2.fit(X, y)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,35,# Predict,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,36,"X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,37,y_1 = regr_1.predict(X_test),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,38,y_2 = regr_2.predict(X_test),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,41,# Plot the results,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,42,plt.figure(),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,43,"plt.scatter(X, y, c=""darkorange"", label=""data"")",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,44,"plt.plot(X_test, y_1, color=""cornflowerblue"", label=""max_depth=2"", linewidth=2)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,45,"plt.plot(X_test, y_2, color=""yellowgreen"", label=""max_depth=5"", linewidth=2)",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,46,"plt.xlabel(""data"")",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,47,"plt.ylabel(""target"")",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,48,"plt.title(""Decision Tree Regression"")",not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,49,plt.legend(),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,50,plt.show(),not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,69,Author: Noel Dawe <noel.dawe@gmail.com>,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,70,,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,71,License: BSD 3 clause,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,73,importing necessary libraries,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,79,Create the dataset,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,84,Fit regression model,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,93,Predict,not
AiLearning/src/py2.x/ml/9.RegTrees/RTSklearn.py,97,Plot the results,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,24,needs to be updated,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,47,"['r', 'x', 'n', 'o', 's'],",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,63,this version does not use recursion,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,74,建立相同元素之间的关系，例如： 左边的r指向右边的r值,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,91,取出 元素 出现次数最高的,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,92,如果该元素在 inTree.children 这个字典中，就进行累加,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,93,如果该元素不存在 就 inTree.children 字典中新增key，value为初始化的 treeNode 对象,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,95,更新 最大元素，对应的 treeNode 对象的count进行叠加,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,98,如果不存在子节点，我们为该inTree添加子节点,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,100,如果满足minSup的dist字典的value值第二位为null， 我们就设置该元素为 本节点对应的tree节点,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,101,如果元素第二位不为null，我们就更新header节点,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,103,headerTable只记录第一次节点出现的位置,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,106,本质上是修改headerTable的key对应的Tree，的nodeLink值,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,109,递归的调用，在items[0]的基础上，添加item0[1]做子节点， count只要循环的进行累计加和而已，统计出节点的最后的统计值。,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,123,支持度>=minSup的dist{所有元素：出现的次数},not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,125,循环 dist{行：出现次数}的样本数据,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,127,对所有的行进行循环，得到行里面的所有元素,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,128,统计每一行中，每个元素出现的总次数,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,130,例如： {'ababa': 3}  count(a)=3+3+3=9   count(b)=3+3=6,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,132,删除 headerTable中，元素次数<最小支持度的元素,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,137,满足minSup: set(各元素集合),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,139,如果不存在，直接返回None,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,143,"格式化： dist{元素key: [元素次数, None]}",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,146,create tree,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,148,循环 dist{行：出现次数}的样本数据,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,150,"print 'tranSet, count=', tranSet, count",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,151,localD = dist{元素key: 元素总出现次数},not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,154,判断是否在满足minSup的集合中,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,156,"print 'headerTable[item][0]=', headerTable[item][0], headerTable[item]",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,158,"print 'localD=', localD",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,160,"p=key,value; 所以是通过value值的大小，进行从大到小进行排序",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,161,orderedItems 表示取出元组的key值，也就是字母本身，但是字母本身是大到小的顺序,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,163,"print 'orderedItems=', orderedItems, 'headerTable', headerTable, '\n\n\n'",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,164,填充树，通过有序的orderedItems的第一位，进行顺序填充 第一层的子节点。,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,192,对 treeNode的link进行循环,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,195,寻找改节点的父节点，相当于找到了该节点的频繁项集,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,197,避免 单独`Z`一个元素，添加了空节点,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,199,"对非basePat的倒叙值作为key,赋值为count数",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,200,prefixPath[1:] 变frozenset后，字母就变无序了,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,201,condPats[frozenset(prefixPath)] = treeNode.count,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,203,递归，寻找改节点的下一个 相同值的链接节点,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,205,print treeNode,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,219,通过value进行从小到大的排序， 得到频繁项集的key,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,220,最小支持项集的key的list集合,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,224,循环遍历 最频繁项集的key，从小到大的递归寻找对应的频繁项集,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,226,preFix为newFreqSet上一次的存储记录，一旦没有myHead，就不会更新,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,236,构建FP-tree,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,239,"挖掘条件 FP-tree, 如果myHead不为空，表示满足minSup {所有的元素+(value, treeNode)}",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,243,递归 myHead 找出频繁项集,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,248,import twitter,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,249,from time import sleep,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,250,import re,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,253,def getLotsOfTweets(searchStr):,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,254,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,255,获取 100个搜索结果页面,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,256,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,257,CONSUMER_KEY = '',not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,258,CONSUMER_SECRET = '',not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,259,ACCESS_TOKEN_KEY = '',not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,260,ACCESS_TOKEN_SECRET = '',not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,261,"api = twitter.Api(consumer_key=CONSUMER_KEY, consumer_secret=CONSUMER_SECRET, access_token_key=ACCESS_TOKEN_KEY, access_token_secret=ACCESS_TOKEN_SECRET)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,263,# you can get 1500 results 15 pages * 100 per page,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,264,resultsPages = [],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,265,"for i in range(1, 15):",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,266,"print ""fetching page %d"" % i",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,267,"searchResults = api.GetSearch(searchStr, per_page=100, page=i)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,268,resultsPages.append(searchResults),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,269,sleep(6),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,270,return resultsPages,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,273,def textParse(bigString):,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,274,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,275,解析页面内容,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,276,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,277,"urlsRemoved = re.sub('(http:[/][/]|www.)([a-z]|[A-Z]|[0-9]|[/.]|[~])*', '', bigString)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,278,"listOfTokens = re.split(r'\W*', urlsRemoved)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,279,return [tok.lower() for tok in listOfTokens if len(tok) > 2],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,282,"def mineTweets(tweetArr, minSup=5):",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,283,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,284,获取频繁项集,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,285,"""""""",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,286,parsedList = [],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,287,for i in range(14):,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,288,for j in range(100):,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,289,parsedList.append(textParse(tweetArr[i][j].text)),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,290,initSet = createInitSet(parsedList),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,291,"myFPtree, myHeaderTab = createTree(initSet, minSup)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,292,myFreqList = [],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,293,"mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,294,return myFreqList,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,298,"rootNode = treeNode('pyramid', 9, None)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,299,"rootNode.children['eye'] = treeNode('eye', 13, None)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,300,"rootNode.children['phoenix'] = treeNode('phoenix', 3, None)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,301,# 将树以文本形式显示,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,302,# print rootNode.disp(),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,304,load样本数据,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,306,"print simpDat, '\n'",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,307,frozen set 格式化 并 重新装载 样本数据，对所有的行进行统计求和，格式: {行：出现次数},not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,311,创建FP树,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,312,输入：dist{行：出现次数}的样本数据  和  最小的支持度,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,313,输出：最终的PF-tree，通过循环获取第一层的节点，然后每一层的节点进行递归的获取每一行的字节点，也就是分支。然后所谓的指针，就是后来的指向已存在的,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,317,抽取条件模式基,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,318,查询树节点的，频繁子项,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,323,创建条件模式基,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,328,# 项目实战,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,329,# 1.twitter项目案例,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,330,# 无法运行，因为没发链接twitter,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,331,lotsOtweets = getLotsOfTweets('RIMM'),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,332,"listOfTerms = mineTweets(lotsOtweets, 20)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,333,print len(listOfTerms),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,334,for t in listOfTerms:,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,335,print t,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,337,# 2.新闻网站点击流中挖掘，例如：文章1阅读过的人，还阅读过什么？,not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,338,parsedDat = [line.split() for line in open('data/12.FPGrowth/kosarak.dat').readlines()],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,339,initSet = createInitSet(parsedDat),not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,340,"myFPtree, myHeaderTab = createTree(initSet, 100000)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,342,myFreList = [],not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,343,"mineTree(myFPtree, myHeaderTab, 100000, set([]), myFreList)",not
AiLearning/src/py2.x/ml/12.FrequentPattemTree/fpGrowth.py,344,print myFreList,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,19,"dataMat.append([float(lineArr[0]), float(lineArr[1]), float(lineArr[2])])",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,41,就是预测 y 的值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,57,回归系数,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,60,重置 wDelta,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,62,它是学习率，代表了权重调整幅度的大小。（也可以理解为随机梯度的步长，使它不断减小，便于拟合）,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,63,输入T和K分别设定了迭代次数和待处理列表的大小。在T次迭代过程中，每次需要重新计算eta,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,66,全部的训练集  内循环中执行批处理，将分类错误的值全部做累加后更新权重向量,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,68,mapper 代码,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,70,"如果预测正确，并且预测结果的绝对值>=1，因为最大间隔为1, 认为没问题。",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,71,"否则算是预测错误, 通过预测错误的结果，来累计更新w.",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,72,mapper 代码,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,73,累积变化,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,74,w通过不断的随机梯度的方式来优化,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,75,在每个 T上应用更改,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,76,"print '-----', w",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,77,"print '++++++', w",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,83,"finalWs = seqPegasos(datMat, labelList, 2, 5000)",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,106,y2 = (0.43799*x)/0.12316,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/pegasos.py,107,2 iterations,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,17,"input key= class for one training example, e.g. ""-1.0""",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,18,e.g. [-1.0],not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,21,"input value = feature vector for one training example, e.g. ""3.0, 7.0, 2.0""",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,25,create matrix E and vector e,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,29,create a tuple with the values to be used by reducer,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,30,and encode it with base64 to avoid potential trouble with '\t' and '\n' used,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,31,as default separators in Hadoop Streaming,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,34,"note: a single constant key ""producedkey"" sends to only one reducer",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,35,"somewhat ""atypical"" due to low degree of parallism on reducer side",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,42,"key isn't used, so ignoring it with _ (underscore).",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,44,unpickle values,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,47,create the I/mu with correct dimensions,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,52,create sumETDe with correct dimensions,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,57,note: omega = result[:-1] and gamma = result[-1],not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/proximalSVM.py,58,but printing entire vector as output,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,13,对数据初始化,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,19,接受输入数据流,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,20,需要 2 个参数，求数据的和与平方和,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,28,所有输入到达后开始处理,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,29,计算数据的平均值，平方的均值，并返回,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,36,从输入流中获取值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMean.py,43,发出平均值和方差,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,24,返回值中包含输入文件的每一行的数据的一个大的List,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,27,创建一个输入的数据行的列表list,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,29,将输入行分割成单独的项目并存储在列表的列表中,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,31,输入 数据的个数，n个数据的均值，n个数据平方之后的均值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,34,累计样本总和，总和 和 平分和的总和,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,42,计算均值( varSum是计算方差的展开形式 ),not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanReducer.py,45,输出 数据总量，均值，平方的均值（方差）,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,27,返回一个 yield 迭代器，每次获取下一个值，节约内存。,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,30,创建一个输入的数据行的列表list,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,31,将得到的数据转化为 float 类型,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,32,获取数据的个数，即输入文件的数据的行数,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,33,将 List 转换为矩阵,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,34,将矩阵的数据分别求 平方，即 2次方,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,36,输出 数据的个数，n个数据的均值，n个数据平方之后的均值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,37,第一行是标准输出，也就是reducer的输出,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,38,第二行识标准错误输出，即对主节点作出的响应报告，表明本节点工作正常。,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,39,【这不就是面试的装逼重点吗？如何设计监听架构细节】注意：一个好的习惯是想标准错误输出发送报告。如果某任务10分钟内没有报告输出，则将被Hadoop中止。,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrMeanMapper.py,40,计算均值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,28,iteration number,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,39,需要 2 个参数,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,40,"input: nodeId, ('w', w-vector) OR nodeId, ('x', int)",not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,43,积累 w向量,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,46,累积数据点计算,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,47,迭代次数,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,50,这用于 debug， eta未在map中使用,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,54,将数据重新形成 X 和 Y,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,56,在第一次迭代时，初始化 w,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,58,calc p=w*dataSet[key].T,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,60,确保一切数据包含相同的key,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,61,它们将在同一个 reducer,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,65,从流输入获取值,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,79,wDelta += label*dataSet,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,80,calc new: eta,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,81,calc new: w = (1.0 - 1/t)*w + (eta/k)*wDelta,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,84,发出 w,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,86,增量 T,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/mrSVM.py,87,emit random ints for mappers iid,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/wc.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/wc.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/wc.py,16,I'm a generator!,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/wc.py,18,+1 for newline,not
AiLearning/src/py2.x/ml/15.BigData_MapReduce/py27dbg.py,14,needs exactly 2 arguments,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,2,coding: utf-8,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,11,导入科学计算包numpy和运算符模块operator,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,44,-----------实现 classify0() 方法的第一种方式----------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,45,1. 距离计算,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,47,tile生成和训练样本对应的矩阵，并与训练样本求差,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,74,取平方,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,76,将矩阵的每一行相加,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,78,开方,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,80,根据距离排序从小到大的排序，返回对应的索引位置,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,81,argsort() 是将x中的元素从小到大排列，提取其对应的index（索引），然后输出到y。,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,82,"例如：y=array([3,0,2,1,4,5]) 则，x[3]=-1最小，所以y[0]=3;x[5]=9最大，所以y[5]=5。",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,83,"print 'distances=', distances",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,85,"print 'distances.argsort()=', sortedDistIndicies",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,87,2. 选择距离最小的k个点,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,90,找到该样本的类型,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,92,在字典中将该类型加一,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,93,字典的get方法,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,94,"如：list.get(k,d) 其中 get相当于一条if...else...语句,参数k在字典中，字典将返回list[k];如果参数k不在字典中则返回参数d,如果K在字典中则返回k对应的value值",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,95,"l = {5:2,3:4}",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,96,"print l.get(3,0)返回的值是4；",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,97,"Print l.get（1,0）返回值是0；",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,99,3. 排序并返回出现最多的那个类型,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,100,字典的 items() 方法，以列表返回可遍历的(键，值)元组数组。,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,101,"例如：dict = {'Name': 'Zara', 'Age': 7}   print ""Value : %s"" %  dict.items()   Value : [('Age', 7), ('Name', 'Zara')]",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,102,sorted 中的第2个参数 key=operator.itemgetter(1) 这个参数的意思是先比较第几个元素,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,103,"例如：a=[('b',2),('a',1),('c',0)]  b=sorted(a,key=operator.itemgetter(1)) >>>b=[('c',0),('a',1),('b',2)] 可以看到排序是按照后边的0,1,2进行排序的，而不是a,b,c",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,104,"b=sorted(a,key=operator.itemgetter(0)) >>>b=[('a',1),('b',2),('c',0)] 这次比较的是前边的a,b,c而不是0,1,2",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,105,"b=sorted(a,key=opertator.itemgetter(1,0)) >>>b=[('c',0),('a',1),('b',2)] 这个是先比较第2个元素，然后对第一个元素进行排序，形成多级排序。",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,106,"sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,107,return sortedClassCount[0][0],not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,108,3.利用max函数直接返回字典中value最大的key,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,112,------------------------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,113,实现 classify0() 方法的第二种方式,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,115,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,116,1. 计算距离,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,118,欧氏距离： 点到点之间的距离,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,119,第一行： 同一个点 到 dataSet的第一个点的距离。,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,120,第二行： 同一个点 到 dataSet的第二个点的距离。,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,121,...,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,122,第N行： 同一个点 到 dataSet的第N个点的距离。,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,124,"[[1,2,3],[1,2,3]]-[[1,2,3],[1,2,0]]",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,125,(A1-A2)^2+(B1-B2)^2+(c1-c2)^2,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,127,inx - dataset 使用了numpy broadcasting，见 https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,128,np.sum() 函数的使用见 https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,129,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,130,"dist = np.sum((inx - dataset)**2, axis=1)**0.5",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,132,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,133,2. k个最近的标签,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,135,对距离排序使用numpy中的argsort函数， 见 https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sort.html#numpy.sort,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,136,函数返回的是索引，因此取前k个索引使用[0 : k],not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,137,将这k个标签存在列表k_labels中,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,138,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,139,k_labels = [labels[index] for index in dist.argsort()[0 : k]],not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,140,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,141,3. 出现次数最多的标签即为最终类别,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,143,"使用collections.Counter可以统计各个标签的出现次数，most_common返回出现次数最多的标签tuple，例如[('lable1', 2)]，因此[0][0]可以取出标签值",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,144,"""""""",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,145,label = Counter(k_labels).most_common(1)[0][0],not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,146,return label,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,148,------------------------------------------------------------------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,161,----------------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,169,获得文件中的数据行的行数,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,171,生成对应的空矩阵,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,172,例如：zeros(2，3)就是生成一个 2*3的矩阵，各个位置上全是 0,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,173,prepare matrix to return,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,174,prepare labels return,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,178,str.strip([chars]) --返回移除字符串头尾指定的字符生成的新字符串,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,180,以 '\t' 切割字符串,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,182,每列的属性数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,184,每列的类别数据，就是 label 标签数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,187,返回数据矩阵returnMat和对应的类别classLabelVector,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,201,计算每种属性的最大值、最小值、范围,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,204,极差,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,206,-------第一种实现方式---start-------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,209,生成与最小值之差组成的矩阵,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,211,将最小值之差除以范围组成矩阵,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,212,element wise divide,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,213,-------第一种实现方式---end---------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,215,# -------第二种实现方式---start---------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,216,norm_dataset = (dataset - minvalue) / ranges,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,217,# -------第二种实现方式---end---------------------------------------------,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,226,设置测试数据的的一个比例（训练数据集比例=1-hoRatio）,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,227,"测试范围,一部分测试一部分作为样本",not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,228,从文件中加载数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,229,load data setfrom file,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,230,归一化数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,232,m 表示数据的行数，即矩阵的第一维,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,234,设置测试的样本数量， numTestVecs:m表示训练样本的数量,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,239,对数据测试,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,265,1. 导入数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,267,load the training set,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,270,hwLabels存储0～9对应的index位置， trainingMat存放的每个位置对应的图片向量,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,273,take off .txt,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,276,将 32*32的矩阵->1*1024的矩阵,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,279,2. 导入测试数据,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,280,iterate through the test set,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,285,take off .txt,not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,296,test1(),not
AiLearning/src/py2.x/ml/2.KNN/kNN.py,297,datingClassTest(),not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,22,导入一些要玩的数据,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,23,iris = datasets.load_iris(),not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,24,"X = iris.data[:, :2]  # 我们只采用前两个feature. 我们可以使用二维数据集避免这个丑陋的切片",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,25,y = iris.target,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,27,"print 'X=', type(X), X",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,28,"print 'y=', type(y), y",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,33,"print 'X=', type(X), X",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,34,"print 'y=', type(y), y",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,36,网格中的步长,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,38,创建彩色的地图,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,39,"cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,40,"cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,46,我们创建了一个knn分类器的实例，并适合数据。,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,50,绘制决策边界。为此，我们将为每个分配一个颜色,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,51,"来绘制网格中的点 [x_min, x_max]x[y_min, y_max].",not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,58,将结果放入一个彩色图中,not
AiLearning/src/py2.x/ml/2.KNN/sklearn-knn-demo.py,63,绘制训练点,not
AiLearning/src/py2.x/ml/4.NaiveBayes/sklearn-nb-demo.py,1,!/usr/bin/python,not
AiLearning/src/py2.x/ml/4.NaiveBayes/sklearn-nb-demo.py,2,coding:utf8,not
AiLearning/src/py2.x/ml/4.NaiveBayes/sklearn-nb-demo.py,14,GaussianNB_高斯朴素贝叶斯,not
AiLearning/src/py2.x/ml/4.NaiveBayes/sklearn-nb-demo.py,26,MultinomialNB_多项朴素贝叶斯,not
AiLearning/src/py2.x/ml/4.NaiveBayes/sklearn-nb-demo.py,37,BernoulliNB_伯努利朴素贝叶斯,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,2,-*- coding:utf-8 -*-,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,17,项目案例1: 屏蔽社区留言板的侮辱性言论,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,24,"[0,0,1,1,1......]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,30,"1 is abusive, 0 not",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,40,create empty set,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,42,操作符 | 用于求两个集合的并集,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,43,union of the two sets,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,54,创建一个和词汇表等长的向量，并将其元素都设置为0,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,55,"[0,0......]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,56,遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,72,文件数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,74,单词数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,76,侮辱性文件的出现概率，即trainCategory中所有的1的个数，,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,77,代表的就是多少个侮辱性文件，与文件的总数相除就得到了侮辱性文件的出现概率,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,79,构造单词出现次数列表,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,80,"[0,0,0,.....]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,81,"[0,0,0,.....]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,83,整个数据集单词出现总数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,87,遍历所有的文件，如果是侮辱性文件，就计算此侮辱性文件中出现的侮辱性单词的个数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,89,"[0,1,1,....]->[0,1,1,...]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,92,如果不是侮辱性文件，则计算非侮辱性文件中出现的侮辱性单词的个数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,95,"类别1，即侮辱性文档的[P(F1|C1),P(F2|C1),P(F3|C1),P(F4|C1),P(F5|C1)....]列表",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,96,即 在1类别下，每个单词出现次数的占比,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,97,"[1,2,3,5]/90->[1/90,...]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,98,"类别0，即正常文档的[P(F1|C0),P(F2|C0),P(F3|C0),P(F4|C0),P(F5|C0)....]列表",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,99,即 在0类别下，每个单词出现次数的占比,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,111,总文件数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,113,总单词数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,115,侮辱性文件的出现概率,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,117,构造单词出现次数列表,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,118,p0Num 正常的统计,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,119,p1Num 侮辱的统计,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,120,避免单词列表中的任何一个单词为0，而导致最后的乘积为0，所以将每个单词的出现次数初始化为 1,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,121,"[0,0......]->[1,1,1,1,1.....]",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,124,整个数据集单词出现总数，2.0根据样本/实际调查结果调整分母的值（2主要是避免分母为0，当然值可以调整）,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,125,p0Denom 正常的统计,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,126,p1Denom 侮辱的统计,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,131,累加辱骂词的频次,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,133,对每篇文章的辱骂的频次 进行统计汇总,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,138,"类别1，即侮辱性文档的[log(P(F1|C1)),log(P(F2|C1)),log(P(F3|C1)),log(P(F4|C1)),log(P(F5|C1))....]列表",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,140,"类别0，即正常文档的[log(P(F1|C0)),log(P(F2|C0)),log(P(F3|C0)),log(P(F4|C0)),log(P(F5|C0))....]列表",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,157,计算公式  log(P(F1|C))+log(P(F2|C))+....+log(P(Fn|C))+log(P(C)),not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,158,使用 NumPy 数组来计算两个向量相乘的结果，这里的相乘是指对应元素相乘，即先将两个向量中的第一个元素相乘，然后将第2个元素相乘，以此类推。,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,159,我的理解是：这里的 vec2Classify * p1Vec 的意思就是将每个词与其对应的概率相关联起来,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,160,可以理解为 1.单词在词汇表中的条件下，文件是good 类别的概率 也可以理解为 2.在整个空间下，文件既在词汇表中又是good类别的概率,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,181,1. 加载数据集,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,183,2. 创建单词集合,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,185,3. 计算单词是否出现并创建数据矩阵,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,188,返回m*len(myVocabList)的矩阵， 记录的都是0，1信息,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,190,4. 训练数据,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,192,5. 测试数据,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,201,------------------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,202,项目案例2: 使用朴素贝叶斯过滤垃圾邮件,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,204,切分文本,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,215,使用正则表达式来切分句子，其中分隔符是除单词、数字外的任意字符串,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,233,切分，解析数据，并归类为 1 类别,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,237,切分，解析数据，并归类为 0 类别,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,242,创建词汇表,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,246,随机取 10 个邮件用来测试,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,248,"random.uniform(x, y) 随机生成一个范围为 x - y 的实数",not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,272,-----------------------------------------------------------------------------------,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,273,项目案例3: 使用朴素贝叶斯从个人广告中获取区域倾向,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,275,将文本文件解析成 词条向量,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,277,创建一个其中所含元素都为0的向量,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,284,文件解析,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,291,RSS源分类器及高频词去除函数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,295,遍历词汇表中的每个词,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,296,统计每个词在文本中出现的次数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,297,根据每个词出现的次数从高到底对字典进行排序,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,298,返回出现次数最高的30个单词,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,304,每次访问一条RSS源,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,315,去掉出现次数最高的那些词,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,335,最具表征性的词汇显示函数,not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,354,testingNB(),not
AiLearning/src/py2.x/ml/4.NaiveBayes/bayes.py,356,laTest(),not
AiLearning/src/py2.x/dl/mnist.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/mnist.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/mnist.py,10,数据加载器基类,not
AiLearning/src/py2.x/dl/mnist.py,37,图像数据加载器,not
AiLearning/src/py2.x/dl/mnist.py,75,标签数据加载器,not
AiLearning/src/py2.x/dl/activators.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/activators.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/activators.py,10,return weighted_input,not
AiLearning/src/py2.x/dl/cnn.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/cnn.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/cnn.py,10,获取卷积区域,not
AiLearning/src/py2.x/dl/cnn.py,29,获取一个2D区域的最大值所在的索引,not
AiLearning/src/py2.x/dl/cnn.py,42,计算卷积,not
AiLearning/src/py2.x/dl/cnn.py,64,为数组增加Zero padding,not
AiLearning/src/py2.x/dl/cnn.py,95,对numpy数组进行element wise操作,not
AiLearning/src/py2.x/dl/cnn.py,213,处理卷积步长，对原始sensitivity map进行扩展,not
AiLearning/src/py2.x/dl/cnn.py,216,full卷积，对sensitivitiy map进行zero padding,not
AiLearning/src/py2.x/dl/cnn.py,217,虽然原始输入的zero padding单元也会获得残差,not
AiLearning/src/py2.x/dl/cnn.py,218,但这个残差不需要继续向上传递，因此就不计算了,not
AiLearning/src/py2.x/dl/cnn.py,223,初始化delta_array，用于保存传递到上一层的,not
AiLearning/src/py2.x/dl/cnn.py,224,sensitivity map,not
AiLearning/src/py2.x/dl/cnn.py,226,对于具有多个filter的卷积层来说，最终传递到上一层的,not
AiLearning/src/py2.x/dl/cnn.py,227,sensitivity map相当于所有的filter的,not
AiLearning/src/py2.x/dl/cnn.py,228,sensitivity map之和,not
AiLearning/src/py2.x/dl/cnn.py,231,将filter权重翻转180度,not
AiLearning/src/py2.x/dl/cnn.py,235,计算与一个filter对应的delta_array,not
AiLearning/src/py2.x/dl/cnn.py,241,将计算结果与激活函数的偏导数做element-wise乘法操作,not
AiLearning/src/py2.x/dl/cnn.py,248,处理卷积步长，对原始sensitivity map进行扩展,not
AiLearning/src/py2.x/dl/cnn.py,252,计算每个权重的梯度,not
AiLearning/src/py2.x/dl/cnn.py,258,计算偏置项的梯度,not
AiLearning/src/py2.x/dl/cnn.py,263,确定扩展后sensitivity map的大小,not
AiLearning/src/py2.x/dl/cnn.py,264,计算stride为1时sensitivity map的大小,not
AiLearning/src/py2.x/dl/cnn.py,269,构建新的sensitivity_map,not
AiLearning/src/py2.x/dl/cnn.py,272,从原始sensitivity map拷贝误差值,not
AiLearning/src/py2.x/dl/cnn.py,405,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py2.x/dl/cnn.py,408,计算forward值,not
AiLearning/src/py2.x/dl/cnn.py,412,求取sensitivity map,not
AiLearning/src/py2.x/dl/cnn.py,415,计算梯度,not
AiLearning/src/py2.x/dl/cnn.py,418,检查梯度,not
AiLearning/src/py2.x/dl/recursive.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/recursive.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/recursive.py,19,递归神经网络实现,not
AiLearning/src/py2.x/dl/recursive.py,34,权重数组W,not
AiLearning/src/py2.x/dl/recursive.py,37,偏置项b,not
AiLearning/src/py2.x/dl/recursive.py,39,递归神经网络生成的树的根节点,not
AiLearning/src/py2.x/dl/recursive.py,85,根据式2计算每个子节点的delta,not
AiLearning/src/py2.x/dl/recursive.py,89,slices = [(子节点编号，子节点delta起始位置，子节点delta结束位置)],not
AiLearning/src/py2.x/dl/recursive.py,93,针对每个子节点，递归调用calc_delta函数,not
AiLearning/src/py2.x/dl/recursive.py,139,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py2.x/dl/recursive.py,144,计算forward值,not
AiLearning/src/py2.x/dl/recursive.py,149,求取sensitivity map,not
AiLearning/src/py2.x/dl/recursive.py,152,计算梯度,not
AiLearning/src/py2.x/dl/recursive.py,155,检查梯度,not
AiLearning/src/py2.x/dl/bp.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/bp.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/bp.py,8,sigmoid 函数,not
AiLearning/src/py2.x/dl/bp.py,21,定义神经网络的节点类,not
AiLearning/src/py2.x/dl/bp.py,37,设置节点所在的层的位置,not
AiLearning/src/py2.x/dl/bp.py,39,设置层中的节点的索引,not
AiLearning/src/py2.x/dl/bp.py,41,设置此节点的下游节点，也就是这个节点与下一层的哪个节点相连,not
AiLearning/src/py2.x/dl/bp.py,43,设置此节点的上游节点，也就是哪几个节点的下游节点与此节点相连,not
AiLearning/src/py2.x/dl/bp.py,45,此节点的输出,not
AiLearning/src/py2.x/dl/bp.py,47,此节点真实值与计算值之间的差值,not
AiLearning/src/py2.x/dl/bp.py,70,使用 list 的 append 方法来将 conn 中的节点添加到 downstream 中,not
AiLearning/src/py2.x/dl/bp.py,82,使用 list 的 append 方法来将 conn 中的节点添加到 upstream 中,not
AiLearning/src/py2.x/dl/bp.py,94,使用 reduce() 函数对其中的因素求和,not
AiLearning/src/py2.x/dl/bp.py,96,对上游节点的 output 乘 weights 之后求和得到的结果应用 sigmoid 函数，得到当前节点的 output,not
AiLearning/src/py2.x/dl/bp.py,108,根据 https://www.zybuluo.com/hanbingtao/note/476663 的 式4 计算隐藏层的delta,not
AiLearning/src/py2.x/dl/bp.py,110,计算此节点的 delta,not
AiLearning/src/py2.x/dl/bp.py,122,就是那输出层的 delta,not
AiLearning/src/py2.x/dl/bp.py,134,打印格式：第几层 - 第几个节点，output 是多少，delta 是多少,not
AiLearning/src/py2.x/dl/bp.py,136,下游节点,not
AiLearning/src/py2.x/dl/bp.py,138,上游节点,not
AiLearning/src/py2.x/dl/bp.py,140,将本节点 + 下游节点 + 上游节点 的信息打印出来,not
AiLearning/src/py2.x/dl/bp.py,144,ConstNode 对象，为了实现一个输出恒为 1 的节点（计算偏置项 wb 时需要）,not
AiLearning/src/py2.x/dl/bp.py,175,使用 list 的 append 方法将包含下游节点的 conn 添加到 downstream 中,not
AiLearning/src/py2.x/dl/bp.py,188,使用我们的 公式 4 来计算下游节点的 delta，求和,not
AiLearning/src/py2.x/dl/bp.py,190,计算隐藏层的本节点的 delta,not
AiLearning/src/py2.x/dl/bp.py,203,将节点的信息打印出来,not
AiLearning/src/py2.x/dl/bp.py,204,格式 第几层-第几个节点的 output,not
AiLearning/src/py2.x/dl/bp.py,206,此节点的下游节点的信息,not
AiLearning/src/py2.x/dl/bp.py,208,将此节点与下游节点的信息组合，一起打印出来,not
AiLearning/src/py2.x/dl/bp.py,212,神经网络的层对象，负责初始化一层。此外，作为 Node 的集合对象，提供对 Node 集合的操作,not
AiLearning/src/py2.x/dl/bp.py,229,设置 层的索引,not
AiLearning/src/py2.x/dl/bp.py,231,设置层中的节点的 list,not
AiLearning/src/py2.x/dl/bp.py,233,将 Node 节点添加到 nodes 中,not
AiLearning/src/py2.x/dl/bp.py,236,将 ConstNode 节点也添加到 nodes 中,not
AiLearning/src/py2.x/dl/bp.py,248,设置输入层中各个节点的 output,not
AiLearning/src/py2.x/dl/bp.py,261,遍历本层的所有节点（除去最后一个节点，因为它是恒为常数的偏置项b）,not
AiLearning/src/py2.x/dl/bp.py,262,调用节点的 calc_output 方法来计算输出向量,not
AiLearning/src/py2.x/dl/bp.py,275,遍历层的所有的节点 nodes，将节点信息打印出来,not
AiLearning/src/py2.x/dl/bp.py,280,Connection 对象类，主要负责记录连接的权重，以及这个连接所关联的上下游的节点,not
AiLearning/src/py2.x/dl/bp.py,296,设置上游节点,not
AiLearning/src/py2.x/dl/bp.py,298,设置下游节点,not
AiLearning/src/py2.x/dl/bp.py,300,设置权重，这里设置的权重是 -0.1 到 0.1 之间的任何数,not
AiLearning/src/py2.x/dl/bp.py,302,设置梯度 为 0.0,not
AiLearning/src/py2.x/dl/bp.py,314,下游节点的 delta * 上游节点的 output 计算得到梯度,not
AiLearning/src/py2.x/dl/bp.py,326,调用计算梯度的函数来将梯度计算出来,not
AiLearning/src/py2.x/dl/bp.py,328,使用梯度下降算法来更新权重,not
AiLearning/src/py2.x/dl/bp.py,351,格式为：上游节点的层的索引+上游节点的节点索引 ---> 下游节点的层的索引+下游节点的节点索引，最后一个数是权重,not
AiLearning/src/py2.x/dl/bp.py,361,Connections 对象，提供 Connection 集合操作。,not
AiLearning/src/py2.x/dl/bp.py,376,初始化一个列表 list,not
AiLearning/src/py2.x/dl/bp.py,403,Network 对象，提供相应 API,not
AiLearning/src/py2.x/dl/bp.py,418,初始化 connections，使用的是 Connections 对象,not
AiLearning/src/py2.x/dl/bp.py,420,初始化 layers,not
AiLearning/src/py2.x/dl/bp.py,422,我们的神经网络的层数,not
AiLearning/src/py2.x/dl/bp.py,424,节点数,not
AiLearning/src/py2.x/dl/bp.py,426,遍历所有的层，将每层信息添加到 layers 中去,not
AiLearning/src/py2.x/dl/bp.py,429,遍历除去输出层之外的所有层，将连接信息添加到 connections 对象中,not
AiLearning/src/py2.x/dl/bp.py,432,遍历 connections，将 conn 添加到 connections 中,not
AiLearning/src/py2.x/dl/bp.py,435,为下游节点添加上游节点为 conn,not
AiLearning/src/py2.x/dl/bp.py,437,为上游节点添加下游节点为 conn,not
AiLearning/src/py2.x/dl/bp.py,453,循环迭代 epoch 次,not
AiLearning/src/py2.x/dl/bp.py,455,遍历每个训练样本,not
AiLearning/src/py2.x/dl/bp.py,457,使用此样本进行训练（一条样本进行训练）,not
AiLearning/src/py2.x/dl/bp.py,459,print 'sample %d training finished' % d,not
AiLearning/src/py2.x/dl/bp.py,472,调用 Network 的 predict 方法，对这个样本进行预测,not
AiLearning/src/py2.x/dl/bp.py,474,计算根据此样本得到的结果的 delta,not
AiLearning/src/py2.x/dl/bp.py,476,更新权重,not
AiLearning/src/py2.x/dl/bp.py,488,获取输出层的所有节点,not
AiLearning/src/py2.x/dl/bp.py,490,遍历所有的 label,not
AiLearning/src/py2.x/dl/bp.py,492,计算输出层节点的 delta,not
AiLearning/src/py2.x/dl/bp.py,494,"这个用法就是切片的用法， [-2::-1] 就是将 layers 这个数组倒过来，从没倒过来的时候的倒数第二个元素开始，到翻转过来的倒数第一个数，比如这样：aaa = [1,2,3,4,5,6,7,8,9],bbb = aaa[-2::-1] ==> bbb = [8, 7, 6, 5, 4, 3, 2, 1]",not
AiLearning/src/py2.x/dl/bp.py,495,实际上就是除掉输出层之外的所有层按照相反的顺序进行遍历,not
AiLearning/src/py2.x/dl/bp.py,497,遍历每层的所有节点,not
AiLearning/src/py2.x/dl/bp.py,499,计算隐藏层的 delta,not
AiLearning/src/py2.x/dl/bp.py,511,按照正常顺序遍历除了输出层的层,not
AiLearning/src/py2.x/dl/bp.py,513,遍历每层的所有节点,not
AiLearning/src/py2.x/dl/bp.py,515,遍历节点的下游节点,not
AiLearning/src/py2.x/dl/bp.py,517,根据下游节点来更新连接的权重,not
AiLearning/src/py2.x/dl/bp.py,529,按照正常顺序遍历除了输出层之外的层,not
AiLearning/src/py2.x/dl/bp.py,531,遍历层中的所有节点,not
AiLearning/src/py2.x/dl/bp.py,533,遍历节点的下游节点,not
AiLearning/src/py2.x/dl/bp.py,535,计算梯度,not
AiLearning/src/py2.x/dl/bp.py,548,调用 predict() 方法，利用样本的特征数据对样本进行预测,not
AiLearning/src/py2.x/dl/bp.py,550,计算 delta,not
AiLearning/src/py2.x/dl/bp.py,552,计算梯度,not
AiLearning/src/py2.x/dl/bp.py,564,首先为输入层设置输出值output为样本的输入向量，即不发生任何变化,not
AiLearning/src/py2.x/dl/bp.py,566,遍历除去输入层开始到最后一层,not
AiLearning/src/py2.x/dl/bp.py,568,计算 output,not
AiLearning/src/py2.x/dl/bp.py,570,将计算得到的输出，也就是我们的预测值返回,not
AiLearning/src/py2.x/dl/bp.py,582,遍历所有的 layers,not
AiLearning/src/py2.x/dl/bp.py,584,将所有的层的信息打印出来,not
AiLearning/src/py2.x/dl/bp.py,588,# ------------------------- 至此，基本上我们把 我们的神经网络实现完成，下面还会介绍一下对应的梯度检查相关的算法，现在我们首先回顾一下我们上面写道的类及他们的作用 ------------------------,not
AiLearning/src/py2.x/dl/bp.py,637,#--------------------------------------回顾完成了，有些问题可能还是没有弄懂，没事，我们接着看下面---------------------------------------------,not
AiLearning/src/py2.x/dl/bp.py,657,初始化 16 进制的数，用来判断位的，分别是,not
AiLearning/src/py2.x/dl/bp.py,658,0x1 ---- 00000001,not
AiLearning/src/py2.x/dl/bp.py,659,0x2 ---- 00000010,not
AiLearning/src/py2.x/dl/bp.py,660,0x4 ---- 00000100,not
AiLearning/src/py2.x/dl/bp.py,661,0x8 ---- 00001000,not
AiLearning/src/py2.x/dl/bp.py,662,0x10 --- 00010000,not
AiLearning/src/py2.x/dl/bp.py,663,0x20 --- 00100000,not
AiLearning/src/py2.x/dl/bp.py,664,0x40 --- 01000000,not
AiLearning/src/py2.x/dl/bp.py,665,0x80 --- 10000000,not
AiLearning/src/py2.x/dl/bp.py,677,此方法就相当于判断一个 8 位的向量，哪一位上有数字，如果有就将这个数设置为  0.9 ，否则，设置为 0.1，通俗比较来说，就是我们这里用 0.9 表示 1，用 0.1 表示 0,not
AiLearning/src/py2.x/dl/bp.py,689,进行二分类，大于 0.5 就设置为 1，小于 0.5 就设置为 0,not
AiLearning/src/py2.x/dl/bp.py,691,遍历 mask,not
AiLearning/src/py2.x/dl/bp.py,694,将结果相加得到最终的预测结果,not
AiLearning/src/py2.x/dl/bp.py,723,计算网络误差,not
AiLearning/src/py2.x/dl/bp.py,726,获取网络在当前样本下每个连接的梯度,not
AiLearning/src/py2.x/dl/bp.py,729,对每个权重做梯度检查,not
AiLearning/src/py2.x/dl/bp.py,731,获取指定连接的梯度,not
AiLearning/src/py2.x/dl/bp.py,734,增加一个很小的值，计算网络的误差,not
AiLearning/src/py2.x/dl/bp.py,739,减去一个很小的值，计算网络的误差,not
AiLearning/src/py2.x/dl/bp.py,740,刚才加过了一次，因此这里需要减去2倍,not
AiLearning/src/py2.x/dl/bp.py,743,根据式6计算期望的梯度值,not
AiLearning/src/py2.x/dl/bp.py,746,打印,not
AiLearning/src/py2.x/dl/bp.py,759,调用 Normalizer() 类,not
AiLearning/src/py2.x/dl/bp.py,761,初始化一个 list，用来存储后面的数据,not
AiLearning/src/py2.x/dl/bp.py,764,0 到 256 ，其中以 8 为步长,not
AiLearning/src/py2.x/dl/bp.py,766,调用 normalizer 对象的 norm 方法,not
AiLearning/src/py2.x/dl/bp.py,768,在 data_set 中 append n,not
AiLearning/src/py2.x/dl/bp.py,770,在 labels 中 append n,not
AiLearning/src/py2.x/dl/bp.py,772,将它们返回,not
AiLearning/src/py2.x/dl/bp.py,785,获取训练数据集,not
AiLearning/src/py2.x/dl/bp.py,787,调用 network 中的 train方法来训练我们的神经网络,not
AiLearning/src/py2.x/dl/bp.py,801,调用 Normalizer() 类,not
AiLearning/src/py2.x/dl/bp.py,803,调用 norm 方法，对数据进行规范化,not
AiLearning/src/py2.x/dl/bp.py,805,对测试数据进行预测,not
AiLearning/src/py2.x/dl/bp.py,807,将结果打印出来,not
AiLearning/src/py2.x/dl/bp.py,837,创建一个有 3 层的网络，每层有 2 个节点,not
AiLearning/src/py2.x/dl/bp.py,839,样本的特征,not
AiLearning/src/py2.x/dl/bp.py,841,样本对应的标签,not
AiLearning/src/py2.x/dl/bp.py,843,使用梯度检查来查看是否正确,not
AiLearning/src/py2.x/dl/bp.py,856,初始化一个神经网络，输入层 8 个节点，隐藏层 3 个节点，输出层 8 个节点,not
AiLearning/src/py2.x/dl/bp.py,858,训练我们的神经网络,not
AiLearning/src/py2.x/dl/bp.py,860,将我们的神经网络的信息打印出来,not
AiLearning/src/py2.x/dl/bp.py,862,打印出神经网络的正确率,not
AiLearning/src/py2.x/dl/lstm.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/lstm.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/lstm.py,18,门的激活函数,not
AiLearning/src/py2.x/dl/lstm.py,20,输出的激活函数,not
AiLearning/src/py2.x/dl/lstm.py,22,当前时刻初始化为t0,not
AiLearning/src/py2.x/dl/lstm.py,24,各个时刻的单元状态向量c,not
AiLearning/src/py2.x/dl/lstm.py,26,各个时刻的输出向量h,not
AiLearning/src/py2.x/dl/lstm.py,28,各个时刻的遗忘门f,not
AiLearning/src/py2.x/dl/lstm.py,30,各个时刻的输入门i,not
AiLearning/src/py2.x/dl/lstm.py,32,各个时刻的输出门o,not
AiLearning/src/py2.x/dl/lstm.py,34,各个时刻的即时状态c~,not
AiLearning/src/py2.x/dl/lstm.py,36,"遗忘门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py2.x/dl/lstm.py,39,"输入门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py2.x/dl/lstm.py,42,"输出门权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py2.x/dl/lstm.py,45,"单元状态权重矩阵Wfh, Wfx, 偏置项bf",not
AiLearning/src/py2.x/dl/lstm.py,74,遗忘门,not
AiLearning/src/py2.x/dl/lstm.py,78,输入门,not
AiLearning/src/py2.x/dl/lstm.py,82,输出门,not
AiLearning/src/py2.x/dl/lstm.py,86,即时状态,not
AiLearning/src/py2.x/dl/lstm.py,90,单元状态,not
AiLearning/src/py2.x/dl/lstm.py,93,输出,not
AiLearning/src/py2.x/dl/lstm.py,101,上次的LSTM输出,not
AiLearning/src/py2.x/dl/lstm.py,132,初始化各个时刻的误差项,not
AiLearning/src/py2.x/dl/lstm.py,133,输出误差项,not
AiLearning/src/py2.x/dl/lstm.py,134,输出门误差项,not
AiLearning/src/py2.x/dl/lstm.py,135,输入门误差项,not
AiLearning/src/py2.x/dl/lstm.py,136,遗忘门误差项,not
AiLearning/src/py2.x/dl/lstm.py,137,即时输出误差项,not
AiLearning/src/py2.x/dl/lstm.py,139,保存从上一层传递下来的当前时刻的误差项,not
AiLearning/src/py2.x/dl/lstm.py,142,迭代计算每个时刻的误差项,not
AiLearning/src/py2.x/dl/lstm.py,161,获得k时刻前向计算的值,not
AiLearning/src/py2.x/dl/lstm.py,171,根据式9计算delta_o,not
AiLearning/src/py2.x/dl/lstm.py,190,保存全部delta值,not
AiLearning/src/py2.x/dl/lstm.py,198,初始化遗忘门权重梯度矩阵和偏置项,not
AiLearning/src/py2.x/dl/lstm.py,201,初始化输入门权重梯度矩阵和偏置项,not
AiLearning/src/py2.x/dl/lstm.py,204,初始化输出门权重梯度矩阵和偏置项,not
AiLearning/src/py2.x/dl/lstm.py,207,初始化单元状态权重梯度矩阵和偏置项,not
AiLearning/src/py2.x/dl/lstm.py,211,计算对上一次输出h的权重梯度,not
AiLearning/src/py2.x/dl/lstm.py,213,计算各个时刻的梯度,not
AiLearning/src/py2.x/dl/lstm.py,219,实际梯度是各时刻梯度之和,not
AiLearning/src/py2.x/dl/lstm.py,229,计算对本次输入x的权重梯度,not
AiLearning/src/py2.x/dl/lstm.py,264,当前时刻初始化为t0,not
AiLearning/src/py2.x/dl/lstm.py,266,各个时刻的单元状态向量c,not
AiLearning/src/py2.x/dl/lstm.py,268,各个时刻的输出向量h,not
AiLearning/src/py2.x/dl/lstm.py,270,各个时刻的遗忘门f,not
AiLearning/src/py2.x/dl/lstm.py,272,各个时刻的输入门i,not
AiLearning/src/py2.x/dl/lstm.py,274,各个时刻的输出门o,not
AiLearning/src/py2.x/dl/lstm.py,276,各个时刻的即时状态c~,not
AiLearning/src/py2.x/dl/lstm.py,291,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py2.x/dl/lstm.py,296,计算forward值,not
AiLearning/src/py2.x/dl/lstm.py,301,求取sensitivity map,not
AiLearning/src/py2.x/dl/lstm.py,304,计算梯度,not
AiLearning/src/py2.x/dl/lstm.py,307,检查梯度,not
AiLearning/src/py2.x/dl/perceptron.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/perceptron.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/perceptron.py,4,神经元 / 感知器,not
AiLearning/src/py2.x/dl/perceptron.py,27,设置的激活函数,not
AiLearning/src/py2.x/dl/perceptron.py,29,权重向量初始化为 0,not
AiLearning/src/py2.x/dl/perceptron.py,31,偏置项初始化为 0,not
AiLearning/src/py2.x/dl/perceptron.py,56,将输入向量的计算结果返回,not
AiLearning/src/py2.x/dl/perceptron.py,57,调用 激活函数 activator ，将输入向量输入，计算感知器的结果,not
AiLearning/src/py2.x/dl/perceptron.py,58,reduce() 函数是 python 2 的内置函数，从 python 3 开始移到了 functools 模块,not
AiLearning/src/py2.x/dl/perceptron.py,59,"reduce() 从左到右对一个序列的项累计地应用有两个参数的函数，以此合并序列到一个单一值，例如 reduce(lambda x,y: x+y, [1,2,3,4,5]) 计算的就是 ((((1+2)+3)+4)+5)",not
AiLearning/src/py2.x/dl/perceptron.py,60,"map() 接收一个函数 f 和一个 list ，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 返回。比如我们的 f 函数是计算平方， map(f, [1,2,3,4,5]) ===> 返回 [1,4,9,16,25]",not
AiLearning/src/py2.x/dl/perceptron.py,61,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py2.x/dl/perceptron.py,92,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py2.x/dl/perceptron.py,94,对每个样本，按照感知器规则更新权重,not
AiLearning/src/py2.x/dl/perceptron.py,96,计算感知器在当前权重下的输出,not
AiLearning/src/py2.x/dl/perceptron.py,98,更新权重,not
AiLearning/src/py2.x/dl/perceptron.py,113,利用感知器规则更新权重,not
AiLearning/src/py2.x/dl/perceptron.py,115,"map() 接收一个函数 f 和一个 list ，并通过把函数 f 依次作用在 list 的每个元素上，得到一个新的 list 返回。比如我们的 f 函数是计算平方， map(f, [1,2,3,4,5]) ===> 返回 [1,4,9,16,25]",not
AiLearning/src/py2.x/dl/perceptron.py,116,"zip() 接收任意多个（包括 0 个和 1个）序列作为参数，返回一个 tuple 列表。例：x = [1,2,3] y = [4,5,6] z = [7,8,9] xyz = zip(x, y, z) ===> [(1,4,7), (2,5,8), (3,6,9)]",not
AiLearning/src/py2.x/dl/perceptron.py,118,更新 bias,not
AiLearning/src/py2.x/dl/perceptron.py,145,构建训练数据，输入向量的列表,not
AiLearning/src/py2.x/dl/perceptron.py,147,期望的输出列表，也就是上面的输入向量的列表中数据对应的标签，是一一对应的,not
AiLearning/src/py2.x/dl/perceptron.py,161,创建感知器，输入参数的个数是 2 个（因为 and 是个二元函数），激活函数为 f,not
AiLearning/src/py2.x/dl/perceptron.py,163,进行训练，迭代 10 轮，学习速率是我们设定的 rate ，为 0.1,not
AiLearning/src/py2.x/dl/perceptron.py,166,返回训练好的感知器,not
AiLearning/src/py2.x/dl/perceptron.py,179,训练 and 感知器,not
AiLearning/src/py2.x/dl/perceptron.py,181,打印训练获得的权重,not
AiLearning/src/py2.x/dl/perceptron.py,183,测试,not
AiLearning/src/py2.x/dl/linear_unit.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/linear_unit.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/linear_unit.py,4,引入 Perceptron 类,not
AiLearning/src/py2.x/dl/linear_unit.py,8,定义激活函数 f,not
AiLearning/src/py2.x/dl/linear_unit.py,29,初始化我们的感知器类，设置输入参数的个数 input_num 和 激活函数 f,not
AiLearning/src/py2.x/dl/linear_unit.py,32,构造简单的数据集,not
AiLearning/src/py2.x/dl/linear_unit.py,43,构建数据集，输入向量列表，每一项是工作年限,not
AiLearning/src/py2.x/dl/linear_unit.py,45,期望的输出列表，也就是输入向量的对应的标签，与工作年限对应的收入年薪,not
AiLearning/src/py2.x/dl/linear_unit.py,50,使用我们的训练数据集对线性单元进行训练,not
AiLearning/src/py2.x/dl/linear_unit.py,60,创建感知器对象，输入参数的个数也就是特征数为 1（工作年限）,not
AiLearning/src/py2.x/dl/linear_unit.py,62,获取构建的数据集,not
AiLearning/src/py2.x/dl/linear_unit.py,64,训练感知器，迭代 10 轮，学习率为 0.01,not
AiLearning/src/py2.x/dl/linear_unit.py,66,返回训练好的线性单元,not
AiLearning/src/py2.x/dl/linear_unit.py,70,将图像画出来,not
AiLearning/src/py2.x/dl/linear_unit.py,80,引入绘图的库,not
AiLearning/src/py2.x/dl/linear_unit.py,82,获取训练数据：特征 input_vecs 与 对应的标签 labels,not
AiLearning/src/py2.x/dl/linear_unit.py,84,figure() 创建一个 Figure 对象，与用户交互的整个窗口，这个 figure 中容纳着 subplots,not
AiLearning/src/py2.x/dl/linear_unit.py,86,在 figure 对象中创建 1行1列中的第一个图,not
AiLearning/src/py2.x/dl/linear_unit.py,88,"scatter(x, y) 绘制散点图，其中的 x,y 是相同长度的数组序列",not
AiLearning/src/py2.x/dl/linear_unit.py,90,设置权重,not
AiLearning/src/py2.x/dl/linear_unit.py,92,设置偏置项,not
AiLearning/src/py2.x/dl/linear_unit.py,94,"range(start, stop, step) 从 start 开始，到 stop 结束，步长为 step",not
AiLearning/src/py2.x/dl/linear_unit.py,96,计算感知器对输入计算得到的值,not
AiLearning/src/py2.x/dl/linear_unit.py,98,将图画出来,not
AiLearning/src/py2.x/dl/linear_unit.py,100,将最终的图展示出来,not
AiLearning/src/py2.x/dl/linear_unit.py,113,首先训练我们的线性单元,not
AiLearning/src/py2.x/dl/linear_unit.py,115,打印训练获得的权重 和 偏置,not
AiLearning/src/py2.x/dl/linear_unit.py,117,测试,not
AiLearning/src/py2.x/dl/rnn.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/rnn.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/rnn.py,10,Python 2,not
AiLearning/src/py2.x/dl/rnn.py,11,Python 3,not
AiLearning/src/py2.x/dl/rnn.py,26,当前时刻初始化为t0,not
AiLearning/src/py2.x/dl/rnn.py,27,保存各个时刻的state,not
AiLearning/src/py2.x/dl/rnn.py,29,初始化s0,not
AiLearning/src/py2.x/dl/rnn.py,31,初始化U,not
AiLearning/src/py2.x/dl/rnn.py,33,初始化W,not
AiLearning/src/py2.x/dl/rnn.py,61,用来保存各个时刻的误差项,not
AiLearning/src/py2.x/dl/rnn.py,66,迭代计算每个时刻的误差项,not
AiLearning/src/py2.x/dl/rnn.py,82,保存各个时刻的权重梯度,not
AiLearning/src/py2.x/dl/rnn.py,88,实际的梯度是各个时刻梯度之和,not
AiLearning/src/py2.x/dl/rnn.py,91,[0]被初始化为0且没有被修改过,not
AiLearning/src/py2.x/dl/rnn.py,102,当前时刻初始化为t0,not
AiLearning/src/py2.x/dl/rnn.py,103,保存各个时刻的state,not
AiLearning/src/py2.x/dl/rnn.py,105,初始化s0,not
AiLearning/src/py2.x/dl/rnn.py,119,设计一个误差函数，取所有节点输出项之和,not
AiLearning/src/py2.x/dl/rnn.py,124,计算forward值,not
AiLearning/src/py2.x/dl/rnn.py,129,求取sensitivity map,not
AiLearning/src/py2.x/dl/rnn.py,132,计算梯度,not
AiLearning/src/py2.x/dl/rnn.py,135,检查梯度,not
AiLearning/src/py2.x/dl/fc.py,1,!/usr/bin/env python,not
AiLearning/src/py2.x/dl/fc.py,2,-*- coding: UTF-8 -*-,not
AiLearning/src/py2.x/dl/fc.py,11,Python 2,not
AiLearning/src/py2.x/dl/fc.py,12,Python 3,not
AiLearning/src/py2.x/dl/fc.py,16,全连接层实现类,not
AiLearning/src/py2.x/dl/fc.py,29,权重数组W,not
AiLearning/src/py2.x/dl/fc.py,32,偏置项b,not
AiLearning/src/py2.x/dl/fc.py,34,输出向量,not
AiLearning/src/py2.x/dl/fc.py,42,式2,not
AiLearning/src/py2.x/dl/fc.py,52,式8,not
AiLearning/src/py2.x/dl/fc.py,69,神经网络类,not
AiLearning/src/py2.x/dl/fc.py,141,获取网络在当前样本下每个连接的梯度,not
AiLearning/src/py2.x/dl/fc.py,145,检查梯度,not
