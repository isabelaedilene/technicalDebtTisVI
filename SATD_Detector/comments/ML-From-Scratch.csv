file path,line #,comment,satd
ML-From-Scratch/setup.py,9,get the dependencies and installs,not
ML-From-Scratch/mlfromscratch/utils/misc.py,24,Sort eigenvalues and eigenvector by largest eigenvalues,not
ML-From-Scratch/mlfromscratch/utils/misc.py,28,Project the data onto principal components,not
ML-From-Scratch/mlfromscratch/utils/misc.py,66,Plot the dataset X and the corresponding labels y in 2D using PCA.,not
ML-From-Scratch/mlfromscratch/utils/misc.py,77,Plot the different class distributions,not
ML-From-Scratch/mlfromscratch/utils/misc.py,84,Plot legend,not
ML-From-Scratch/mlfromscratch/utils/misc.py,88,Plot title,not
ML-From-Scratch/mlfromscratch/utils/misc.py,97,Axis labels,not
ML-From-Scratch/mlfromscratch/utils/misc.py,103,Plot the dataset X and the corresponding labels y in 3D using PCA.,not
ML-From-Scratch/mlfromscratch/utils/data_operation.py,43,Squared distance between each coordinate,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,64,Concatenate x and y and do a random shuffle,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,69,Uses 50% of training samples without replacements,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,72,100% with replacements,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,100,X_std = (X - X.mean(axis=0)) / X.std(axis=0),not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,108,Split the training data from test data in the ratio specified in,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,109,test_size,not
ML-From-Scratch/mlfromscratch/utils/data_manipulation.py,140,Add left over samples to last set as training samples,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,33,Parameters used to update velocity,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,47,Set intial best as the current initialization,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,50,Set initial velocity to zero,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,69,Two random parameters used to update the velocity,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,74,Layer weights velocity,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,81,Bias weight velocity,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,88,Update layer weights with velocity,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,104,The best individual of the population is initialized as population's first ind.,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,109,Calculate new velocity and update the NN weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,111,Calculate the fitness of the updated individual,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,114,If the current fitness is higher than the individual's previous highest,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,115,=> update the individual's best layer setup,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,119,If the individual's fitness is higher than the highest recorded fitness for the,not
ML-From-Scratch/mlfromscratch/supervised_learning/particle_swarm_optimization.py,120,whole population => update the best individual,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,14,Project data onto vector,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,19,Separate data by class,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,23,Calculate the covariance matrices of the two datasets,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,28,Calculate the mean of the two datasets,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,33,Determine the vector which when X is projected onto it best separates the,not
ML-From-Scratch/mlfromscratch/supervised_learning/linear_discriminant_analysis.py,34,data by class. w = (mean1 - mean2) / (cov1 + cov2),not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,64,Insert constant ones for bias weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,69,Do gradient descent for n_iterations,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,72,Calculate l2 loss,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,75,Gradient of l2 loss w.r.t w,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,77,Update the weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,81,Insert constant ones for bias weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,100,No regularization,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,106,If not gradient descent => Least squares approximation of w,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,108,Insert constant ones for bias weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,110,Calculate weights by least squares (using Moore-Penrose pseudoinverse),not
ML-From-Scratch/mlfromscratch/supervised_learning/regression.py,163,No regularization,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,26,Within class scatter matrix:,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,27,SW = sum{ (X_for_class - mean_of_X_for_class)^2 },not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,28,<=> (n_samples_X_for_class - 1) * covar(X_for_class),not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,34,Between class scatter:,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,35,SB = sum{ n_samples_for_class * (mean_for_class - total_mean)^2 },not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,48,Determine SW^-1 * SB by calculating inverse of SW,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,51,Get eigenvalues and eigenvectors of SW^-1 * SB,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,54,Sort the eigenvalues and corresponding eigenvectors from largest,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,55,to smallest eigenvalue and select the first n_components,not
ML-From-Scratch/mlfromscratch/supervised_learning/multi_class_lda.py,60,Project the data onto eigenvectors,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,13,Calculate the mean and variance of each feature for each class,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,15,Only select the rows where the label equals the given class,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,18,Add the mean and variance for each feature (column),not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,25,Added in denominator to prevent division by zero,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,52,Go through list of classes,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,54,Initialize posterior as prior,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,56,Naive assumption (independence):,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,57,"P(x1,x2,x3|Y) = P(x1|Y)*P(x2|Y)*P(x3|Y)",not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,58,Posterior is product of prior and likelihoods (ignoring scaling factor),not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,60,Likelihood of feature value given distribution of feature values given y,not
ML-From-Scratch/mlfromscratch/supervised_learning/naive_bayes.py,64,Return the class with the largest posterior probability,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,27,"Initialize parameters between [-1/sqrt(N), 1/sqrt(N)]",not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,33,Tune parameters for n iterations,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,35,Make a new prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,38,Move against the gradient of the loss function with,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,39,respect to the parameters to minimize the loss,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,42,Make a diagonal matrix of the sigmoid gradient column vector,not
ML-From-Scratch/mlfromscratch/supervised_learning/logistic_regression.py,44,Batch opt:,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,6,Import helper functions,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,35,Number of trees,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,36,Maxmimum number of features per tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,38,Minimum information gain req. to continue,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,39,Maximum depth for tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,42,Initialize decision trees,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,53,If max_features have not been defined => select it as,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,54,sqrt(n_features),not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,58,Choose one random subset of the data for each tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,63,Feature bagging (select random subsets of the features),not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,65,Save the indices of the features for prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,67,Choose the features corresponding to the indices,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,69,Fit the tree to the data,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,74,Let each tree make a prediction on the data,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,76,Indices of the features that the tree has trained on,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,78,Make a prediction based on those features,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,83,For each sample,not
ML-From-Scratch/mlfromscratch/supervised_learning/random_forest.py,85,Select the most common class prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,8,Import helper functions,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,11,Decision stump used as weak classifier in this impl. of Adaboost,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,14,Determines if sample shall be classified as -1 or 1 given threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,16,The index of the feature used to make classification,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,18,The threshold value that the feature should be measured against,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,20,Value indicative of the classifier's accuracy,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,39,Initialize weights to 1/N,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,43,Iterate through classifiers,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,46,Minimum error given for using a certain feature value threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,47,for predicting sample label,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,49,Iterate throught every unique feature value and see what value,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,50,makes the best threshold for predicting y,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,54,Try every unique feature value as threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,57,Set all predictions to '1' initially,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,59,Label the samples whose values are below threshold as '-1',not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,61,Error = sum of weights of misclassified samples,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,64,If the error is over 50% we flip the polarity so that samples that,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,65,"were classified as 0 are classified as 1, and vice versa",not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,66,E.g error = 0.8 => (1 - error) = 0.2,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,71,If this threshold resulted in the smallest error we save the,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,72,configuration,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,78,"Calculate the alpha which is used to update the sample weights,",not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,79,Alpha is also an approximation of this classifier's proficiency,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,81,Set all predictions to '1' initially,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,83,The indexes where the sample values are below threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,85,Label those as '-1',not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,87,Calculate new weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,88,Missclassified samples gets larger weights and correctly classified samples smaller,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,90,Normalize to one,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,93,Save classifier,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,99,For each classifier => label the samples,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,101,Set all predictions to '1' initially,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,103,The indexes where the sample values are below threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,105,Label those as '-1',not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,107,Add predictions weighted by the classifiers alpha,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,108,(alpha indicative of classifier's proficiency),not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,111,Return sign of prediction sum,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,126,"Change labels to {-1, 1}",not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,133,Adaboost classification with 5 weak classifiers,not
ML-From-Scratch/mlfromscratch/supervised_learning/adaboost.py,141,Reduce dimensions to 2d using pca and plot the results,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,26,Index for the feature that is tested,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,27,Threshold value for feature,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,28,Value if the node is a leaf in the tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,29,'Left' subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,30,'Right' subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,33,Super class of RegressionTree and ClassificationTree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,50,Root node in dec. tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,51,Minimum n of samples to justify split,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,53,The minimum impurity to justify split,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,55,The maximum depth to grow the tree to,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,57,"Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)",not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,59,Function to determine prediction of y at leaf,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,61,If y is one-hot encoded (multi-dim) or not (one-dim),not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,63,If Gradient Boost,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,77,Feature index and threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,78,Subsets of the data,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,80,Check if expansion of y is needed,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,84,Add y as last column of X,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,90,Calculate the impurity for each feature,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,92,All values of feature_i,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,96,Iterate through all unique values of feature column i and,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,97,calculate the impurity,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,99,Divide X and y depending on if the feature value of X at index feature_i,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,100,meets the threshold,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,104,Select the y-values of the two sets,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,108,Calculate impurity,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,111,If this threshold resulted in a higher information gain than previously,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,112,recorded save the threshold value and the feature,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,113,index,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,118,X of left subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,119,y of left subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,120,X of right subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,121,y of right subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,125,Build subtrees for the right and left branches,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,131,We're at leaf => determine value,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,144,If we have a value (i.e we're at a leaf) => return value as the prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,148,Choose the feature that we will test,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,151,Determine if we will follow left or right branch,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,159,Test subtree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,172,If we're at leaf => print the label,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,175,Go deeper down the tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,177,Print test,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,179,Print the true scenario,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,182,Print the false scenario,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,208,Split,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,219,"y split into y, y_pred",not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,221,Newton's Method,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,242,Calculate the variance reduction,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,258,Calculate information gain,not
ML-From-Scratch/mlfromscratch/supervised_learning/decision_tree.py,271,Count number of occurences of samples with label,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,34,Hidden layer,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,38,Output layer,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,49,..............,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,50,Forward Pass,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,51,..............,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,53,HIDDEN LAYER,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,56,OUTPUT LAYER,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,60,...............,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,61,Backward Pass,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,62,...............,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,64,OUTPUT LAYER,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,65,Grad. w.r.t input of output layer,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,69,HIDDEN LAYER,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,70,Grad. w.r.t input of hidden layer,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,75,Update weights (by gradient descent),not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,76,Move against the gradient to minimize loss,SATD
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,82,Use the trained model to predict labels of X,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,84,Forward pass:,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,97,Convert the nominal y values to binary,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,102,MLP,not
ML-From-Scratch/mlfromscratch/supervised_learning/multilayer_perceptron.py,114,Reduce dimension to two using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,24,gradient w.r.t y_pred,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,29,w.r.t y_pred,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,56,Number of trees,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,57,Step size for weight update,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,58,The minimum n of sampels to justify split,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,59,Minimum variance reduction to continue,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,60,Maximum depth for tree,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,64,Log loss for classification,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,67,Initialize regression trees,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,92,Make predictions,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,94,Estimate gradient and update prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,100,Turn into probability distribution (Softmax),not
ML-From-Scratch/mlfromscratch/supervised_learning/xgboost.py,102,Set label to the value that maximizes probability,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,42,Prior parameters,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,48,Allows for simulation from the scaled inverse chi squared,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,49,distribution. Assumes the variance is distributed according to,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,50,this distribution.,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,51,Reference:,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,52,https://en.wikipedia.org/wiki/Scaled_inverse_chi-squared_distribution,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,60,If polynomial transformation,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,68,Least squares approximate of beta,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,71,The posterior parameters can be determined analytically since we assume,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,72,conjugate priors for the likelihoods.,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,74,Normal prior / likelihood => Normal posterior,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,77,Scaled inverse chi-squared prior / likelihood => Scaled inverse chi-squared posterior,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,82,Simulate parameter values for n_draws,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,87,Save parameter draws,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,90,Select the mean of the simulated variables as the ones used to make predictions,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,93,Lower and upper boundary of the credible interval,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,101,If polynomial transformation,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,106,If the lower and upper boundaries for the 95%,not
ML-From-Scratch/mlfromscratch/supervised_learning/bayesian_regression.py,107,equal tail interval should be returned,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,40,"Initialize weights between [-1/sqrt(N), 1/sqrt(N)]",not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,46,Calculate outputs,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,49,Calculate the loss gradient w.r.t the input of the activation function,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,51,Calculate the gradient of the loss with respect to each weight,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,54,Update weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/perceptron.py,58,Use the trained model to predict labels of X,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,9,Hide cvxopt output,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,45,Set gamma to 1/n_features by default,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,49,Initialize kernel method with parameters,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,55,Calculate kernel matrix,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,61,Define the quadratic optimization problem,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,78,Solve the quadratic optimization problem using cvxopt,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,81,Lagrange multipliers,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,84,Extract support vectors,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,85,Get indexes of non-zero lagr. multipiers,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,87,Get the corresponding lagr. multipliers,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,89,Get the samples that will act as support vectors,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,91,Get the corresponding labels,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,94,Calculate intercept with first support vector,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,102,Iterate through list of samples and make predictions,not
ML-From-Scratch/mlfromscratch/supervised_learning/support_vector_machine.py,105,Determine the label of the sample by the support vectors,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,44,Square loss for regression,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,45,Log loss for classification,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,50,Initialize regression trees,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,66,Update y prediction,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,72,Make predictions,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,79,Turn into probability distribution,not
ML-From-Scratch/mlfromscratch/supervised_learning/gradient_boosting.py,81,Set label to the value that maximizes probability,not
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,24,Determine the class of each sample,not
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,26,Sort the training samples by their distance to the test sample and get the K nearest,not
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,28,Extract the labels of the K nearest neighboring training samples,not
ML-From-Scratch/mlfromscratch/supervised_learning/k_nearest_neighbors.py,30,Label sample as the most common class label,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,42,Mutation of weight with probability self.mutation_rate,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,54,The child inherits both weights W and bias weights w0,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,65,Perform crossover,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,69,Perform crossover between the individuals' neuron weights,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,91,The 40% highest fittest individuals will be selected for the next generation,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,93,The fittest 60% of the population will be selected as parents to form offspring,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,97,Determine the fitness of the individuals in the population,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,100,Sort population by fitness,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,104,Get the individual with the highest fitness,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,109,The 'winners' are selected for the next generation,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,113,The probability that a individual will be selected as a parent is proportionate to its fitness,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,115,Select parents according to probabilities (without replacement to preserve diversity),not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,118,Perform crossover to produce offspring,not
ML-From-Scratch/mlfromscratch/supervised_learning/neuroevolution.py,120,Save mutated offspring for next population,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,4,Optimizers for models that use gradient based methods for finding the,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,5,weights that minimizes the loss.,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,6,A great resource for understanding these methods:,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,7,http://sebastianruder.com/optimizing-gradient-descent/index.html,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,16,If not initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,19,Use momentum if set,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,21,Move against the gradient to minimize loss,SATD
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,31,Calculate the gradient of the loss a bit further down the slope from w,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,33,Initialize on first update,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,38,Move against the gradient to minimize loss,SATD
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,44,Sum of squares of the gradients,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,48,If not initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,51,Add the square of the gradient of the loss function at w,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,53,Adaptive gradient with higher learning rate for sparse data,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,58,Running average of squared parameter updates,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,59,Running average of the squared gradient of w,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,60,Parameter update,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,65,If not initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,71,Update average of gradients at w,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,77,Adaptive learning rate,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,80,Calculate the update,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,83,Update the running average of w updates,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,91,Running average of the square gradients at w,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,96,If not initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,102,Divide the learning rate for a weight by a running average of the magnitudes of recent,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,103,gradients for that weight,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,112,Decay rates,not
ML-From-Scratch/mlfromscratch/deep_learning/optimizers.py,117,If not initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,61,Initialize the weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,65,Weight optimizers,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,77,Save weights used during forwards pass,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,81,Calculate gradient w.r.t layer weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,85,Update the layer weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,89,Return accumulated gradient for next layer,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,90,Calculated based on the weights used during the forward pass,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,124,Weight of the previous state,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,125,Weight of the output,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,126,Weight of the input,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,130,Initialize the weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,136,Weight optimizers,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,148,Save these values for use in backprop.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,153,Set last time step to zero for calculation of the state_input at time step zero,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,156,Input to state_t is the current input and output of previous states,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,166,Variables where we save the accumulated gradient w.r.t each parameter,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,170,The gradient w.r.t the layer input.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,171,Will be passed on to the previous layer in the network,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,174,Back Propagation Through Time,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,176,Update gradient w.r.t V at time step t,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,178,Calculate the gradient w.r.t the state input,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,180,Gradient w.r.t the layer input,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,182,Update gradient w.r.t W and U by backprop. from time step t for at most,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,183,self.bptt_trunc number of time steps,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,187,Calculate gradient w.r.t previous state,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,190,Update weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,228,Initialize the weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,234,Weight optimizers,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,244,Turn image shape into column shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,245,(enables dot product between input and weights),not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,247,Turn weights into column shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,249,Calculate output,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,251,"Reshape into (n_filters, out_height, out_width, batch_size)",not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,253,Redistribute axises so that batch size comes first,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,257,Reshape accumulated gradient into column shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,261,Take dot product between column shaped accum. gradient and column shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,262,layer input to determine the gradient at the layer with respect to layer weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,264,The gradient with respect to bias terms is the sum similarly to in Dense layer,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,267,Update the layers weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,271,Recalculate the gradient which will be propogated back to prev. layer,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,273,Reshape from column shape to image shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,301,Initialize the parameters,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,304,parameter optimizers,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,313,Initialize running mean and variance if first run,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,327,Statistics saved for backward pass,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,338,Save parameters used during the forward pass,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,341,If the layer is trainable the parameters are updated,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,352,The gradient of the loss with respect to the layer inputs (use weights and statistics from forward pass),not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,384,MaxPool or AveragePool specific method,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,397,MaxPool or AveragePool specific method,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,536,Repeat each axis as specified by size,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,541,Down sample input to previous shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,644,Method which calculates the padding based on the specified output shape and the,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,645,shape of the filters,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,648,No padding,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,651,Pad so that the output shape is the same as input shape (given that stride=1),not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,655,Derived from:,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,656,output_height = (height + pad_h - filter_height) / stride + 1,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,657,In this case output_height = height and stride = 1. This gives the,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,658,expression for the padding below.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,667,Reference: CS231n Stanford,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,669,First figure out what the size of the output should be,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,689,Method which turns the image shaped input to column shape.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,690,Used during the forward pass.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,691,Reference: CS231n Stanford,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,697,Add padding to the image,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,700,Calculate the indices where the dot products are to be applied between weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,701,and the image,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,704,Get content from image at those indices,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,707,Reshape content into column shape,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,713,Method which turns the column shaped input to image shape.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,714,Used during the backward pass.,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,715,Reference: CS231n Stanford,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,723,Calculate the indices where the dot products are applied between weights,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,724,and the image,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,729,Add column content to the images at the indices,not
ML-From-Scratch/mlfromscratch/deep_learning/layers.py,732,Return image without padding,not
ML-From-Scratch/mlfromscratch/deep_learning/loss_functions.py,29,Avoid division by zero,not
ML-From-Scratch/mlfromscratch/deep_learning/loss_functions.py,37,Avoid division by zero,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,41,If this is not the first layer added then set the input shape,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,42,to the output shape of the last added layer,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,46,If the layer has weights that needs to be initialized,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,50,Add layer to the network,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,66,Calculate the gradient of the loss function wrt y_pred,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,68,Backpropagate. Update weights,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,104,Print model name,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,106,Network input shape (first layer's input shape),not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,108,Iterate through network and get each layer's configuration,not
ML-From-Scratch/mlfromscratch/deep_learning/neural_network.py,117,Print network configuration table,not
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,3,Collection of activation functions,not
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,4,Reference: https://en.wikipedia.org/wiki/Activation_function,not
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,57,"Reference : https://arxiv.org/abs/1706.02515,",not
ML-From-Scratch/mlfromscratch/deep_learning/activation_functions.py,58,https://github.com/bioinf-jku/SNNs/blob/master/SelfNormalizingNetworks_MLP_MNIST.ipynb,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,36,Initialize the environment,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,46,Choose action randomly,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,49,Take action with highest predicted utility given state,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,56,Make sure we restrict memory size to specified limit,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,61,Select states and new states from replay,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,65,Predict the expected utility of current state and new state,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,73,Construct training set,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,79,If we're done the utility is simply the reward of executing action a in,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,80,"state s, otherwise we add the expected maximum future reward as well",not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,100,Take a step,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,105,Sample replay batch from memory,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,109,Construct training set from replay,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,112,Learn control policy,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,123,Reduce the epsilon parameter,not
ML-From-Scratch/mlfromscratch/reinforcement_learning/deep_q_network.py,133,"self.env = gym.wrappers.Monitor(self.env, '/tmp/cartpole-experiment-1', force=True)",not
ML-From-Scratch/mlfromscratch/examples/gaussian_mixture_model.py,14,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/gaussian_mixture_model.py,17,Cluster the data,not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,13,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,19,"fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,32,Training error plot,not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,47,Color map,not
ML-From-Scratch/mlfromscratch/examples/lasso_regression.py,50,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,14,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,20,"Time. Fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,21,Temperature. Reduce to one-dim,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,31,Color map,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,38,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_regressor.py,39,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,23,Model builder,not
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,33,Print the model summary of a individual in the population,not
ML-From-Scratch/mlfromscratch/examples/particle_swarm_optimization.py,67,Reduce dimension to 2D using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,12,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,17,Three -> two classes,not
ML-From-Scratch/mlfromscratch/examples/linear_discriminant_analysis.py,23,Fit and predict using LDA,not
ML-From-Scratch/mlfromscratch/examples/apriori.py,7,Demo transaction set,not
ML-From-Scratch/mlfromscratch/examples/apriori.py,8,Example 2: https://en.wikipedia.org/wiki/Apriori_algorithm,not
ML-From-Scratch/mlfromscratch/examples/apriori.py,23,Get and print the frequent itemsets,not
ML-From-Scratch/mlfromscratch/examples/apriori.py,27,Get and print the rules,not
ML-From-Scratch/mlfromscratch/examples/multi_class_lda.py,9,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/multi_class_lda.py,14,Project the data onto the 2 primary components,not
ML-From-Scratch/mlfromscratch/examples/naive_bayes.py,22,Reduce dimension to two using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,4,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,9,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,12,Cluster the data using K-Medoids,not
ML-From-Scratch/mlfromscratch/examples/partitioning_around_medoids.py,16,Project the data onto the 2 primary principal components,not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,13,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,19,"fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,33,Training error plot,not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,48,Color map,not
ML-From-Scratch/mlfromscratch/examples/elastic_net.py,51,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,6,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,13,Load dataset,not
ML-From-Scratch/mlfromscratch/examples/logistic_regression.py,29,Reduce dimension to two using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/deep_q_network.py,18,Model builder,not
ML-From-Scratch/mlfromscratch/examples/adaboost.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/adaboost.py,20,"Change labels to {-1, 1}",not
ML-From-Scratch/mlfromscratch/examples/adaboost.py,27,Adaboost classification with 5 weak classifiers,not
ML-From-Scratch/mlfromscratch/examples/adaboost.py,35,Reduce dimensions to 2d using pca and plot the results,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,19,Select the samples of the digit 2,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,22,Limit dataset to 500 samples,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,29,Training error plot,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,37,Get the images that were reconstructed during training,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,40,Plot the reconstructed images during the first iteration,not
ML-From-Scratch/mlfromscratch/examples/restricted_boltzmann_machine.py,52,Plot the images during the last iteration,not
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,22,Training error plot,not
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,37,Color map,not
ML-From-Scratch/mlfromscratch/examples/linear_regression.py,40,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,13,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,19,"fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,26,Finding regularization constant using cross validation,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,46,Print the mean squared error,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,49,Save reg. constant that gave lowest error,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,54,Make final prediction,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,66,Color map,not
ML-From-Scratch/mlfromscratch/examples/polynomial_regression.py,69,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_classifier.py,6,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,10,Demo of how to reduce the dimensionality of the data to two dimension,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,11,and plot the results.,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,13,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,18,Project the data onto the 2 primary principal components,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,28,Plot the different class distributions,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,35,Add a legend,not
ML-From-Scratch/mlfromscratch/examples/principal_component_analysis.py,38,Axis labels,not
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,6,Demo transaction set,not
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,7,Example:,not
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,8,https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Frequent_Pattern_Mining/The_FP-Growth_Algorithm,not
ML-From-Scratch/mlfromscratch/examples/fp_growth.py,33,Get and print the frequent itemsets,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,8,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,23,----------,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,24,Conv Net,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,25,----------,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,33,Convert to one-hot encoding,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,38,"Reshape X to (n_samples, channels, height, width)",not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,67,Training and validation error plot,not
ML-From-Scratch/mlfromscratch/examples/convolutional_neural_network.py,83,Reduce dimension to 2D using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/k_means.py,10,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/k_means.py,13,Cluster the data using K-Means,not
ML-From-Scratch/mlfromscratch/examples/k_means.py,17,Project the data onto the 2 primary principal components,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,17,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,23,"Time. Fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,24,Insert bias term,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,25,Temperature. Reduce to one-dim,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,35,Color map,not
ML-From-Scratch/mlfromscratch/examples/gradient_boosting_regressor.py,42,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/decision_tree_classifier.py,8,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/dbscan.py,8,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/dbscan.py,13,Load the dataset,not
ML-From-Scratch/mlfromscratch/examples/dbscan.py,16,Cluster the data using DBSCAN,not
ML-From-Scratch/mlfromscratch/examples/dbscan.py,20,Project the data onto the 2 primary principal components,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,7,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,21,-----,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,22,MLP,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,23,-----,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,29,Convert to one-hot encoding,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,60,Training and validation error plot,not
ML-From-Scratch/mlfromscratch/examples/multilayer_perceptron.py,73,Reduce dimension to 2D using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/demo.py,25,...........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,26,LOAD DATA,not
ML-From-Scratch/mlfromscratch/examples/demo.py,27,...........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,33,"Change labels to {0, 1}",not
ML-From-Scratch/mlfromscratch/examples/demo.py,41,..........................,not
ML-From-Scratch/mlfromscratch/examples/demo.py,42,DIMENSIONALITY REDUCTION,not
ML-From-Scratch/mlfromscratch/examples/demo.py,43,..........................,not
ML-From-Scratch/mlfromscratch/examples/demo.py,45,Reduce to 5 dimensions,not
ML-From-Scratch/mlfromscratch/examples/demo.py,49,..........................,not
ML-From-Scratch/mlfromscratch/examples/demo.py,50,TRAIN / TEST SPLIT,not
ML-From-Scratch/mlfromscratch/examples/demo.py,51,..........................,not
ML-From-Scratch/mlfromscratch/examples/demo.py,53,"Rescaled labels {-1, 1}",not
ML-From-Scratch/mlfromscratch/examples/demo.py,57,.......,not
ML-From-Scratch/mlfromscratch/examples/demo.py,58,SETUP,not
ML-From-Scratch/mlfromscratch/examples/demo.py,59,.......,not
ML-From-Scratch/mlfromscratch/examples/demo.py,80,........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,81,TRAIN,not
ML-From-Scratch/mlfromscratch/examples/demo.py,82,........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,109,.........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,110,PREDICT,not
ML-From-Scratch/mlfromscratch/examples/demo.py,111,.........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,126,..........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,127,ACCURACY,not
ML-From-Scratch/mlfromscratch/examples/demo.py,128,..........,not
ML-From-Scratch/mlfromscratch/examples/demo.py,131,Rescaled {-1 1},not
ML-From-Scratch/mlfromscratch/examples/demo.py,134,Categorical,not
ML-From-Scratch/mlfromscratch/examples/demo.py,138,.......,not
ML-From-Scratch/mlfromscratch/examples/demo.py,139,PLOT,not
ML-From-Scratch/mlfromscratch/examples/demo.py,140,.......,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,12,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,18,"fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,25,Prior parameters,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,26,- Weights are assumed distr. according to a Normal distribution,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,27,- The variance of the weights are assumed distributed according to,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,28,a scaled inverse chi-squared distribution.,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,29,High prior uncertainty!,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,30,Normal,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,33,Scaled inverse chi-squared,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,37,The credible interval,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,52,Get prediction line,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,55,Print the mean squared error,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,58,Color map,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,61,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/bayesian_regression.py,73,"plt.legend((m1, m2), (""Training data"", ""Test data""), loc='lower right')",not
ML-From-Scratch/mlfromscratch/examples/perceptron.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/perceptron.py,18,One-hot encoding of nominal y-values,not
ML-From-Scratch/mlfromscratch/examples/perceptron.py,23,Perceptron,not
ML-From-Scratch/mlfromscratch/examples/perceptron.py,37,Reduce dimension to two using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/support_vector_machine.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/support_vector_machine.py,26,Reduce dimension to two using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,5,Import helper functions,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,13,Load temperature data,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,19,"fraction of the year [0, 1]",not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,26,Finding regularization constant using cross validation,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,46,Print the mean squared error,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,49,Save reg. constant that gave lowest error,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,54,Make final prediction,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,67,Color map,not
ML-From-Scratch/mlfromscratch/examples/ridge_regression.py,70,Plot the results,not
ML-From-Scratch/mlfromscratch/examples/k_nearest_neighbors.py,23,Reduce dimensions to 2d using pca and plot the results,not
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,23,Model builder,not
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,33,Print the model summary of a individual in the population,not
ML-From-Scratch/mlfromscratch/examples/neuroevolution.py,56,Reduce dimension to 2D using PCA and plot the results,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,27,Mark endpoint as 1,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,40,Mark endpoint as 1,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,46,Model definition,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,53,Print a problem instance and the correct solution,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,63,Predict labels of the test data,not
ML-From-Scratch/mlfromscratch/examples/recurrent_neural_network.py,70,Print a problem instance and the correct solution,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,51,dimension,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,71,Calculate probabilities of X belonging to the different clusters,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,75,Determine responsibility as P(X|y)*P(y)/P(X),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,77,Assign samples to cluster that has largest probability,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,79,Save value for convergence check,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,84,Iterate through clusters and recalculate mean and covariance,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,92,Update weights,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,102,"print (""Likelihood update: %s (tol: %s)"" % (diff, self.tolerance))",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,107,Initialize the gaussians randomly,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,110,Run EM until convergence or for max iterations,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,112,E-step,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,113,M-step,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,115,Check convergence,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/gaussian_mixture_model.py,119,Make new assignments and return them,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,31,List of freqeuent itemsets,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,32,List of transactions,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,47,Find frequent items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,59,Find all combinations of size k-1 in candidate,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,60,"E.g [1,2,3] => [[1,2],[1,3],[2,3]]",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,63,t - is tuple. If size == 1 get the element,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,77,Valid if every element but the last are the same,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,78,and the last element in itemset1 is smaller than the last,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,79,in itemset2,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,88,JOIN: Add the last element in itemset2 to itemset1 to,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,89,create a new candidate,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,94,PRUNE: Check if any subset of candidate have been determined,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,95,to be infrequent,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,105,If items is in fact only one item,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,108,Iterate through list of items and make sure that,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,109,all items are in the transaction,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,118,Get all unique items in the transactions,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,120,Get the frequent items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,123,Generate new candidates from last added frequent itemsets,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,125,Get the frequent itemsets among those candidates,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,128,If there are no frequent itemsets we're done,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,132,Add them to the total list of frequent itemsets and start over,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,135,Flatten the array and return every frequent itemset,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,146,Get all combinations of sub-itemsets of size k - 1 from itemset,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,147,"E.g [1,2,3] => [[1,2],[1,3],[2,3]]",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,151,itertools.combinations returns tuples => convert to list,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,154,"Calculate the confidence as sup(A and B) / sup(B), if antecedent",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,155,is B in an itemset of A and B,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,158,The concequent is the initial_itemset except for antecedent,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,160,If single item => get item,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,165,Create new rule,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,173,If there are subsets that could result in rules,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,174,recursively add rules from subsets,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,182,Only consider itemsets of size >= 2 items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/apriori.py,188,Remove empty values,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,53,For each cluster,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,57,Add distance between sample and medoid as cost,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,71,One prediction for each sample,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,81,Initialize medoids randomly,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,83,Assign samples to closest medoids,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,86,Calculate the initial cost (total distance between samples and,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,87,corresponding medoids),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,90,Iterate until we no longer have a cheaper cost,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,95,Get all non-medoid samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,97,Calculate the cost when swapping medoid and samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,99,Swap sample with the medoid,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,102,Assign samples to new medoids,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,104,Calculate the cost with the new set of medoids,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,107,If the swap gives us a lower cost we save the medoids and cost,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,111,If there was a swap that resultet in a lower cost we save the,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,112,resulting medoids from the best swap and the new cost,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,116,Else finished,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/partitioning_around_medoids.py,121,Return the samples cluster indices as labels,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,39,Bias visible,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,40,Bias hidden,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,52,Positive phase,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,57,Negative phase,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/restricted_boltzmann_machine.py,70,Reconstruct a batch of images from the training set,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,17,"Where (eigenvector[:,0] corresponds to eigenvalue[0])",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,20,Sort the eigenvalues and corresponding eigenvectors from largest,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,21,to smallest eigenvalue and select the first n_components,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/principal_component_analysis.py,26,Project the data onto principal components,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,24,Build the discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,27,Build the generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,30,Build the combined model,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,93,Rescale -1 to 1,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,100,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,101,Train Discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,102,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,106,Select a random half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,110,Sample noise to use as generator input,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,113,Generate a half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,119,Train the discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,126,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,127,Train Generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,128,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,130,We only want to train the generator for the combined model,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,133,Sample noise and use as generator input,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,136,The generator wants the discriminator to label the generated samples as valid,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,139,Train the generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,142,Display the progress,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,145,If at save interval => save generated image samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dcgan.py,154,Rescale images 0 - 1 (from -1 to 1),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,31,Build the discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,34,Build the generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,37,Build the combined model,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,86,"Rescale [-1, 1]",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,93,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,94,Train Discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,95,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,99,Select a random half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,103,Sample noise to use as generator input,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,106,Generate a half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,109,"Valid = [1, 0], Fake = [0, 1]",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,113,Train the discriminator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,120,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,121,Train Generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,122,---------------------,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,124,We only want to train the generator for the combined model,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,127,Sample noise and use as generator input,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,130,The generator wants the discriminator to label the generated samples as valid,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,133,Train the generator,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,136,Display the progress,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,139,If at save interval => save generated image samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,144,Grid size,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,146,Generate images and reshape to image shape,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/generative_adversarial_network.py,149,Rescale images 0 - 1,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,8,'Value' of the item,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,10,Number of times the item occurs in a,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,11,transaction,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,13,Child nodes in the FP Growth Tree,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,31,The root of the initial FP Growth Tree,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,33,Prefixes of itemsets in the FP Growth Tree,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,37,Count the number of transactions that contains item.,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,51,Get all unique items in the transactions,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,59,Sort by support - Highest to lowest,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,62,Only return the items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,69,Create new node as the first item in children list,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,72,If parent already contains item => increase the support,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,78,Execute _insert_tree on the rest of the children list,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,79,from the new node,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,84,Get frequent items sorted by support,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,88,Construct the root of the FP Growth tree,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,91,Remove items that are not frequent according to,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,92,unique_frequent_items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,126,If the current node is a prefix to the itemset,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,127,add the current prefixes value as prefix to the itemset,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,136,Recursive call with child as new node. Add the child item as potential,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,137,prefix.,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,151,Calculate new frequent items from the conditional database,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,152,of suffix,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,159,Output new frequent itemset as the suffix added to the frequent,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,160,items,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,163,Find larger frequent itemset by finding prefixes,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,164,of the frequent items in the FP Growth Tree for the conditional,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,165,database.,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,168,If no suffix (first run),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,171,Determine prefixes to itemset,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,175,Build new conditional database,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,178,If support = 4 => add 4 of the corresponding prefix set,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,181,Create new suffix,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/fp_growth.py,188,Build the FP Growth Tree,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,64,One prediction for each sample,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,74,Initialize centroids as k random samples from X,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,77,Iterate until convergence or for max iterations,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,79,Assign samples to closest centroids (create clusters),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,81,Save current centroids for convergence check,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,83,Calculate new centroids from the clusters,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/k_means.py,85,If no centroids have changed => convergence,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,38,Iterate through neighbors,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,42,Fetch the sample's distant neighbors (neighbors of neighbor),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,44,Make sure the neighbor's neighbors are more than min_samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,45,(If this is true the neighbor is a core point),not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,47,Expand the cluster from the neighbor,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,50,Add expanded cluster to this cluster,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,53,If the neighbor is not a core point we only add the neighbor point,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,60,Set default value to number of clusters,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,61,Will make sure all outliers have same cluster label,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,68,DBSCAN,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,75,Iterate through samples and expand clusters from them,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,76,if they have more neighbors than self.min_samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,82,If core point => mark as visited,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,84,Sample has more neighbors than self.min_samples => expand,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,85,cluster from sample,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,88,Add cluster to list of clusters,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/dbscan.py,91,Get the resulting cluster labels,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,29,Select random letters as new individual,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,37,Calculate loss as the alphabetical distance between,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,38,the characters in the individual and the target string,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,53,Make change with probability mutation_rate,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,56,Return mutated individual as string,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,61,Select random crossover point,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,68,Initialize new population,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,77,If we have found individual which matches the target => Done,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,81,Set the probability that the individual should be selected as a parent,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,82,proportionate to the individual's fitness.,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,85,Determine the next generation,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,88,Select two parents randomly according to probabilities,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,90,Perform crossover to produce offspring,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/genetic_algorithm.py,92,Save mutated offspring for next generation,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,25,The dimension of the data embedding,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,74,"Rescale [-1, 1]",not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,79,Select a random half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,83,Train the Autoencoder,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,86,Display the progress,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,89,If at save interval => save generated image samples,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,94,Grid size,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,95,Select a random half batch of images,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,98,Generate images and reshape to image shape,not
ML-From-Scratch/mlfromscratch/unsupervised_learning/autoencoder.py,101,Rescale images 0 - 1,not
