file path,line #,comment,satd
Mask_RCNN/setup.py,27,parse_requirements() returns generator of pip.req.InstallRequirement objects,not
Mask_RCNN/mrcnn/model.py,28,Requires TensorFlow 1.3+ and Keras 2.0.8+.,not
Mask_RCNN/mrcnn/model.py,34,,not
Mask_RCNN/mrcnn/model.py,35,Utility Functions,not
Mask_RCNN/mrcnn/model.py,36,,not
Mask_RCNN/mrcnn/model.py,80,Currently supports ResNet only,not
Mask_RCNN/mrcnn/model.py,88,,not
Mask_RCNN/mrcnn/model.py,89,Resnet Graph,not
Mask_RCNN/mrcnn/model.py,90,,not
Mask_RCNN/mrcnn/model.py,92,Code adopted from:,not
Mask_RCNN/mrcnn/model.py,93,https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py,not
Mask_RCNN/mrcnn/model.py,178,Stage 1,not
Mask_RCNN/mrcnn/model.py,184,Stage 2,not
Mask_RCNN/mrcnn/model.py,188,Stage 3,not
Mask_RCNN/mrcnn/model.py,193,Stage 4,not
Mask_RCNN/mrcnn/model.py,199,Stage 5,not
Mask_RCNN/mrcnn/model.py,209,,not
Mask_RCNN/mrcnn/model.py,210,Proposal Layer,not
Mask_RCNN/mrcnn/model.py,211,,not
Mask_RCNN/mrcnn/model.py,218,"Convert to y, x, h, w",not
Mask_RCNN/mrcnn/model.py,223,Apply deltas,not
Mask_RCNN/mrcnn/model.py,228,"Convert back to y1, x1, y2, x2",not
Mask_RCNN/mrcnn/model.py,242,Split,not
Mask_RCNN/mrcnn/model.py,245,Clip,not
Mask_RCNN/mrcnn/model.py,277,"Box Scores. Use the foreground class confidence. [Batch, num_rois, 1]",not
Mask_RCNN/mrcnn/model.py,279,"Box deltas [batch, num_rois, 4]",not
Mask_RCNN/mrcnn/model.py,282,Anchors,not
Mask_RCNN/mrcnn/model.py,285,Improve performance by trimming to top anchors by score,not
Mask_RCNN/mrcnn/model.py,286,and doing the rest on the smaller subset.,not
Mask_RCNN/mrcnn/model.py,298,Apply deltas to anchors to get refined anchors.,not
Mask_RCNN/mrcnn/model.py,299,"[batch, N, (y1, x1, y2, x2)]",not
Mask_RCNN/mrcnn/model.py,305,"Clip to image boundaries. Since we're in normalized coordinates,",not
Mask_RCNN/mrcnn/model.py,306,"clip to 0..1 range. [batch, N, (y1, x1, y2, x2)]",not
Mask_RCNN/mrcnn/model.py,313,Filter out small boxes,not
Mask_RCNN/mrcnn/model.py,314,"According to Xinlei Chen's paper, this reduces detection accuracy",not
Mask_RCNN/mrcnn/model.py,315,"for small objects, so we're skipping it.",not
Mask_RCNN/mrcnn/model.py,317,Non-max suppression,not
Mask_RCNN/mrcnn/model.py,323,Pad if needed,not
Mask_RCNN/mrcnn/model.py,335,,not
Mask_RCNN/mrcnn/model.py,336,ROIAlign Layer,not
Mask_RCNN/mrcnn/model.py,337,,not
Mask_RCNN/mrcnn/model.py,369,"Crop boxes [batch, num_boxes, (y1, x1, y2, x2)] in normalized coords",not
Mask_RCNN/mrcnn/model.py,372,Image meta,not
Mask_RCNN/mrcnn/model.py,373,Holds details about the image. See compose_image_meta(),not
Mask_RCNN/mrcnn/model.py,376,Feature Maps. List of feature maps from different level of the,not
Mask_RCNN/mrcnn/model.py,377,"feature pyramid. Each is [batch, height, width, channels]",not
Mask_RCNN/mrcnn/model.py,380,Assign each ROI to a level in the pyramid based on the ROI area.,not
Mask_RCNN/mrcnn/model.py,384,Use shape of first image. Images in a batch must have the same size.,not
Mask_RCNN/mrcnn/model.py,386,Equation 1 in the Feature Pyramid Networks paper. Account for,not
Mask_RCNN/mrcnn/model.py,387,the fact that our coordinates are normalized here.,not
Mask_RCNN/mrcnn/model.py,388,e.g. a 224x224 ROI (in pixels) maps to P4,not
Mask_RCNN/mrcnn/model.py,395,Loop through levels and apply ROI pooling to each. P2 to P5.,not
Mask_RCNN/mrcnn/model.py,402,Box indices for crop_and_resize.,not
Mask_RCNN/mrcnn/model.py,405,Keep track of which box is mapped to which level,not
Mask_RCNN/mrcnn/model.py,408,Stop gradient propogation to ROI proposals,not
Mask_RCNN/mrcnn/model.py,412,Crop and Resize,not
Mask_RCNN/mrcnn/model.py,413,"From Mask R-CNN paper: ""We sample four regular locations, so",not
Mask_RCNN/mrcnn/model.py,414,"that we can evaluate either max or average pooling. In fact,",not
Mask_RCNN/mrcnn/model.py,415,interpolating only a single value at each bin center (without,not
Mask_RCNN/mrcnn/model.py,416,"pooling) is nearly as effective.""",not
Mask_RCNN/mrcnn/model.py,417,,not
Mask_RCNN/mrcnn/model.py,418,"Here we use the simplified approach of a single value per bin,",not
Mask_RCNN/mrcnn/model.py,419,which is how it's done in tf.crop_and_resize(),not
Mask_RCNN/mrcnn/model.py,420,"Result: [batch * num_boxes, pool_height, pool_width, channels]",not
Mask_RCNN/mrcnn/model.py,425,Pack pooled features into one tensor,not
Mask_RCNN/mrcnn/model.py,428,Pack box_to_level mapping into one array and add another,not
Mask_RCNN/mrcnn/model.py,429,column representing the order of pooled boxes,not
Mask_RCNN/mrcnn/model.py,435,Rearrange pooled features to match the order of the original boxes,not
Mask_RCNN/mrcnn/model.py,436,Sort box_to_level by batch then box index,not
Mask_RCNN/mrcnn/model.py,437,"TF doesn't have a way to sort by two columns, so merge them and sort.",not
Mask_RCNN/mrcnn/model.py,444,Re-add the batch dimension,not
Mask_RCNN/mrcnn/model.py,453,,not
Mask_RCNN/mrcnn/model.py,454,Detection Target Layer,not
Mask_RCNN/mrcnn/model.py,455,,not
Mask_RCNN/mrcnn/model.py,461,1. Tile boxes2 and repeat boxes1. This allows us to compare,not
Mask_RCNN/mrcnn/model.py,462,every boxes1 against every boxes2 without loops.,not
Mask_RCNN/mrcnn/model.py,463,TF doesn't have an equivalent to np.repeat() so simulate it,not
Mask_RCNN/mrcnn/model.py,464,using tf.tile() and tf.reshape.,not
Mask_RCNN/mrcnn/model.py,468,2. Compute intersections,not
Mask_RCNN/mrcnn/model.py,476,3. Compute unions,not
Mask_RCNN/mrcnn/model.py,480,"4. Compute IoU and reshape to [boxes1, boxes2]",not
Mask_RCNN/mrcnn/model.py,507,Assertions,not
Mask_RCNN/mrcnn/model.py,515,Remove zero padding,not
Mask_RCNN/mrcnn/model.py,523,Handle COCO crowds,not
Mask_RCNN/mrcnn/model.py,524,A crowd box in COCO is a bounding box around several instances. Exclude,not
Mask_RCNN/mrcnn/model.py,525,them from training. A crowd box is given a negative class ID.,not
Mask_RCNN/mrcnn/model.py,533,"Compute overlaps matrix [proposals, gt_boxes]",not
Mask_RCNN/mrcnn/model.py,536,"Compute overlaps with crowd boxes [proposals, crowd_boxes]",not
Mask_RCNN/mrcnn/model.py,541,Determine positive and negative ROIs,not
Mask_RCNN/mrcnn/model.py,543,1. Positive ROIs are those with >= 0.5 IoU with a GT box,not
Mask_RCNN/mrcnn/model.py,546,2. Negative ROIs are those with < 0.5 with every GT box. Skip crowds.,not
Mask_RCNN/mrcnn/model.py,549,Subsample ROIs. Aim for 33% positive,not
Mask_RCNN/mrcnn/model.py,550,Positive ROIs,not
Mask_RCNN/mrcnn/model.py,555,Negative ROIs. Add enough to maintain positive:negative ratio.,not
Mask_RCNN/mrcnn/model.py,559,Gather selected ROIs,not
Mask_RCNN/mrcnn/model.py,563,Assign positive ROIs to GT boxes.,not
Mask_RCNN/mrcnn/model.py,573,Compute bbox refinement for positive ROIs,not
Mask_RCNN/mrcnn/model.py,577,Assign positive ROIs to GT masks,not
Mask_RCNN/mrcnn/model.py,578,"Permute masks to [N, height, width, 1]",not
Mask_RCNN/mrcnn/model.py,580,Pick the right mask for each ROI,not
Mask_RCNN/mrcnn/model.py,583,Compute mask targets,not
Mask_RCNN/mrcnn/model.py,586,Transform ROI coordinates from normalized image space,not
Mask_RCNN/mrcnn/model.py,587,to normalized mini-mask space.,not
Mask_RCNN/mrcnn/model.py,601,Remove the extra dimension from masks.,not
Mask_RCNN/mrcnn/model.py,604,Threshold mask pixels at 0.5 to have GT masks be 0 or 1 to use with,not
Mask_RCNN/mrcnn/model.py,605,binary cross entropy loss.,not
Mask_RCNN/mrcnn/model.py,608,Append negative ROIs and pad bbox deltas and masks that,not
Mask_RCNN/mrcnn/model.py,609,are not used for negative ROIs with zeros.,not
Mask_RCNN/mrcnn/model.py,657,Slice the batch and run a graph for each slice,not
Mask_RCNN/mrcnn/model.py,658,TODO: Rename target_bbox to target_deltas for clarity,SATD
Mask_RCNN/mrcnn/model.py,669,rois,not
Mask_RCNN/mrcnn/model.py,670,class_ids,not
Mask_RCNN/mrcnn/model.py,671,deltas,not
Mask_RCNN/mrcnn/model.py,673,masks,not
Mask_RCNN/mrcnn/model.py,680,,not
Mask_RCNN/mrcnn/model.py,681,Detection Layer,not
Mask_RCNN/mrcnn/model.py,682,,not
Mask_RCNN/mrcnn/model.py,699,Class IDs per ROI,not
Mask_RCNN/mrcnn/model.py,701,Class probability of the top class of each ROI,not
Mask_RCNN/mrcnn/model.py,704,Class-specific bounding box deltas,not
Mask_RCNN/mrcnn/model.py,706,Apply bounding box deltas,not
Mask_RCNN/mrcnn/model.py,707,"Shape: [boxes, (y1, x1, y2, x2)] in normalized coordinates",not
Mask_RCNN/mrcnn/model.py,710,Clip boxes to image window,not
Mask_RCNN/mrcnn/model.py,713,TODO: Filter out boxes with zero area,SATD
Mask_RCNN/mrcnn/model.py,715,Filter out background boxes,not
Mask_RCNN/mrcnn/model.py,717,Filter out low confidence boxes,not
Mask_RCNN/mrcnn/model.py,724,Apply per-class NMS,not
Mask_RCNN/mrcnn/model.py,725,1. Prepare variables,not
Mask_RCNN/mrcnn/model.py,733,Indices of ROIs of the given class,not
Mask_RCNN/mrcnn/model.py,735,Apply NMS,not
Mask_RCNN/mrcnn/model.py,741,Map indices,not
Mask_RCNN/mrcnn/model.py,743,Pad with -1 so returned tensors have the same shape,not
Mask_RCNN/mrcnn/model.py,747,Set shape so map_fn() can infer result shape,not
Mask_RCNN/mrcnn/model.py,751,2. Map over class IDs,not
Mask_RCNN/mrcnn/model.py,754,"3. Merge results into one list, and remove -1 padding",not
Mask_RCNN/mrcnn/model.py,757,4. Compute intersection between keep and nms_keep,not
Mask_RCNN/mrcnn/model.py,761,Keep top detections,not
Mask_RCNN/mrcnn/model.py,768,"Arrange output as [N, (y1, x1, y2, x2, class_id, score)]",not
Mask_RCNN/mrcnn/model.py,769,Coordinates are normalized.,not
Mask_RCNN/mrcnn/model.py,776,Pad with zeros if detections < DETECTION_MAX_INSTANCES,not
Mask_RCNN/mrcnn/model.py,801,Get windows of images in normalized coordinates. Windows are the area,not
Mask_RCNN/mrcnn/model.py,802,in the image that excludes the padding.,not
Mask_RCNN/mrcnn/model.py,803,Use the shape of the first image in the batch to normalize the window,not
Mask_RCNN/mrcnn/model.py,804,because we know that all images get resized to the same size.,not
Mask_RCNN/mrcnn/model.py,809,Run detection refinement graph on each item in the batch,not
Mask_RCNN/mrcnn/model.py,815,Reshape output,not
Mask_RCNN/mrcnn/model.py,816,"[batch, num_detections, (y1, x1, y2, x2, class_id, class_score)] in",not
Mask_RCNN/mrcnn/model.py,817,normalized coordinates,not
Mask_RCNN/mrcnn/model.py,826,,not
Mask_RCNN/mrcnn/model.py,827,Region Proposal Network (RPN),not
Mask_RCNN/mrcnn/model.py,828,,not
Mask_RCNN/mrcnn/model.py,844,TODO: check if stride of 2 causes alignment issues if the feature map,SATD
Mask_RCNN/mrcnn/model.py,845,is not even.,not
Mask_RCNN/mrcnn/model.py,846,Shared convolutional base of the RPN,not
Mask_RCNN/mrcnn/model.py,851,"Anchor Score. [batch, height, width, anchors per location * 2].",not
Mask_RCNN/mrcnn/model.py,855,"Reshape to [batch, anchors, 2]",not
Mask_RCNN/mrcnn/model.py,859,Softmax on last dimension of BG/FG.,not
Mask_RCNN/mrcnn/model.py,863,"Bounding box refinement. [batch, H, W, anchors per location * depth]",not
Mask_RCNN/mrcnn/model.py,864,"where depth is [x, y, log(w), log(h)]",not
Mask_RCNN/mrcnn/model.py,868,"Reshape to [batch, anchors, 4]",not
Mask_RCNN/mrcnn/model.py,896,,not
Mask_RCNN/mrcnn/model.py,897,Feature Pyramid Network Heads,not
Mask_RCNN/mrcnn/model.py,898,,not
Mask_RCNN/mrcnn/model.py,922,ROI Pooling,not
Mask_RCNN/mrcnn/model.py,923,"Shape: [batch, num_rois, POOL_SIZE, POOL_SIZE, channels]",not
Mask_RCNN/mrcnn/model.py,926,Two 1024 FC layers (implemented with Conv2D for consistency),not
Mask_RCNN/mrcnn/model.py,939,Classifier head,not
Mask_RCNN/mrcnn/model.py,945,BBox head,not
Mask_RCNN/mrcnn/model.py,946,"[batch, num_rois, NUM_CLASSES * (dy, dx, log(dh), log(dw))]",not
Mask_RCNN/mrcnn/model.py,949,"Reshape to [batch, num_rois, NUM_CLASSES, (dy, dx, log(dh), log(dw))]",not
Mask_RCNN/mrcnn/model.py,971,ROI Pooling,not
Mask_RCNN/mrcnn/model.py,972,"Shape: [batch, num_rois, MASK_POOL_SIZE, MASK_POOL_SIZE, channels]",not
Mask_RCNN/mrcnn/model.py,976,Conv layers,not
Mask_RCNN/mrcnn/model.py,1008,,not
Mask_RCNN/mrcnn/model.py,1009,Loss Functions,not
Mask_RCNN/mrcnn/model.py,1010,,not
Mask_RCNN/mrcnn/model.py,1029,Squeeze last dim to simplify,not
Mask_RCNN/mrcnn/model.py,1031,Get anchor classes. Convert the -1/+1 match to 0/1 values.,not
Mask_RCNN/mrcnn/model.py,1033,"Positive and Negative anchors contribute to the loss,",not
Mask_RCNN/mrcnn/model.py,1034,but neutral anchors (match value = 0) don't.,not
Mask_RCNN/mrcnn/model.py,1036,Pick rows that contribute to the loss and filter out the rest.,not
Mask_RCNN/mrcnn/model.py,1039,Cross entropy loss,not
Mask_RCNN/mrcnn/model.py,1057,"Positive anchors contribute to the loss, but negative and",not
Mask_RCNN/mrcnn/model.py,1058,neutral anchors (match value of 0 or -1) don't.,not
Mask_RCNN/mrcnn/model.py,1062,Pick bbox deltas that contribute to the loss,not
Mask_RCNN/mrcnn/model.py,1065,Trim target bounding box deltas to the same length as rpn_bbox.,not
Mask_RCNN/mrcnn/model.py,1087,"During model building, Keras calls this function with",not
Mask_RCNN/mrcnn/model.py,1088,target_class_ids of type float32. Unclear why. Cast it,not
Mask_RCNN/mrcnn/model.py,1089,to int to get around it.,not
Mask_RCNN/mrcnn/model.py,1092,Find predictions of classes that are not in the dataset.,not
Mask_RCNN/mrcnn/model.py,1094,TODO: Update this line to work with batch > 1. Right now it assumes all,SATD
Mask_RCNN/mrcnn/model.py,1095,images in a batch have the same active_class_ids,not
Mask_RCNN/mrcnn/model.py,1098,Loss,not
Mask_RCNN/mrcnn/model.py,1102,Erase losses of predictions of classes that are not in the active,not
Mask_RCNN/mrcnn/model.py,1103,classes of the image.,not
Mask_RCNN/mrcnn/model.py,1106,Computer loss mean. Use only predictions that contribute,not
Mask_RCNN/mrcnn/model.py,1107,to the loss to get a correct mean.,not
Mask_RCNN/mrcnn/model.py,1119,Reshape to merge batch and roi dimensions for simplicity.,not
Mask_RCNN/mrcnn/model.py,1124,Only positive ROIs contribute to the loss. And only,not
Mask_RCNN/mrcnn/model.py,1125,the right class_id of each ROI. Get their indices.,not
Mask_RCNN/mrcnn/model.py,1131,Gather the deltas (predicted and true) that contribute to loss,not
Mask_RCNN/mrcnn/model.py,1135,Smooth-L1 Loss,not
Mask_RCNN/mrcnn/model.py,1152,Reshape for simplicity. Merge first two dimensions into one.,not
Mask_RCNN/mrcnn/model.py,1159,"Permute predicted masks to [N, num_classes, height, width]",not
Mask_RCNN/mrcnn/model.py,1162,Only positive ROIs contribute to the loss. And only,not
Mask_RCNN/mrcnn/model.py,1163,the class specific mask of each ROI.,not
Mask_RCNN/mrcnn/model.py,1169,Gather the masks (predicted and true) that contribute to loss,not
Mask_RCNN/mrcnn/model.py,1173,"Compute binary cross entropy. If no positive ROIs, then return 0.",not
Mask_RCNN/mrcnn/model.py,1174,"shape: [batch, roi, num_classes]",not
Mask_RCNN/mrcnn/model.py,1182,,not
Mask_RCNN/mrcnn/model.py,1183,Data Generator,not
Mask_RCNN/mrcnn/model.py,1184,,not
Mask_RCNN/mrcnn/model.py,1210,Load image and mask,not
Mask_RCNN/mrcnn/model.py,1222,Random horizontal flips.,not
Mask_RCNN/mrcnn/model.py,1223,TODO: will be removed in a future update in favor of augmentation,SATD
Mask_RCNN/mrcnn/model.py,1230,Augmentation,not
Mask_RCNN/mrcnn/model.py,1231,This requires the imgaug lib (https://github.com/aleju/imgaug),not
Mask_RCNN/mrcnn/model.py,1235,Augmenters that are safe to apply to masks,not
Mask_RCNN/mrcnn/model.py,1236,"Some, such as Affine, have settings that make them unsafe, so always",not
Mask_RCNN/mrcnn/model.py,1237,test your augmentation on masks,not
Mask_RCNN/mrcnn/model.py,1246,Store shapes before augmentation to compare,not
Mask_RCNN/mrcnn/model.py,1249,Make augmenters deterministic to apply similarly to images and masks,not
Mask_RCNN/mrcnn/model.py,1252,Change mask to np.uint8 because imgaug doesn't support np.bool,not
Mask_RCNN/mrcnn/model.py,1255,Verify that shapes didn't change,not
Mask_RCNN/mrcnn/model.py,1258,Change mask back to bool,not
Mask_RCNN/mrcnn/model.py,1261,Note that some boxes might be all zeros if the corresponding mask got cropped out.,not
Mask_RCNN/mrcnn/model.py,1262,and here is to filter them out,not
Mask_RCNN/mrcnn/model.py,1266,Bounding boxes. Note that some boxes might be all zeros,not
Mask_RCNN/mrcnn/model.py,1267,if the corresponding mask got cropped out.,not
Mask_RCNN/mrcnn/model.py,1268,"bbox: [num_instances, (y1, x1, y2, x2)]",not
Mask_RCNN/mrcnn/model.py,1271,Active classes,not
Mask_RCNN/mrcnn/model.py,1272,"Different datasets have different classes, so track the",not
Mask_RCNN/mrcnn/model.py,1273,classes supported in the dataset of this image.,not
Mask_RCNN/mrcnn/model.py,1278,Resize masks to smaller size to reduce memory usage,not
Mask_RCNN/mrcnn/model.py,1282,Image meta data,not
Mask_RCNN/mrcnn/model.py,1317,It's common to add GT Boxes to ROIs but we don't do that here because,not
Mask_RCNN/mrcnn/model.py,1318,"according to XinLei Chen's paper, it doesn't help.",not
Mask_RCNN/mrcnn/model.py,1320,Trim empty padding in gt_boxes and gt_masks parts,not
Mask_RCNN/mrcnn/model.py,1327,Compute areas of ROIs and ground truth boxes.,not
Mask_RCNN/mrcnn/model.py,1333,"Compute overlaps [rpn_rois, gt_boxes]",not
Mask_RCNN/mrcnn/model.py,1340,Assign ROIs to GT boxes,not
Mask_RCNN/mrcnn/model.py,1344,GT box assigned to each ROI,not
Mask_RCNN/mrcnn/model.py,1348,Positive ROIs are those with >= 0.5 IoU with a GT box.,not
Mask_RCNN/mrcnn/model.py,1351,Negative ROIs are those with max IoU 0.1-0.5 (hard example mining),not
Mask_RCNN/mrcnn/model.py,1352,"TODO: To hard example mine or not to hard example mine, that's the question",SATD
Mask_RCNN/mrcnn/model.py,1353,bg_ids = np.where((rpn_roi_iou_max >= 0.1) & (rpn_roi_iou_max < 0.5))[0],not
Mask_RCNN/mrcnn/model.py,1356,Subsample ROIs. Aim for 33% foreground.,not
Mask_RCNN/mrcnn/model.py,1357,FG,not
Mask_RCNN/mrcnn/model.py,1363,BG,not
Mask_RCNN/mrcnn/model.py,1369,Combine indices of ROIs to keep,not
Mask_RCNN/mrcnn/model.py,1371,Need more?,not
Mask_RCNN/mrcnn/model.py,1374,Looks like we don't have enough samples to maintain the desired,not
Mask_RCNN/mrcnn/model.py,1375,balance. Reduce requirements and fill in the rest. This is,not
Mask_RCNN/mrcnn/model.py,1376,likely different from the Mask RCNN paper.,not
Mask_RCNN/mrcnn/model.py,1378,There is a small chance we have neither fg nor bg samples.,not
Mask_RCNN/mrcnn/model.py,1380,Pick bg regions with easier IoU threshold,not
Mask_RCNN/mrcnn/model.py,1387,Fill the rest with repeated bg rois.,not
Mask_RCNN/mrcnn/model.py,1395,Reset the gt boxes assigned to BG ROIs.,not
Mask_RCNN/mrcnn/model.py,1399,"For each kept ROI, assign a class_id, and for FG ROIs also add bbox refinement.",not
Mask_RCNN/mrcnn/model.py,1405,"Class-aware bbox deltas. [y, x, log(h), log(w)]",not
Mask_RCNN/mrcnn/model.py,1411,Normalize bbox refinements,not
Mask_RCNN/mrcnn/model.py,1414,Generate class-specific target masks,not
Mask_RCNN/mrcnn/model.py,1424,"Create a mask placeholder, the size of the image",not
Mask_RCNN/mrcnn/model.py,1426,GT box,not
Mask_RCNN/mrcnn/model.py,1430,Resize mini mask to size of GT box,not
Mask_RCNN/mrcnn/model.py,1433,Place the mini batch in the placeholder,not
Mask_RCNN/mrcnn/model.py,1436,Pick part of the mask and resize it,not
Mask_RCNN/mrcnn/model.py,1458,"RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral",not
Mask_RCNN/mrcnn/model.py,1460,"RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))]",not
Mask_RCNN/mrcnn/model.py,1463,Handle COCO crowds,not
Mask_RCNN/mrcnn/model.py,1464,A crowd box in COCO is a bounding box around several instances. Exclude,not
Mask_RCNN/mrcnn/model.py,1465,them from training. A crowd box is given a negative class ID.,not
Mask_RCNN/mrcnn/model.py,1468,Filter out crowds from ground truth class IDs and boxes,not
Mask_RCNN/mrcnn/model.py,1473,"Compute overlaps with crowd boxes [anchors, crowds]",not
Mask_RCNN/mrcnn/model.py,1478,All anchors don't intersect a crowd,not
Mask_RCNN/mrcnn/model.py,1481,"Compute overlaps [num_anchors, num_gt_boxes]",not
Mask_RCNN/mrcnn/model.py,1484,Match anchors to GT Boxes,not
Mask_RCNN/mrcnn/model.py,1485,If an anchor overlaps a GT box with IoU >= 0.7 then it's positive.,not
Mask_RCNN/mrcnn/model.py,1486,If an anchor overlaps a GT box with IoU < 0.3 then it's negative.,not
Mask_RCNN/mrcnn/model.py,1487,"Neutral anchors are those that don't match the conditions above,",not
Mask_RCNN/mrcnn/model.py,1488,and they don't influence the loss function.,not
Mask_RCNN/mrcnn/model.py,1489,"However, don't keep any GT box unmatched (rare, but happens). Instead,",not
Mask_RCNN/mrcnn/model.py,1490,match it to the closest anchor (even if its max IoU is < 0.3).,not
Mask_RCNN/mrcnn/model.py,1491,,not
Mask_RCNN/mrcnn/model.py,1492,1. Set negative anchors first. They get overwritten below if a GT box is,not
Mask_RCNN/mrcnn/model.py,1493,matched to them. Skip boxes in crowd areas.,not
Mask_RCNN/mrcnn/model.py,1497,2. Set an anchor for each GT box (regardless of IoU value).,not
Mask_RCNN/mrcnn/model.py,1498,If multiple anchors have the same IoU match all of them,not
Mask_RCNN/mrcnn/model.py,1501,3. Set anchors with high overlap as positive.,not
Mask_RCNN/mrcnn/model.py,1504,Subsample to balance positive and negative anchors,not
Mask_RCNN/mrcnn/model.py,1505,Don't let positives be more than half the anchors,not
Mask_RCNN/mrcnn/model.py,1509,Reset the extra ones to neutral,not
Mask_RCNN/mrcnn/model.py,1512,Same for negative proposals,not
Mask_RCNN/mrcnn/model.py,1517,Rest the extra ones to neutral,not
Mask_RCNN/mrcnn/model.py,1521,"For positive anchors, compute shift and scale needed to transform them",not
Mask_RCNN/mrcnn/model.py,1522,to match the corresponding GT boxes.,not
Mask_RCNN/mrcnn/model.py,1524,index into rpn_bbox,not
Mask_RCNN/mrcnn/model.py,1525,TODO: use box_refinement() rather than duplicating the code here,SATD
Mask_RCNN/mrcnn/model.py,1527,Closest gt box (it might have IoU < 0.7),not
Mask_RCNN/mrcnn/model.py,1530,Convert coordinates to center plus width/height.,not
Mask_RCNN/mrcnn/model.py,1531,GT Box,not
Mask_RCNN/mrcnn/model.py,1536,Anchor,not
Mask_RCNN/mrcnn/model.py,1542,Compute the bbox refinement that the RPN should predict.,not
Mask_RCNN/mrcnn/model.py,1549,Normalize,not
Mask_RCNN/mrcnn/model.py,1567,placeholder,not
Mask_RCNN/mrcnn/model.py,1570,Generate random ROIs around GT boxes (90% of count),not
Mask_RCNN/mrcnn/model.py,1576,random boundaries,not
Mask_RCNN/mrcnn/model.py,1582,"To avoid generating boxes with zero area, we generate double what",not
Mask_RCNN/mrcnn/model.py,1583,we need and filter out the extra. If we get fewer valid boxes,not
Mask_RCNN/mrcnn/model.py,1584,"than we need, we loop and try again.",not
Mask_RCNN/mrcnn/model.py,1588,Filter out zero area boxes,not
Mask_RCNN/mrcnn/model.py,1597,Sort on axis 1 to ensure x1 <= x2 and y1 <= y2 and then reshape,not
Mask_RCNN/mrcnn/model.py,1598,"into x1, y1, x2, y2 order",not
Mask_RCNN/mrcnn/model.py,1604,Generate random ROIs anywhere in the image (10% of count),not
Mask_RCNN/mrcnn/model.py,1606,"To avoid generating boxes with zero area, we generate double what",not
Mask_RCNN/mrcnn/model.py,1607,we need and filter out the extra. If we get fewer valid boxes,not
Mask_RCNN/mrcnn/model.py,1608,"than we need, we loop and try again.",not
Mask_RCNN/mrcnn/model.py,1612,Filter out zero area boxes,not
Mask_RCNN/mrcnn/model.py,1621,Sort on axis 1 to ensure x1 <= x2 and y1 <= y2 and then reshape,not
Mask_RCNN/mrcnn/model.py,1622,"into x1, y1, x2, y2 order",not
Mask_RCNN/mrcnn/model.py,1673,batch item index,not
Mask_RCNN/mrcnn/model.py,1679,Anchors,not
Mask_RCNN/mrcnn/model.py,1680,"[anchor_count, (y1, x1, y2, x2)]",not
Mask_RCNN/mrcnn/model.py,1688,Keras requires a generator to run indefinitely.,not
Mask_RCNN/mrcnn/model.py,1691,Increment index to pick next image. Shuffle if at the start of an epoch.,not
Mask_RCNN/mrcnn/model.py,1696,Get GT bounding boxes and masks for image.,not
Mask_RCNN/mrcnn/model.py,1699,If the image source is not to be augmented pass None as augmentation,not
Mask_RCNN/mrcnn/model.py,1711,Skip images that have no instances. This can happen in cases,not
Mask_RCNN/mrcnn/model.py,1712,where we train on a subset of classes and the image doesn't,not
Mask_RCNN/mrcnn/model.py,1713,have any of the classes we care about.,not
Mask_RCNN/mrcnn/model.py,1717,RPN Targets,not
Mask_RCNN/mrcnn/model.py,1721,Mask R-CNN Targets,not
Mask_RCNN/mrcnn/model.py,1730,Init batch arrays,not
Mask_RCNN/mrcnn/model.py,1760,"If more instances than fits in the array, sub-sample from them.",not
Mask_RCNN/mrcnn/model.py,1768,Add to batch,not
Mask_RCNN/mrcnn/model.py,1785,Batch full?,not
Mask_RCNN/mrcnn/model.py,1795,Keras requires that output and targets have the same number of dimensions,not
Mask_RCNN/mrcnn/model.py,1803,start a new batch,not
Mask_RCNN/mrcnn/model.py,1808,Log it and skip the image,not
Mask_RCNN/mrcnn/model.py,1816,,not
Mask_RCNN/mrcnn/model.py,1817,MaskRCNN Class,not
Mask_RCNN/mrcnn/model.py,1818,,not
Mask_RCNN/mrcnn/model.py,1847,Image size must be dividable by 2 multiple times,not
Mask_RCNN/mrcnn/model.py,1854,Inputs,not
Mask_RCNN/mrcnn/model.py,1860,RPN GT,not
Mask_RCNN/mrcnn/model.py,1866,"Detection GT (class IDs, bounding boxes, and masks)",not
Mask_RCNN/mrcnn/model.py,1867,1. GT Class IDs (zero padded),not
Mask_RCNN/mrcnn/model.py,1870,2. GT Boxes in pixels (zero padded),not
Mask_RCNN/mrcnn/model.py,1871,"[batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)] in image coordinates",not
Mask_RCNN/mrcnn/model.py,1874,Normalize coordinates,not
Mask_RCNN/mrcnn/model.py,1877,3. GT Masks (zero padded),not
Mask_RCNN/mrcnn/model.py,1878,"[batch, height, width, MAX_GT_INSTANCES]",not
Mask_RCNN/mrcnn/model.py,1889,Anchors in normalized coordinates,not
Mask_RCNN/mrcnn/model.py,1892,Build the shared convolutional layers.,not
Mask_RCNN/mrcnn/model.py,1893,Bottom-up Layers,not
Mask_RCNN/mrcnn/model.py,1894,"Returns a list of the last layers of each stage, 5 in total.",not
Mask_RCNN/mrcnn/model.py,1895,"Don't create the thead (stage 5), so we pick the 4th item in the list.",not
Mask_RCNN/mrcnn/model.py,1902,Top-down Layers,not
Mask_RCNN/mrcnn/model.py,1903,TODO: add assert to varify feature map sizes match what's in config,SATD
Mask_RCNN/mrcnn/model.py,1914,Attach 3x3 conv to all P layers to get the final feature maps.,not
Mask_RCNN/mrcnn/model.py,1919,P6 is used for the 5th anchor scale in RPN. Generated by,not
Mask_RCNN/mrcnn/model.py,1920,subsampling from P5 with stride of 2.,not
Mask_RCNN/mrcnn/model.py,1923,"Note that P6 is used in RPN, but not in the classifier heads.",not
Mask_RCNN/mrcnn/model.py,1927,Anchors,not
Mask_RCNN/mrcnn/model.py,1930,Duplicate across the batch dimension because Keras requires it,not
Mask_RCNN/mrcnn/model.py,1931,TODO: can this be optimized to avoid duplicating the anchors?,SATD
Mask_RCNN/mrcnn/model.py,1933,A hack to get around Keras's bad support for constants,SATD
Mask_RCNN/mrcnn/model.py,1938,RPN Model,not
Mask_RCNN/mrcnn/model.py,1941,Loop through pyramid layers,not
Mask_RCNN/mrcnn/model.py,1942,list of lists,not
Mask_RCNN/mrcnn/model.py,1945,Concatenate layer outputs,not
Mask_RCNN/mrcnn/model.py,1946,Convert from list of lists of level outputs to list of lists,not
Mask_RCNN/mrcnn/model.py,1947,of outputs across levels.,not
Mask_RCNN/mrcnn/model.py,1948,"e.g. [[a1, b1, c1], [a2, b2, c2]] => [[a1, a2], [b1, b2], [c1, c2]]",not
Mask_RCNN/mrcnn/model.py,1956,Generate proposals,not
Mask_RCNN/mrcnn/model.py,1957,"Proposals are [batch, N, (y1, x1, y2, x2)] in normalized coordinates",not
Mask_RCNN/mrcnn/model.py,1958,and zero padded.,not
Mask_RCNN/mrcnn/model.py,1968,Class ID mask to mark class IDs supported by the dataset the image,not
Mask_RCNN/mrcnn/model.py,1969,came from.,not
Mask_RCNN/mrcnn/model.py,1975,Ignore predicted ROIs and use ROIs provided as an input.,not
Mask_RCNN/mrcnn/model.py,1978,Normalize coordinates,not
Mask_RCNN/mrcnn/model.py,1984,Generate detection targets,not
Mask_RCNN/mrcnn/model.py,1985,Subsamples proposals and generates target outputs for training,not
Mask_RCNN/mrcnn/model.py,1986,"Note that proposal class IDs, gt_boxes, and gt_masks are zero",not
Mask_RCNN/mrcnn/model.py,1987,"padded. Equally, returned rois and targets are zero padded.",not
Mask_RCNN/mrcnn/model.py,1992,Network Heads,not
Mask_RCNN/mrcnn/model.py,1993,TODO: verify that this handles zero padded ROIs,SATD
Mask_RCNN/mrcnn/model.py,2006,TODO: clean up (use tf.identify if necessary),SATD
Mask_RCNN/mrcnn/model.py,2009,Losses,not
Mask_RCNN/mrcnn/model.py,2021,Model,not
Mask_RCNN/mrcnn/model.py,2032,Network Heads,not
Mask_RCNN/mrcnn/model.py,2033,Proposal classifier and BBox regressor heads,not
Mask_RCNN/mrcnn/model.py,2040,Detections,not
Mask_RCNN/mrcnn/model.py,2041,"output is [batch, num_detections, (y1, x1, y2, x2, class_id, score)] in",not
Mask_RCNN/mrcnn/model.py,2042,normalized coordinates,not
Mask_RCNN/mrcnn/model.py,2046,Create masks for detections,not
Mask_RCNN/mrcnn/model.py,2059,Add multi-GPU support.,not
Mask_RCNN/mrcnn/model.py,2072,Get directory names. Each directory corresponds to a model,not
Mask_RCNN/mrcnn/model.py,2082,Pick last directory,not
Mask_RCNN/mrcnn/model.py,2084,Find the last checkpoint,not
Mask_RCNN/mrcnn/model.py,2102,Conditional import to support versions of Keras before 2.2,not
Mask_RCNN/mrcnn/model.py,2103,TODO: remove in about 6 months (end of 2018),SATD
Mask_RCNN/mrcnn/model.py,2107,Keras before 2.2 used the 'topology' namespace.,not
Mask_RCNN/mrcnn/model.py,2119,"In multi-GPU training, we wrap the model. Get layers",not
Mask_RCNN/mrcnn/model.py,2120,of the inner model because they have the weights.,not
Mask_RCNN/mrcnn/model.py,2125,Exclude some layers,not
Mask_RCNN/mrcnn/model.py,2136,Update the log directory,not
Mask_RCNN/mrcnn/model.py,2157,Optimizer object,not
Mask_RCNN/mrcnn/model.py,2161,Add Losses,not
Mask_RCNN/mrcnn/model.py,2162,"First, clear previously set losses to avoid duplication",not
Mask_RCNN/mrcnn/model.py,2177,Add L2 Regularization,not
Mask_RCNN/mrcnn/model.py,2178,Skip gamma and beta weights of batch normalization layers.,not
Mask_RCNN/mrcnn/model.py,2185,Compile,not
Mask_RCNN/mrcnn/model.py,2190,Add metrics for losses,not
Mask_RCNN/mrcnn/model.py,2205,Print message on the first call (but not on recursive calls),not
Mask_RCNN/mrcnn/model.py,2211,"In multi-GPU training, we wrap the model. Get layers",not
Mask_RCNN/mrcnn/model.py,2212,of the inner model because they have the weights.,not
Mask_RCNN/mrcnn/model.py,2217,Is the layer a model?,not
Mask_RCNN/mrcnn/model.py,2226,Is it trainable?,not
Mask_RCNN/mrcnn/model.py,2228,"Update layer. If layer is a container, update inner layer.",not
Mask_RCNN/mrcnn/model.py,2233,Print trainable layer names,not
Mask_RCNN/mrcnn/model.py,2246,Set date and epoch counter as if starting a new model,not
Mask_RCNN/mrcnn/model.py,2250,If we have a model path with date and epochs use them,not
Mask_RCNN/mrcnn/model.py,2252,Continue from we left of. Get epoch and date from the file name,not
Mask_RCNN/mrcnn/model.py,2253,A sample model path might look like:,not
Mask_RCNN/mrcnn/model.py,2254,\path\to\logs\coco20171029T2315\mask_rcnn_coco_0001.h5 (Windows),not
Mask_RCNN/mrcnn/model.py,2255,/path/to/logs/coco20171029T2315/mask_rcnn_coco_0001.h5 (Linux),not
Mask_RCNN/mrcnn/model.py,2261,"Epoch number in file is 1-based, and in Keras code it's 0-based.",not
Mask_RCNN/mrcnn/model.py,2262,"So, adjust for that then increment by one to start from the next epoch",not
Mask_RCNN/mrcnn/model.py,2266,Directory for training logs,not
Mask_RCNN/mrcnn/model.py,2270,Path to save after each epoch. Include placeholders that get filled by Keras.,not
Mask_RCNN/mrcnn/model.py,2312,Pre-defined layer regular expressions,not
Mask_RCNN/mrcnn/model.py,2314,all layers but the backbone,not
Mask_RCNN/mrcnn/model.py,2316,From a specific Resnet stage and up,not
Mask_RCNN/mrcnn/model.py,2320,All layers,not
Mask_RCNN/mrcnn/model.py,2326,Data generators,not
Mask_RCNN/mrcnn/model.py,2334,Create log_dir if it does not exist,not
Mask_RCNN/mrcnn/model.py,2338,Callbacks,not
Mask_RCNN/mrcnn/model.py,2346,Add custom callbacks to the list,not
Mask_RCNN/mrcnn/model.py,2350,Train,not
Mask_RCNN/mrcnn/model.py,2356,Work-around for Windows: Keras fails on Windows when using,SATD
Mask_RCNN/mrcnn/model.py,2357,multiprocessing workers. See discussion here:,not
Mask_RCNN/mrcnn/model.py,2358,https://github.com/matterport/Mask_RCNN/issues/13#issuecomment-353124009,not
Mask_RCNN/mrcnn/model.py,2394,Resize image,not
Mask_RCNN/mrcnn/model.py,2395,TODO: move resizing to mold_image(),SATD
Mask_RCNN/mrcnn/model.py,2403,Build image_meta,not
Mask_RCNN/mrcnn/model.py,2407,Append,not
Mask_RCNN/mrcnn/model.py,2411,Pack into arrays,not
Mask_RCNN/mrcnn/model.py,2436,How many detections do we have?,not
Mask_RCNN/mrcnn/model.py,2437,Detections array is padded with zeros. Find the first class_id == 0.,not
Mask_RCNN/mrcnn/model.py,2441,"Extract boxes, class_ids, scores, and class-specific masks",not
Mask_RCNN/mrcnn/model.py,2447,Translate normalized coordinates in the resized image to pixel,not
Mask_RCNN/mrcnn/model.py,2448,coordinates in the original image before resizing,not
Mask_RCNN/mrcnn/model.py,2452,window height,not
Mask_RCNN/mrcnn/model.py,2453,window width,not
Mask_RCNN/mrcnn/model.py,2455,Convert boxes to normalized coordinates on the window,not
Mask_RCNN/mrcnn/model.py,2457,Convert boxes to pixel coordinates on the original image,not
Mask_RCNN/mrcnn/model.py,2460,Filter out detections with zero area. Happens in early training when,not
Mask_RCNN/mrcnn/model.py,2461,network weights are still random,not
Mask_RCNN/mrcnn/model.py,2471,Resize masks to original image size and set boundary threshold.,not
Mask_RCNN/mrcnn/model.py,2474,Convert neural network mask to full size mask,not
Mask_RCNN/mrcnn/model.py,2502,Mold inputs to format expected by the neural network,not
Mask_RCNN/mrcnn/model.py,2505,Validate image sizes,not
Mask_RCNN/mrcnn/model.py,2506,All images in a batch MUST be of the same size,not
Mask_RCNN/mrcnn/model.py,2512,Anchors,not
Mask_RCNN/mrcnn/model.py,2514,Duplicate across the batch dimension because Keras requires it,not
Mask_RCNN/mrcnn/model.py,2515,TODO: can this be optimized to avoid duplicating the anchors?,SATD
Mask_RCNN/mrcnn/model.py,2522,Run object detection,not
Mask_RCNN/mrcnn/model.py,2525,Process detections,not
Mask_RCNN/mrcnn/model.py,2563,Validate image sizes,not
Mask_RCNN/mrcnn/model.py,2564,All images in a batch MUST be of the same size,not
Mask_RCNN/mrcnn/model.py,2569,Anchors,not
Mask_RCNN/mrcnn/model.py,2571,Duplicate across the batch dimension because Keras requires it,not
Mask_RCNN/mrcnn/model.py,2572,TODO: can this be optimized to avoid duplicating the anchors?,SATD
Mask_RCNN/mrcnn/model.py,2579,Run object detection,not
Mask_RCNN/mrcnn/model.py,2582,Process detections,not
Mask_RCNN/mrcnn/model.py,2601,Cache anchors and reuse if image shape is the same,not
Mask_RCNN/mrcnn/model.py,2605,Generate Anchors,not
Mask_RCNN/mrcnn/model.py,2612,Keep a copy of the latest anchors in pixel coordinates because,not
Mask_RCNN/mrcnn/model.py,2613,it's used in inspect_model notebooks.,not
Mask_RCNN/mrcnn/model.py,2614,TODO: Remove this after the notebook are refactored to not use it,SATD
Mask_RCNN/mrcnn/model.py,2616,Normalize coordinates,not
Mask_RCNN/mrcnn/model.py,2628,Put a limit on how deep we go to avoid very long loops,not
Mask_RCNN/mrcnn/model.py,2631,Convert name to a regex and allow matching a number prefix,not
Mask_RCNN/mrcnn/model.py,2632,because Keras adds them automatically,not
Mask_RCNN/mrcnn/model.py,2660,Loop through all layers,not
Mask_RCNN/mrcnn/model.py,2662,"If layer is a wrapper, find inner trainable layer",not
Mask_RCNN/mrcnn/model.py,2664,Include layer if it has weights,not
Mask_RCNN/mrcnn/model.py,2684,Organize desired outputs into an ordered dict,not
Mask_RCNN/mrcnn/model.py,2689,Build a Keras function to run parts of the computation graph,not
Mask_RCNN/mrcnn/model.py,2695,Prepare inputs,not
Mask_RCNN/mrcnn/model.py,2701,Anchors,not
Mask_RCNN/mrcnn/model.py,2703,Duplicate across the batch dimension because Keras requires it,not
Mask_RCNN/mrcnn/model.py,2704,TODO: can this be optimized to avoid duplicating the anchors?,SATD
Mask_RCNN/mrcnn/model.py,2708,Run inference,not
Mask_RCNN/mrcnn/model.py,2713,Pack the generated Numpy arrays into a a dict and log the results.,not
Mask_RCNN/mrcnn/model.py,2721,,not
Mask_RCNN/mrcnn/model.py,2722,Data Formatting,not
Mask_RCNN/mrcnn/model.py,2723,,not
Mask_RCNN/mrcnn/model.py,2740,size=1,not
Mask_RCNN/mrcnn/model.py,2741,size=3,not
Mask_RCNN/mrcnn/model.py,2742,size=3,not
Mask_RCNN/mrcnn/model.py,2743,"size=4 (y1, x1, y2, x2) in image cooredinates",not
Mask_RCNN/mrcnn/model.py,2744,size=1,not
Mask_RCNN/mrcnn/model.py,2745,size=num_classes,not
Mask_RCNN/mrcnn/model.py,2761,"(y1, x1, y2, x2) window of image in in pixels",not
Mask_RCNN/mrcnn/model.py,2785,"(y1, x1, y2, x2) window of image in in pixels",not
Mask_RCNN/mrcnn/model.py,2811,,not
Mask_RCNN/mrcnn/model.py,2812,Miscellenous Graph Functions,not
Mask_RCNN/mrcnn/model.py,2813,,not
Mask_RCNN/mrcnn/utils.py,26,URL from which to download the latest COCO trained weights,not
Mask_RCNN/mrcnn/utils.py,30,,not
Mask_RCNN/mrcnn/utils.py,31,Bounding Boxes,not
Mask_RCNN/mrcnn/utils.py,32,,not
Mask_RCNN/mrcnn/utils.py,43,Bounding box.,not
Mask_RCNN/mrcnn/utils.py,49,x2 and y2 should not be part of the box. Increment by 1.,not
Mask_RCNN/mrcnn/utils.py,53,No mask for this instance. Might happen due to,not
Mask_RCNN/mrcnn/utils.py,54,resizing or cropping. Set bbox to zeros,not
Mask_RCNN/mrcnn/utils.py,70,Calculate intersection areas,not
Mask_RCNN/mrcnn/utils.py,87,Areas of anchors and GT boxes,not
Mask_RCNN/mrcnn/utils.py,91,"Compute overlaps to generate matrix [boxes1 count, boxes2 count]",not
Mask_RCNN/mrcnn/utils.py,92,Each cell contains the IoU value.,not
Mask_RCNN/mrcnn/utils.py,105,If either set of masks is empty return empty result,not
Mask_RCNN/mrcnn/utils.py,108,flatten masks and compute their areas,not
Mask_RCNN/mrcnn/utils.py,114,intersections and union,not
Mask_RCNN/mrcnn/utils.py,132,Compute box areas,not
Mask_RCNN/mrcnn/utils.py,139,Get indicies of boxes sorted by scores (highest first),not
Mask_RCNN/mrcnn/utils.py,144,Pick top box and add its index to the list,not
Mask_RCNN/mrcnn/utils.py,147,Compute IoU of the picked box with the rest,not
Mask_RCNN/mrcnn/utils.py,149,Identify boxes with IoU over the threshold. This,not
Mask_RCNN/mrcnn/utils.py,150,"returns indices into ixs[1:], so add 1 to get",not
Mask_RCNN/mrcnn/utils.py,151,indices into ixs.,not
Mask_RCNN/mrcnn/utils.py,153,Remove indices of the picked and overlapped boxes.,not
Mask_RCNN/mrcnn/utils.py,165,"Convert to y, x, h, w",not
Mask_RCNN/mrcnn/utils.py,170,Apply deltas,not
Mask_RCNN/mrcnn/utils.py,175,"Convert back to y1, x1, y2, x2",not
Mask_RCNN/mrcnn/utils.py,235,,not
Mask_RCNN/mrcnn/utils.py,236,Dataset,not
Mask_RCNN/mrcnn/utils.py,237,,not
Mask_RCNN/mrcnn/utils.py,258,Background is always the first class,not
Mask_RCNN/mrcnn/utils.py,264,Does the class exist already?,not
Mask_RCNN/mrcnn/utils.py,267,"source.class_id combination already available, skip",not
Mask_RCNN/mrcnn/utils.py,269,Add the class,not
Mask_RCNN/mrcnn/utils.py,305,Build (or rebuild) everything else from the info dicts.,not
Mask_RCNN/mrcnn/utils.py,312,Mapping from source class and image IDs to internal IDs,not
Mask_RCNN/mrcnn/utils.py,318,Map sources to class_ids they support,not
Mask_RCNN/mrcnn/utils.py,321,Loop over datasets,not
Mask_RCNN/mrcnn/utils.py,324,Find classes that belong to this dataset,not
Mask_RCNN/mrcnn/utils.py,326,Include BG class in all datasets,not
Mask_RCNN/mrcnn/utils.py,358,Load image,not
Mask_RCNN/mrcnn/utils.py,360,If grayscale. Convert to RGB for consistency.,not
Mask_RCNN/mrcnn/utils.py,363,"If has an alpha channel, remove it for consistency",not
Mask_RCNN/mrcnn/utils.py,380,Override this function to load a mask from your dataset.,not
Mask_RCNN/mrcnn/utils.py,381,"Otherwise, it returns an empty mask.",not
Mask_RCNN/mrcnn/utils.py,420,Keep track of image dtype and return results in the same dtype,not
Mask_RCNN/mrcnn/utils.py,422,"Default window (y1, x1, y2, x2) and default scale == 1.",not
Mask_RCNN/mrcnn/utils.py,432,Scale?,not
Mask_RCNN/mrcnn/utils.py,434,Scale up but not down,not
Mask_RCNN/mrcnn/utils.py,439,Does it exceed max dim?,not
Mask_RCNN/mrcnn/utils.py,445,Resize image using bilinear interpolation,not
Mask_RCNN/mrcnn/utils.py,450,Need padding or cropping?,not
Mask_RCNN/mrcnn/utils.py,452,Get new height and width,not
Mask_RCNN/mrcnn/utils.py,463,Both sides must be divisible by 64,not
Mask_RCNN/mrcnn/utils.py,465,Height,not
Mask_RCNN/mrcnn/utils.py,472,Width,not
Mask_RCNN/mrcnn/utils.py,483,Pick a random crop,not
Mask_RCNN/mrcnn/utils.py,504,"Suppress warning from scipy 0.13.0, the output shape of zoom() is",not
Mask_RCNN/mrcnn/utils.py,505,calculated with round() instead of int(),not
Mask_RCNN/mrcnn/utils.py,525,Pick slice and cast to bool in case load_mask() returned wrong dtype,not
Mask_RCNN/mrcnn/utils.py,531,Resize with bilinear interpolation,not
Mask_RCNN/mrcnn/utils.py,549,Resize with bilinear interpolation,not
Mask_RCNN/mrcnn/utils.py,555,TODO: Build and use this function to reduce code duplication,SATD
Mask_RCNN/mrcnn/utils.py,573,Put the mask in the right location.,not
Mask_RCNN/mrcnn/utils.py,579,,not
Mask_RCNN/mrcnn/utils.py,580,Anchors,not
Mask_RCNN/mrcnn/utils.py,581,,not
Mask_RCNN/mrcnn/utils.py,593,Get all combinations of scales and ratios,not
Mask_RCNN/mrcnn/utils.py,598,Enumerate heights and widths from scales and ratios,not
Mask_RCNN/mrcnn/utils.py,602,Enumerate shifts in feature space,not
Mask_RCNN/mrcnn/utils.py,607,"Enumerate combinations of shifts, widths, and heights",not
Mask_RCNN/mrcnn/utils.py,611,"Reshape to get a list of (y, x) and a list of (h, w)",not
Mask_RCNN/mrcnn/utils.py,616,"Convert to corner coordinates (y1, x1, y2, x2)",not
Mask_RCNN/mrcnn/utils.py,633,Anchors,not
Mask_RCNN/mrcnn/utils.py,634,"[anchor_count, (y1, x1, y2, x2)]",not
Mask_RCNN/mrcnn/utils.py,642,,not
Mask_RCNN/mrcnn/utils.py,643,Miscellaneous,not
Mask_RCNN/mrcnn/utils.py,644,,not
Mask_RCNN/mrcnn/utils.py,668,Trim zero padding,not
Mask_RCNN/mrcnn/utils.py,669,TODO: cleaner to do zero unpadding upstream,SATD
Mask_RCNN/mrcnn/utils.py,674,Sort predictions by score from high to low,not
Mask_RCNN/mrcnn/utils.py,681,"Compute IoU overlaps [pred_masks, gt_masks]",not
Mask_RCNN/mrcnn/utils.py,684,Loop through predictions and find matching ground truth boxes,not
Mask_RCNN/mrcnn/utils.py,689,Find best matching ground truth box,not
Mask_RCNN/mrcnn/utils.py,690,1. Sort matches by score,not
Mask_RCNN/mrcnn/utils.py,692,2. Remove low scores,not
Mask_RCNN/mrcnn/utils.py,696,3. Find the match,not
Mask_RCNN/mrcnn/utils.py,698,"If ground truth box is already matched, go to next one",not
Mask_RCNN/mrcnn/utils.py,701,"If we reach IoU smaller than the threshold, end the loop",not
Mask_RCNN/mrcnn/utils.py,705,Do we have a match?,not
Mask_RCNN/mrcnn/utils.py,726,Get matches and overlaps,not
Mask_RCNN/mrcnn/utils.py,732,Compute precision and recall at each prediction box step,not
Mask_RCNN/mrcnn/utils.py,736,Pad with start and end values to simplify the math,not
Mask_RCNN/mrcnn/utils.py,740,"Ensure precision values decrease but don't increase. This way, the",not
Mask_RCNN/mrcnn/utils.py,741,precision value at each recall threshold is the maximum it can be,not
Mask_RCNN/mrcnn/utils.py,742,"for all following recall thresholds, as specified by the VOC paper.",not
Mask_RCNN/mrcnn/utils.py,746,Compute mean AP over recall range,not
Mask_RCNN/mrcnn/utils.py,758,Default is 0.5 to 0.95 with increments of 0.05,not
Mask_RCNN/mrcnn/utils.py,761,Compute AP over range of IoU thresholds,not
Mask_RCNN/mrcnn/utils.py,785,Measure overlaps,not
Mask_RCNN/mrcnn/utils.py,796,## Batch Slicing,not
Mask_RCNN/mrcnn/utils.py,797,"Some custom layers support a batch size of 1 only, and require a lot of work",not
Mask_RCNN/mrcnn/utils.py,798,to support batches greater than 1. This function slices an input tensor,not
Mask_RCNN/mrcnn/utils.py,799,"across the batch dimension and feeds batches of size 1. Effectively,",not
Mask_RCNN/mrcnn/utils.py,800,an easy way to support batches > 1 quickly with little code modification.,not
Mask_RCNN/mrcnn/utils.py,801,"In the long run, it's more efficient to modify the code to support large",not
Mask_RCNN/mrcnn/utils.py,802,batches and getting rid of this function. Consider this a temporary solution,not
Mask_RCNN/mrcnn/utils.py,824,Change outputs from a list of slices where each is,not
Mask_RCNN/mrcnn/utils.py,825,a list of outputs to a list of outputs and each has,not
Mask_RCNN/mrcnn/utils.py,826,a list of slices,not
Mask_RCNN/mrcnn/utils.py,897,New in 0.14: anti_aliasing. Default it to False for backward,not
Mask_RCNN/mrcnn/utils.py,898,compatibility with skimage 0.13.,not
Mask_RCNN/mrcnn/config.py,13,Base Configuration Class,not
Mask_RCNN/mrcnn/config.py,14,"Don't use this class directly. Instead, sub-class it and override",not
Mask_RCNN/mrcnn/config.py,15,the configurations you need to change.,not
Mask_RCNN/mrcnn/config.py,22,"Name the configurations. For example, 'COCO', 'Experiment 3', ...etc.",not
Mask_RCNN/mrcnn/config.py,23,Useful if your code needs to do things differently depending on which,not
Mask_RCNN/mrcnn/config.py,24,experiment is running.,not
Mask_RCNN/mrcnn/config.py,25,Override in sub-classes,not
Mask_RCNN/mrcnn/config.py,27,"NUMBER OF GPUs to use. When using only a CPU, this needs to be set to 1.",not
Mask_RCNN/mrcnn/config.py,30,Number of images to train with on each GPU. A 12GB GPU can typically,not
Mask_RCNN/mrcnn/config.py,31,handle 2 images of 1024x1024px.,not
Mask_RCNN/mrcnn/config.py,32,Adjust based on your GPU memory and image sizes. Use the highest,not
Mask_RCNN/mrcnn/config.py,33,number that your GPU can handle for best performance.,SATD
Mask_RCNN/mrcnn/config.py,36,Number of training steps per epoch,not
Mask_RCNN/mrcnn/config.py,37,This doesn't need to match the size of the training set. Tensorboard,not
Mask_RCNN/mrcnn/config.py,38,"updates are saved at the end of each epoch, so setting this to a",not
Mask_RCNN/mrcnn/config.py,39,smaller number means getting more frequent TensorBoard updates.,not
Mask_RCNN/mrcnn/config.py,40,Validation stats are also calculated at each epoch end and they,not
Mask_RCNN/mrcnn/config.py,41,"might take a while, so don't set this too small to avoid spending",not
Mask_RCNN/mrcnn/config.py,42,a lot of time on validation stats.,not
Mask_RCNN/mrcnn/config.py,45,Number of validation steps to run at the end of every training epoch.,not
Mask_RCNN/mrcnn/config.py,46,"A bigger number improves accuracy of validation stats, but slows",not
Mask_RCNN/mrcnn/config.py,47,down the training.,not
Mask_RCNN/mrcnn/config.py,50,Backbone network architecture,not
Mask_RCNN/mrcnn/config.py,51,"Supported values are: resnet50, resnet101.",not
Mask_RCNN/mrcnn/config.py,52,You can also provide a callable that should have the signature,not
Mask_RCNN/mrcnn/config.py,53,"of model.resnet_graph. If you do so, you need to supply a callable",not
Mask_RCNN/mrcnn/config.py,54,to COMPUTE_BACKBONE_SHAPE as well,not
Mask_RCNN/mrcnn/config.py,57,Only useful if you supply a callable to BACKBONE. Should compute,not
Mask_RCNN/mrcnn/config.py,58,the shape of each layer of the FPN Pyramid.,not
Mask_RCNN/mrcnn/config.py,59,See model.compute_backbone_shapes,not
Mask_RCNN/mrcnn/config.py,62,The strides of each layer of the FPN Pyramid. These values,not
Mask_RCNN/mrcnn/config.py,63,are based on a Resnet101 backbone.,not
Mask_RCNN/mrcnn/config.py,66,Size of the fully-connected layers in the classification graph,not
Mask_RCNN/mrcnn/config.py,69,Size of the top-down layers used to build the feature pyramid,not
Mask_RCNN/mrcnn/config.py,72,Number of classification classes (including background),not
Mask_RCNN/mrcnn/config.py,73,Override in sub-classes,not
Mask_RCNN/mrcnn/config.py,75,Length of square anchor side in pixels,not
Mask_RCNN/mrcnn/config.py,78,Ratios of anchors at each cell (width/height),not
Mask_RCNN/mrcnn/config.py,79,"A value of 1 represents a square anchor, and 0.5 is a wide anchor",not
Mask_RCNN/mrcnn/config.py,82,Anchor stride,not
Mask_RCNN/mrcnn/config.py,83,If 1 then anchors are created for each cell in the backbone feature map.,not
Mask_RCNN/mrcnn/config.py,84,"If 2, then anchors are created for every other cell, and so on.",not
Mask_RCNN/mrcnn/config.py,87,Non-max suppression threshold to filter RPN proposals.,not
Mask_RCNN/mrcnn/config.py,88,You can increase this during training to generate more propsals.,not
Mask_RCNN/mrcnn/config.py,91,How many anchors per image to use for RPN training,not
Mask_RCNN/mrcnn/config.py,94,ROIs kept after tf.nn.top_k and before non-maximum suppression,not
Mask_RCNN/mrcnn/config.py,97,ROIs kept after non-maximum suppression (training and inference),not
Mask_RCNN/mrcnn/config.py,101,"If enabled, resizes instance masks to a smaller size to reduce",not
Mask_RCNN/mrcnn/config.py,102,memory load. Recommended when using high-resolution images.,not
Mask_RCNN/mrcnn/config.py,104,"(height, width) of the mini-mask",not
Mask_RCNN/mrcnn/config.py,106,Input image resizing,not
Mask_RCNN/mrcnn/config.py,107,"Generally, use the ""square"" resizing mode for training and predicting",not
Mask_RCNN/mrcnn/config.py,108,"and it should work well in most cases. In this mode, images are scaled",SATD
Mask_RCNN/mrcnn/config.py,109,"up such that the small side is = IMAGE_MIN_DIM, but ensuring that the",not
Mask_RCNN/mrcnn/config.py,110,scaling doesn't make the long side > IMAGE_MAX_DIM. Then the image is,not
Mask_RCNN/mrcnn/config.py,111,padded with zeros to make it a square so multiple images can be put,not
Mask_RCNN/mrcnn/config.py,112,in one batch.,not
Mask_RCNN/mrcnn/config.py,113,Available resizing modes:,not
Mask_RCNN/mrcnn/config.py,114,none:   No resizing or padding. Return the image unchanged.,not
Mask_RCNN/mrcnn/config.py,115,square: Resize and pad with zeros to get a square image,not
Mask_RCNN/mrcnn/config.py,116,"of size [max_dim, max_dim].",not
Mask_RCNN/mrcnn/config.py,117,pad64:  Pads width and height with zeros to make them multiples of 64.,not
Mask_RCNN/mrcnn/config.py,118,"If IMAGE_MIN_DIM or IMAGE_MIN_SCALE are not None, then it scales",not
Mask_RCNN/mrcnn/config.py,119,up before padding. IMAGE_MAX_DIM is ignored in this mode.,not
Mask_RCNN/mrcnn/config.py,120,The multiple of 64 is needed to ensure smooth scaling of feature,not
Mask_RCNN/mrcnn/config.py,121,maps up and down the 6 levels of the FPN pyramid (2**6=64).,not
Mask_RCNN/mrcnn/config.py,122,"crop:   Picks random crops from the image. First, scales the image based",not
Mask_RCNN/mrcnn/config.py,123,"on IMAGE_MIN_DIM and IMAGE_MIN_SCALE, then picks a random crop of",not
Mask_RCNN/mrcnn/config.py,124,size IMAGE_MIN_DIM x IMAGE_MIN_DIM. Can be used in training only.,not
Mask_RCNN/mrcnn/config.py,125,IMAGE_MAX_DIM is not used in this mode.,not
Mask_RCNN/mrcnn/config.py,129,Minimum scaling ratio. Checked after MIN_IMAGE_DIM and can force further,not
Mask_RCNN/mrcnn/config.py,130,"up scaling. For example, if set to 2 then images are scaled up to double",not
Mask_RCNN/mrcnn/config.py,131,"the width and height, or more, even if MIN_IMAGE_DIM doesn't require it.",not
Mask_RCNN/mrcnn/config.py,132,"However, in 'square' mode, it can be overruled by IMAGE_MAX_DIM.",not
Mask_RCNN/mrcnn/config.py,134,"Number of color channels per image. RGB = 3, grayscale = 1, RGB-D = 4",not
Mask_RCNN/mrcnn/config.py,135,Changing this requires other changes in the code. See the WIKI for more,not
Mask_RCNN/mrcnn/config.py,136,details: https://github.com/matterport/Mask_RCNN/wiki,not
Mask_RCNN/mrcnn/config.py,139,Image mean (RGB),not
Mask_RCNN/mrcnn/config.py,142,Number of ROIs per image to feed to classifier/mask heads,not
Mask_RCNN/mrcnn/config.py,143,The Mask RCNN paper uses 512 but often the RPN doesn't generate,not
Mask_RCNN/mrcnn/config.py,144,enough positive proposals to fill this and keep a positive:negative,not
Mask_RCNN/mrcnn/config.py,145,ratio of 1:3. You can increase the number of proposals by adjusting,not
Mask_RCNN/mrcnn/config.py,146,the RPN NMS threshold.,not
Mask_RCNN/mrcnn/config.py,149,Percent of positive ROIs used to train classifier/mask heads,not
Mask_RCNN/mrcnn/config.py,152,Pooled ROIs,not
Mask_RCNN/mrcnn/config.py,156,Shape of output mask,not
Mask_RCNN/mrcnn/config.py,157,To change this you also need to change the neural network mask branch,not
Mask_RCNN/mrcnn/config.py,160,Maximum number of ground truth instances to use in one image,not
Mask_RCNN/mrcnn/config.py,163,Bounding box refinement standard deviation for RPN and final detections.,not
Mask_RCNN/mrcnn/config.py,167,Max number of final detections,not
Mask_RCNN/mrcnn/config.py,170,Minimum probability value to accept a detected instance,not
Mask_RCNN/mrcnn/config.py,171,ROIs below this threshold are skipped,not
Mask_RCNN/mrcnn/config.py,174,Non-maximum suppression threshold for detection,not
Mask_RCNN/mrcnn/config.py,177,Learning rate and momentum,not
Mask_RCNN/mrcnn/config.py,178,"The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes",not
Mask_RCNN/mrcnn/config.py,179,weights to explode. Likely due to differences in optimizer,not
Mask_RCNN/mrcnn/config.py,180,implementation.,not
Mask_RCNN/mrcnn/config.py,184,Weight decay regularization,not
Mask_RCNN/mrcnn/config.py,187,Loss weights for more precise optimization.,not
Mask_RCNN/mrcnn/config.py,188,Can be used for R-CNN training setup.,not
Mask_RCNN/mrcnn/config.py,197,Use RPN ROIs or externally generated ROIs for training,not
Mask_RCNN/mrcnn/config.py,198,Keep this True for most situations. Set to False if you want to train,not
Mask_RCNN/mrcnn/config.py,199,the head branches on ROI generated by code rather than the ROIs from,not
Mask_RCNN/mrcnn/config.py,200,"the RPN. For example, to debug the classifier head without having to",not
Mask_RCNN/mrcnn/config.py,201,train the RPN.,not
Mask_RCNN/mrcnn/config.py,204,Train or freeze batch normalization layers,not
Mask_RCNN/mrcnn/config.py,205,None: Train BN layers. This is the normal mode,not
Mask_RCNN/mrcnn/config.py,206,False: Freeze BN layers. Good when using a small batch size,not
Mask_RCNN/mrcnn/config.py,207,True: (don't use). Set layer in training mode even when predicting,not
Mask_RCNN/mrcnn/config.py,208,Defaulting to False since batch size is often small,not
Mask_RCNN/mrcnn/config.py,210,Gradient norm clipping,not
Mask_RCNN/mrcnn/config.py,215,Effective batch size,not
Mask_RCNN/mrcnn/config.py,218,Input image size,not
Mask_RCNN/mrcnn/config.py,226,Image meta data length,not
Mask_RCNN/mrcnn/config.py,227,See compose_image_meta() for details,not
Mask_RCNN/mrcnn/visualize.py,23,Root directory of the project,not
Mask_RCNN/mrcnn/visualize.py,26,Import Mask RCNN,not
Mask_RCNN/mrcnn/visualize.py,27,To find local version of the library,not
Mask_RCNN/mrcnn/visualize.py,31,,not
Mask_RCNN/mrcnn/visualize.py,32,Visualization,not
Mask_RCNN/mrcnn/visualize.py,33,,not
Mask_RCNN/mrcnn/visualize.py,100,Number of instances,not
Mask_RCNN/mrcnn/visualize.py,107,"If no axis is passed, create one and automatically call show()",not
Mask_RCNN/mrcnn/visualize.py,113,Generate random colors,not
Mask_RCNN/mrcnn/visualize.py,116,Show area outside image boundaries.,not
Mask_RCNN/mrcnn/visualize.py,127,Bounding box,not
Mask_RCNN/mrcnn/visualize.py,129,Skip this instance. Has no bbox. Likely lost in image cropping.,not
Mask_RCNN/mrcnn/visualize.py,138,Label,not
Mask_RCNN/mrcnn/visualize.py,149,Mask,not
Mask_RCNN/mrcnn/visualize.py,154,Mask Polygon,not
Mask_RCNN/mrcnn/visualize.py,155,Pad to ensure proper polygons for masks that touch image edges.,not
Mask_RCNN/mrcnn/visualize.py,161,"Subtract the padding and flip (y, x) to (x, y)",not
Mask_RCNN/mrcnn/visualize.py,177,Match predictions to ground truth,not
Mask_RCNN/mrcnn/visualize.py,182,Ground truth = green. Predictions = red,not
Mask_RCNN/mrcnn/visualize.py,185,Concatenate GT and predictions,not
Mask_RCNN/mrcnn/visualize.py,190,Captions per instance show score/IoU,not
Mask_RCNN/mrcnn/visualize.py,196,Set title if not provided,not
Mask_RCNN/mrcnn/visualize.py,198,Display,not
Mask_RCNN/mrcnn/visualize.py,215,Pick random anchors in case there are too many.,not
Mask_RCNN/mrcnn/visualize.py,227,Show area outside image boundaries.,not
Mask_RCNN/mrcnn/visualize.py,235,ROI,not
Mask_RCNN/mrcnn/visualize.py,241,Refined ROI,not
Mask_RCNN/mrcnn/visualize.py,247,Connect the top-left corners of the anchor and proposal for easy visualization,not
Mask_RCNN/mrcnn/visualize.py,250,Label,not
Mask_RCNN/mrcnn/visualize.py,255,Mask,not
Mask_RCNN/mrcnn/visualize.py,262,Print stats,not
Mask_RCNN/mrcnn/visualize.py,269,TODO: Replace with matplotlib equivalent?,SATD
Mask_RCNN/mrcnn/visualize.py,288,Pick top prominent classes in this image,not
Mask_RCNN/mrcnn/visualize.py,294,Generate images and titles,not
Mask_RCNN/mrcnn/visualize.py,297,Pull masks of instances belonging to the same class.,not
Mask_RCNN/mrcnn/visualize.py,312,Plot the Precision-Recall curve,not
Mask_RCNN/mrcnn/visualize.py,375,Number of boxes,not
Mask_RCNN/mrcnn/visualize.py,379,Matplotlib Axis,not
Mask_RCNN/mrcnn/visualize.py,383,Generate random colors,not
Mask_RCNN/mrcnn/visualize.py,386,Show area outside image boundaries.,not
Mask_RCNN/mrcnn/visualize.py,396,Box visibility,not
Mask_RCNN/mrcnn/visualize.py,411,Boxes,not
Mask_RCNN/mrcnn/visualize.py,414,Skip this instance. Has no bbox. Likely lost in cropping.,not
Mask_RCNN/mrcnn/visualize.py,422,Refined boxes,not
Mask_RCNN/mrcnn/visualize.py,428,Connect the top-left corners of the anchor and proposal,not
Mask_RCNN/mrcnn/visualize.py,432,Captions,not
Mask_RCNN/mrcnn/visualize.py,435,"If there are refined boxes, display captions on them",not
Mask_RCNN/mrcnn/visualize.py,443,Masks,not
Mask_RCNN/mrcnn/visualize.py,447,Mask Polygon,not
Mask_RCNN/mrcnn/visualize.py,448,Pad to ensure proper polygons for masks that touch image edges.,not
Mask_RCNN/mrcnn/visualize.py,454,"Subtract the padding and flip (y, x) to (x, y)",not
Mask_RCNN/mrcnn/visualize.py,482,list of Numpy arrays,not
Mask_RCNN/mrcnn/visualize.py,483,list of TF tensors,not
Mask_RCNN/mrcnn/visualize.py,486,Detect problematic layers. Exclude biases of conv layers.,not
Mask_RCNN/mrcnn/visualize.py,492,Add row,not
Mask_RCNN/mrcnn/parallel_model.py,58,Slice inputs. Slice inputs on the CPU to avoid sending a copy,not
Mask_RCNN/mrcnn/parallel_model.py,59,of the full inputs to all GPUs. Saves on bandwidth and memory.,not
Mask_RCNN/mrcnn/parallel_model.py,69,Run the model call() on each GPU to place the ops there,not
Mask_RCNN/mrcnn/parallel_model.py,73,Run a slice of inputs through this replica,not
Mask_RCNN/mrcnn/parallel_model.py,80,Create the model replica and get the outputs,not
Mask_RCNN/mrcnn/parallel_model.py,84,Save the outputs for merging back together later,not
Mask_RCNN/mrcnn/parallel_model.py,88,Merge outputs on CPU,not
Mask_RCNN/mrcnn/parallel_model.py,92,Concatenate or average outputs?,not
Mask_RCNN/mrcnn/parallel_model.py,93,Outputs usually have a batch dimension and we concatenate,not
Mask_RCNN/mrcnn/parallel_model.py,94,"across it. If they don't, then the output is likely a loss",not
Mask_RCNN/mrcnn/parallel_model.py,95,or a metric value that gets averaged across the batch.,not
Mask_RCNN/mrcnn/parallel_model.py,96,Keras expects losses and metrics to be scalars.,not
Mask_RCNN/mrcnn/parallel_model.py,98,Average,not
Mask_RCNN/mrcnn/parallel_model.py,101,Concatenate,not
Mask_RCNN/mrcnn/parallel_model.py,108,Testing code below. It creates a simple model to train on MNIST and,not
Mask_RCNN/mrcnn/parallel_model.py,109,tries to run it on 2 GPUs. It saves the graph so it can be viewed,not
Mask_RCNN/mrcnn/parallel_model.py,110,in TensorBoard. Run it as:,not
Mask_RCNN/mrcnn/parallel_model.py,111,,not
Mask_RCNN/mrcnn/parallel_model.py,112,python3 parallel_model.py,not
Mask_RCNN/mrcnn/parallel_model.py,122,Root directory of the project,not
Mask_RCNN/mrcnn/parallel_model.py,125,Directory to save logs and trained model,not
Mask_RCNN/mrcnn/parallel_model.py,129,"Reset default graph. Keras leaves old ops in the graph,",not
Mask_RCNN/mrcnn/parallel_model.py,130,which are ignored for execution but clutter graph,not
Mask_RCNN/mrcnn/parallel_model.py,131,visualization in TensorBoard.,not
Mask_RCNN/mrcnn/parallel_model.py,146,Load MNIST Data,not
Mask_RCNN/mrcnn/parallel_model.py,154,Build data generator and model,not
Mask_RCNN/mrcnn/parallel_model.py,158,Add multi-GPU support.,not
Mask_RCNN/mrcnn/parallel_model.py,168,Train,not
Mask_RCNN/samples/coco/coco.py,34,https://github.com/aleju/imgaug (pip3 install imgaug),not
Mask_RCNN/samples/coco/coco.py,36,Download and install the Python COCO tools from https://github.com/waleedka/coco,not
Mask_RCNN/samples/coco/coco.py,37,That's a fork from the original https://github.com/pdollar/coco with a bug,not
Mask_RCNN/samples/coco/coco.py,38,fix for Python 3.,not
Mask_RCNN/samples/coco/coco.py,39,I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50,not
Mask_RCNN/samples/coco/coco.py,40,If the PR is merged then use the original repo.,not
Mask_RCNN/samples/coco/coco.py,41,"Note: Edit PythonAPI/Makefile and replace ""python"" with ""python3"".",not
Mask_RCNN/samples/coco/coco.py,50,Root directory of the project,not
Mask_RCNN/samples/coco/coco.py,53,Import Mask RCNN,not
Mask_RCNN/samples/coco/coco.py,54,To find local version of the library,not
Mask_RCNN/samples/coco/coco.py,58,Path to trained weights file,not
Mask_RCNN/samples/coco/coco.py,61,"Directory to save logs and model checkpoints, if not provided",not
Mask_RCNN/samples/coco/coco.py,62,through the command line argument --logs,not
Mask_RCNN/samples/coco/coco.py,66,,not
Mask_RCNN/samples/coco/coco.py,67,Configurations,not
Mask_RCNN/samples/coco/coco.py,68,,not
Mask_RCNN/samples/coco/coco.py,76,Give the configuration a recognizable name,not
Mask_RCNN/samples/coco/coco.py,79,"We use a GPU with 12GB memory, which can fit two images.",not
Mask_RCNN/samples/coco/coco.py,80,Adjust down if you use a smaller GPU.,not
Mask_RCNN/samples/coco/coco.py,83,Uncomment to train on 8 GPUs (default is 1),not
Mask_RCNN/samples/coco/coco.py,84,GPU_COUNT = 8,not
Mask_RCNN/samples/coco/coco.py,86,Number of classes (including background),not
Mask_RCNN/samples/coco/coco.py,87,COCO has 80 classes,not
Mask_RCNN/samples/coco/coco.py,90,,not
Mask_RCNN/samples/coco/coco.py,91,Dataset,not
Mask_RCNN/samples/coco/coco.py,92,,not
Mask_RCNN/samples/coco/coco.py,116,Load all classes or a subset?,not
Mask_RCNN/samples/coco/coco.py,118,All classes,not
Mask_RCNN/samples/coco/coco.py,121,All images or a subset?,not
Mask_RCNN/samples/coco/coco.py,126,Remove duplicates,not
Mask_RCNN/samples/coco/coco.py,129,All images,not
Mask_RCNN/samples/coco/coco.py,132,Add classes,not
Mask_RCNN/samples/coco/coco.py,136,Add images,not
Mask_RCNN/samples/coco/coco.py,158,Setup paths and file names,not
Mask_RCNN/samples/coco/coco.py,167,"print(""Image paths:""); print(imgDir); print(imgZipFile); print(imgURL)",not
Mask_RCNN/samples/coco/coco.py,169,Create main folder if it doesn't exist yet,not
Mask_RCNN/samples/coco/coco.py,173,Download images if not available locally,not
Mask_RCNN/samples/coco/coco.py,186,Setup annotations data paths,not
Mask_RCNN/samples/coco/coco.py,203,"print(""Annotations paths:""); print(annDir); print(annFile); print(annZipFile); print(annURL)",not
Mask_RCNN/samples/coco/coco.py,205,Download annotations if not available locally,not
Mask_RCNN/samples/coco/coco.py,232,"If not a COCO image, delegate to parent class.",not
Mask_RCNN/samples/coco/coco.py,240,"Build mask of shape [height, width, instance_count] and list",not
Mask_RCNN/samples/coco/coco.py,241,of class IDs that correspond to each channel of the mask.,not
Mask_RCNN/samples/coco/coco.py,248,Some objects are so small that they're less than 1 pixel area,not
Mask_RCNN/samples/coco/coco.py,249,and end up rounded out. Skip those objects.,not
Mask_RCNN/samples/coco/coco.py,252,"Is it a crowd? If so, use a negative class ID.",not
Mask_RCNN/samples/coco/coco.py,254,Use negative class ID for crowds,not
Mask_RCNN/samples/coco/coco.py,256,"For crowd masks, annToMask() sometimes returns a mask",not
Mask_RCNN/samples/coco/coco.py,257,"smaller than the given dimensions. If so, resize it.",not
Mask_RCNN/samples/coco/coco.py,263,Pack instance masks into an array,not
Mask_RCNN/samples/coco/coco.py,269,Call super class to return an empty mask,not
Mask_RCNN/samples/coco/coco.py,280,The following two functions are from pycocotools with a few changes.,not
Mask_RCNN/samples/coco/coco.py,289,polygon -- a single object might consist of multiple parts,not
Mask_RCNN/samples/coco/coco.py,290,we merge all parts into one mask rle code,not
Mask_RCNN/samples/coco/coco.py,294,uncompressed RLE,not
Mask_RCNN/samples/coco/coco.py,297,rle,not
Mask_RCNN/samples/coco/coco.py,311,,not
Mask_RCNN/samples/coco/coco.py,312,COCO Evaluation,not
Mask_RCNN/samples/coco/coco.py,313,,not
Mask_RCNN/samples/coco/coco.py,318,"If no results, return an empty list",not
Mask_RCNN/samples/coco/coco.py,324,Loop through detections,not
Mask_RCNN/samples/coco/coco.py,348,Pick COCO images from the dataset,not
Mask_RCNN/samples/coco/coco.py,351,Limit to a subset,not
Mask_RCNN/samples/coco/coco.py,355,Get corresponding COCO image IDs.,not
Mask_RCNN/samples/coco/coco.py,363,Load image,not
Mask_RCNN/samples/coco/coco.py,366,Run detection,not
Mask_RCNN/samples/coco/coco.py,371,Convert results to COCO format,not
Mask_RCNN/samples/coco/coco.py,372,Cast masks to uint8 because COCO tools errors out on bool,not
Mask_RCNN/samples/coco/coco.py,379,Load results. This modifies results with additional attributes.,not
Mask_RCNN/samples/coco/coco.py,382,Evaluate,not
Mask_RCNN/samples/coco/coco.py,394,,not
Mask_RCNN/samples/coco/coco.py,395,Training,not
Mask_RCNN/samples/coco/coco.py,396,,not
Mask_RCNN/samples/coco/coco.py,402,Parse command line arguments,not
Mask_RCNN/samples/coco/coco.py,439,Configurations,not
Mask_RCNN/samples/coco/coco.py,444,Set batch size to 1 since we'll be running inference on,not
Mask_RCNN/samples/coco/coco.py,445,one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU,not
Mask_RCNN/samples/coco/coco.py,452,Create model,not
Mask_RCNN/samples/coco/coco.py,460,Select weights file to load,not
Mask_RCNN/samples/coco/coco.py,464,Find last trained weights,not
Mask_RCNN/samples/coco/coco.py,467,Start from ImageNet trained weights,not
Mask_RCNN/samples/coco/coco.py,472,Load weights,not
Mask_RCNN/samples/coco/coco.py,476,Train or evaluate,not
Mask_RCNN/samples/coco/coco.py,478,Training dataset. Use the training set and 35K from the,not
Mask_RCNN/samples/coco/coco.py,479,"validation set, as as in the Mask RCNN paper.",not
Mask_RCNN/samples/coco/coco.py,486,Validation dataset,not
Mask_RCNN/samples/coco/coco.py,492,Image Augmentation,not
Mask_RCNN/samples/coco/coco.py,493,Right/Left flip 50% of the time,not
Mask_RCNN/samples/coco/coco.py,496,*** This training schedule is an example. Update to your needs ***,not
Mask_RCNN/samples/coco/coco.py,498,Training - Stage 1,not
Mask_RCNN/samples/coco/coco.py,506,Training - Stage 2,not
Mask_RCNN/samples/coco/coco.py,507,Finetune layers from ResNet stage 4 and up,not
Mask_RCNN/samples/coco/coco.py,515,Training - Stage 3,not
Mask_RCNN/samples/coco/coco.py,516,Fine tune all layers,not
Mask_RCNN/samples/coco/coco.py,525,Validation dataset,not
Mask_RCNN/samples/nucleus/nucleus.py,28,Set matplotlib backend,not
Mask_RCNN/samples/nucleus/nucleus.py,29,This has to be done before other importa that might,not
Mask_RCNN/samples/nucleus/nucleus.py,30,"set it, but only if we're running in script mode",not
Mask_RCNN/samples/nucleus/nucleus.py,31,rather than being imported.,not
Mask_RCNN/samples/nucleus/nucleus.py,34,Agg backend runs without a display,not
Mask_RCNN/samples/nucleus/nucleus.py,46,Root directory of the project,not
Mask_RCNN/samples/nucleus/nucleus.py,49,Import Mask RCNN,not
Mask_RCNN/samples/nucleus/nucleus.py,50,To find local version of the library,not
Mask_RCNN/samples/nucleus/nucleus.py,56,Path to trained weights file,not
Mask_RCNN/samples/nucleus/nucleus.py,59,"Directory to save logs and model checkpoints, if not provided",not
Mask_RCNN/samples/nucleus/nucleus.py,60,through the command line argument --logs,not
Mask_RCNN/samples/nucleus/nucleus.py,63,Results directory,not
Mask_RCNN/samples/nucleus/nucleus.py,64,Save submission files here,not
Mask_RCNN/samples/nucleus/nucleus.py,67,"The dataset doesn't have a standard train/val split, so I picked",not
Mask_RCNN/samples/nucleus/nucleus.py,68,a variety of images to surve as a validation set.,not
Mask_RCNN/samples/nucleus/nucleus.py,98,,not
Mask_RCNN/samples/nucleus/nucleus.py,99,Configurations,not
Mask_RCNN/samples/nucleus/nucleus.py,100,,not
Mask_RCNN/samples/nucleus/nucleus.py,104,Give the configuration a recognizable name,not
Mask_RCNN/samples/nucleus/nucleus.py,107,Adjust depending on your GPU memory,not
Mask_RCNN/samples/nucleus/nucleus.py,110,Number of classes (including background),not
Mask_RCNN/samples/nucleus/nucleus.py,111,Background + nucleus,not
Mask_RCNN/samples/nucleus/nucleus.py,113,Number of training and validation steps per epoch,not
Mask_RCNN/samples/nucleus/nucleus.py,117,Don't exclude based on confidence. Since we have two classes,not
Mask_RCNN/samples/nucleus/nucleus.py,118,then 0.5 is the minimum anyway as it picks between nucleus and BG,not
Mask_RCNN/samples/nucleus/nucleus.py,121,Backbone network architecture,not
Mask_RCNN/samples/nucleus/nucleus.py,122,"Supported values are: resnet50, resnet101",not
Mask_RCNN/samples/nucleus/nucleus.py,125,Input image resizing,not
Mask_RCNN/samples/nucleus/nucleus.py,126,Random crops of size 512x512,not
Mask_RCNN/samples/nucleus/nucleus.py,132,Length of square anchor side in pixels,not
Mask_RCNN/samples/nucleus/nucleus.py,135,ROIs kept after non-maximum supression (training and inference),not
Mask_RCNN/samples/nucleus/nucleus.py,139,Non-max suppression threshold to filter RPN proposals.,not
Mask_RCNN/samples/nucleus/nucleus.py,140,You can increase this during training to generate more propsals.,not
Mask_RCNN/samples/nucleus/nucleus.py,143,How many anchors per image to use for RPN training,not
Mask_RCNN/samples/nucleus/nucleus.py,146,Image mean (RGB),not
Mask_RCNN/samples/nucleus/nucleus.py,149,"If enabled, resizes instance masks to a smaller size to reduce",not
Mask_RCNN/samples/nucleus/nucleus.py,150,memory load. Recommended when using high-resolution images.,not
Mask_RCNN/samples/nucleus/nucleus.py,152,"(height, width) of the mini-mask",not
Mask_RCNN/samples/nucleus/nucleus.py,154,Number of ROIs per image to feed to classifier/mask heads,not
Mask_RCNN/samples/nucleus/nucleus.py,155,The Mask RCNN paper uses 512 but often the RPN doesn't generate,not
Mask_RCNN/samples/nucleus/nucleus.py,156,enough positive proposals to fill this and keep a positive:negative,not
Mask_RCNN/samples/nucleus/nucleus.py,157,ratio of 1:3. You can increase the number of proposals by adjusting,not
Mask_RCNN/samples/nucleus/nucleus.py,158,the RPN NMS threshold.,not
Mask_RCNN/samples/nucleus/nucleus.py,161,Maximum number of ground truth instances to use in one image,not
Mask_RCNN/samples/nucleus/nucleus.py,164,Max number of final detections per image,not
Mask_RCNN/samples/nucleus/nucleus.py,169,Set batch size to 1 to run one image at a time,not
Mask_RCNN/samples/nucleus/nucleus.py,172,Don't resize imager for inferencing,not
Mask_RCNN/samples/nucleus/nucleus.py,174,Non-max suppression threshold to filter RPN proposals.,not
Mask_RCNN/samples/nucleus/nucleus.py,175,You can increase this during training to generate more propsals.,not
Mask_RCNN/samples/nucleus/nucleus.py,179,,not
Mask_RCNN/samples/nucleus/nucleus.py,180,Dataset,not
Mask_RCNN/samples/nucleus/nucleus.py,181,,not
Mask_RCNN/samples/nucleus/nucleus.py,194,Add classes. We have one class.,not
Mask_RCNN/samples/nucleus/nucleus.py,195,"Naming the dataset nucleus, and the class nucleus",not
Mask_RCNN/samples/nucleus/nucleus.py,198,Which subset?,not
Mask_RCNN/samples/nucleus/nucleus.py,199,"""val"": use hard-coded list above",not
Mask_RCNN/samples/nucleus/nucleus.py,200,"""train"": use data from stage1_train minus the hard-coded list above",not
Mask_RCNN/samples/nucleus/nucleus.py,201,else: use the data from the specified sub-directory,not
Mask_RCNN/samples/nucleus/nucleus.py,208,Get image ids from directory names,not
Mask_RCNN/samples/nucleus/nucleus.py,213,Add images,not
Mask_RCNN/samples/nucleus/nucleus.py,228,Get mask directory from image path,not
Mask_RCNN/samples/nucleus/nucleus.py,231,Read mask files from .png image,not
Mask_RCNN/samples/nucleus/nucleus.py,238,"Return mask, and array of class IDs of each instance. Since we have",not
Mask_RCNN/samples/nucleus/nucleus.py,239,"one class ID, we return an array of ones",not
Mask_RCNN/samples/nucleus/nucleus.py,251,,not
Mask_RCNN/samples/nucleus/nucleus.py,252,Training,not
Mask_RCNN/samples/nucleus/nucleus.py,253,,not
Mask_RCNN/samples/nucleus/nucleus.py,257,Training dataset.,not
Mask_RCNN/samples/nucleus/nucleus.py,262,Validation dataset,not
Mask_RCNN/samples/nucleus/nucleus.py,267,Image augmentation,not
Mask_RCNN/samples/nucleus/nucleus.py,268,http://imgaug.readthedocs.io/en/latest/source/augmenters.html,not
Mask_RCNN/samples/nucleus/nucleus.py,279,*** This training schedule is an example. Update to your needs ***,not
Mask_RCNN/samples/nucleus/nucleus.py,281,"If starting from imagenet, train heads only for a bit",not
Mask_RCNN/samples/nucleus/nucleus.py,282,since they have random weights,not
Mask_RCNN/samples/nucleus/nucleus.py,298,,not
Mask_RCNN/samples/nucleus/nucleus.py,299,RLE Encoding,not
Mask_RCNN/samples/nucleus/nucleus.py,300,,not
Mask_RCNN/samples/nucleus/nucleus.py,307,Flatten it column wise,not
Mask_RCNN/samples/nucleus/nucleus.py,309,Compute gradient. Equals 1 or -1 at transition points,not
Mask_RCNN/samples/nucleus/nucleus.py,311,1-based indicies of transition points (where gradient != 0),not
Mask_RCNN/samples/nucleus/nucleus.py,313,Convert second index in each pair to lenth,not
Mask_RCNN/samples/nucleus/nucleus.py,330,Reshape and transpose,not
Mask_RCNN/samples/nucleus/nucleus.py,338,"If mask is empty, return line with image ID only",not
Mask_RCNN/samples/nucleus/nucleus.py,341,Remove mask overlaps,not
Mask_RCNN/samples/nucleus/nucleus.py,342,Multiply each instance mask by its score order,not
Mask_RCNN/samples/nucleus/nucleus.py,343,then take the maximum across the last dimension,not
Mask_RCNN/samples/nucleus/nucleus.py,344,1-based descending,not
Mask_RCNN/samples/nucleus/nucleus.py,346,Loop over instance masks,not
Mask_RCNN/samples/nucleus/nucleus.py,350,Skip if empty,not
Mask_RCNN/samples/nucleus/nucleus.py,358,,not
Mask_RCNN/samples/nucleus/nucleus.py,359,Detection,not
Mask_RCNN/samples/nucleus/nucleus.py,360,,not
Mask_RCNN/samples/nucleus/nucleus.py,366,Create directory,not
Mask_RCNN/samples/nucleus/nucleus.py,373,Read dataset,not
Mask_RCNN/samples/nucleus/nucleus.py,377,Load over images,not
Mask_RCNN/samples/nucleus/nucleus.py,380,Load image and run detection,not
Mask_RCNN/samples/nucleus/nucleus.py,382,Detect objects,not
Mask_RCNN/samples/nucleus/nucleus.py,384,Encode image to RLE. Returns a string of multiple lines,not
Mask_RCNN/samples/nucleus/nucleus.py,388,Save image with masks,not
Mask_RCNN/samples/nucleus/nucleus.py,396,Save to csv file,not
Mask_RCNN/samples/nucleus/nucleus.py,404,,not
Mask_RCNN/samples/nucleus/nucleus.py,405,Command Line,not
Mask_RCNN/samples/nucleus/nucleus.py,406,,not
Mask_RCNN/samples/nucleus/nucleus.py,411,Parse command line arguments,not
Mask_RCNN/samples/nucleus/nucleus.py,432,Validate arguments,not
Mask_RCNN/samples/nucleus/nucleus.py,444,Configurations,not
Mask_RCNN/samples/nucleus/nucleus.py,451,Create model,not
Mask_RCNN/samples/nucleus/nucleus.py,459,Select weights file to load,not
Mask_RCNN/samples/nucleus/nucleus.py,462,Download weights file,not
Mask_RCNN/samples/nucleus/nucleus.py,466,Find last trained weights,not
Mask_RCNN/samples/nucleus/nucleus.py,469,Start from ImageNet trained weights,not
Mask_RCNN/samples/nucleus/nucleus.py,474,Load weights,not
Mask_RCNN/samples/nucleus/nucleus.py,477,Exclude the last layers because they require a matching,not
Mask_RCNN/samples/nucleus/nucleus.py,478,number of classes,not
Mask_RCNN/samples/nucleus/nucleus.py,485,Train or evaluate,not
Mask_RCNN/samples/shapes/shapes.py,19,Root directory of the project,not
Mask_RCNN/samples/shapes/shapes.py,22,Import Mask RCNN,not
Mask_RCNN/samples/shapes/shapes.py,23,To find local version of the library,not
Mask_RCNN/samples/shapes/shapes.py,33,Give the configuration a recognizable name,not
Mask_RCNN/samples/shapes/shapes.py,36,Train on 1 GPU and 8 images per GPU. We can put multiple images on each,not
Mask_RCNN/samples/shapes/shapes.py,37,GPU because the images are small. Batch size is 8 (GPUs * images/GPU).,not
Mask_RCNN/samples/shapes/shapes.py,41,Number of classes (including background),not
Mask_RCNN/samples/shapes/shapes.py,42,background + 3 shapes,not
Mask_RCNN/samples/shapes/shapes.py,44,Use small images for faster training. Set the limits of the small side,not
Mask_RCNN/samples/shapes/shapes.py,45,"the large side, and that determines the image shape.",not
Mask_RCNN/samples/shapes/shapes.py,49,Use smaller anchors because our image and objects are small,not
Mask_RCNN/samples/shapes/shapes.py,50,anchor side in pixels,not
Mask_RCNN/samples/shapes/shapes.py,52,Reduce training ROIs per image because the images are small and have,not
Mask_RCNN/samples/shapes/shapes.py,53,few objects. Aim to allow ROI sampling to pick 33% positive ROIs.,not
Mask_RCNN/samples/shapes/shapes.py,56,Use a small epoch since the data is simple,not
Mask_RCNN/samples/shapes/shapes.py,59,use small validation steps since the epoch is small,not
Mask_RCNN/samples/shapes/shapes.py,74,Add classes,not
Mask_RCNN/samples/shapes/shapes.py,79,Add images,not
Mask_RCNN/samples/shapes/shapes.py,80,Generate random specifications of images (i.e. color and,not
Mask_RCNN/samples/shapes/shapes.py,81,list of shapes sizes and locations). This is more compact than,not
Mask_RCNN/samples/shapes/shapes.py,82,actual images. Images are generated on the fly in load_image().,not
Mask_RCNN/samples/shapes/shapes.py,121,Handle occlusions,not
Mask_RCNN/samples/shapes/shapes.py,127,Map class names to class IDs.,not
Mask_RCNN/samples/shapes/shapes.py,133,"Get the center x, y and the size s",not
Mask_RCNN/samples/shapes/shapes.py,157,Shape,not
Mask_RCNN/samples/shapes/shapes.py,159,Color,not
Mask_RCNN/samples/shapes/shapes.py,161,"Center x, y",not
Mask_RCNN/samples/shapes/shapes.py,165,Size,not
Mask_RCNN/samples/shapes/shapes.py,174,Pick random background color,not
Mask_RCNN/samples/shapes/shapes.py,176,Generate a few random shapes and record their,not
Mask_RCNN/samples/shapes/shapes.py,177,bounding boxes,not
Mask_RCNN/samples/shapes/shapes.py,186,Apply non-max suppression wit 0.3 threshold to avoid,not
Mask_RCNN/samples/shapes/shapes.py,187,shapes covering each other,not
Mask_RCNN/samples/balloon/balloon.py,37,Root directory of the project,not
Mask_RCNN/samples/balloon/balloon.py,40,Import Mask RCNN,not
Mask_RCNN/samples/balloon/balloon.py,41,To find local version of the library,not
Mask_RCNN/samples/balloon/balloon.py,45,Path to trained weights file,not
Mask_RCNN/samples/balloon/balloon.py,48,"Directory to save logs and model checkpoints, if not provided",not
Mask_RCNN/samples/balloon/balloon.py,49,through the command line argument --logs,not
Mask_RCNN/samples/balloon/balloon.py,52,,not
Mask_RCNN/samples/balloon/balloon.py,53,Configurations,not
Mask_RCNN/samples/balloon/balloon.py,54,,not
Mask_RCNN/samples/balloon/balloon.py,61,Give the configuration a recognizable name,not
Mask_RCNN/samples/balloon/balloon.py,64,"We use a GPU with 12GB memory, which can fit two images.",not
Mask_RCNN/samples/balloon/balloon.py,65,Adjust down if you use a smaller GPU.,not
Mask_RCNN/samples/balloon/balloon.py,68,Number of classes (including background),not
Mask_RCNN/samples/balloon/balloon.py,69,Background + balloon,not
Mask_RCNN/samples/balloon/balloon.py,71,Number of training steps per epoch,not
Mask_RCNN/samples/balloon/balloon.py,74,Skip detections with < 90% confidence,not
Mask_RCNN/samples/balloon/balloon.py,78,,not
Mask_RCNN/samples/balloon/balloon.py,79,Dataset,not
Mask_RCNN/samples/balloon/balloon.py,80,,not
Mask_RCNN/samples/balloon/balloon.py,89,Add classes. We have only one class to add.,not
Mask_RCNN/samples/balloon/balloon.py,92,Train or validation dataset?,not
Mask_RCNN/samples/balloon/balloon.py,96,Load annotations,not
Mask_RCNN/samples/balloon/balloon.py,97,VGG Image Annotator (up to version 1.6) saves each image in the form:,not
Mask_RCNN/samples/balloon/balloon.py,98,"{ 'filename': '28503151_5b5b7ec140_b.jpg',",not
Mask_RCNN/samples/balloon/balloon.py,99,'regions': {,not
Mask_RCNN/samples/balloon/balloon.py,100,'0': {,not
Mask_RCNN/samples/balloon/balloon.py,101,"'region_attributes': {},",not
Mask_RCNN/samples/balloon/balloon.py,102,'shape_attributes': {,not
Mask_RCNN/samples/balloon/balloon.py,103,"'all_points_x': [...],",not
Mask_RCNN/samples/balloon/balloon.py,104,"'all_points_y': [...],",not
Mask_RCNN/samples/balloon/balloon.py,105,"'name': 'polygon'}},",not
Mask_RCNN/samples/balloon/balloon.py,106,... more regions ...,not
Mask_RCNN/samples/balloon/balloon.py,107,"},",not
Mask_RCNN/samples/balloon/balloon.py,108,'size': 100202,not
Mask_RCNN/samples/balloon/balloon.py,109,},not
Mask_RCNN/samples/balloon/balloon.py,110,We mostly care about the x and y coordinates of each region,not
Mask_RCNN/samples/balloon/balloon.py,111,"Note: In VIA 2.0, regions was changed from a dict to a list.",not
Mask_RCNN/samples/balloon/balloon.py,113,don't need the dict keys,not
Mask_RCNN/samples/balloon/balloon.py,115,The VIA tool saves images in the JSON even if they don't have any,not
Mask_RCNN/samples/balloon/balloon.py,116,annotations. Skip unannotated images.,not
Mask_RCNN/samples/balloon/balloon.py,119,Add images,not
Mask_RCNN/samples/balloon/balloon.py,121,"Get the x, y coordinaets of points of the polygons that make up",not
Mask_RCNN/samples/balloon/balloon.py,122,the outline of each object instance. These are stores in the,not
Mask_RCNN/samples/balloon/balloon.py,123,shape_attributes (see json format above),not
Mask_RCNN/samples/balloon/balloon.py,124,The if condition is needed to support VIA versions 1.x and 2.x.,not
Mask_RCNN/samples/balloon/balloon.py,130,load_mask() needs the image size to convert polygons to masks.,not
Mask_RCNN/samples/balloon/balloon.py,131,"Unfortunately, VIA doesn't include it in JSON, so we must read",not
Mask_RCNN/samples/balloon/balloon.py,132,the image. This is only managable since the dataset is tiny.,not
Mask_RCNN/samples/balloon/balloon.py,139,use file name as a unique image id,not
Mask_RCNN/samples/balloon/balloon.py,151,"If not a balloon dataset image, delegate to parent class.",not
Mask_RCNN/samples/balloon/balloon.py,156,Convert polygons to a bitmap mask of shape,not
Mask_RCNN/samples/balloon/balloon.py,157,"[height, width, instance_count]",not
Mask_RCNN/samples/balloon/balloon.py,162,Get indexes of pixels inside the polygon and set them to 1,not
Mask_RCNN/samples/balloon/balloon.py,166,"Return mask, and array of class IDs of each instance. Since we have",not
Mask_RCNN/samples/balloon/balloon.py,167,"one class ID only, we return an array of 1s",not
Mask_RCNN/samples/balloon/balloon.py,181,Training dataset.,not
Mask_RCNN/samples/balloon/balloon.py,186,Validation dataset,not
Mask_RCNN/samples/balloon/balloon.py,191,*** This training schedule is an example. Update to your needs ***,not
Mask_RCNN/samples/balloon/balloon.py,192,"Since we're using a very small dataset, and starting from",not
Mask_RCNN/samples/balloon/balloon.py,193,"COCO trained weights, we don't need to train too long. Also,",not
Mask_RCNN/samples/balloon/balloon.py,194,"no need to train all layers, just the heads should do it.",not
Mask_RCNN/samples/balloon/balloon.py,209,Make a grayscale copy of the image. The grayscale copy still,not
Mask_RCNN/samples/balloon/balloon.py,210,"has 3 RGB channels, though.",not
Mask_RCNN/samples/balloon/balloon.py,212,Copy color pixels from the original color image where mask is set,not
Mask_RCNN/samples/balloon/balloon.py,214,"We're treating all instances as one, so collapse the mask into one layer",not
Mask_RCNN/samples/balloon/balloon.py,225,Image or video?,not
Mask_RCNN/samples/balloon/balloon.py,227,Run model detection and generate the color splash effect,not
Mask_RCNN/samples/balloon/balloon.py,229,Read image,not
Mask_RCNN/samples/balloon/balloon.py,231,Detect objects,not
Mask_RCNN/samples/balloon/balloon.py,233,Color splash,not
Mask_RCNN/samples/balloon/balloon.py,235,Save output,not
Mask_RCNN/samples/balloon/balloon.py,240,Video capture,not
Mask_RCNN/samples/balloon/balloon.py,246,Define codec and create video writer,not
Mask_RCNN/samples/balloon/balloon.py,256,Read next image,not
Mask_RCNN/samples/balloon/balloon.py,259,"OpenCV returns images as BGR, convert to RGB",not
Mask_RCNN/samples/balloon/balloon.py,261,Detect objects,not
Mask_RCNN/samples/balloon/balloon.py,263,Color splash,not
Mask_RCNN/samples/balloon/balloon.py,265,RGB -> BGR to save image to video,not
Mask_RCNN/samples/balloon/balloon.py,267,Add image to video writer,not
Mask_RCNN/samples/balloon/balloon.py,274,,not
Mask_RCNN/samples/balloon/balloon.py,275,Training,not
Mask_RCNN/samples/balloon/balloon.py,276,,not
Mask_RCNN/samples/balloon/balloon.py,281,Parse command line arguments,not
Mask_RCNN/samples/balloon/balloon.py,305,Validate arguments,not
Mask_RCNN/samples/balloon/balloon.py,316,Configurations,not
Mask_RCNN/samples/balloon/balloon.py,321,Set batch size to 1 since we'll be running inference on,not
Mask_RCNN/samples/balloon/balloon.py,322,one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU,not
Mask_RCNN/samples/balloon/balloon.py,328,Create model,not
Mask_RCNN/samples/balloon/balloon.py,336,Select weights file to load,not
Mask_RCNN/samples/balloon/balloon.py,339,Download weights file,not
Mask_RCNN/samples/balloon/balloon.py,343,Find last trained weights,not
Mask_RCNN/samples/balloon/balloon.py,346,Start from ImageNet trained weights,not
Mask_RCNN/samples/balloon/balloon.py,351,Load weights,not
Mask_RCNN/samples/balloon/balloon.py,354,Exclude the last layers because they require a matching,not
Mask_RCNN/samples/balloon/balloon.py,355,number of classes,not
Mask_RCNN/samples/balloon/balloon.py,362,Train or evaluate,not
